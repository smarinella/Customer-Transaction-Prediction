{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c816da90",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d27b23",
   "metadata": {},
   "source": [
    "<br>\n",
    "<center><font size='10' style=\"color:orange\"><b> Customer Transaction Prediction </b> </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be2374f",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df34e5e5",
   "metadata": {},
   "source": [
    "<br>\n",
    "<center><font size='5' style=\"color:black\"><b> Proyecto Final - Coder House </b> </font>\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<center><font size='5' style=\"color:black\"><b> Notebook Denise Navarro Quantín </b> </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8368aacc",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887efd37",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015ecf30",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5975ac",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fedf2ee",
   "metadata": {},
   "source": [
    "<font size='6' style=\"color:orange\"><b> Content </b> </font>\n",
    "<a name=\"content\"></a>\n",
    "<br>\n",
    "\n",
    "\n",
    "1. [Introduction](#introduction) \n",
    "<br>\n",
    "\n",
    "2. [Import Libraries](#libraries) \n",
    "<br>\n",
    "\n",
    "3. [Dataset](#Dataset) \n",
    "<br>\n",
    "\n",
    "4. [Models - Default Parameters](#default)\n",
    "\n",
    "    4.1 [Logistic Regression](#lgr_default)\n",
    "    \n",
    "    4.2 [GaussianNB](#gbn_default)\n",
    "    \n",
    "    4.3 [Random Forest Classifier](#rfc_default)\n",
    "    \n",
    "    4.4 [K Neighbors Classifier](#knc_default)\n",
    "\n",
    "    4.5 [XGBoost Classifier](#xgb_default)\n",
    "\n",
    "    4.6 [Catboost Classifier](#cb_default)\n",
    "\n",
    "    4.7 [MLP Classifier](#mlp_default)\n",
    "\n",
    "    4.8 [Linear Discriminant Analysis](#lda_default)\n",
    "\n",
    "    4.9 [Calibrated Classifier with GaussianNB](#cccv_default)\n",
    "\n",
    "    4.10 [SGD Classifier](#sgdc_default)\n",
    "    \n",
    "    4.11 [Bagging Classifier](#bgc_default)\n",
    "    \n",
    "    4.12 [Models with default parameters - Summary](#summary_default)\n",
    "\n",
    "<br>\n",
    "\n",
    "5. [Models - PCA](#PCA)\n",
    "\n",
    "    5.1 [Logistic Regression - PCA](#lgr_pca)\n",
    "    \n",
    "    5.2 [K Neighbors Classifier - PCA](#knc_pca)\n",
    "\n",
    "<br>\n",
    "\n",
    "6. [Optuna](#optuna)\n",
    "\n",
    "    6.1 [Logistic Regression - Optuna](#lgr_opt)\n",
    "    \n",
    "    6.1.1 [Logistic Regression - PCA 100](#lgr_opt_100)\n",
    "    \n",
    "    6.1.2 [Logistic Regression - PCA 175](#lgr_opt_175)\n",
    "    \n",
    "    6.1.3 [Logistic Regression - Full Dataset](#lgr_opt_full)\n",
    "    \n",
    "    6.2 [K Neighbors Classifier - Optuna](#knc_opt)\n",
    "\n",
    "    6.1.2 [K Neighbors Classifier - PCA 175](#knc_opt_175)\n",
    "\n",
    "<br>\n",
    "\n",
    "7. [Model Stacking](#stacking)\n",
    "    \n",
    "    7.1 [GaussianNB x 3](#ensemble_2)\n",
    "    \n",
    "    7.2 [GaussianNB x 6](#ensemble_3)\n",
    "    \n",
    "    7.3 [GaussianNB x 12](#ensemble_4)\n",
    "    \n",
    "    7.4 [GaussianNB x 24](#ensemble_5)\n",
    "    \n",
    "    7.5 [GaussianNB + Logistic Regression (Final GaussianNB)](#ensemble_6)\n",
    "    \n",
    "    7.6 [Logistic Regression + GaussianNB (Final Logistic Regression)](#ensemble_7)\n",
    "    \n",
    "    7.7 [Logistic Regression + Catboost Classifier (Final Catboost Classifier)](#ensemble_8)\n",
    "    \n",
    "    7.8 [Logistic Regression + Catboost Classifier + GaussianNB (Final GaussianNB)](#ensemble_9)\n",
    "  \n",
    "    7.9 [Logistic Regression + Catboost Classifier (opt) + GaussianNB + K Neighbors Classifier (opt) (Final GaussianNB)](#ensemble_10)\n",
    "    \n",
    "    7.10 [GaussianNB + Logistict Regression + Calibrated Classifier CV (Final GaussianNB)](#ensemble_11)\n",
    "    \n",
    "    7.11 [GaussianNB + Linear Discriminant Analysis (Final GaussianNB)](#ensemble_12)\n",
    "    \n",
    "    7.12 [GaussianNB + Logistict Regression + Linear Discriminant Analysis (Final GaussianNB)](#ensemble_13)\n",
    "    \n",
    "    7.13 [GaussianNB + XGBoost Classifier + Logistic Regression (Final GaussianNB)](#ensemble_14)\n",
    "    \n",
    "    7.14 [GaussianNB X 6 + Linear Discriminant Analysis (Final GaussianNB)](#ensemble_15)\n",
    "    \n",
    "    7.15 [Model Stacking - Summary](#summary_stacking)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37847a0b",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce17c8aa",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94956ec",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c45e3f6",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a1ce6c",
   "metadata": {},
   "source": [
    "<font size='6' style=\"color:orange\">  <b> Introduction </b> </font>\n",
    "<a name=\"introduction\"></a>\n",
    "\n",
    "[[ Back to Top ]](#content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1fb6296",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'> \n",
    "Para realizar el Proyecto hemos dividido el trabajo en una fase individual y otra grupal. El objetivo de la fase de trabajo individual es explorar los distintos modelos, de forma tal que podamos ver cuáles son los que tienen mejor rendimiento. Luego continuaremos el trabajo grupal en una notebook común, donde solamente se encontrarán los modelos más relevantes para el Proyecto. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84728065",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'> \n",
    "En lo que respecta a la fase de trabajo individual, el primer paso será analizar distintos modelos de clasificación con los hiperparámetros que vienen por default, de forma tal que podamos ver cuáles son los que brindan mejores métricas, siempre teniendo en cuenta que a su vez mantengan un equilibrio con el costo del modelo. \n",
    "<p style='text-align: justify;'>     \n",
    "Luego realizaremos una reducción de dimensionalidad utilizando PCA en algunos modelos. El PCA resulta de mucha utilidad en la presencia de modelos con gran cantidad de variables como este ya que permitiría disminuir el costo de los mismos. Es por ello que resulta interesante observar de qué manera se comportan algunos modelos ante la reducción de dimensionalidad.\n",
    "<p style='text-align: justify;'> \n",
    "Posteriormente se utilizará la librería Optuna para hallar los hiperparámetros de los modelos que nos permitan obtener mejores resultados. Debido a que el dataset con el que trabajamos resulta muy grande, trabajaremos en Optuna con reducción de dimensionalidad (utilizando PCA), de forma tal que podamos disminuir los tiempos de ejecución de la optimización. Luego analizaremos si resulta viable extrapolar los hiperparámetros optimizados al full dataset.\n",
    "<p style='text-align: justify;'> \n",
    "Finalmente haremos stacking de modelos de forma tal que podamos obtener como resultado un modelo superior, buscando el que permita obtener la mejor relación entre el recall y el costo. En esta etapa resulta importante comparar los resultados de los modelos de ensamble con los de los modelos simples.\n",
    "    \n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47eb2e6",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe1c5a6",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e59d139",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2beeae7",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e3d7f9",
   "metadata": {},
   "source": [
    "<font size='6' style=\"color:orange\">  <b> Import Libraries </b> </font>\n",
    "<a name=\"libraries\"></a>\n",
    "\n",
    "[[ Back to Top ]](#content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4f43840",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T18:29:35.402429Z",
     "start_time": "2022-11-26T18:29:32.681722Z"
    }
   },
   "outputs": [],
   "source": [
    "# Numeric, scientific and data science libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import gmean\n",
    "from statistics import geometric_mean\n",
    "import pickle\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from PIL import Image\n",
    "\n",
    "# Data preparation for training - Sklearn\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Evaluation metrics and visualization - Sklearn\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score \n",
    "\n",
    "# Models from Sklearn, XGBOOST and Catboost\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "# Feature Importance\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Bayesian Optimization\n",
    "import optuna\n",
    "\n",
    "# Others\n",
    "import joblib\n",
    "import time\n",
    "from numpy import load\n",
    "from numpy import save\n",
    "from typing import List\n",
    "from scipy.stats import gmean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4a4963",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143456ee",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821cba1f",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2abd74",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a27e30",
   "metadata": {},
   "source": [
    "<font size='6' style=\"color:orange\">  <b> Dataset </b> </font>\n",
    "<a name=\"Dataset\"></a>\n",
    "\n",
    "[[ Back to Top ]](#content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80e7b275",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T18:29:39.221600Z",
     "start_time": "2022-11-26T18:29:35.952069Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID_code</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train_0</th>\n",
       "      <td>0</td>\n",
       "      <td>8.9255</td>\n",
       "      <td>-6.7863</td>\n",
       "      <td>11.9081</td>\n",
       "      <td>5.0930</td>\n",
       "      <td>11.4607</td>\n",
       "      <td>-9.2834</td>\n",
       "      <td>5.1187</td>\n",
       "      <td>18.6266</td>\n",
       "      <td>-4.9200</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4354</td>\n",
       "      <td>3.9642</td>\n",
       "      <td>3.1364</td>\n",
       "      <td>1.6910</td>\n",
       "      <td>18.5227</td>\n",
       "      <td>-2.3978</td>\n",
       "      <td>7.8784</td>\n",
       "      <td>8.5635</td>\n",
       "      <td>12.7803</td>\n",
       "      <td>-1.0914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_1</th>\n",
       "      <td>0</td>\n",
       "      <td>11.5006</td>\n",
       "      <td>-4.1473</td>\n",
       "      <td>13.8588</td>\n",
       "      <td>5.3890</td>\n",
       "      <td>12.3622</td>\n",
       "      <td>7.0433</td>\n",
       "      <td>5.6208</td>\n",
       "      <td>16.5338</td>\n",
       "      <td>3.1468</td>\n",
       "      <td>...</td>\n",
       "      <td>7.6421</td>\n",
       "      <td>7.7214</td>\n",
       "      <td>2.5837</td>\n",
       "      <td>10.9516</td>\n",
       "      <td>15.4305</td>\n",
       "      <td>2.0339</td>\n",
       "      <td>8.1267</td>\n",
       "      <td>8.7889</td>\n",
       "      <td>18.3560</td>\n",
       "      <td>1.9518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_2</th>\n",
       "      <td>0</td>\n",
       "      <td>8.6093</td>\n",
       "      <td>-2.7457</td>\n",
       "      <td>12.0805</td>\n",
       "      <td>7.8928</td>\n",
       "      <td>10.5825</td>\n",
       "      <td>-9.0837</td>\n",
       "      <td>6.9427</td>\n",
       "      <td>14.6155</td>\n",
       "      <td>-4.9193</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9057</td>\n",
       "      <td>9.7905</td>\n",
       "      <td>1.6704</td>\n",
       "      <td>1.6858</td>\n",
       "      <td>21.6042</td>\n",
       "      <td>3.1417</td>\n",
       "      <td>-6.5213</td>\n",
       "      <td>8.2675</td>\n",
       "      <td>14.7222</td>\n",
       "      <td>0.3965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_3</th>\n",
       "      <td>0</td>\n",
       "      <td>11.0604</td>\n",
       "      <td>-2.1518</td>\n",
       "      <td>8.9522</td>\n",
       "      <td>7.1957</td>\n",
       "      <td>12.5846</td>\n",
       "      <td>-1.8361</td>\n",
       "      <td>5.8428</td>\n",
       "      <td>14.9250</td>\n",
       "      <td>-5.8609</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4666</td>\n",
       "      <td>4.7433</td>\n",
       "      <td>0.7178</td>\n",
       "      <td>1.4214</td>\n",
       "      <td>23.0347</td>\n",
       "      <td>-1.2706</td>\n",
       "      <td>-2.9275</td>\n",
       "      <td>10.2922</td>\n",
       "      <td>17.9697</td>\n",
       "      <td>-8.9996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_4</th>\n",
       "      <td>0</td>\n",
       "      <td>9.8369</td>\n",
       "      <td>-1.4834</td>\n",
       "      <td>12.8746</td>\n",
       "      <td>6.6375</td>\n",
       "      <td>12.2772</td>\n",
       "      <td>2.4486</td>\n",
       "      <td>5.9405</td>\n",
       "      <td>19.2514</td>\n",
       "      <td>6.2654</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.4905</td>\n",
       "      <td>9.5214</td>\n",
       "      <td>-0.1508</td>\n",
       "      <td>9.1942</td>\n",
       "      <td>13.2876</td>\n",
       "      <td>-1.5121</td>\n",
       "      <td>3.9267</td>\n",
       "      <td>9.5031</td>\n",
       "      <td>17.9974</td>\n",
       "      <td>-8.8104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         target    var_0   var_1    var_2   var_3    var_4   var_5   var_6  \\\n",
       "ID_code                                                                      \n",
       "train_0       0   8.9255 -6.7863  11.9081  5.0930  11.4607 -9.2834  5.1187   \n",
       "train_1       0  11.5006 -4.1473  13.8588  5.3890  12.3622  7.0433  5.6208   \n",
       "train_2       0   8.6093 -2.7457  12.0805  7.8928  10.5825 -9.0837  6.9427   \n",
       "train_3       0  11.0604 -2.1518   8.9522  7.1957  12.5846 -1.8361  5.8428   \n",
       "train_4       0   9.8369 -1.4834  12.8746  6.6375  12.2772  2.4486  5.9405   \n",
       "\n",
       "           var_7   var_8  ...  var_190  var_191  var_192  var_193  var_194  \\\n",
       "ID_code                   ...                                                \n",
       "train_0  18.6266 -4.9200  ...   4.4354   3.9642   3.1364   1.6910  18.5227   \n",
       "train_1  16.5338  3.1468  ...   7.6421   7.7214   2.5837  10.9516  15.4305   \n",
       "train_2  14.6155 -4.9193  ...   2.9057   9.7905   1.6704   1.6858  21.6042   \n",
       "train_3  14.9250 -5.8609  ...   4.4666   4.7433   0.7178   1.4214  23.0347   \n",
       "train_4  19.2514  6.2654  ...  -1.4905   9.5214  -0.1508   9.1942  13.2876   \n",
       "\n",
       "         var_195  var_196  var_197  var_198  var_199  \n",
       "ID_code                                               \n",
       "train_0  -2.3978   7.8784   8.5635  12.7803  -1.0914  \n",
       "train_1   2.0339   8.1267   8.7889  18.3560   1.9518  \n",
       "train_2   3.1417  -6.5213   8.2675  14.7222   0.3965  \n",
       "train_3  -1.2706  -2.9275  10.2922  17.9697  -8.9996  \n",
       "train_4  -1.5121   3.9267   9.5031  17.9974  -8.8104  \n",
       "\n",
       "[5 rows x 201 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se abre el archivo\n",
    "\n",
    "df = pd.read_pickle(\"trainDownCast.pkl\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b095d883",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-12T20:38:00.546460Z",
     "start_time": "2022-11-12T20:37:59.149356Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.100490</td>\n",
       "      <td>10.679914</td>\n",
       "      <td>-1.627622</td>\n",
       "      <td>10.715192</td>\n",
       "      <td>6.796529</td>\n",
       "      <td>11.078333</td>\n",
       "      <td>-5.065317</td>\n",
       "      <td>5.408949</td>\n",
       "      <td>16.545850</td>\n",
       "      <td>0.284162</td>\n",
       "      <td>...</td>\n",
       "      <td>3.234440</td>\n",
       "      <td>7.438408</td>\n",
       "      <td>1.927839</td>\n",
       "      <td>3.331774</td>\n",
       "      <td>17.993784</td>\n",
       "      <td>-0.142088</td>\n",
       "      <td>2.303335</td>\n",
       "      <td>8.908158</td>\n",
       "      <td>15.870720</td>\n",
       "      <td>-3.326537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.300653</td>\n",
       "      <td>3.040051</td>\n",
       "      <td>4.050044</td>\n",
       "      <td>2.640894</td>\n",
       "      <td>2.043319</td>\n",
       "      <td>1.623150</td>\n",
       "      <td>7.863267</td>\n",
       "      <td>0.866607</td>\n",
       "      <td>3.418076</td>\n",
       "      <td>3.332634</td>\n",
       "      <td>...</td>\n",
       "      <td>4.559922</td>\n",
       "      <td>3.023272</td>\n",
       "      <td>1.478423</td>\n",
       "      <td>3.992030</td>\n",
       "      <td>3.135162</td>\n",
       "      <td>1.429372</td>\n",
       "      <td>5.454369</td>\n",
       "      <td>0.921625</td>\n",
       "      <td>3.010945</td>\n",
       "      <td>10.438015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.408400</td>\n",
       "      <td>-15.043400</td>\n",
       "      <td>2.117100</td>\n",
       "      <td>-0.040200</td>\n",
       "      <td>5.074800</td>\n",
       "      <td>-32.562600</td>\n",
       "      <td>2.347300</td>\n",
       "      <td>5.349700</td>\n",
       "      <td>-10.505500</td>\n",
       "      <td>...</td>\n",
       "      <td>-14.093300</td>\n",
       "      <td>-2.691700</td>\n",
       "      <td>-3.814500</td>\n",
       "      <td>-11.783400</td>\n",
       "      <td>8.694400</td>\n",
       "      <td>-5.261000</td>\n",
       "      <td>-14.209600</td>\n",
       "      <td>5.960600</td>\n",
       "      <td>6.299300</td>\n",
       "      <td>-38.852800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.453850</td>\n",
       "      <td>-4.740025</td>\n",
       "      <td>8.722475</td>\n",
       "      <td>5.254075</td>\n",
       "      <td>9.883175</td>\n",
       "      <td>-11.200350</td>\n",
       "      <td>4.767700</td>\n",
       "      <td>13.943800</td>\n",
       "      <td>-2.317800</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.058825</td>\n",
       "      <td>5.157400</td>\n",
       "      <td>0.889775</td>\n",
       "      <td>0.584600</td>\n",
       "      <td>15.629800</td>\n",
       "      <td>-1.170700</td>\n",
       "      <td>-1.946925</td>\n",
       "      <td>8.252800</td>\n",
       "      <td>13.829700</td>\n",
       "      <td>-11.208475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.524750</td>\n",
       "      <td>-1.608050</td>\n",
       "      <td>10.580000</td>\n",
       "      <td>6.825000</td>\n",
       "      <td>11.108250</td>\n",
       "      <td>-4.833150</td>\n",
       "      <td>5.385100</td>\n",
       "      <td>16.456800</td>\n",
       "      <td>0.393700</td>\n",
       "      <td>...</td>\n",
       "      <td>3.203600</td>\n",
       "      <td>7.347750</td>\n",
       "      <td>1.901300</td>\n",
       "      <td>3.396350</td>\n",
       "      <td>17.957950</td>\n",
       "      <td>-0.172700</td>\n",
       "      <td>2.408900</td>\n",
       "      <td>8.888200</td>\n",
       "      <td>15.934050</td>\n",
       "      <td>-2.819550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.758200</td>\n",
       "      <td>1.358625</td>\n",
       "      <td>12.516700</td>\n",
       "      <td>8.324100</td>\n",
       "      <td>12.261125</td>\n",
       "      <td>0.924800</td>\n",
       "      <td>6.003000</td>\n",
       "      <td>19.102900</td>\n",
       "      <td>2.937900</td>\n",
       "      <td>...</td>\n",
       "      <td>6.406200</td>\n",
       "      <td>9.512525</td>\n",
       "      <td>2.949500</td>\n",
       "      <td>6.205800</td>\n",
       "      <td>20.396525</td>\n",
       "      <td>0.829600</td>\n",
       "      <td>6.556725</td>\n",
       "      <td>9.593300</td>\n",
       "      <td>18.064725</td>\n",
       "      <td>4.836800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.315000</td>\n",
       "      <td>10.376800</td>\n",
       "      <td>19.353000</td>\n",
       "      <td>13.188300</td>\n",
       "      <td>16.671400</td>\n",
       "      <td>17.251600</td>\n",
       "      <td>8.447700</td>\n",
       "      <td>27.691800</td>\n",
       "      <td>10.151300</td>\n",
       "      <td>...</td>\n",
       "      <td>18.440900</td>\n",
       "      <td>16.716500</td>\n",
       "      <td>8.402400</td>\n",
       "      <td>18.281800</td>\n",
       "      <td>27.928800</td>\n",
       "      <td>4.272900</td>\n",
       "      <td>18.321500</td>\n",
       "      <td>12.000400</td>\n",
       "      <td>26.079100</td>\n",
       "      <td>28.500700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              target          var_0          var_1          var_2  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean        0.100490      10.679914      -1.627622      10.715192   \n",
       "std         0.300653       3.040051       4.050044       2.640894   \n",
       "min         0.000000       0.408400     -15.043400       2.117100   \n",
       "25%         0.000000       8.453850      -4.740025       8.722475   \n",
       "50%         0.000000      10.524750      -1.608050      10.580000   \n",
       "75%         0.000000      12.758200       1.358625      12.516700   \n",
       "max         1.000000      20.315000      10.376800      19.353000   \n",
       "\n",
       "               var_3          var_4          var_5          var_6  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean        6.796529      11.078333      -5.065317       5.408949   \n",
       "std         2.043319       1.623150       7.863267       0.866607   \n",
       "min        -0.040200       5.074800     -32.562600       2.347300   \n",
       "25%         5.254075       9.883175     -11.200350       4.767700   \n",
       "50%         6.825000      11.108250      -4.833150       5.385100   \n",
       "75%         8.324100      12.261125       0.924800       6.003000   \n",
       "max        13.188300      16.671400      17.251600       8.447700   \n",
       "\n",
       "               var_7          var_8  ...        var_190        var_191  \\\n",
       "count  200000.000000  200000.000000  ...  200000.000000  200000.000000   \n",
       "mean       16.545850       0.284162  ...       3.234440       7.438408   \n",
       "std         3.418076       3.332634  ...       4.559922       3.023272   \n",
       "min         5.349700     -10.505500  ...     -14.093300      -2.691700   \n",
       "25%        13.943800      -2.317800  ...      -0.058825       5.157400   \n",
       "50%        16.456800       0.393700  ...       3.203600       7.347750   \n",
       "75%        19.102900       2.937900  ...       6.406200       9.512525   \n",
       "max        27.691800      10.151300  ...      18.440900      16.716500   \n",
       "\n",
       "             var_192        var_193        var_194        var_195  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean        1.927839       3.331774      17.993784      -0.142088   \n",
       "std         1.478423       3.992030       3.135162       1.429372   \n",
       "min        -3.814500     -11.783400       8.694400      -5.261000   \n",
       "25%         0.889775       0.584600      15.629800      -1.170700   \n",
       "50%         1.901300       3.396350      17.957950      -0.172700   \n",
       "75%         2.949500       6.205800      20.396525       0.829600   \n",
       "max         8.402400      18.281800      27.928800       4.272900   \n",
       "\n",
       "             var_196        var_197        var_198        var_199  \n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000  \n",
       "mean        2.303335       8.908158      15.870720      -3.326537  \n",
       "std         5.454369       0.921625       3.010945      10.438015  \n",
       "min       -14.209600       5.960600       6.299300     -38.852800  \n",
       "25%        -1.946925       8.252800      13.829700     -11.208475  \n",
       "50%         2.408900       8.888200      15.934050      -2.819550  \n",
       "75%         6.556725       9.593300      18.064725       4.836800  \n",
       "max        18.321500      12.000400      26.079100      28.500700  \n",
       "\n",
       "[8 rows x 201 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se revisa de manera general la forma en la que se comportan todas las variables del dataset\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a98e54",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2dd7b43",
   "metadata": {},
   "source": [
    "<font size='4' style=\"color:orange\">  <b> Definition of X and y </b> </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc981f20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T18:29:42.801251Z",
     "start_time": "2022-11-26T18:29:42.718254Z"
    }
   },
   "outputs": [],
   "source": [
    "# Se separa en X e y\n",
    "X = df.drop(\"target\", axis=1) # Se elimina del dataset la variable a predecir\n",
    "y = df.target # Se define el Target "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d129ac15",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T18:29:43.304249Z",
     "start_time": "2022-11-26T18:29:43.242177Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>var_9</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID_code</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train_0</th>\n",
       "      <td>8.9255</td>\n",
       "      <td>-6.7863</td>\n",
       "      <td>11.9081</td>\n",
       "      <td>5.0930</td>\n",
       "      <td>11.4607</td>\n",
       "      <td>-9.2834</td>\n",
       "      <td>5.1187</td>\n",
       "      <td>18.6266</td>\n",
       "      <td>-4.9200</td>\n",
       "      <td>5.7470</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4354</td>\n",
       "      <td>3.9642</td>\n",
       "      <td>3.1364</td>\n",
       "      <td>1.6910</td>\n",
       "      <td>18.5227</td>\n",
       "      <td>-2.3978</td>\n",
       "      <td>7.8784</td>\n",
       "      <td>8.5635</td>\n",
       "      <td>12.7803</td>\n",
       "      <td>-1.0914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_1</th>\n",
       "      <td>11.5006</td>\n",
       "      <td>-4.1473</td>\n",
       "      <td>13.8588</td>\n",
       "      <td>5.3890</td>\n",
       "      <td>12.3622</td>\n",
       "      <td>7.0433</td>\n",
       "      <td>5.6208</td>\n",
       "      <td>16.5338</td>\n",
       "      <td>3.1468</td>\n",
       "      <td>8.0851</td>\n",
       "      <td>...</td>\n",
       "      <td>7.6421</td>\n",
       "      <td>7.7214</td>\n",
       "      <td>2.5837</td>\n",
       "      <td>10.9516</td>\n",
       "      <td>15.4305</td>\n",
       "      <td>2.0339</td>\n",
       "      <td>8.1267</td>\n",
       "      <td>8.7889</td>\n",
       "      <td>18.3560</td>\n",
       "      <td>1.9518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_2</th>\n",
       "      <td>8.6093</td>\n",
       "      <td>-2.7457</td>\n",
       "      <td>12.0805</td>\n",
       "      <td>7.8928</td>\n",
       "      <td>10.5825</td>\n",
       "      <td>-9.0837</td>\n",
       "      <td>6.9427</td>\n",
       "      <td>14.6155</td>\n",
       "      <td>-4.9193</td>\n",
       "      <td>5.9525</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9057</td>\n",
       "      <td>9.7905</td>\n",
       "      <td>1.6704</td>\n",
       "      <td>1.6858</td>\n",
       "      <td>21.6042</td>\n",
       "      <td>3.1417</td>\n",
       "      <td>-6.5213</td>\n",
       "      <td>8.2675</td>\n",
       "      <td>14.7222</td>\n",
       "      <td>0.3965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_3</th>\n",
       "      <td>11.0604</td>\n",
       "      <td>-2.1518</td>\n",
       "      <td>8.9522</td>\n",
       "      <td>7.1957</td>\n",
       "      <td>12.5846</td>\n",
       "      <td>-1.8361</td>\n",
       "      <td>5.8428</td>\n",
       "      <td>14.9250</td>\n",
       "      <td>-5.8609</td>\n",
       "      <td>8.2450</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4666</td>\n",
       "      <td>4.7433</td>\n",
       "      <td>0.7178</td>\n",
       "      <td>1.4214</td>\n",
       "      <td>23.0347</td>\n",
       "      <td>-1.2706</td>\n",
       "      <td>-2.9275</td>\n",
       "      <td>10.2922</td>\n",
       "      <td>17.9697</td>\n",
       "      <td>-8.9996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_4</th>\n",
       "      <td>9.8369</td>\n",
       "      <td>-1.4834</td>\n",
       "      <td>12.8746</td>\n",
       "      <td>6.6375</td>\n",
       "      <td>12.2772</td>\n",
       "      <td>2.4486</td>\n",
       "      <td>5.9405</td>\n",
       "      <td>19.2514</td>\n",
       "      <td>6.2654</td>\n",
       "      <td>7.6784</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.4905</td>\n",
       "      <td>9.5214</td>\n",
       "      <td>-0.1508</td>\n",
       "      <td>9.1942</td>\n",
       "      <td>13.2876</td>\n",
       "      <td>-1.5121</td>\n",
       "      <td>3.9267</td>\n",
       "      <td>9.5031</td>\n",
       "      <td>17.9974</td>\n",
       "      <td>-8.8104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_199995</th>\n",
       "      <td>11.4880</td>\n",
       "      <td>-0.4956</td>\n",
       "      <td>8.2622</td>\n",
       "      <td>3.5142</td>\n",
       "      <td>10.3404</td>\n",
       "      <td>11.6081</td>\n",
       "      <td>5.6709</td>\n",
       "      <td>15.1516</td>\n",
       "      <td>-0.6209</td>\n",
       "      <td>5.6669</td>\n",
       "      <td>...</td>\n",
       "      <td>6.1415</td>\n",
       "      <td>13.2305</td>\n",
       "      <td>3.9901</td>\n",
       "      <td>0.9388</td>\n",
       "      <td>18.0249</td>\n",
       "      <td>-1.7939</td>\n",
       "      <td>2.1661</td>\n",
       "      <td>8.5326</td>\n",
       "      <td>16.6660</td>\n",
       "      <td>-17.8661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_199996</th>\n",
       "      <td>4.9149</td>\n",
       "      <td>-2.4484</td>\n",
       "      <td>16.7052</td>\n",
       "      <td>6.6345</td>\n",
       "      <td>8.3096</td>\n",
       "      <td>-10.5628</td>\n",
       "      <td>5.8802</td>\n",
       "      <td>21.5940</td>\n",
       "      <td>-3.6797</td>\n",
       "      <td>6.0019</td>\n",
       "      <td>...</td>\n",
       "      <td>4.9611</td>\n",
       "      <td>4.6549</td>\n",
       "      <td>0.6998</td>\n",
       "      <td>1.8341</td>\n",
       "      <td>22.2717</td>\n",
       "      <td>1.7337</td>\n",
       "      <td>-2.1651</td>\n",
       "      <td>6.7419</td>\n",
       "      <td>15.9054</td>\n",
       "      <td>0.3388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_199997</th>\n",
       "      <td>11.2232</td>\n",
       "      <td>-5.0518</td>\n",
       "      <td>10.5127</td>\n",
       "      <td>5.6456</td>\n",
       "      <td>9.3410</td>\n",
       "      <td>-5.4086</td>\n",
       "      <td>4.5555</td>\n",
       "      <td>21.5571</td>\n",
       "      <td>0.1202</td>\n",
       "      <td>6.1629</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0651</td>\n",
       "      <td>5.4414</td>\n",
       "      <td>3.1032</td>\n",
       "      <td>4.8793</td>\n",
       "      <td>23.5311</td>\n",
       "      <td>-1.5736</td>\n",
       "      <td>1.2832</td>\n",
       "      <td>8.7155</td>\n",
       "      <td>13.8329</td>\n",
       "      <td>4.1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_199998</th>\n",
       "      <td>9.7148</td>\n",
       "      <td>-8.6098</td>\n",
       "      <td>13.6104</td>\n",
       "      <td>5.7930</td>\n",
       "      <td>12.5173</td>\n",
       "      <td>0.5339</td>\n",
       "      <td>6.0479</td>\n",
       "      <td>17.0152</td>\n",
       "      <td>-2.1926</td>\n",
       "      <td>8.7542</td>\n",
       "      <td>...</td>\n",
       "      <td>2.6840</td>\n",
       "      <td>8.6587</td>\n",
       "      <td>2.7337</td>\n",
       "      <td>11.1178</td>\n",
       "      <td>20.4158</td>\n",
       "      <td>-0.0786</td>\n",
       "      <td>6.7980</td>\n",
       "      <td>10.0342</td>\n",
       "      <td>15.5289</td>\n",
       "      <td>-13.9001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_199999</th>\n",
       "      <td>10.8762</td>\n",
       "      <td>-5.7105</td>\n",
       "      <td>12.1183</td>\n",
       "      <td>8.0328</td>\n",
       "      <td>11.5577</td>\n",
       "      <td>0.3488</td>\n",
       "      <td>5.2839</td>\n",
       "      <td>15.2058</td>\n",
       "      <td>-0.4541</td>\n",
       "      <td>9.3688</td>\n",
       "      <td>...</td>\n",
       "      <td>8.9842</td>\n",
       "      <td>1.6893</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.3766</td>\n",
       "      <td>15.2101</td>\n",
       "      <td>-2.4907</td>\n",
       "      <td>-2.2342</td>\n",
       "      <td>8.1857</td>\n",
       "      <td>12.1284</td>\n",
       "      <td>0.1385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                var_0   var_1    var_2   var_3    var_4    var_5   var_6  \\\n",
       "ID_code                                                                    \n",
       "train_0        8.9255 -6.7863  11.9081  5.0930  11.4607  -9.2834  5.1187   \n",
       "train_1       11.5006 -4.1473  13.8588  5.3890  12.3622   7.0433  5.6208   \n",
       "train_2        8.6093 -2.7457  12.0805  7.8928  10.5825  -9.0837  6.9427   \n",
       "train_3       11.0604 -2.1518   8.9522  7.1957  12.5846  -1.8361  5.8428   \n",
       "train_4        9.8369 -1.4834  12.8746  6.6375  12.2772   2.4486  5.9405   \n",
       "...               ...     ...      ...     ...      ...      ...     ...   \n",
       "train_199995  11.4880 -0.4956   8.2622  3.5142  10.3404  11.6081  5.6709   \n",
       "train_199996   4.9149 -2.4484  16.7052  6.6345   8.3096 -10.5628  5.8802   \n",
       "train_199997  11.2232 -5.0518  10.5127  5.6456   9.3410  -5.4086  4.5555   \n",
       "train_199998   9.7148 -8.6098  13.6104  5.7930  12.5173   0.5339  6.0479   \n",
       "train_199999  10.8762 -5.7105  12.1183  8.0328  11.5577   0.3488  5.2839   \n",
       "\n",
       "                var_7   var_8   var_9  ...  var_190  var_191  var_192  \\\n",
       "ID_code                                ...                              \n",
       "train_0       18.6266 -4.9200  5.7470  ...   4.4354   3.9642   3.1364   \n",
       "train_1       16.5338  3.1468  8.0851  ...   7.6421   7.7214   2.5837   \n",
       "train_2       14.6155 -4.9193  5.9525  ...   2.9057   9.7905   1.6704   \n",
       "train_3       14.9250 -5.8609  8.2450  ...   4.4666   4.7433   0.7178   \n",
       "train_4       19.2514  6.2654  7.6784  ...  -1.4905   9.5214  -0.1508   \n",
       "...               ...     ...     ...  ...      ...      ...      ...   \n",
       "train_199995  15.1516 -0.6209  5.6669  ...   6.1415  13.2305   3.9901   \n",
       "train_199996  21.5940 -3.6797  6.0019  ...   4.9611   4.6549   0.6998   \n",
       "train_199997  21.5571  0.1202  6.1629  ...   4.0651   5.4414   3.1032   \n",
       "train_199998  17.0152 -2.1926  8.7542  ...   2.6840   8.6587   2.7337   \n",
       "train_199999  15.2058 -0.4541  9.3688  ...   8.9842   1.6893   0.1276   \n",
       "\n",
       "              var_193  var_194  var_195  var_196  var_197  var_198  var_199  \n",
       "ID_code                                                                      \n",
       "train_0        1.6910  18.5227  -2.3978   7.8784   8.5635  12.7803  -1.0914  \n",
       "train_1       10.9516  15.4305   2.0339   8.1267   8.7889  18.3560   1.9518  \n",
       "train_2        1.6858  21.6042   3.1417  -6.5213   8.2675  14.7222   0.3965  \n",
       "train_3        1.4214  23.0347  -1.2706  -2.9275  10.2922  17.9697  -8.9996  \n",
       "train_4        9.1942  13.2876  -1.5121   3.9267   9.5031  17.9974  -8.8104  \n",
       "...               ...      ...      ...      ...      ...      ...      ...  \n",
       "train_199995   0.9388  18.0249  -1.7939   2.1661   8.5326  16.6660 -17.8661  \n",
       "train_199996   1.8341  22.2717   1.7337  -2.1651   6.7419  15.9054   0.3388  \n",
       "train_199997   4.8793  23.5311  -1.5736   1.2832   8.7155  13.8329   4.1995  \n",
       "train_199998  11.1178  20.4158  -0.0786   6.7980  10.0342  15.5289 -13.9001  \n",
       "train_199999   0.3766  15.2101  -2.4907  -2.2342   8.1857  12.1284   0.1385  \n",
       "\n",
       "[200000 rows x 200 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6a7c805",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T18:29:43.777158Z",
     "start_time": "2022-11-26T18:29:43.742126Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID_code\n",
       "train_0         0\n",
       "train_1         0\n",
       "train_2         0\n",
       "train_3         0\n",
       "train_4         0\n",
       "               ..\n",
       "train_199995    0\n",
       "train_199996    0\n",
       "train_199997    0\n",
       "train_199998    0\n",
       "train_199999    0\n",
       "Name: target, Length: 200000, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4335bc41",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fca9b7",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd9be4b",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eed9c54",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efba7f1b",
   "metadata": {},
   "source": [
    "<font size='6' style=\"color:orange\">  <b> Models - Default Parameters </b> </font>\n",
    "<a name=\"default\"></a>\n",
    "\n",
    "[[ Back to Top ]](#content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c009407",
   "metadata": {},
   "source": [
    "En este apartado se buscarán algunos modelos de clasificación con los parámetros default, de forma tal que podamos ver cuáles nos serán más útiles para utilizar en el futuro. Los modelos empleados son los siguientes:\n",
    "\n",
    "- Logistic Regression\n",
    "- GaussianNB\n",
    "- Random forest\n",
    "- K Neighbors Classifier\n",
    "- XGBoost Classifier\n",
    "- Catboost Classifier \n",
    "- MLP Classifier \n",
    "- Linear Discriminant Analysis \n",
    "- Calibrated Classifier with GaussianNB \n",
    "- SGD Classifier\n",
    "- Bagging Classifier \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352d27fb",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4457fa97",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27dadd4",
   "metadata": {},
   "source": [
    "<font size='5' style=\"color:orange\">  <b> Logistic Regression - Default </b> </font>\n",
    "<a name=\"lgr_default\"></a>\n",
    "\n",
    "[[ Back to Top ]](#content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1a8df608",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T02:28:58.125260Z",
     "start_time": "2022-11-08T02:10:56.929585Z"
    }
   },
   "outputs": [],
   "source": [
    "# Logistic Regression - Full dataset\n",
    "\n",
    "# Cabe aclarar que en la regresión logística no se utilizó el parámetro max_iter default ya que arrojaba un error.\n",
    "# Es por ello que se ha definido el max_iter = 7000. Sin embargo, no se realizó una optimización de hiperparámetros para \n",
    "# elegir este max_iter.\n",
    "\n",
    "lgr = LogisticRegression(max_iter = 7000)\n",
    "\n",
    "\n",
    "skf = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 1 )\n",
    "\n",
    "lgr_full_results    = []\n",
    "lgr_full_results_cm = []\n",
    "\n",
    "for train_index, test_index in skf.split(X,y):\n",
    "    \n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    lgr.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = lgr.predict(X_test)\n",
    "    \n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall    = recall_score(y_test, y_pred)\n",
    "    f1        = f1_score(y_test, y_pred)\n",
    "    cm        = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    list_results   = [precision, recall, f1]\n",
    "    list_cm = [cm]\n",
    "    lgr_full_results.append(list_results)\n",
    "    lgr_full_results_cm.append(list_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d5d10445",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T02:28:58.220028Z",
     "start_time": "2022-11-08T02:28:58.190026Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRECISION</th>\n",
       "      <th>RECALL</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegression_full</th>\n",
       "      <td>0.68548</td>\n",
       "      <td>0.269483</td>\n",
       "      <td>0.386856</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         PRECISION    RECALL        F1\n",
       "LogisticRegression_full    0.68548  0.269483  0.386856"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filas    = ['LogisticRegression_full']\n",
    "columnas = [\"PRECISION\", \"RECALL\", \"F1\"]\n",
    "resultados = pd.DataFrame([gmean(lgr_full_results)], columns=columnas, index=filas)\n",
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a6a758c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T02:31:20.557017Z",
     "start_time": "2022-11-08T02:31:20.541019Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRECISION</th>\n",
       "      <th>RECALL</th>\n",
       "      <th>F1</th>\n",
       "      <th>TIEMPO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegression_full</th>\n",
       "      <td>0.68548</td>\n",
       "      <td>0.269483</td>\n",
       "      <td>0.386856</td>\n",
       "      <td>1081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         PRECISION    RECALL        F1  TIEMPO\n",
       "LogisticRegression_full    0.68548  0.269483  0.386856    1081"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tiempo expresado en segundos\n",
    "resultados['TIEMPO']= 1081\n",
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "b973f8b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-18T00:26:27.019713Z",
     "start_time": "2022-11-18T00:26:27.003553Z"
    }
   },
   "outputs": [],
   "source": [
    "resultados.to_pickle(\"resultados_lgr_full.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3b817e4e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T02:31:36.977227Z",
     "start_time": "2022-11-08T02:31:36.963754Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[17741.69449217,   248.10252564],\n",
       "        [ 1467.9280316 ,   541.60745703]]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados_cm = gmean(lgr_full_results_cm)\n",
    "resultados_cm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cc58b333",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T02:36:05.250390Z",
     "start_time": "2022-11-08T02:36:05.245259Z"
    }
   },
   "outputs": [],
   "source": [
    " with open('resultados_lgr_full_cm.pkl','wb') as f:\n",
    "        pickle.dump(resultados_cm, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "id": "d6fc6da6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-25T02:27:31.169992Z",
     "start_time": "2022-11-25T02:27:31.157827Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('resultados_lgr_full_cm.pkl','rb') as f:\n",
    "        resultados_cm = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "id": "a8e963ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-25T02:23:42.263997Z",
     "start_time": "2022-11-25T02:23:41.999942Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm_display_lgr_full = ConfusionMatrixDisplay(confusion_matrix = resultados_cm.reshape(2,2), display_labels = [0, 1])\n",
    "cm_display_lgr_full.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b3fb77",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0751553c",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee7859a",
   "metadata": {},
   "source": [
    "<font size='5' style=\"color:orange\">  <b> GaussianNB - Default </b> </font>\n",
    "<a name=\"gbn_default\"></a>\n",
    "\n",
    "[[ Back to Top ]](#content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "74a8dde1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T02:39:03.867309Z",
     "start_time": "2022-11-08T02:38:57.799629Z"
    }
   },
   "outputs": [],
   "source": [
    "# GaussianNB - Full dataset\n",
    "\n",
    "gnb = GaussianNB()\n",
    "\n",
    "skf = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 1 )\n",
    "\n",
    "gnb_full_results    = []\n",
    "gnb_full_results_cm = []\n",
    "\n",
    "for train_index, test_index in skf.split(X,y):\n",
    "    \n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    gnb.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = gnb.predict(X_test)\n",
    "    \n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall    = recall_score(y_test, y_pred)\n",
    "    f1        = f1_score(y_test, y_pred)\n",
    "    cm        = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    list_results   = [precision, recall, f1]\n",
    "    list_cm = [cm]\n",
    "    gnb_full_results.append(list_results)\n",
    "    gnb_full_results_cm.append(list_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "860e95a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T02:40:21.782723Z",
     "start_time": "2022-11-08T02:40:21.770641Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRECISION</th>\n",
       "      <th>RECALL</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GaussianNB_full</th>\n",
       "      <td>0.647487</td>\n",
       "      <td>0.403787</td>\n",
       "      <td>0.497367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 PRECISION    RECALL        F1\n",
       "GaussianNB_full   0.647487  0.403787  0.497367"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filas    = ['GaussianNB_full']\n",
    "columnas = [\"PRECISION\", \"RECALL\", \"F1\"]\n",
    "resultados = pd.DataFrame([gmean(gnb_full_results)], columns=columnas, index=filas)\n",
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4435b888",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T02:41:27.111043Z",
     "start_time": "2022-11-08T02:41:27.102854Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRECISION</th>\n",
       "      <th>RECALL</th>\n",
       "      <th>F1</th>\n",
       "      <th>TIEMPO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GaussianNB_full</th>\n",
       "      <td>0.647487</td>\n",
       "      <td>0.403787</td>\n",
       "      <td>0.497367</td>\n",
       "      <td>6.07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 PRECISION    RECALL        F1  TIEMPO\n",
       "GaussianNB_full   0.647487  0.403787  0.497367    6.07"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tiempo expresado en segundos\n",
    "resultados['TIEMPO']= 6.07\n",
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "276b5f92",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T02:41:54.590364Z",
     "start_time": "2022-11-08T02:41:54.570940Z"
    }
   },
   "outputs": [],
   "source": [
    "resultados.to_pickle(\"resultados_gnb_full.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b39a4b19",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T02:42:22.089636Z",
     "start_time": "2022-11-08T02:42:22.084694Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[17548.37388377,   440.75391567],\n",
       "        [ 1197.81284369,   811.53110098]]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados_cm= gmean(gnb_full_results_cm)\n",
    "resultados_cm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "04e5f361",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T02:42:50.938058Z",
     "start_time": "2022-11-08T02:42:50.920086Z"
    }
   },
   "outputs": [],
   "source": [
    " with open('resultados_gnb_full_cm.pkl','wb') as f:\n",
    "        pickle.dump(resultados_cm, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "id": "b1899d83",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-25T23:08:14.819210Z",
     "start_time": "2022-11-25T23:08:14.804160Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('resultados_gnb_full_cm.pkl','rb') as f:\n",
    "        resultados_cm = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "id": "3a6c0426",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-25T23:08:49.810418Z",
     "start_time": "2022-11-25T23:08:49.688462Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm_display_lgr_full = ConfusionMatrixDisplay(confusion_matrix = resultados_cm.reshape(2,2), display_labels = [0, 1])\n",
    "cm_display_lgr_full.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9497373",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffd7a6b",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbea1f9",
   "metadata": {},
   "source": [
    "<font size='5' style=\"color:orange\">  <b> Random Forest Classifier - Default </b> </font>\n",
    "<a name=\"rfc_default\"></a>\n",
    "\n",
    "[[ Back to Top ]](#content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c72e7e45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T21:42:59.167904Z",
     "start_time": "2022-11-08T20:03:21.030851Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# RandomForestClassifier - Full dataset\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "skf = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 1 )\n",
    "\n",
    "rfc_full_results    = []\n",
    "rfc_full_results_cm = []\n",
    "\n",
    "for train_index, test_index in skf.split(X,y):\n",
    "    \n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    rfc.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = rfc.predict(X_test)\n",
    "    \n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall    = recall_score(y_test, y_pred)\n",
    "    f1        = f1_score(y_test, y_pred)\n",
    "    cm        = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    results_list    = [precision, recall, f1]\n",
    "    cm_list = [cm]\n",
    "    rfc_full_results.append(results_list)\n",
    "    rfc_full_results_cm.append(cm_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "424e837a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T21:42:59.263397Z",
     "start_time": "2022-11-08T21:42:59.233396Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRECISION</th>\n",
       "      <th>RECALL</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier_full</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             PRECISION  RECALL   F1\n",
       "RandomForestClassifier_full        0.0     0.0  0.0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filas    = ['RandomForestClassifier_full']\n",
    "columnas = [\"PRECISION\", \"RECALL\", \"F1\"]\n",
    "resultados = pd.DataFrame([gmean(rfc_full_results)], columns=columnas, index=filas)\n",
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8158772b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T21:46:00.950047Z",
     "start_time": "2022-11-08T21:46:00.932086Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRECISION</th>\n",
       "      <th>RECALL</th>\n",
       "      <th>F1</th>\n",
       "      <th>TIEMPO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier_full</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5978</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             PRECISION  RECALL   F1  TIEMPO\n",
       "RandomForestClassifier_full        0.0     0.0  0.0    5978"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tiempo expresado en segundos\n",
    "resultados['TIEMPO']= 5978\n",
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "32958a45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T21:46:06.543693Z",
     "start_time": "2022-11-08T21:46:06.511187Z"
    }
   },
   "outputs": [],
   "source": [
    "resultados.to_pickle(\"resultados_rfc_full.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d4610675",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T21:46:08.934162Z",
     "start_time": "2022-11-08T21:46:08.906051Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\stats\\_stats_py.py:279: RuntimeWarning: divide by zero encountered in log\n",
      "  log_a = np.log(np.array(a, dtype=dtype))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[17990.19999555,     0.        ],\n",
       "        [ 2009.69994775,     0.        ]]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados_cm = gmean(rfc_full_results_cm)\n",
    "resultados_cm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1ea43783",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T21:46:12.853483Z",
     "start_time": "2022-11-08T21:46:12.840483Z"
    }
   },
   "outputs": [],
   "source": [
    " with open('resultados_rfc_full_cm.pkl','wb') as f:\n",
    "        pickle.dump(resultados_cm, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538efe8c",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fce85c2",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a656437d",
   "metadata": {},
   "source": [
    "<font size='5' style=\"color:orange\">  <b> K Neighbors Classifier - Default </b> </font>\n",
    "<a name=\"knc_default\"></a>\n",
    "\n",
    "[[ Back to Top ]](#content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "927cf3fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-10T23:57:21.120556Z",
     "start_time": "2022-11-10T23:44:20.457668Z"
    }
   },
   "outputs": [],
   "source": [
    "# KNeighborsClassifier - Full dataset\n",
    "\n",
    "knc = KNeighborsClassifier()\n",
    "    \n",
    "skf = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 1 )\n",
    "\n",
    "knc_full_results    = []\n",
    "knc_full_results_cm = []\n",
    "\n",
    "for train_index, test_index in skf.split(X,y):\n",
    "    \n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    knc.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = knc.predict(X_test)\n",
    "    \n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall    = recall_score(y_test, y_pred)\n",
    "    f1        = f1_score(y_test, y_pred)\n",
    "    cm        = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    list_results   = [precision, recall, f1]\n",
    "    list_cm = [cm]\n",
    "    knc_full_results.append(list_results)\n",
    "    knc_full_results_cm.append(list_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "67a0a008",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-10T23:57:21.182914Z",
     "start_time": "2022-11-10T23:57:21.169512Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRECISION</th>\n",
       "      <th>RECALL</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier_full</th>\n",
       "      <td>0.223142</td>\n",
       "      <td>0.003169</td>\n",
       "      <td>0.006247</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           PRECISION    RECALL        F1\n",
       "KNeighborsClassifier_full   0.223142  0.003169  0.006247"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filas    = ['KNeighborsClassifier_full']\n",
    "columnas = [\"PRECISION\", \"RECALL\", \"F1\"]\n",
    "resultados = pd.DataFrame([gmean(knc_full_results)], columns=columnas, index=filas)\n",
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "00324088",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-11T00:02:34.716144Z",
     "start_time": "2022-11-11T00:02:34.699094Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRECISION</th>\n",
       "      <th>RECALL</th>\n",
       "      <th>F1</th>\n",
       "      <th>TIEMPO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier_full</th>\n",
       "      <td>0.223142</td>\n",
       "      <td>0.003169</td>\n",
       "      <td>0.006247</td>\n",
       "      <td>781</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           PRECISION    RECALL        F1  TIEMPO\n",
       "KNeighborsClassifier_full   0.223142  0.003169  0.006247     781"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tiempo expresado en segundos\n",
    "resultados['TIEMPO'] = 781\n",
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "e01ff6d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-11T00:02:35.390936Z",
     "start_time": "2022-11-11T00:02:35.373320Z"
    }
   },
   "outputs": [],
   "source": [
    "resultados.to_pickle(\"resultados_knc_full.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "97f43f8d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-11T00:02:36.032919Z",
     "start_time": "2022-11-11T00:02:36.016010Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1.79686995e+04, 2.10021668e+01],\n",
       "        [2.00229720e+03, 6.36867140e+00]]])"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados_cm = gmean(knc_full_results_cm)\n",
    "resultados_cm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "54595107",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-11T00:02:36.786342Z",
     "start_time": "2022-11-11T00:02:36.774332Z"
    }
   },
   "outputs": [],
   "source": [
    " with open('resultados_knc_full_cm.pkl','wb') as f:\n",
    "        pickle.dump(resultados_cm, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c830c903",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f21823",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38006ba6",
   "metadata": {},
   "source": [
    "<font size='5' style=\"color:orange\">  <b> XGBoost Classifier - Default </b> </font>\n",
    "<a name=\"xgb_default\"></a>\n",
    "\n",
    "[[ Back to Top ]](#content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "42b469e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-10T02:40:40.595346Z",
     "start_time": "2022-11-10T02:15:48.039055Z"
    }
   },
   "outputs": [],
   "source": [
    "# XGB Classifier - Full dataset\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "    \n",
    "skf = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 1 )\n",
    "\n",
    "xgb_full_results    = []\n",
    "xgb_full_results_cm = []\n",
    "\n",
    "for train_index, test_index in skf.split(X,y):\n",
    "    \n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    xgb.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = xgb.predict(X_test)\n",
    "    \n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall    = recall_score(y_test, y_pred)\n",
    "    f1        = f1_score(y_test, y_pred)\n",
    "    cm        = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    list_results   = [precision, recall, f1]\n",
    "    list_cm = [cm]\n",
    "    xgb_full_results.append(list_results)\n",
    "    xgb_full_results_cm.append(list_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "f9184082",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-10T02:40:40.642346Z",
     "start_time": "2022-11-10T02:40:40.628346Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRECISION</th>\n",
       "      <th>RECALL</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>XGBoost_full</th>\n",
       "      <td>0.693811</td>\n",
       "      <td>0.247841</td>\n",
       "      <td>0.365173</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              PRECISION    RECALL        F1\n",
       "XGBoost_full   0.693811  0.247841  0.365173"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filas    = ['XGBoost_full']\n",
    "columnas = [\"PRECISION\", \"RECALL\", \"F1\"]\n",
    "resultados = pd.DataFrame([gmean(xgb_full_results)], columns=columnas, index=filas)\n",
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "31229dd6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-10T02:45:56.832029Z",
     "start_time": "2022-11-10T02:45:56.823014Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRECISION</th>\n",
       "      <th>RECALL</th>\n",
       "      <th>F1</th>\n",
       "      <th>TIEMPO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>XGBoost_full</th>\n",
       "      <td>0.693811</td>\n",
       "      <td>0.247841</td>\n",
       "      <td>0.365173</td>\n",
       "      <td>1493</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              PRECISION    RECALL        F1  TIEMPO\n",
       "XGBoost_full   0.693811  0.247841  0.365173    1493"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tiempo expresado en segundos\n",
    "resultados['TIEMPO'] = 1493\n",
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "5aefbaf6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-10T02:45:57.910995Z",
     "start_time": "2022-11-10T02:45:57.895473Z"
    }
   },
   "outputs": [],
   "source": [
    "resultados.to_pickle(\"resultados_xgb_full.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "07788627",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-10T02:45:58.569730Z",
     "start_time": "2022-11-10T02:45:58.554591Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[17770.3980353 ,   219.63054203],\n",
       "        [ 1511.03421725,   498.11093953]]])"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados_cm = gmean(xgb_full_results_cm)\n",
    "resultados_cm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "840116ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-10T02:45:59.231432Z",
     "start_time": "2022-11-10T02:45:59.225433Z"
    }
   },
   "outputs": [],
   "source": [
    " with open('resultados_xgb_full_cm.pkl','wb') as f:\n",
    "        pickle.dump(resultados_cm, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3281a92",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af37e378",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1ff418",
   "metadata": {},
   "source": [
    "<font size='5' style=\"color:orange\">  <b> Catboost Classifier - Default </b> </font>\n",
    "<a name=\"cb_default\"></a>\n",
    "\n",
    "[[ Back to Top ]](#content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "b6de5c04",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-11T00:13:36.095775Z",
     "start_time": "2022-11-11T00:03:04.873526Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.09461\n",
      "0:\tlearn: 0.6142038\ttotal: 221ms\tremaining: 3m 41s\n",
      "1:\tlearn: 0.5502873\ttotal: 287ms\tremaining: 2m 23s\n",
      "2:\tlearn: 0.5015346\ttotal: 357ms\tremaining: 1m 58s\n",
      "3:\tlearn: 0.4635310\ttotal: 421ms\tremaining: 1m 44s\n",
      "4:\tlearn: 0.4322948\ttotal: 493ms\tremaining: 1m 38s\n",
      "5:\tlearn: 0.4070403\ttotal: 550ms\tremaining: 1m 31s\n",
      "6:\tlearn: 0.3867937\ttotal: 606ms\tremaining: 1m 25s\n",
      "7:\tlearn: 0.3706352\ttotal: 661ms\tremaining: 1m 21s\n",
      "8:\tlearn: 0.3580597\ttotal: 723ms\tremaining: 1m 19s\n",
      "9:\tlearn: 0.3479389\ttotal: 783ms\tremaining: 1m 17s\n",
      "10:\tlearn: 0.3398434\ttotal: 837ms\tremaining: 1m 15s\n",
      "11:\tlearn: 0.3322477\ttotal: 890ms\tremaining: 1m 13s\n",
      "12:\tlearn: 0.3264440\ttotal: 941ms\tremaining: 1m 11s\n",
      "13:\tlearn: 0.3212962\ttotal: 1s\tremaining: 1m 10s\n",
      "14:\tlearn: 0.3171745\ttotal: 1.05s\tremaining: 1m 9s\n",
      "15:\tlearn: 0.3136426\ttotal: 1.1s\tremaining: 1m 7s\n",
      "16:\tlearn: 0.3104751\ttotal: 1.15s\tremaining: 1m 6s\n",
      "17:\tlearn: 0.3078731\ttotal: 1.2s\tremaining: 1m 5s\n",
      "18:\tlearn: 0.3055370\ttotal: 1.25s\tremaining: 1m 4s\n",
      "19:\tlearn: 0.3034041\ttotal: 1.31s\tremaining: 1m 4s\n",
      "20:\tlearn: 0.3014853\ttotal: 1.36s\tremaining: 1m 3s\n",
      "21:\tlearn: 0.2996796\ttotal: 1.42s\tremaining: 1m 3s\n",
      "22:\tlearn: 0.2980928\ttotal: 1.47s\tremaining: 1m 2s\n",
      "23:\tlearn: 0.2966960\ttotal: 1.52s\tremaining: 1m 1s\n",
      "24:\tlearn: 0.2953797\ttotal: 1.57s\tremaining: 1m 1s\n",
      "25:\tlearn: 0.2941080\ttotal: 1.63s\tremaining: 1m\n",
      "26:\tlearn: 0.2929355\ttotal: 1.68s\tremaining: 1m\n",
      "27:\tlearn: 0.2918143\ttotal: 1.74s\tremaining: 1m\n",
      "28:\tlearn: 0.2906902\ttotal: 1.79s\tremaining: 59.9s\n",
      "29:\tlearn: 0.2896840\ttotal: 1.84s\tremaining: 59.4s\n",
      "30:\tlearn: 0.2887160\ttotal: 1.89s\tremaining: 59.1s\n",
      "31:\tlearn: 0.2878081\ttotal: 1.94s\tremaining: 58.8s\n",
      "32:\tlearn: 0.2869141\ttotal: 2s\tremaining: 58.5s\n",
      "33:\tlearn: 0.2860566\ttotal: 2.05s\tremaining: 58.1s\n",
      "34:\tlearn: 0.2851636\ttotal: 2.1s\tremaining: 58s\n",
      "35:\tlearn: 0.2843442\ttotal: 2.16s\tremaining: 57.8s\n",
      "36:\tlearn: 0.2835199\ttotal: 2.21s\tremaining: 57.6s\n",
      "37:\tlearn: 0.2827355\ttotal: 2.26s\tremaining: 57.3s\n",
      "38:\tlearn: 0.2818968\ttotal: 2.31s\tremaining: 57s\n",
      "39:\tlearn: 0.2812021\ttotal: 2.36s\tremaining: 56.7s\n",
      "40:\tlearn: 0.2803988\ttotal: 2.42s\tremaining: 56.7s\n",
      "41:\tlearn: 0.2795960\ttotal: 2.48s\tremaining: 56.7s\n",
      "42:\tlearn: 0.2788981\ttotal: 2.54s\tremaining: 56.5s\n",
      "43:\tlearn: 0.2781514\ttotal: 2.6s\tremaining: 56.4s\n",
      "44:\tlearn: 0.2773885\ttotal: 2.65s\tremaining: 56.3s\n",
      "45:\tlearn: 0.2767020\ttotal: 2.71s\tremaining: 56.2s\n",
      "46:\tlearn: 0.2760428\ttotal: 2.75s\tremaining: 55.8s\n",
      "47:\tlearn: 0.2754169\ttotal: 2.8s\tremaining: 55.5s\n",
      "48:\tlearn: 0.2747545\ttotal: 2.85s\tremaining: 55.3s\n",
      "49:\tlearn: 0.2740447\ttotal: 2.91s\tremaining: 55.2s\n",
      "50:\tlearn: 0.2733770\ttotal: 2.96s\tremaining: 55s\n",
      "51:\tlearn: 0.2727955\ttotal: 3s\tremaining: 54.8s\n",
      "52:\tlearn: 0.2721900\ttotal: 3.06s\tremaining: 54.6s\n",
      "53:\tlearn: 0.2715424\ttotal: 3.11s\tremaining: 54.5s\n",
      "54:\tlearn: 0.2708886\ttotal: 3.17s\tremaining: 54.4s\n",
      "55:\tlearn: 0.2702778\ttotal: 3.24s\tremaining: 54.7s\n",
      "56:\tlearn: 0.2696702\ttotal: 3.3s\tremaining: 54.6s\n",
      "57:\tlearn: 0.2690893\ttotal: 3.38s\tremaining: 54.9s\n",
      "58:\tlearn: 0.2685493\ttotal: 3.43s\tremaining: 54.8s\n",
      "59:\tlearn: 0.2680068\ttotal: 3.49s\tremaining: 54.7s\n",
      "60:\tlearn: 0.2674528\ttotal: 3.54s\tremaining: 54.6s\n",
      "61:\tlearn: 0.2668972\ttotal: 3.6s\tremaining: 54.5s\n",
      "62:\tlearn: 0.2663603\ttotal: 3.66s\tremaining: 54.4s\n",
      "63:\tlearn: 0.2658702\ttotal: 3.71s\tremaining: 54.2s\n",
      "64:\tlearn: 0.2653351\ttotal: 3.76s\tremaining: 54.1s\n",
      "65:\tlearn: 0.2647585\ttotal: 3.82s\tremaining: 54.1s\n",
      "66:\tlearn: 0.2641885\ttotal: 3.88s\tremaining: 54.1s\n",
      "67:\tlearn: 0.2636967\ttotal: 3.94s\tremaining: 54s\n",
      "68:\tlearn: 0.2631355\ttotal: 4s\tremaining: 54s\n",
      "69:\tlearn: 0.2626274\ttotal: 4.06s\tremaining: 53.9s\n",
      "70:\tlearn: 0.2621702\ttotal: 4.11s\tremaining: 53.8s\n",
      "71:\tlearn: 0.2616628\ttotal: 4.16s\tremaining: 53.7s\n",
      "72:\tlearn: 0.2612038\ttotal: 4.22s\tremaining: 53.6s\n",
      "73:\tlearn: 0.2607650\ttotal: 4.27s\tremaining: 53.4s\n",
      "74:\tlearn: 0.2603129\ttotal: 4.32s\tremaining: 53.3s\n",
      "75:\tlearn: 0.2598294\ttotal: 4.38s\tremaining: 53.3s\n",
      "76:\tlearn: 0.2593102\ttotal: 4.51s\tremaining: 54s\n",
      "77:\tlearn: 0.2588808\ttotal: 4.56s\tremaining: 54s\n",
      "78:\tlearn: 0.2584642\ttotal: 4.62s\tremaining: 53.9s\n",
      "79:\tlearn: 0.2579396\ttotal: 4.69s\tremaining: 54s\n",
      "80:\tlearn: 0.2575016\ttotal: 4.75s\tremaining: 53.9s\n",
      "81:\tlearn: 0.2571289\ttotal: 4.82s\tremaining: 54s\n",
      "82:\tlearn: 0.2566727\ttotal: 4.88s\tremaining: 54s\n",
      "83:\tlearn: 0.2562483\ttotal: 4.95s\tremaining: 54s\n",
      "84:\tlearn: 0.2558233\ttotal: 5.01s\tremaining: 53.9s\n",
      "85:\tlearn: 0.2554091\ttotal: 5.06s\tremaining: 53.8s\n",
      "86:\tlearn: 0.2549930\ttotal: 5.11s\tremaining: 53.6s\n",
      "87:\tlearn: 0.2545453\ttotal: 5.17s\tremaining: 53.6s\n",
      "88:\tlearn: 0.2541514\ttotal: 5.22s\tremaining: 53.5s\n",
      "89:\tlearn: 0.2537286\ttotal: 5.28s\tremaining: 53.4s\n",
      "90:\tlearn: 0.2533429\ttotal: 5.34s\tremaining: 53.4s\n",
      "91:\tlearn: 0.2529483\ttotal: 5.41s\tremaining: 53.4s\n",
      "92:\tlearn: 0.2525452\ttotal: 5.47s\tremaining: 53.4s\n",
      "93:\tlearn: 0.2521266\ttotal: 5.53s\tremaining: 53.3s\n",
      "94:\tlearn: 0.2517388\ttotal: 5.59s\tremaining: 53.3s\n",
      "95:\tlearn: 0.2513463\ttotal: 5.65s\tremaining: 53.2s\n",
      "96:\tlearn: 0.2509959\ttotal: 5.7s\tremaining: 53.1s\n",
      "97:\tlearn: 0.2506223\ttotal: 5.77s\tremaining: 53.1s\n",
      "98:\tlearn: 0.2502622\ttotal: 5.83s\tremaining: 53.1s\n",
      "99:\tlearn: 0.2498870\ttotal: 5.88s\tremaining: 52.9s\n",
      "100:\tlearn: 0.2495113\ttotal: 5.94s\tremaining: 52.9s\n",
      "101:\tlearn: 0.2491540\ttotal: 5.99s\tremaining: 52.8s\n",
      "102:\tlearn: 0.2487877\ttotal: 6.08s\tremaining: 52.9s\n",
      "103:\tlearn: 0.2484240\ttotal: 6.16s\tremaining: 53.1s\n",
      "104:\tlearn: 0.2481031\ttotal: 6.23s\tremaining: 53.1s\n",
      "105:\tlearn: 0.2477184\ttotal: 6.3s\tremaining: 53.1s\n",
      "106:\tlearn: 0.2473682\ttotal: 6.36s\tremaining: 53.1s\n",
      "107:\tlearn: 0.2470292\ttotal: 6.43s\tremaining: 53.1s\n",
      "108:\tlearn: 0.2466912\ttotal: 6.5s\tremaining: 53.1s\n",
      "109:\tlearn: 0.2463625\ttotal: 6.58s\tremaining: 53.2s\n",
      "110:\tlearn: 0.2460212\ttotal: 6.65s\tremaining: 53.3s\n",
      "111:\tlearn: 0.2456700\ttotal: 6.72s\tremaining: 53.3s\n",
      "112:\tlearn: 0.2453363\ttotal: 6.78s\tremaining: 53.3s\n",
      "113:\tlearn: 0.2449699\ttotal: 6.85s\tremaining: 53.3s\n",
      "114:\tlearn: 0.2446664\ttotal: 6.9s\tremaining: 53.1s\n",
      "115:\tlearn: 0.2443156\ttotal: 6.96s\tremaining: 53.1s\n",
      "116:\tlearn: 0.2440216\ttotal: 7.01s\tremaining: 52.9s\n",
      "117:\tlearn: 0.2436853\ttotal: 7.07s\tremaining: 52.9s\n",
      "118:\tlearn: 0.2433734\ttotal: 7.12s\tremaining: 52.7s\n",
      "119:\tlearn: 0.2430472\ttotal: 7.18s\tremaining: 52.7s\n",
      "120:\tlearn: 0.2427014\ttotal: 7.24s\tremaining: 52.6s\n",
      "121:\tlearn: 0.2423825\ttotal: 7.3s\tremaining: 52.6s\n",
      "122:\tlearn: 0.2420962\ttotal: 7.35s\tremaining: 52.4s\n",
      "123:\tlearn: 0.2417855\ttotal: 7.41s\tremaining: 52.3s\n",
      "124:\tlearn: 0.2414989\ttotal: 7.46s\tremaining: 52.2s\n",
      "125:\tlearn: 0.2411818\ttotal: 7.51s\tremaining: 52.1s\n",
      "126:\tlearn: 0.2408652\ttotal: 7.56s\tremaining: 52s\n",
      "127:\tlearn: 0.2405471\ttotal: 7.63s\tremaining: 52s\n",
      "128:\tlearn: 0.2402491\ttotal: 7.68s\tremaining: 51.9s\n",
      "129:\tlearn: 0.2399493\ttotal: 7.75s\tremaining: 51.8s\n",
      "130:\tlearn: 0.2396565\ttotal: 7.8s\tremaining: 51.7s\n",
      "131:\tlearn: 0.2393401\ttotal: 7.86s\tremaining: 51.7s\n",
      "132:\tlearn: 0.2390614\ttotal: 7.91s\tremaining: 51.6s\n",
      "133:\tlearn: 0.2387541\ttotal: 7.97s\tremaining: 51.5s\n",
      "134:\tlearn: 0.2384429\ttotal: 8.02s\tremaining: 51.4s\n",
      "135:\tlearn: 0.2381707\ttotal: 8.08s\tremaining: 51.4s\n",
      "136:\tlearn: 0.2378813\ttotal: 8.15s\tremaining: 51.3s\n",
      "137:\tlearn: 0.2376128\ttotal: 8.21s\tremaining: 51.3s\n",
      "138:\tlearn: 0.2373229\ttotal: 8.27s\tremaining: 51.3s\n",
      "139:\tlearn: 0.2370330\ttotal: 8.35s\tremaining: 51.3s\n",
      "140:\tlearn: 0.2367503\ttotal: 8.41s\tremaining: 51.3s\n",
      "141:\tlearn: 0.2364960\ttotal: 8.47s\tremaining: 51.2s\n",
      "142:\tlearn: 0.2362407\ttotal: 8.54s\tremaining: 51.2s\n",
      "143:\tlearn: 0.2359843\ttotal: 8.6s\tremaining: 51.1s\n",
      "144:\tlearn: 0.2357119\ttotal: 8.67s\tremaining: 51.1s\n",
      "145:\tlearn: 0.2354612\ttotal: 8.74s\tremaining: 51.1s\n",
      "146:\tlearn: 0.2351958\ttotal: 8.8s\tremaining: 51.1s\n",
      "147:\tlearn: 0.2349225\ttotal: 8.86s\tremaining: 51s\n",
      "148:\tlearn: 0.2346514\ttotal: 8.91s\tremaining: 50.9s\n",
      "149:\tlearn: 0.2343706\ttotal: 8.97s\tremaining: 50.8s\n",
      "150:\tlearn: 0.2341148\ttotal: 9.02s\tremaining: 50.7s\n",
      "151:\tlearn: 0.2338524\ttotal: 9.07s\tremaining: 50.6s\n",
      "152:\tlearn: 0.2335941\ttotal: 9.12s\tremaining: 50.5s\n",
      "153:\tlearn: 0.2333354\ttotal: 9.17s\tremaining: 50.4s\n",
      "154:\tlearn: 0.2331005\ttotal: 9.23s\tremaining: 50.3s\n",
      "155:\tlearn: 0.2328300\ttotal: 9.29s\tremaining: 50.3s\n",
      "156:\tlearn: 0.2325541\ttotal: 9.35s\tremaining: 50.2s\n",
      "157:\tlearn: 0.2323009\ttotal: 9.39s\tremaining: 50.1s\n",
      "158:\tlearn: 0.2320775\ttotal: 9.44s\tremaining: 49.9s\n",
      "159:\tlearn: 0.2318313\ttotal: 9.49s\tremaining: 49.8s\n",
      "160:\tlearn: 0.2315827\ttotal: 9.54s\tremaining: 49.7s\n",
      "161:\tlearn: 0.2313356\ttotal: 9.59s\tremaining: 49.6s\n",
      "162:\tlearn: 0.2310893\ttotal: 9.64s\tremaining: 49.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163:\tlearn: 0.2308516\ttotal: 9.7s\tremaining: 49.4s\n",
      "164:\tlearn: 0.2306189\ttotal: 9.75s\tremaining: 49.4s\n",
      "165:\tlearn: 0.2303548\ttotal: 9.81s\tremaining: 49.3s\n",
      "166:\tlearn: 0.2301090\ttotal: 9.86s\tremaining: 49.2s\n",
      "167:\tlearn: 0.2298659\ttotal: 9.92s\tremaining: 49.1s\n",
      "168:\tlearn: 0.2296394\ttotal: 9.97s\tremaining: 49s\n",
      "169:\tlearn: 0.2294082\ttotal: 10s\tremaining: 48.9s\n",
      "170:\tlearn: 0.2291841\ttotal: 10.1s\tremaining: 48.9s\n",
      "171:\tlearn: 0.2289364\ttotal: 10.1s\tremaining: 48.8s\n",
      "172:\tlearn: 0.2287056\ttotal: 10.2s\tremaining: 48.7s\n",
      "173:\tlearn: 0.2284449\ttotal: 10.2s\tremaining: 48.6s\n",
      "174:\tlearn: 0.2282165\ttotal: 10.3s\tremaining: 48.5s\n",
      "175:\tlearn: 0.2280002\ttotal: 10.3s\tremaining: 48.4s\n",
      "176:\tlearn: 0.2277399\ttotal: 10.4s\tremaining: 48.4s\n",
      "177:\tlearn: 0.2275053\ttotal: 10.5s\tremaining: 48.4s\n",
      "178:\tlearn: 0.2272979\ttotal: 10.5s\tremaining: 48.3s\n",
      "179:\tlearn: 0.2270767\ttotal: 10.6s\tremaining: 48.2s\n",
      "180:\tlearn: 0.2268469\ttotal: 10.6s\tremaining: 48.1s\n",
      "181:\tlearn: 0.2266316\ttotal: 10.7s\tremaining: 48s\n",
      "182:\tlearn: 0.2264050\ttotal: 10.7s\tremaining: 47.9s\n",
      "183:\tlearn: 0.2261756\ttotal: 10.8s\tremaining: 47.8s\n",
      "184:\tlearn: 0.2259580\ttotal: 10.8s\tremaining: 47.8s\n",
      "185:\tlearn: 0.2257576\ttotal: 10.9s\tremaining: 47.7s\n",
      "186:\tlearn: 0.2255616\ttotal: 10.9s\tremaining: 47.6s\n",
      "187:\tlearn: 0.2253396\ttotal: 11s\tremaining: 47.5s\n",
      "188:\tlearn: 0.2251348\ttotal: 11s\tremaining: 47.4s\n",
      "189:\tlearn: 0.2249119\ttotal: 11.1s\tremaining: 47.3s\n",
      "190:\tlearn: 0.2246856\ttotal: 11.2s\tremaining: 47.3s\n",
      "191:\tlearn: 0.2244443\ttotal: 11.2s\tremaining: 47.2s\n",
      "192:\tlearn: 0.2242311\ttotal: 11.3s\tremaining: 47.1s\n",
      "193:\tlearn: 0.2240321\ttotal: 11.3s\tremaining: 47.1s\n",
      "194:\tlearn: 0.2238317\ttotal: 11.4s\tremaining: 47s\n",
      "195:\tlearn: 0.2236180\ttotal: 11.5s\tremaining: 47s\n",
      "196:\tlearn: 0.2234035\ttotal: 11.5s\tremaining: 46.9s\n",
      "197:\tlearn: 0.2231868\ttotal: 11.6s\tremaining: 46.9s\n",
      "198:\tlearn: 0.2229884\ttotal: 11.6s\tremaining: 46.8s\n",
      "199:\tlearn: 0.2227877\ttotal: 11.7s\tremaining: 46.8s\n",
      "200:\tlearn: 0.2226054\ttotal: 11.7s\tremaining: 46.7s\n",
      "201:\tlearn: 0.2224084\ttotal: 11.8s\tremaining: 46.6s\n",
      "202:\tlearn: 0.2222092\ttotal: 11.9s\tremaining: 46.5s\n",
      "203:\tlearn: 0.2220199\ttotal: 11.9s\tremaining: 46.4s\n",
      "204:\tlearn: 0.2218160\ttotal: 12s\tremaining: 46.4s\n",
      "205:\tlearn: 0.2216224\ttotal: 12s\tremaining: 46.3s\n",
      "206:\tlearn: 0.2214257\ttotal: 12.1s\tremaining: 46.2s\n",
      "207:\tlearn: 0.2212214\ttotal: 12.1s\tremaining: 46.1s\n",
      "208:\tlearn: 0.2210361\ttotal: 12.2s\tremaining: 46s\n",
      "209:\tlearn: 0.2208618\ttotal: 12.2s\tremaining: 46s\n",
      "210:\tlearn: 0.2206686\ttotal: 12.3s\tremaining: 45.9s\n",
      "211:\tlearn: 0.2204740\ttotal: 12.3s\tremaining: 45.9s\n",
      "212:\tlearn: 0.2202936\ttotal: 12.4s\tremaining: 45.8s\n",
      "213:\tlearn: 0.2201032\ttotal: 12.5s\tremaining: 45.8s\n",
      "214:\tlearn: 0.2199117\ttotal: 12.5s\tremaining: 45.7s\n",
      "215:\tlearn: 0.2197210\ttotal: 12.6s\tremaining: 45.7s\n",
      "216:\tlearn: 0.2195242\ttotal: 12.6s\tremaining: 45.6s\n",
      "217:\tlearn: 0.2193328\ttotal: 12.7s\tremaining: 45.6s\n",
      "218:\tlearn: 0.2191655\ttotal: 12.8s\tremaining: 45.5s\n",
      "219:\tlearn: 0.2189751\ttotal: 12.8s\tremaining: 45.4s\n",
      "220:\tlearn: 0.2187876\ttotal: 12.9s\tremaining: 45.3s\n",
      "221:\tlearn: 0.2186024\ttotal: 12.9s\tremaining: 45.3s\n",
      "222:\tlearn: 0.2184242\ttotal: 13s\tremaining: 45.2s\n",
      "223:\tlearn: 0.2182313\ttotal: 13s\tremaining: 45.2s\n",
      "224:\tlearn: 0.2180544\ttotal: 13.1s\tremaining: 45.1s\n",
      "225:\tlearn: 0.2178802\ttotal: 13.1s\tremaining: 45s\n",
      "226:\tlearn: 0.2177076\ttotal: 13.2s\tremaining: 45s\n",
      "227:\tlearn: 0.2175233\ttotal: 13.3s\tremaining: 44.9s\n",
      "228:\tlearn: 0.2173505\ttotal: 13.3s\tremaining: 44.8s\n",
      "229:\tlearn: 0.2171802\ttotal: 13.4s\tremaining: 44.8s\n",
      "230:\tlearn: 0.2170019\ttotal: 13.4s\tremaining: 44.7s\n",
      "231:\tlearn: 0.2168266\ttotal: 13.5s\tremaining: 44.6s\n",
      "232:\tlearn: 0.2166443\ttotal: 13.5s\tremaining: 44.6s\n",
      "233:\tlearn: 0.2164755\ttotal: 13.6s\tremaining: 44.5s\n",
      "234:\tlearn: 0.2162758\ttotal: 13.6s\tremaining: 44.4s\n",
      "235:\tlearn: 0.2161219\ttotal: 13.7s\tremaining: 44.3s\n",
      "236:\tlearn: 0.2159514\ttotal: 13.8s\tremaining: 44.3s\n",
      "237:\tlearn: 0.2157774\ttotal: 13.8s\tremaining: 44.2s\n",
      "238:\tlearn: 0.2156090\ttotal: 13.9s\tremaining: 44.2s\n",
      "239:\tlearn: 0.2154495\ttotal: 14s\tremaining: 44.2s\n",
      "240:\tlearn: 0.2152821\ttotal: 14s\tremaining: 44.1s\n",
      "241:\tlearn: 0.2151103\ttotal: 14.1s\tremaining: 44.1s\n",
      "242:\tlearn: 0.2149517\ttotal: 14.1s\tremaining: 44s\n",
      "243:\tlearn: 0.2147655\ttotal: 14.2s\tremaining: 43.9s\n",
      "244:\tlearn: 0.2146186\ttotal: 14.2s\tremaining: 43.8s\n",
      "245:\tlearn: 0.2144456\ttotal: 14.3s\tremaining: 43.8s\n",
      "246:\tlearn: 0.2142730\ttotal: 14.3s\tremaining: 43.7s\n",
      "247:\tlearn: 0.2141233\ttotal: 14.4s\tremaining: 43.7s\n",
      "248:\tlearn: 0.2139714\ttotal: 14.5s\tremaining: 43.6s\n",
      "249:\tlearn: 0.2138123\ttotal: 14.5s\tremaining: 43.5s\n",
      "250:\tlearn: 0.2136373\ttotal: 14.6s\tremaining: 43.5s\n",
      "251:\tlearn: 0.2134857\ttotal: 14.6s\tremaining: 43.4s\n",
      "252:\tlearn: 0.2133177\ttotal: 14.7s\tremaining: 43.4s\n",
      "253:\tlearn: 0.2131544\ttotal: 14.8s\tremaining: 43.3s\n",
      "254:\tlearn: 0.2130085\ttotal: 14.8s\tremaining: 43.3s\n",
      "255:\tlearn: 0.2128505\ttotal: 14.9s\tremaining: 43.2s\n",
      "256:\tlearn: 0.2126930\ttotal: 14.9s\tremaining: 43.1s\n",
      "257:\tlearn: 0.2125359\ttotal: 15s\tremaining: 43.1s\n",
      "258:\tlearn: 0.2123811\ttotal: 15s\tremaining: 43s\n",
      "259:\tlearn: 0.2122241\ttotal: 15.1s\tremaining: 42.9s\n",
      "260:\tlearn: 0.2120620\ttotal: 15.1s\tremaining: 42.8s\n",
      "261:\tlearn: 0.2118923\ttotal: 15.2s\tremaining: 42.8s\n",
      "262:\tlearn: 0.2117447\ttotal: 15.2s\tremaining: 42.7s\n",
      "263:\tlearn: 0.2115985\ttotal: 15.3s\tremaining: 42.6s\n",
      "264:\tlearn: 0.2114587\ttotal: 15.3s\tremaining: 42.6s\n",
      "265:\tlearn: 0.2112826\ttotal: 15.4s\tremaining: 42.5s\n",
      "266:\tlearn: 0.2111463\ttotal: 15.4s\tremaining: 42.4s\n",
      "267:\tlearn: 0.2109991\ttotal: 15.5s\tremaining: 42.3s\n",
      "268:\tlearn: 0.2108480\ttotal: 15.6s\tremaining: 42.3s\n",
      "269:\tlearn: 0.2107005\ttotal: 15.6s\tremaining: 42.2s\n",
      "270:\tlearn: 0.2105514\ttotal: 15.7s\tremaining: 42.1s\n",
      "271:\tlearn: 0.2104161\ttotal: 15.7s\tremaining: 42.1s\n",
      "272:\tlearn: 0.2102733\ttotal: 15.8s\tremaining: 42.1s\n",
      "273:\tlearn: 0.2101380\ttotal: 15.9s\tremaining: 42s\n",
      "274:\tlearn: 0.2099875\ttotal: 15.9s\tremaining: 42s\n",
      "275:\tlearn: 0.2098539\ttotal: 16s\tremaining: 41.9s\n",
      "276:\tlearn: 0.2097140\ttotal: 16s\tremaining: 41.9s\n",
      "277:\tlearn: 0.2095815\ttotal: 16.1s\tremaining: 41.8s\n",
      "278:\tlearn: 0.2094411\ttotal: 16.1s\tremaining: 41.7s\n",
      "279:\tlearn: 0.2092908\ttotal: 16.2s\tremaining: 41.7s\n",
      "280:\tlearn: 0.2091255\ttotal: 16.3s\tremaining: 41.6s\n",
      "281:\tlearn: 0.2089686\ttotal: 16.3s\tremaining: 41.6s\n",
      "282:\tlearn: 0.2088277\ttotal: 16.4s\tremaining: 41.5s\n",
      "283:\tlearn: 0.2086815\ttotal: 16.5s\tremaining: 41.5s\n",
      "284:\tlearn: 0.2085397\ttotal: 16.5s\tremaining: 41.4s\n",
      "285:\tlearn: 0.2084062\ttotal: 16.6s\tremaining: 41.3s\n",
      "286:\tlearn: 0.2082602\ttotal: 16.6s\tremaining: 41.3s\n",
      "287:\tlearn: 0.2081233\ttotal: 16.7s\tremaining: 41.2s\n",
      "288:\tlearn: 0.2079967\ttotal: 16.7s\tremaining: 41.1s\n",
      "289:\tlearn: 0.2078546\ttotal: 16.8s\tremaining: 41.1s\n",
      "290:\tlearn: 0.2077187\ttotal: 16.8s\tremaining: 41s\n",
      "291:\tlearn: 0.2075759\ttotal: 16.9s\tremaining: 40.9s\n",
      "292:\tlearn: 0.2074353\ttotal: 16.9s\tremaining: 40.9s\n",
      "293:\tlearn: 0.2072937\ttotal: 17s\tremaining: 40.8s\n",
      "294:\tlearn: 0.2071665\ttotal: 17s\tremaining: 40.7s\n",
      "295:\tlearn: 0.2070291\ttotal: 17.1s\tremaining: 40.7s\n",
      "296:\tlearn: 0.2068993\ttotal: 17.2s\tremaining: 40.6s\n",
      "297:\tlearn: 0.2067548\ttotal: 17.2s\tremaining: 40.6s\n",
      "298:\tlearn: 0.2066122\ttotal: 17.3s\tremaining: 40.5s\n",
      "299:\tlearn: 0.2064743\ttotal: 17.4s\tremaining: 40.5s\n",
      "300:\tlearn: 0.2063554\ttotal: 17.4s\tremaining: 40.5s\n",
      "301:\tlearn: 0.2062363\ttotal: 17.5s\tremaining: 40.4s\n",
      "302:\tlearn: 0.2061047\ttotal: 17.5s\tremaining: 40.3s\n",
      "303:\tlearn: 0.2059788\ttotal: 17.6s\tremaining: 40.2s\n",
      "304:\tlearn: 0.2058576\ttotal: 17.6s\tremaining: 40.2s\n",
      "305:\tlearn: 0.2057170\ttotal: 17.7s\tremaining: 40.1s\n",
      "306:\tlearn: 0.2055827\ttotal: 17.7s\tremaining: 40s\n",
      "307:\tlearn: 0.2054614\ttotal: 17.8s\tremaining: 40s\n",
      "308:\tlearn: 0.2053341\ttotal: 17.9s\tremaining: 39.9s\n",
      "309:\tlearn: 0.2052065\ttotal: 17.9s\tremaining: 39.9s\n",
      "310:\tlearn: 0.2050832\ttotal: 18s\tremaining: 39.8s\n",
      "311:\tlearn: 0.2049471\ttotal: 18s\tremaining: 39.8s\n",
      "312:\tlearn: 0.2048159\ttotal: 18.1s\tremaining: 39.7s\n",
      "313:\tlearn: 0.2046850\ttotal: 18.2s\tremaining: 39.7s\n",
      "314:\tlearn: 0.2045371\ttotal: 18.2s\tremaining: 39.6s\n",
      "315:\tlearn: 0.2044135\ttotal: 18.3s\tremaining: 39.6s\n",
      "316:\tlearn: 0.2042814\ttotal: 18.3s\tremaining: 39.5s\n",
      "317:\tlearn: 0.2041494\ttotal: 18.4s\tremaining: 39.5s\n",
      "318:\tlearn: 0.2040276\ttotal: 18.5s\tremaining: 39.4s\n",
      "319:\tlearn: 0.2039000\ttotal: 18.5s\tremaining: 39.4s\n",
      "320:\tlearn: 0.2037744\ttotal: 18.6s\tremaining: 39.3s\n",
      "321:\tlearn: 0.2036416\ttotal: 18.6s\tremaining: 39.3s\n",
      "322:\tlearn: 0.2035283\ttotal: 18.7s\tremaining: 39.2s\n",
      "323:\tlearn: 0.2034080\ttotal: 18.8s\tremaining: 39.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "324:\tlearn: 0.2032764\ttotal: 18.8s\tremaining: 39.1s\n",
      "325:\tlearn: 0.2031677\ttotal: 18.9s\tremaining: 39s\n",
      "326:\tlearn: 0.2030588\ttotal: 18.9s\tremaining: 39s\n",
      "327:\tlearn: 0.2029347\ttotal: 19s\tremaining: 38.9s\n",
      "328:\tlearn: 0.2028085\ttotal: 19s\tremaining: 38.8s\n",
      "329:\tlearn: 0.2026965\ttotal: 19.1s\tremaining: 38.8s\n",
      "330:\tlearn: 0.2025661\ttotal: 19.1s\tremaining: 38.7s\n",
      "331:\tlearn: 0.2024338\ttotal: 19.2s\tremaining: 38.6s\n",
      "332:\tlearn: 0.2023132\ttotal: 19.3s\tremaining: 38.6s\n",
      "333:\tlearn: 0.2022004\ttotal: 19.3s\tremaining: 38.5s\n",
      "334:\tlearn: 0.2020762\ttotal: 19.4s\tremaining: 38.4s\n",
      "335:\tlearn: 0.2019654\ttotal: 19.4s\tremaining: 38.4s\n",
      "336:\tlearn: 0.2018397\ttotal: 19.5s\tremaining: 38.3s\n",
      "337:\tlearn: 0.2017325\ttotal: 19.5s\tremaining: 38.2s\n",
      "338:\tlearn: 0.2016174\ttotal: 19.6s\tremaining: 38.2s\n",
      "339:\tlearn: 0.2014878\ttotal: 19.6s\tremaining: 38.1s\n",
      "340:\tlearn: 0.2013604\ttotal: 19.7s\tremaining: 38.1s\n",
      "341:\tlearn: 0.2012432\ttotal: 19.7s\tremaining: 38s\n",
      "342:\tlearn: 0.2011109\ttotal: 19.8s\tremaining: 37.9s\n",
      "343:\tlearn: 0.2009930\ttotal: 19.9s\tremaining: 37.9s\n",
      "344:\tlearn: 0.2008642\ttotal: 19.9s\tremaining: 37.8s\n",
      "345:\tlearn: 0.2007522\ttotal: 20s\tremaining: 37.8s\n",
      "346:\tlearn: 0.2006387\ttotal: 20.1s\tremaining: 37.7s\n",
      "347:\tlearn: 0.2005229\ttotal: 20.1s\tremaining: 37.7s\n",
      "348:\tlearn: 0.2003975\ttotal: 20.2s\tremaining: 37.6s\n",
      "349:\tlearn: 0.2002762\ttotal: 20.2s\tremaining: 37.6s\n",
      "350:\tlearn: 0.2001578\ttotal: 20.3s\tremaining: 37.5s\n",
      "351:\tlearn: 0.2000369\ttotal: 20.4s\tremaining: 37.5s\n",
      "352:\tlearn: 0.1999184\ttotal: 20.4s\tremaining: 37.4s\n",
      "353:\tlearn: 0.1998020\ttotal: 20.5s\tremaining: 37.3s\n",
      "354:\tlearn: 0.1996778\ttotal: 20.5s\tremaining: 37.3s\n",
      "355:\tlearn: 0.1995744\ttotal: 20.6s\tremaining: 37.2s\n",
      "356:\tlearn: 0.1994528\ttotal: 20.6s\tremaining: 37.2s\n",
      "357:\tlearn: 0.1993557\ttotal: 20.7s\tremaining: 37.1s\n",
      "358:\tlearn: 0.1992359\ttotal: 20.8s\tremaining: 37.1s\n",
      "359:\tlearn: 0.1991195\ttotal: 20.8s\tremaining: 37s\n",
      "360:\tlearn: 0.1990026\ttotal: 20.9s\tremaining: 37s\n",
      "361:\tlearn: 0.1988939\ttotal: 21s\tremaining: 36.9s\n",
      "362:\tlearn: 0.1987770\ttotal: 21s\tremaining: 36.9s\n",
      "363:\tlearn: 0.1986681\ttotal: 21.1s\tremaining: 36.8s\n",
      "364:\tlearn: 0.1985500\ttotal: 21.1s\tremaining: 36.7s\n",
      "365:\tlearn: 0.1984401\ttotal: 21.2s\tremaining: 36.7s\n",
      "366:\tlearn: 0.1983356\ttotal: 21.2s\tremaining: 36.6s\n",
      "367:\tlearn: 0.1982123\ttotal: 21.3s\tremaining: 36.5s\n",
      "368:\tlearn: 0.1980958\ttotal: 21.3s\tremaining: 36.5s\n",
      "369:\tlearn: 0.1979884\ttotal: 21.4s\tremaining: 36.4s\n",
      "370:\tlearn: 0.1978842\ttotal: 21.5s\tremaining: 36.4s\n",
      "371:\tlearn: 0.1977815\ttotal: 21.5s\tremaining: 36.3s\n",
      "372:\tlearn: 0.1976685\ttotal: 21.6s\tremaining: 36.3s\n",
      "373:\tlearn: 0.1975425\ttotal: 21.6s\tremaining: 36.2s\n",
      "374:\tlearn: 0.1974352\ttotal: 21.7s\tremaining: 36.2s\n",
      "375:\tlearn: 0.1973306\ttotal: 21.8s\tremaining: 36.1s\n",
      "376:\tlearn: 0.1972352\ttotal: 21.8s\tremaining: 36s\n",
      "377:\tlearn: 0.1971339\ttotal: 21.9s\tremaining: 36s\n",
      "378:\tlearn: 0.1970180\ttotal: 21.9s\tremaining: 35.9s\n",
      "379:\tlearn: 0.1969103\ttotal: 22s\tremaining: 35.9s\n",
      "380:\tlearn: 0.1968020\ttotal: 22.1s\tremaining: 35.8s\n",
      "381:\tlearn: 0.1966810\ttotal: 22.1s\tremaining: 35.8s\n",
      "382:\tlearn: 0.1965704\ttotal: 22.2s\tremaining: 35.7s\n",
      "383:\tlearn: 0.1964690\ttotal: 22.2s\tremaining: 35.7s\n",
      "384:\tlearn: 0.1963655\ttotal: 22.3s\tremaining: 35.6s\n",
      "385:\tlearn: 0.1962550\ttotal: 22.4s\tremaining: 35.6s\n",
      "386:\tlearn: 0.1961508\ttotal: 22.4s\tremaining: 35.5s\n",
      "387:\tlearn: 0.1960432\ttotal: 22.5s\tremaining: 35.5s\n",
      "388:\tlearn: 0.1959516\ttotal: 22.5s\tremaining: 35.4s\n",
      "389:\tlearn: 0.1958338\ttotal: 22.6s\tremaining: 35.4s\n",
      "390:\tlearn: 0.1957140\ttotal: 22.7s\tremaining: 35.3s\n",
      "391:\tlearn: 0.1955990\ttotal: 22.7s\tremaining: 35.2s\n",
      "392:\tlearn: 0.1954874\ttotal: 22.8s\tremaining: 35.2s\n",
      "393:\tlearn: 0.1953783\ttotal: 22.9s\tremaining: 35.1s\n",
      "394:\tlearn: 0.1952901\ttotal: 22.9s\tremaining: 35.1s\n",
      "395:\tlearn: 0.1951638\ttotal: 23s\tremaining: 35s\n",
      "396:\tlearn: 0.1950567\ttotal: 23s\tremaining: 35s\n",
      "397:\tlearn: 0.1949557\ttotal: 23.1s\tremaining: 34.9s\n",
      "398:\tlearn: 0.1948487\ttotal: 23.1s\tremaining: 34.8s\n",
      "399:\tlearn: 0.1947485\ttotal: 23.2s\tremaining: 34.8s\n",
      "400:\tlearn: 0.1946609\ttotal: 23.2s\tremaining: 34.7s\n",
      "401:\tlearn: 0.1945520\ttotal: 23.3s\tremaining: 34.7s\n",
      "402:\tlearn: 0.1944509\ttotal: 23.4s\tremaining: 34.6s\n",
      "403:\tlearn: 0.1943501\ttotal: 23.4s\tremaining: 34.6s\n",
      "404:\tlearn: 0.1942528\ttotal: 23.5s\tremaining: 34.5s\n",
      "405:\tlearn: 0.1941366\ttotal: 23.5s\tremaining: 34.4s\n",
      "406:\tlearn: 0.1940301\ttotal: 23.6s\tremaining: 34.4s\n",
      "407:\tlearn: 0.1939278\ttotal: 23.7s\tremaining: 34.3s\n",
      "408:\tlearn: 0.1938239\ttotal: 23.7s\tremaining: 34.3s\n",
      "409:\tlearn: 0.1937298\ttotal: 23.8s\tremaining: 34.2s\n",
      "410:\tlearn: 0.1936405\ttotal: 23.8s\tremaining: 34.1s\n",
      "411:\tlearn: 0.1935519\ttotal: 23.9s\tremaining: 34.1s\n",
      "412:\tlearn: 0.1934592\ttotal: 23.9s\tremaining: 34s\n",
      "413:\tlearn: 0.1933540\ttotal: 24s\tremaining: 33.9s\n",
      "414:\tlearn: 0.1932602\ttotal: 24s\tremaining: 33.9s\n",
      "415:\tlearn: 0.1931626\ttotal: 24.1s\tremaining: 33.8s\n",
      "416:\tlearn: 0.1930588\ttotal: 24.1s\tremaining: 33.8s\n",
      "417:\tlearn: 0.1929540\ttotal: 24.2s\tremaining: 33.7s\n",
      "418:\tlearn: 0.1928494\ttotal: 24.3s\tremaining: 33.7s\n",
      "419:\tlearn: 0.1927460\ttotal: 24.3s\tremaining: 33.6s\n",
      "420:\tlearn: 0.1926427\ttotal: 24.4s\tremaining: 33.6s\n",
      "421:\tlearn: 0.1925477\ttotal: 24.5s\tremaining: 33.5s\n",
      "422:\tlearn: 0.1924379\ttotal: 24.5s\tremaining: 33.5s\n",
      "423:\tlearn: 0.1923460\ttotal: 24.6s\tremaining: 33.4s\n",
      "424:\tlearn: 0.1922412\ttotal: 24.6s\tremaining: 33.3s\n",
      "425:\tlearn: 0.1921288\ttotal: 24.7s\tremaining: 33.3s\n",
      "426:\tlearn: 0.1920280\ttotal: 24.8s\tremaining: 33.3s\n",
      "427:\tlearn: 0.1919289\ttotal: 24.8s\tremaining: 33.2s\n",
      "428:\tlearn: 0.1918278\ttotal: 24.9s\tremaining: 33.2s\n",
      "429:\tlearn: 0.1917201\ttotal: 25s\tremaining: 33.1s\n",
      "430:\tlearn: 0.1916233\ttotal: 25s\tremaining: 33s\n",
      "431:\tlearn: 0.1915236\ttotal: 25.1s\tremaining: 33s\n",
      "432:\tlearn: 0.1914149\ttotal: 25.1s\tremaining: 32.9s\n",
      "433:\tlearn: 0.1913171\ttotal: 25.2s\tremaining: 32.9s\n",
      "434:\tlearn: 0.1912262\ttotal: 25.3s\tremaining: 32.8s\n",
      "435:\tlearn: 0.1911423\ttotal: 25.3s\tremaining: 32.8s\n",
      "436:\tlearn: 0.1910541\ttotal: 25.4s\tremaining: 32.7s\n",
      "437:\tlearn: 0.1909584\ttotal: 25.5s\tremaining: 32.7s\n",
      "438:\tlearn: 0.1908617\ttotal: 25.5s\tremaining: 32.6s\n",
      "439:\tlearn: 0.1907539\ttotal: 25.6s\tremaining: 32.6s\n",
      "440:\tlearn: 0.1906703\ttotal: 25.7s\tremaining: 32.5s\n",
      "441:\tlearn: 0.1905849\ttotal: 25.7s\tremaining: 32.5s\n",
      "442:\tlearn: 0.1904757\ttotal: 25.8s\tremaining: 32.4s\n",
      "443:\tlearn: 0.1903948\ttotal: 25.8s\tremaining: 32.4s\n",
      "444:\tlearn: 0.1903034\ttotal: 25.9s\tremaining: 32.3s\n",
      "445:\tlearn: 0.1902155\ttotal: 26s\tremaining: 32.3s\n",
      "446:\tlearn: 0.1901232\ttotal: 26s\tremaining: 32.2s\n",
      "447:\tlearn: 0.1900513\ttotal: 26.1s\tremaining: 32.1s\n",
      "448:\tlearn: 0.1899610\ttotal: 26.1s\tremaining: 32.1s\n",
      "449:\tlearn: 0.1898653\ttotal: 26.2s\tremaining: 32s\n",
      "450:\tlearn: 0.1897659\ttotal: 26.3s\tremaining: 32s\n",
      "451:\tlearn: 0.1896659\ttotal: 26.3s\tremaining: 31.9s\n",
      "452:\tlearn: 0.1895769\ttotal: 26.4s\tremaining: 31.8s\n",
      "453:\tlearn: 0.1894860\ttotal: 26.4s\tremaining: 31.8s\n",
      "454:\tlearn: 0.1894027\ttotal: 26.5s\tremaining: 31.7s\n",
      "455:\tlearn: 0.1893257\ttotal: 26.5s\tremaining: 31.6s\n",
      "456:\tlearn: 0.1892263\ttotal: 26.6s\tremaining: 31.6s\n",
      "457:\tlearn: 0.1891463\ttotal: 26.6s\tremaining: 31.5s\n",
      "458:\tlearn: 0.1890565\ttotal: 26.7s\tremaining: 31.5s\n",
      "459:\tlearn: 0.1889637\ttotal: 26.8s\tremaining: 31.4s\n",
      "460:\tlearn: 0.1888876\ttotal: 26.8s\tremaining: 31.3s\n",
      "461:\tlearn: 0.1887931\ttotal: 26.9s\tremaining: 31.3s\n",
      "462:\tlearn: 0.1886992\ttotal: 26.9s\tremaining: 31.2s\n",
      "463:\tlearn: 0.1886124\ttotal: 27s\tremaining: 31.2s\n",
      "464:\tlearn: 0.1885278\ttotal: 27s\tremaining: 31.1s\n",
      "465:\tlearn: 0.1884500\ttotal: 27.1s\tremaining: 31s\n",
      "466:\tlearn: 0.1883522\ttotal: 27.1s\tremaining: 31s\n",
      "467:\tlearn: 0.1882650\ttotal: 27.2s\tremaining: 30.9s\n",
      "468:\tlearn: 0.1881851\ttotal: 27.2s\tremaining: 30.8s\n",
      "469:\tlearn: 0.1880933\ttotal: 27.3s\tremaining: 30.8s\n",
      "470:\tlearn: 0.1879979\ttotal: 27.4s\tremaining: 30.7s\n",
      "471:\tlearn: 0.1879171\ttotal: 27.4s\tremaining: 30.7s\n",
      "472:\tlearn: 0.1878186\ttotal: 27.5s\tremaining: 30.6s\n",
      "473:\tlearn: 0.1877330\ttotal: 27.6s\tremaining: 30.6s\n",
      "474:\tlearn: 0.1876523\ttotal: 27.6s\tremaining: 30.5s\n",
      "475:\tlearn: 0.1875693\ttotal: 27.7s\tremaining: 30.5s\n",
      "476:\tlearn: 0.1874756\ttotal: 27.8s\tremaining: 30.4s\n",
      "477:\tlearn: 0.1873868\ttotal: 27.8s\tremaining: 30.4s\n",
      "478:\tlearn: 0.1873000\ttotal: 27.9s\tremaining: 30.4s\n",
      "479:\tlearn: 0.1872012\ttotal: 28s\tremaining: 30.3s\n",
      "480:\tlearn: 0.1871168\ttotal: 28.1s\tremaining: 30.3s\n",
      "481:\tlearn: 0.1870187\ttotal: 28.1s\tremaining: 30.2s\n",
      "482:\tlearn: 0.1869287\ttotal: 28.2s\tremaining: 30.2s\n",
      "483:\tlearn: 0.1868439\ttotal: 28.2s\tremaining: 30.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "484:\tlearn: 0.1867607\ttotal: 28.3s\tremaining: 30.1s\n",
      "485:\tlearn: 0.1866770\ttotal: 28.4s\tremaining: 30s\n",
      "486:\tlearn: 0.1865926\ttotal: 28.4s\tremaining: 30s\n",
      "487:\tlearn: 0.1865167\ttotal: 28.5s\tremaining: 29.9s\n",
      "488:\tlearn: 0.1864231\ttotal: 28.6s\tremaining: 29.9s\n",
      "489:\tlearn: 0.1863288\ttotal: 28.6s\tremaining: 29.8s\n",
      "490:\tlearn: 0.1862551\ttotal: 28.7s\tremaining: 29.7s\n",
      "491:\tlearn: 0.1861638\ttotal: 28.8s\tremaining: 29.7s\n",
      "492:\tlearn: 0.1860791\ttotal: 28.8s\tremaining: 29.6s\n",
      "493:\tlearn: 0.1859942\ttotal: 28.9s\tremaining: 29.6s\n",
      "494:\tlearn: 0.1859187\ttotal: 28.9s\tremaining: 29.5s\n",
      "495:\tlearn: 0.1858380\ttotal: 29s\tremaining: 29.5s\n",
      "496:\tlearn: 0.1857576\ttotal: 29.1s\tremaining: 29.4s\n",
      "497:\tlearn: 0.1856768\ttotal: 29.1s\tremaining: 29.4s\n",
      "498:\tlearn: 0.1855888\ttotal: 29.2s\tremaining: 29.3s\n",
      "499:\tlearn: 0.1855075\ttotal: 29.3s\tremaining: 29.3s\n",
      "500:\tlearn: 0.1854214\ttotal: 29.3s\tremaining: 29.2s\n",
      "501:\tlearn: 0.1853293\ttotal: 29.4s\tremaining: 29.1s\n",
      "502:\tlearn: 0.1852444\ttotal: 29.4s\tremaining: 29.1s\n",
      "503:\tlearn: 0.1851575\ttotal: 29.5s\tremaining: 29s\n",
      "504:\tlearn: 0.1850844\ttotal: 29.6s\tremaining: 29s\n",
      "505:\tlearn: 0.1849902\ttotal: 29.6s\tremaining: 28.9s\n",
      "506:\tlearn: 0.1849020\ttotal: 29.7s\tremaining: 28.9s\n",
      "507:\tlearn: 0.1848166\ttotal: 29.8s\tremaining: 28.8s\n",
      "508:\tlearn: 0.1847257\ttotal: 29.8s\tremaining: 28.8s\n",
      "509:\tlearn: 0.1846588\ttotal: 29.9s\tremaining: 28.7s\n",
      "510:\tlearn: 0.1845702\ttotal: 30s\tremaining: 28.7s\n",
      "511:\tlearn: 0.1844794\ttotal: 30s\tremaining: 28.6s\n",
      "512:\tlearn: 0.1843789\ttotal: 30.1s\tremaining: 28.6s\n",
      "513:\tlearn: 0.1842983\ttotal: 30.2s\tremaining: 28.5s\n",
      "514:\tlearn: 0.1842167\ttotal: 30.2s\tremaining: 28.5s\n",
      "515:\tlearn: 0.1841316\ttotal: 30.3s\tremaining: 28.4s\n",
      "516:\tlearn: 0.1840534\ttotal: 30.4s\tremaining: 28.4s\n",
      "517:\tlearn: 0.1839661\ttotal: 30.4s\tremaining: 28.3s\n",
      "518:\tlearn: 0.1838844\ttotal: 30.5s\tremaining: 28.3s\n",
      "519:\tlearn: 0.1837999\ttotal: 30.6s\tremaining: 28.2s\n",
      "520:\tlearn: 0.1837180\ttotal: 30.6s\tremaining: 28.2s\n",
      "521:\tlearn: 0.1836383\ttotal: 30.7s\tremaining: 28.1s\n",
      "522:\tlearn: 0.1835594\ttotal: 30.8s\tremaining: 28.1s\n",
      "523:\tlearn: 0.1834884\ttotal: 30.8s\tremaining: 28s\n",
      "524:\tlearn: 0.1834261\ttotal: 30.9s\tremaining: 27.9s\n",
      "525:\tlearn: 0.1833495\ttotal: 31s\tremaining: 27.9s\n",
      "526:\tlearn: 0.1832678\ttotal: 31s\tremaining: 27.8s\n",
      "527:\tlearn: 0.1831997\ttotal: 31.1s\tremaining: 27.8s\n",
      "528:\tlearn: 0.1831147\ttotal: 31.1s\tremaining: 27.7s\n",
      "529:\tlearn: 0.1830353\ttotal: 31.2s\tremaining: 27.7s\n",
      "530:\tlearn: 0.1829579\ttotal: 31.3s\tremaining: 27.6s\n",
      "531:\tlearn: 0.1828887\ttotal: 31.3s\tremaining: 27.5s\n",
      "532:\tlearn: 0.1828156\ttotal: 31.4s\tremaining: 27.5s\n",
      "533:\tlearn: 0.1827322\ttotal: 31.4s\tremaining: 27.4s\n",
      "534:\tlearn: 0.1826579\ttotal: 31.5s\tremaining: 27.4s\n",
      "535:\tlearn: 0.1825811\ttotal: 31.6s\tremaining: 27.3s\n",
      "536:\tlearn: 0.1825016\ttotal: 31.6s\tremaining: 27.3s\n",
      "537:\tlearn: 0.1824217\ttotal: 31.7s\tremaining: 27.2s\n",
      "538:\tlearn: 0.1823403\ttotal: 31.8s\tremaining: 27.2s\n",
      "539:\tlearn: 0.1822613\ttotal: 31.8s\tremaining: 27.1s\n",
      "540:\tlearn: 0.1821930\ttotal: 31.9s\tremaining: 27.1s\n",
      "541:\tlearn: 0.1821121\ttotal: 32s\tremaining: 27s\n",
      "542:\tlearn: 0.1820243\ttotal: 32s\tremaining: 27s\n",
      "543:\tlearn: 0.1819447\ttotal: 32.1s\tremaining: 26.9s\n",
      "544:\tlearn: 0.1818549\ttotal: 32.2s\tremaining: 26.9s\n",
      "545:\tlearn: 0.1817768\ttotal: 32.2s\tremaining: 26.8s\n",
      "546:\tlearn: 0.1816949\ttotal: 32.3s\tremaining: 26.8s\n",
      "547:\tlearn: 0.1816276\ttotal: 32.4s\tremaining: 26.7s\n",
      "548:\tlearn: 0.1815532\ttotal: 32.5s\tremaining: 26.7s\n",
      "549:\tlearn: 0.1814832\ttotal: 32.5s\tremaining: 26.6s\n",
      "550:\tlearn: 0.1814187\ttotal: 32.6s\tremaining: 26.6s\n",
      "551:\tlearn: 0.1813295\ttotal: 32.7s\tremaining: 26.5s\n",
      "552:\tlearn: 0.1812481\ttotal: 32.7s\tremaining: 26.5s\n",
      "553:\tlearn: 0.1811680\ttotal: 32.8s\tremaining: 26.4s\n",
      "554:\tlearn: 0.1810800\ttotal: 32.9s\tremaining: 26.4s\n",
      "555:\tlearn: 0.1810215\ttotal: 33s\tremaining: 26.3s\n",
      "556:\tlearn: 0.1809453\ttotal: 33s\tremaining: 26.3s\n",
      "557:\tlearn: 0.1808722\ttotal: 33.1s\tremaining: 26.2s\n",
      "558:\tlearn: 0.1807936\ttotal: 33.1s\tremaining: 26.2s\n",
      "559:\tlearn: 0.1807148\ttotal: 33.2s\tremaining: 26.1s\n",
      "560:\tlearn: 0.1806353\ttotal: 33.3s\tremaining: 26.1s\n",
      "561:\tlearn: 0.1805616\ttotal: 33.4s\tremaining: 26s\n",
      "562:\tlearn: 0.1804661\ttotal: 33.4s\tremaining: 26s\n",
      "563:\tlearn: 0.1803843\ttotal: 33.5s\tremaining: 25.9s\n",
      "564:\tlearn: 0.1803053\ttotal: 33.6s\tremaining: 25.8s\n",
      "565:\tlearn: 0.1802257\ttotal: 33.6s\tremaining: 25.8s\n",
      "566:\tlearn: 0.1801400\ttotal: 33.7s\tremaining: 25.7s\n",
      "567:\tlearn: 0.1800719\ttotal: 33.8s\tremaining: 25.7s\n",
      "568:\tlearn: 0.1799960\ttotal: 33.9s\tremaining: 25.7s\n",
      "569:\tlearn: 0.1799172\ttotal: 34s\tremaining: 25.6s\n",
      "570:\tlearn: 0.1798481\ttotal: 34s\tremaining: 25.6s\n",
      "571:\tlearn: 0.1797774\ttotal: 34.1s\tremaining: 25.5s\n",
      "572:\tlearn: 0.1797147\ttotal: 34.2s\tremaining: 25.5s\n",
      "573:\tlearn: 0.1796373\ttotal: 34.3s\tremaining: 25.4s\n",
      "574:\tlearn: 0.1795649\ttotal: 34.3s\tremaining: 25.4s\n",
      "575:\tlearn: 0.1794935\ttotal: 34.4s\tremaining: 25.3s\n",
      "576:\tlearn: 0.1794281\ttotal: 34.5s\tremaining: 25.3s\n",
      "577:\tlearn: 0.1793334\ttotal: 34.5s\tremaining: 25.2s\n",
      "578:\tlearn: 0.1792514\ttotal: 34.6s\tremaining: 25.2s\n",
      "579:\tlearn: 0.1791808\ttotal: 34.7s\tremaining: 25.1s\n",
      "580:\tlearn: 0.1791051\ttotal: 34.8s\tremaining: 25.1s\n",
      "581:\tlearn: 0.1790339\ttotal: 34.9s\tremaining: 25s\n",
      "582:\tlearn: 0.1789536\ttotal: 34.9s\tremaining: 25s\n",
      "583:\tlearn: 0.1788883\ttotal: 35s\tremaining: 24.9s\n",
      "584:\tlearn: 0.1788019\ttotal: 35.1s\tremaining: 24.9s\n",
      "585:\tlearn: 0.1787303\ttotal: 35.1s\tremaining: 24.8s\n",
      "586:\tlearn: 0.1786441\ttotal: 35.2s\tremaining: 24.8s\n",
      "587:\tlearn: 0.1785641\ttotal: 35.3s\tremaining: 24.7s\n",
      "588:\tlearn: 0.1784955\ttotal: 35.3s\tremaining: 24.7s\n",
      "589:\tlearn: 0.1784240\ttotal: 35.4s\tremaining: 24.6s\n",
      "590:\tlearn: 0.1783528\ttotal: 35.5s\tremaining: 24.5s\n",
      "591:\tlearn: 0.1782841\ttotal: 35.5s\tremaining: 24.5s\n",
      "592:\tlearn: 0.1782148\ttotal: 35.6s\tremaining: 24.4s\n",
      "593:\tlearn: 0.1781486\ttotal: 35.6s\tremaining: 24.4s\n",
      "594:\tlearn: 0.1780777\ttotal: 35.7s\tremaining: 24.3s\n",
      "595:\tlearn: 0.1780130\ttotal: 35.8s\tremaining: 24.3s\n",
      "596:\tlearn: 0.1779400\ttotal: 35.8s\tremaining: 24.2s\n",
      "597:\tlearn: 0.1778732\ttotal: 35.9s\tremaining: 24.1s\n",
      "598:\tlearn: 0.1777992\ttotal: 35.9s\tremaining: 24.1s\n",
      "599:\tlearn: 0.1777324\ttotal: 36s\tremaining: 24s\n",
      "600:\tlearn: 0.1776453\ttotal: 36.1s\tremaining: 24s\n",
      "601:\tlearn: 0.1775798\ttotal: 36.1s\tremaining: 23.9s\n",
      "602:\tlearn: 0.1775057\ttotal: 36.2s\tremaining: 23.8s\n",
      "603:\tlearn: 0.1774366\ttotal: 36.3s\tremaining: 23.8s\n",
      "604:\tlearn: 0.1773608\ttotal: 36.3s\tremaining: 23.7s\n",
      "605:\tlearn: 0.1773002\ttotal: 36.4s\tremaining: 23.6s\n",
      "606:\tlearn: 0.1772241\ttotal: 36.4s\tremaining: 23.6s\n",
      "607:\tlearn: 0.1771486\ttotal: 36.5s\tremaining: 23.5s\n",
      "608:\tlearn: 0.1770674\ttotal: 36.6s\tremaining: 23.5s\n",
      "609:\tlearn: 0.1769960\ttotal: 36.6s\tremaining: 23.4s\n",
      "610:\tlearn: 0.1769226\ttotal: 36.7s\tremaining: 23.4s\n",
      "611:\tlearn: 0.1768474\ttotal: 36.7s\tremaining: 23.3s\n",
      "612:\tlearn: 0.1767819\ttotal: 36.8s\tremaining: 23.2s\n",
      "613:\tlearn: 0.1766987\ttotal: 36.9s\tremaining: 23.2s\n",
      "614:\tlearn: 0.1766304\ttotal: 36.9s\tremaining: 23.1s\n",
      "615:\tlearn: 0.1765593\ttotal: 37s\tremaining: 23.1s\n",
      "616:\tlearn: 0.1764953\ttotal: 37.1s\tremaining: 23s\n",
      "617:\tlearn: 0.1764258\ttotal: 37.1s\tremaining: 22.9s\n",
      "618:\tlearn: 0.1763487\ttotal: 37.2s\tremaining: 22.9s\n",
      "619:\tlearn: 0.1762783\ttotal: 37.2s\tremaining: 22.8s\n",
      "620:\tlearn: 0.1761947\ttotal: 37.3s\tremaining: 22.8s\n",
      "621:\tlearn: 0.1761224\ttotal: 37.4s\tremaining: 22.7s\n",
      "622:\tlearn: 0.1760504\ttotal: 37.4s\tremaining: 22.6s\n",
      "623:\tlearn: 0.1759734\ttotal: 37.5s\tremaining: 22.6s\n",
      "624:\tlearn: 0.1758991\ttotal: 37.5s\tremaining: 22.5s\n",
      "625:\tlearn: 0.1758255\ttotal: 37.6s\tremaining: 22.4s\n",
      "626:\tlearn: 0.1757476\ttotal: 37.6s\tremaining: 22.4s\n",
      "627:\tlearn: 0.1756850\ttotal: 37.7s\tremaining: 22.3s\n",
      "628:\tlearn: 0.1756229\ttotal: 37.7s\tremaining: 22.3s\n",
      "629:\tlearn: 0.1755531\ttotal: 37.8s\tremaining: 22.2s\n",
      "630:\tlearn: 0.1754777\ttotal: 37.8s\tremaining: 22.1s\n",
      "631:\tlearn: 0.1754104\ttotal: 37.9s\tremaining: 22.1s\n",
      "632:\tlearn: 0.1753482\ttotal: 37.9s\tremaining: 22s\n",
      "633:\tlearn: 0.1752809\ttotal: 38s\tremaining: 21.9s\n",
      "634:\tlearn: 0.1752134\ttotal: 38.1s\tremaining: 21.9s\n",
      "635:\tlearn: 0.1751564\ttotal: 38.1s\tremaining: 21.8s\n",
      "636:\tlearn: 0.1750860\ttotal: 38.2s\tremaining: 21.8s\n",
      "637:\tlearn: 0.1750161\ttotal: 38.2s\tremaining: 21.7s\n",
      "638:\tlearn: 0.1749448\ttotal: 38.3s\tremaining: 21.6s\n",
      "639:\tlearn: 0.1748830\ttotal: 38.4s\tremaining: 21.6s\n",
      "640:\tlearn: 0.1748117\ttotal: 38.4s\tremaining: 21.5s\n",
      "641:\tlearn: 0.1747403\ttotal: 38.5s\tremaining: 21.5s\n",
      "642:\tlearn: 0.1746735\ttotal: 38.5s\tremaining: 21.4s\n",
      "643:\tlearn: 0.1746025\ttotal: 38.6s\tremaining: 21.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "644:\tlearn: 0.1745316\ttotal: 38.6s\tremaining: 21.3s\n",
      "645:\tlearn: 0.1744701\ttotal: 38.7s\tremaining: 21.2s\n",
      "646:\tlearn: 0.1743927\ttotal: 38.8s\tremaining: 21.1s\n",
      "647:\tlearn: 0.1743089\ttotal: 38.8s\tremaining: 21.1s\n",
      "648:\tlearn: 0.1742425\ttotal: 38.9s\tremaining: 21s\n",
      "649:\tlearn: 0.1741921\ttotal: 38.9s\tremaining: 21s\n",
      "650:\tlearn: 0.1741049\ttotal: 39s\tremaining: 20.9s\n",
      "651:\tlearn: 0.1740426\ttotal: 39s\tremaining: 20.8s\n",
      "652:\tlearn: 0.1739703\ttotal: 39.1s\tremaining: 20.8s\n",
      "653:\tlearn: 0.1739081\ttotal: 39.1s\tremaining: 20.7s\n",
      "654:\tlearn: 0.1738384\ttotal: 39.2s\tremaining: 20.6s\n",
      "655:\tlearn: 0.1737571\ttotal: 39.2s\tremaining: 20.6s\n",
      "656:\tlearn: 0.1736926\ttotal: 39.3s\tremaining: 20.5s\n",
      "657:\tlearn: 0.1736270\ttotal: 39.3s\tremaining: 20.4s\n",
      "658:\tlearn: 0.1735605\ttotal: 39.4s\tremaining: 20.4s\n",
      "659:\tlearn: 0.1734865\ttotal: 39.4s\tremaining: 20.3s\n",
      "660:\tlearn: 0.1734095\ttotal: 39.5s\tremaining: 20.3s\n",
      "661:\tlearn: 0.1733406\ttotal: 39.6s\tremaining: 20.2s\n",
      "662:\tlearn: 0.1732736\ttotal: 39.6s\tremaining: 20.1s\n",
      "663:\tlearn: 0.1732152\ttotal: 39.7s\tremaining: 20.1s\n",
      "664:\tlearn: 0.1731559\ttotal: 39.7s\tremaining: 20s\n",
      "665:\tlearn: 0.1730888\ttotal: 39.8s\tremaining: 19.9s\n",
      "666:\tlearn: 0.1730252\ttotal: 39.8s\tremaining: 19.9s\n",
      "667:\tlearn: 0.1729823\ttotal: 39.9s\tremaining: 19.8s\n",
      "668:\tlearn: 0.1729113\ttotal: 39.9s\tremaining: 19.7s\n",
      "669:\tlearn: 0.1728504\ttotal: 40s\tremaining: 19.7s\n",
      "670:\tlearn: 0.1727820\ttotal: 40s\tremaining: 19.6s\n",
      "671:\tlearn: 0.1727303\ttotal: 40.1s\tremaining: 19.6s\n",
      "672:\tlearn: 0.1726598\ttotal: 40.1s\tremaining: 19.5s\n",
      "673:\tlearn: 0.1726028\ttotal: 40.2s\tremaining: 19.4s\n",
      "674:\tlearn: 0.1725386\ttotal: 40.3s\tremaining: 19.4s\n",
      "675:\tlearn: 0.1724706\ttotal: 40.3s\tremaining: 19.3s\n",
      "676:\tlearn: 0.1724042\ttotal: 40.4s\tremaining: 19.3s\n",
      "677:\tlearn: 0.1723420\ttotal: 40.4s\tremaining: 19.2s\n",
      "678:\tlearn: 0.1722794\ttotal: 40.5s\tremaining: 19.1s\n",
      "679:\tlearn: 0.1722158\ttotal: 40.5s\tremaining: 19.1s\n",
      "680:\tlearn: 0.1721566\ttotal: 40.6s\tremaining: 19s\n",
      "681:\tlearn: 0.1720858\ttotal: 40.6s\tremaining: 18.9s\n",
      "682:\tlearn: 0.1720222\ttotal: 40.7s\tremaining: 18.9s\n",
      "683:\tlearn: 0.1719572\ttotal: 40.7s\tremaining: 18.8s\n",
      "684:\tlearn: 0.1718936\ttotal: 40.8s\tremaining: 18.8s\n",
      "685:\tlearn: 0.1718347\ttotal: 40.8s\tremaining: 18.7s\n",
      "686:\tlearn: 0.1717613\ttotal: 40.9s\tremaining: 18.6s\n",
      "687:\tlearn: 0.1716903\ttotal: 40.9s\tremaining: 18.6s\n",
      "688:\tlearn: 0.1716186\ttotal: 41s\tremaining: 18.5s\n",
      "689:\tlearn: 0.1715448\ttotal: 41s\tremaining: 18.4s\n",
      "690:\tlearn: 0.1714869\ttotal: 41.1s\tremaining: 18.4s\n",
      "691:\tlearn: 0.1714231\ttotal: 41.2s\tremaining: 18.3s\n",
      "692:\tlearn: 0.1713552\ttotal: 41.2s\tremaining: 18.3s\n",
      "693:\tlearn: 0.1712904\ttotal: 41.2s\tremaining: 18.2s\n",
      "694:\tlearn: 0.1712225\ttotal: 41.3s\tremaining: 18.1s\n",
      "695:\tlearn: 0.1711526\ttotal: 41.4s\tremaining: 18.1s\n",
      "696:\tlearn: 0.1711036\ttotal: 41.4s\tremaining: 18s\n",
      "697:\tlearn: 0.1710293\ttotal: 41.5s\tremaining: 17.9s\n",
      "698:\tlearn: 0.1709584\ttotal: 41.5s\tremaining: 17.9s\n",
      "699:\tlearn: 0.1708947\ttotal: 41.6s\tremaining: 17.8s\n",
      "700:\tlearn: 0.1708358\ttotal: 41.6s\tremaining: 17.7s\n",
      "701:\tlearn: 0.1707770\ttotal: 41.7s\tremaining: 17.7s\n",
      "702:\tlearn: 0.1707058\ttotal: 41.7s\tremaining: 17.6s\n",
      "703:\tlearn: 0.1706376\ttotal: 41.8s\tremaining: 17.6s\n",
      "704:\tlearn: 0.1705655\ttotal: 41.8s\tremaining: 17.5s\n",
      "705:\tlearn: 0.1704954\ttotal: 41.9s\tremaining: 17.4s\n",
      "706:\tlearn: 0.1704285\ttotal: 42s\tremaining: 17.4s\n",
      "707:\tlearn: 0.1703645\ttotal: 42s\tremaining: 17.3s\n",
      "708:\tlearn: 0.1703001\ttotal: 42.1s\tremaining: 17.3s\n",
      "709:\tlearn: 0.1702411\ttotal: 42.1s\tremaining: 17.2s\n",
      "710:\tlearn: 0.1701832\ttotal: 42.2s\tremaining: 17.1s\n",
      "711:\tlearn: 0.1701263\ttotal: 42.2s\tremaining: 17.1s\n",
      "712:\tlearn: 0.1700576\ttotal: 42.3s\tremaining: 17s\n",
      "713:\tlearn: 0.1699924\ttotal: 42.3s\tremaining: 17s\n",
      "714:\tlearn: 0.1699383\ttotal: 42.4s\tremaining: 16.9s\n",
      "715:\tlearn: 0.1698709\ttotal: 42.5s\tremaining: 16.8s\n",
      "716:\tlearn: 0.1698121\ttotal: 42.5s\tremaining: 16.8s\n",
      "717:\tlearn: 0.1697781\ttotal: 42.5s\tremaining: 16.7s\n",
      "718:\tlearn: 0.1697158\ttotal: 42.6s\tremaining: 16.7s\n",
      "719:\tlearn: 0.1696511\ttotal: 42.7s\tremaining: 16.6s\n",
      "720:\tlearn: 0.1695878\ttotal: 42.7s\tremaining: 16.5s\n",
      "721:\tlearn: 0.1695226\ttotal: 42.8s\tremaining: 16.5s\n",
      "722:\tlearn: 0.1694520\ttotal: 42.8s\tremaining: 16.4s\n",
      "723:\tlearn: 0.1694010\ttotal: 42.9s\tremaining: 16.3s\n",
      "724:\tlearn: 0.1693407\ttotal: 42.9s\tremaining: 16.3s\n",
      "725:\tlearn: 0.1692741\ttotal: 43s\tremaining: 16.2s\n",
      "726:\tlearn: 0.1692080\ttotal: 43s\tremaining: 16.2s\n",
      "727:\tlearn: 0.1691385\ttotal: 43.1s\tremaining: 16.1s\n",
      "728:\tlearn: 0.1690816\ttotal: 43.1s\tremaining: 16s\n",
      "729:\tlearn: 0.1690234\ttotal: 43.2s\tremaining: 16s\n",
      "730:\tlearn: 0.1689647\ttotal: 43.2s\tremaining: 15.9s\n",
      "731:\tlearn: 0.1689104\ttotal: 43.3s\tremaining: 15.8s\n",
      "732:\tlearn: 0.1688437\ttotal: 43.4s\tremaining: 15.8s\n",
      "733:\tlearn: 0.1687783\ttotal: 43.4s\tremaining: 15.7s\n",
      "734:\tlearn: 0.1687116\ttotal: 43.5s\tremaining: 15.7s\n",
      "735:\tlearn: 0.1686389\ttotal: 43.5s\tremaining: 15.6s\n",
      "736:\tlearn: 0.1685813\ttotal: 43.6s\tremaining: 15.5s\n",
      "737:\tlearn: 0.1685124\ttotal: 43.6s\tremaining: 15.5s\n",
      "738:\tlearn: 0.1684503\ttotal: 43.7s\tremaining: 15.4s\n",
      "739:\tlearn: 0.1683843\ttotal: 43.7s\tremaining: 15.4s\n",
      "740:\tlearn: 0.1683247\ttotal: 43.8s\tremaining: 15.3s\n",
      "741:\tlearn: 0.1682600\ttotal: 43.8s\tremaining: 15.2s\n",
      "742:\tlearn: 0.1682077\ttotal: 43.9s\tremaining: 15.2s\n",
      "743:\tlearn: 0.1681420\ttotal: 44s\tremaining: 15.1s\n",
      "744:\tlearn: 0.1680806\ttotal: 44s\tremaining: 15.1s\n",
      "745:\tlearn: 0.1680179\ttotal: 44.1s\tremaining: 15s\n",
      "746:\tlearn: 0.1679563\ttotal: 44.1s\tremaining: 14.9s\n",
      "747:\tlearn: 0.1679136\ttotal: 44.2s\tremaining: 14.9s\n",
      "748:\tlearn: 0.1678469\ttotal: 44.2s\tremaining: 14.8s\n",
      "749:\tlearn: 0.1677952\ttotal: 44.3s\tremaining: 14.8s\n",
      "750:\tlearn: 0.1677237\ttotal: 44.3s\tremaining: 14.7s\n",
      "751:\tlearn: 0.1676526\ttotal: 44.4s\tremaining: 14.6s\n",
      "752:\tlearn: 0.1675837\ttotal: 44.4s\tremaining: 14.6s\n",
      "753:\tlearn: 0.1675293\ttotal: 44.5s\tremaining: 14.5s\n",
      "754:\tlearn: 0.1674728\ttotal: 44.5s\tremaining: 14.5s\n",
      "755:\tlearn: 0.1674094\ttotal: 44.6s\tremaining: 14.4s\n",
      "756:\tlearn: 0.1673444\ttotal: 44.7s\tremaining: 14.3s\n",
      "757:\tlearn: 0.1672777\ttotal: 44.7s\tremaining: 14.3s\n",
      "758:\tlearn: 0.1672132\ttotal: 44.8s\tremaining: 14.2s\n",
      "759:\tlearn: 0.1671577\ttotal: 44.8s\tremaining: 14.1s\n",
      "760:\tlearn: 0.1670921\ttotal: 44.9s\tremaining: 14.1s\n",
      "761:\tlearn: 0.1670222\ttotal: 44.9s\tremaining: 14s\n",
      "762:\tlearn: 0.1669592\ttotal: 45s\tremaining: 14s\n",
      "763:\tlearn: 0.1668957\ttotal: 45s\tremaining: 13.9s\n",
      "764:\tlearn: 0.1668410\ttotal: 45.1s\tremaining: 13.8s\n",
      "765:\tlearn: 0.1667754\ttotal: 45.1s\tremaining: 13.8s\n",
      "766:\tlearn: 0.1667147\ttotal: 45.2s\tremaining: 13.7s\n",
      "767:\tlearn: 0.1666523\ttotal: 45.2s\tremaining: 13.7s\n",
      "768:\tlearn: 0.1665787\ttotal: 45.3s\tremaining: 13.6s\n",
      "769:\tlearn: 0.1665122\ttotal: 45.3s\tremaining: 13.5s\n",
      "770:\tlearn: 0.1664426\ttotal: 45.4s\tremaining: 13.5s\n",
      "771:\tlearn: 0.1663882\ttotal: 45.4s\tremaining: 13.4s\n",
      "772:\tlearn: 0.1663371\ttotal: 45.5s\tremaining: 13.4s\n",
      "773:\tlearn: 0.1662860\ttotal: 45.5s\tremaining: 13.3s\n",
      "774:\tlearn: 0.1662376\ttotal: 45.6s\tremaining: 13.2s\n",
      "775:\tlearn: 0.1661826\ttotal: 45.6s\tremaining: 13.2s\n",
      "776:\tlearn: 0.1661181\ttotal: 45.7s\tremaining: 13.1s\n",
      "777:\tlearn: 0.1660637\ttotal: 45.7s\tremaining: 13.1s\n",
      "778:\tlearn: 0.1660050\ttotal: 45.8s\tremaining: 13s\n",
      "779:\tlearn: 0.1659432\ttotal: 45.8s\tremaining: 12.9s\n",
      "780:\tlearn: 0.1658856\ttotal: 45.9s\tremaining: 12.9s\n",
      "781:\tlearn: 0.1658313\ttotal: 46s\tremaining: 12.8s\n",
      "782:\tlearn: 0.1657657\ttotal: 46s\tremaining: 12.8s\n",
      "783:\tlearn: 0.1657111\ttotal: 46.1s\tremaining: 12.7s\n",
      "784:\tlearn: 0.1656489\ttotal: 46.1s\tremaining: 12.6s\n",
      "785:\tlearn: 0.1655919\ttotal: 46.2s\tremaining: 12.6s\n",
      "786:\tlearn: 0.1655295\ttotal: 46.2s\tremaining: 12.5s\n",
      "787:\tlearn: 0.1654638\ttotal: 46.3s\tremaining: 12.5s\n",
      "788:\tlearn: 0.1654044\ttotal: 46.4s\tremaining: 12.4s\n",
      "789:\tlearn: 0.1653418\ttotal: 46.4s\tremaining: 12.3s\n",
      "790:\tlearn: 0.1652764\ttotal: 46.5s\tremaining: 12.3s\n",
      "791:\tlearn: 0.1652226\ttotal: 46.6s\tremaining: 12.2s\n",
      "792:\tlearn: 0.1651567\ttotal: 46.6s\tremaining: 12.2s\n",
      "793:\tlearn: 0.1651035\ttotal: 46.7s\tremaining: 12.1s\n",
      "794:\tlearn: 0.1650358\ttotal: 46.7s\tremaining: 12s\n",
      "795:\tlearn: 0.1649782\ttotal: 46.8s\tremaining: 12s\n",
      "796:\tlearn: 0.1649150\ttotal: 46.8s\tremaining: 11.9s\n",
      "797:\tlearn: 0.1648866\ttotal: 46.9s\tremaining: 11.9s\n",
      "798:\tlearn: 0.1648307\ttotal: 46.9s\tremaining: 11.8s\n",
      "799:\tlearn: 0.1647715\ttotal: 47s\tremaining: 11.7s\n",
      "800:\tlearn: 0.1647112\ttotal: 47s\tremaining: 11.7s\n",
      "801:\tlearn: 0.1646518\ttotal: 47.1s\tremaining: 11.6s\n",
      "802:\tlearn: 0.1645869\ttotal: 47.2s\tremaining: 11.6s\n",
      "803:\tlearn: 0.1645357\ttotal: 47.2s\tremaining: 11.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "804:\tlearn: 0.1644805\ttotal: 47.3s\tremaining: 11.4s\n",
      "805:\tlearn: 0.1644272\ttotal: 47.3s\tremaining: 11.4s\n",
      "806:\tlearn: 0.1643749\ttotal: 47.4s\tremaining: 11.3s\n",
      "807:\tlearn: 0.1643157\ttotal: 47.4s\tremaining: 11.3s\n",
      "808:\tlearn: 0.1642647\ttotal: 47.5s\tremaining: 11.2s\n",
      "809:\tlearn: 0.1642073\ttotal: 47.5s\tremaining: 11.2s\n",
      "810:\tlearn: 0.1641522\ttotal: 47.6s\tremaining: 11.1s\n",
      "811:\tlearn: 0.1640929\ttotal: 47.7s\tremaining: 11s\n",
      "812:\tlearn: 0.1640352\ttotal: 47.7s\tremaining: 11s\n",
      "813:\tlearn: 0.1639790\ttotal: 47.8s\tremaining: 10.9s\n",
      "814:\tlearn: 0.1639288\ttotal: 47.8s\tremaining: 10.9s\n",
      "815:\tlearn: 0.1638703\ttotal: 47.9s\tremaining: 10.8s\n",
      "816:\tlearn: 0.1638278\ttotal: 47.9s\tremaining: 10.7s\n",
      "817:\tlearn: 0.1637740\ttotal: 48s\tremaining: 10.7s\n",
      "818:\tlearn: 0.1637200\ttotal: 48s\tremaining: 10.6s\n",
      "819:\tlearn: 0.1636733\ttotal: 48.1s\tremaining: 10.6s\n",
      "820:\tlearn: 0.1636052\ttotal: 48.2s\tremaining: 10.5s\n",
      "821:\tlearn: 0.1635383\ttotal: 48.2s\tremaining: 10.4s\n",
      "822:\tlearn: 0.1634809\ttotal: 48.3s\tremaining: 10.4s\n",
      "823:\tlearn: 0.1634299\ttotal: 48.3s\tremaining: 10.3s\n",
      "824:\tlearn: 0.1633888\ttotal: 48.4s\tremaining: 10.3s\n",
      "825:\tlearn: 0.1633328\ttotal: 48.4s\tremaining: 10.2s\n",
      "826:\tlearn: 0.1632863\ttotal: 48.5s\tremaining: 10.1s\n",
      "827:\tlearn: 0.1632369\ttotal: 48.6s\tremaining: 10.1s\n",
      "828:\tlearn: 0.1631871\ttotal: 48.6s\tremaining: 10s\n",
      "829:\tlearn: 0.1631292\ttotal: 48.7s\tremaining: 9.97s\n",
      "830:\tlearn: 0.1630750\ttotal: 48.7s\tremaining: 9.91s\n",
      "831:\tlearn: 0.1630201\ttotal: 48.8s\tremaining: 9.85s\n",
      "832:\tlearn: 0.1629647\ttotal: 48.9s\tremaining: 9.8s\n",
      "833:\tlearn: 0.1629040\ttotal: 48.9s\tremaining: 9.74s\n",
      "834:\tlearn: 0.1628431\ttotal: 49s\tremaining: 9.68s\n",
      "835:\tlearn: 0.1628087\ttotal: 49s\tremaining: 9.62s\n",
      "836:\tlearn: 0.1627534\ttotal: 49.1s\tremaining: 9.56s\n",
      "837:\tlearn: 0.1627148\ttotal: 49.1s\tremaining: 9.5s\n",
      "838:\tlearn: 0.1626518\ttotal: 49.2s\tremaining: 9.44s\n",
      "839:\tlearn: 0.1625968\ttotal: 49.3s\tremaining: 9.38s\n",
      "840:\tlearn: 0.1625469\ttotal: 49.3s\tremaining: 9.32s\n",
      "841:\tlearn: 0.1624832\ttotal: 49.4s\tremaining: 9.27s\n",
      "842:\tlearn: 0.1624251\ttotal: 49.4s\tremaining: 9.21s\n",
      "843:\tlearn: 0.1623702\ttotal: 49.5s\tremaining: 9.15s\n",
      "844:\tlearn: 0.1623196\ttotal: 49.6s\tremaining: 9.09s\n",
      "845:\tlearn: 0.1622636\ttotal: 49.6s\tremaining: 9.04s\n",
      "846:\tlearn: 0.1622109\ttotal: 49.7s\tremaining: 8.98s\n",
      "847:\tlearn: 0.1621644\ttotal: 49.8s\tremaining: 8.92s\n",
      "848:\tlearn: 0.1621087\ttotal: 49.8s\tremaining: 8.86s\n",
      "849:\tlearn: 0.1620525\ttotal: 49.9s\tremaining: 8.8s\n",
      "850:\tlearn: 0.1619885\ttotal: 50s\tremaining: 8.75s\n",
      "851:\tlearn: 0.1619311\ttotal: 50s\tremaining: 8.69s\n",
      "852:\tlearn: 0.1618826\ttotal: 50.1s\tremaining: 8.63s\n",
      "853:\tlearn: 0.1618155\ttotal: 50.1s\tremaining: 8.57s\n",
      "854:\tlearn: 0.1617519\ttotal: 50.2s\tremaining: 8.51s\n",
      "855:\tlearn: 0.1617024\ttotal: 50.2s\tremaining: 8.45s\n",
      "856:\tlearn: 0.1616464\ttotal: 50.3s\tremaining: 8.4s\n",
      "857:\tlearn: 0.1615991\ttotal: 50.4s\tremaining: 8.34s\n",
      "858:\tlearn: 0.1615593\ttotal: 50.4s\tremaining: 8.28s\n",
      "859:\tlearn: 0.1614928\ttotal: 50.5s\tremaining: 8.22s\n",
      "860:\tlearn: 0.1614420\ttotal: 50.6s\tremaining: 8.16s\n",
      "861:\tlearn: 0.1613779\ttotal: 50.6s\tremaining: 8.11s\n",
      "862:\tlearn: 0.1613067\ttotal: 50.7s\tremaining: 8.05s\n",
      "863:\tlearn: 0.1612553\ttotal: 50.8s\tremaining: 7.99s\n",
      "864:\tlearn: 0.1611891\ttotal: 50.8s\tremaining: 7.93s\n",
      "865:\tlearn: 0.1611424\ttotal: 50.9s\tremaining: 7.87s\n",
      "866:\tlearn: 0.1610972\ttotal: 51s\tremaining: 7.82s\n",
      "867:\tlearn: 0.1610492\ttotal: 51s\tremaining: 7.76s\n",
      "868:\tlearn: 0.1609863\ttotal: 51.1s\tremaining: 7.7s\n",
      "869:\tlearn: 0.1609237\ttotal: 51.2s\tremaining: 7.64s\n",
      "870:\tlearn: 0.1608644\ttotal: 51.2s\tremaining: 7.58s\n",
      "871:\tlearn: 0.1608160\ttotal: 51.3s\tremaining: 7.52s\n",
      "872:\tlearn: 0.1607643\ttotal: 51.3s\tremaining: 7.46s\n",
      "873:\tlearn: 0.1607008\ttotal: 51.4s\tremaining: 7.41s\n",
      "874:\tlearn: 0.1606532\ttotal: 51.4s\tremaining: 7.35s\n",
      "875:\tlearn: 0.1605971\ttotal: 51.5s\tremaining: 7.29s\n",
      "876:\tlearn: 0.1605404\ttotal: 51.6s\tremaining: 7.23s\n",
      "877:\tlearn: 0.1604781\ttotal: 51.6s\tremaining: 7.18s\n",
      "878:\tlearn: 0.1604270\ttotal: 51.7s\tremaining: 7.12s\n",
      "879:\tlearn: 0.1603694\ttotal: 51.8s\tremaining: 7.06s\n",
      "880:\tlearn: 0.1603097\ttotal: 51.8s\tremaining: 7s\n",
      "881:\tlearn: 0.1602488\ttotal: 51.9s\tremaining: 6.94s\n",
      "882:\tlearn: 0.1601879\ttotal: 52s\tremaining: 6.88s\n",
      "883:\tlearn: 0.1601383\ttotal: 52s\tremaining: 6.83s\n",
      "884:\tlearn: 0.1600992\ttotal: 52.1s\tremaining: 6.77s\n",
      "885:\tlearn: 0.1600269\ttotal: 52.2s\tremaining: 6.71s\n",
      "886:\tlearn: 0.1599685\ttotal: 52.2s\tremaining: 6.65s\n",
      "887:\tlearn: 0.1599095\ttotal: 52.3s\tremaining: 6.59s\n",
      "888:\tlearn: 0.1598659\ttotal: 52.3s\tremaining: 6.54s\n",
      "889:\tlearn: 0.1598199\ttotal: 52.4s\tremaining: 6.48s\n",
      "890:\tlearn: 0.1597619\ttotal: 52.5s\tremaining: 6.42s\n",
      "891:\tlearn: 0.1597018\ttotal: 52.5s\tremaining: 6.36s\n",
      "892:\tlearn: 0.1596428\ttotal: 52.6s\tremaining: 6.3s\n",
      "893:\tlearn: 0.1595881\ttotal: 52.7s\tremaining: 6.24s\n",
      "894:\tlearn: 0.1595314\ttotal: 52.7s\tremaining: 6.18s\n",
      "895:\tlearn: 0.1594863\ttotal: 52.8s\tremaining: 6.13s\n",
      "896:\tlearn: 0.1594332\ttotal: 52.8s\tremaining: 6.07s\n",
      "897:\tlearn: 0.1593688\ttotal: 52.9s\tremaining: 6.01s\n",
      "898:\tlearn: 0.1593097\ttotal: 53s\tremaining: 5.95s\n",
      "899:\tlearn: 0.1592460\ttotal: 53s\tremaining: 5.89s\n",
      "900:\tlearn: 0.1591938\ttotal: 53.1s\tremaining: 5.83s\n",
      "901:\tlearn: 0.1591424\ttotal: 53.1s\tremaining: 5.77s\n",
      "902:\tlearn: 0.1591007\ttotal: 53.2s\tremaining: 5.71s\n",
      "903:\tlearn: 0.1590557\ttotal: 53.2s\tremaining: 5.65s\n",
      "904:\tlearn: 0.1590011\ttotal: 53.3s\tremaining: 5.59s\n",
      "905:\tlearn: 0.1589580\ttotal: 53.4s\tremaining: 5.54s\n",
      "906:\tlearn: 0.1588967\ttotal: 53.4s\tremaining: 5.48s\n",
      "907:\tlearn: 0.1588472\ttotal: 53.5s\tremaining: 5.42s\n",
      "908:\tlearn: 0.1587983\ttotal: 53.5s\tremaining: 5.36s\n",
      "909:\tlearn: 0.1587526\ttotal: 53.6s\tremaining: 5.3s\n",
      "910:\tlearn: 0.1586904\ttotal: 53.7s\tremaining: 5.24s\n",
      "911:\tlearn: 0.1586338\ttotal: 53.7s\tremaining: 5.18s\n",
      "912:\tlearn: 0.1586013\ttotal: 53.8s\tremaining: 5.12s\n",
      "913:\tlearn: 0.1585545\ttotal: 53.8s\tremaining: 5.07s\n",
      "914:\tlearn: 0.1585038\ttotal: 53.9s\tremaining: 5s\n",
      "915:\tlearn: 0.1584558\ttotal: 54s\tremaining: 4.95s\n",
      "916:\tlearn: 0.1583981\ttotal: 54s\tremaining: 4.89s\n",
      "917:\tlearn: 0.1583581\ttotal: 54.1s\tremaining: 4.83s\n",
      "918:\tlearn: 0.1583074\ttotal: 54.2s\tremaining: 4.77s\n",
      "919:\tlearn: 0.1582733\ttotal: 54.2s\tremaining: 4.71s\n",
      "920:\tlearn: 0.1582200\ttotal: 54.3s\tremaining: 4.66s\n",
      "921:\tlearn: 0.1581596\ttotal: 54.3s\tremaining: 4.6s\n",
      "922:\tlearn: 0.1581052\ttotal: 54.4s\tremaining: 4.54s\n",
      "923:\tlearn: 0.1580533\ttotal: 54.5s\tremaining: 4.48s\n",
      "924:\tlearn: 0.1580045\ttotal: 54.5s\tremaining: 4.42s\n",
      "925:\tlearn: 0.1579589\ttotal: 54.6s\tremaining: 4.36s\n",
      "926:\tlearn: 0.1579118\ttotal: 54.6s\tremaining: 4.3s\n",
      "927:\tlearn: 0.1578423\ttotal: 54.7s\tremaining: 4.25s\n",
      "928:\tlearn: 0.1578018\ttotal: 54.8s\tremaining: 4.19s\n",
      "929:\tlearn: 0.1577432\ttotal: 54.8s\tremaining: 4.13s\n",
      "930:\tlearn: 0.1576794\ttotal: 54.9s\tremaining: 4.07s\n",
      "931:\tlearn: 0.1576288\ttotal: 54.9s\tremaining: 4.01s\n",
      "932:\tlearn: 0.1575767\ttotal: 55s\tremaining: 3.95s\n",
      "933:\tlearn: 0.1575191\ttotal: 55.1s\tremaining: 3.89s\n",
      "934:\tlearn: 0.1574638\ttotal: 55.1s\tremaining: 3.83s\n",
      "935:\tlearn: 0.1574108\ttotal: 55.2s\tremaining: 3.77s\n",
      "936:\tlearn: 0.1573631\ttotal: 55.2s\tremaining: 3.71s\n",
      "937:\tlearn: 0.1572999\ttotal: 55.3s\tremaining: 3.65s\n",
      "938:\tlearn: 0.1572436\ttotal: 55.3s\tremaining: 3.59s\n",
      "939:\tlearn: 0.1571896\ttotal: 55.4s\tremaining: 3.54s\n",
      "940:\tlearn: 0.1571268\ttotal: 55.5s\tremaining: 3.48s\n",
      "941:\tlearn: 0.1570631\ttotal: 55.5s\tremaining: 3.42s\n",
      "942:\tlearn: 0.1570127\ttotal: 55.6s\tremaining: 3.36s\n",
      "943:\tlearn: 0.1569621\ttotal: 55.7s\tremaining: 3.3s\n",
      "944:\tlearn: 0.1569069\ttotal: 55.7s\tremaining: 3.24s\n",
      "945:\tlearn: 0.1568531\ttotal: 55.8s\tremaining: 3.18s\n",
      "946:\tlearn: 0.1568050\ttotal: 55.8s\tremaining: 3.13s\n",
      "947:\tlearn: 0.1567504\ttotal: 55.9s\tremaining: 3.07s\n",
      "948:\tlearn: 0.1567001\ttotal: 56s\tremaining: 3.01s\n",
      "949:\tlearn: 0.1566534\ttotal: 56s\tremaining: 2.95s\n",
      "950:\tlearn: 0.1566026\ttotal: 56.1s\tremaining: 2.89s\n",
      "951:\tlearn: 0.1565524\ttotal: 56.1s\tremaining: 2.83s\n",
      "952:\tlearn: 0.1564972\ttotal: 56.2s\tremaining: 2.77s\n",
      "953:\tlearn: 0.1564497\ttotal: 56.3s\tremaining: 2.71s\n",
      "954:\tlearn: 0.1563983\ttotal: 56.3s\tremaining: 2.65s\n",
      "955:\tlearn: 0.1563417\ttotal: 56.4s\tremaining: 2.59s\n",
      "956:\tlearn: 0.1562934\ttotal: 56.4s\tremaining: 2.54s\n",
      "957:\tlearn: 0.1562270\ttotal: 56.5s\tremaining: 2.48s\n",
      "958:\tlearn: 0.1561717\ttotal: 56.5s\tremaining: 2.42s\n",
      "959:\tlearn: 0.1561224\ttotal: 56.6s\tremaining: 2.36s\n",
      "960:\tlearn: 0.1560703\ttotal: 56.6s\tremaining: 2.3s\n",
      "961:\tlearn: 0.1560213\ttotal: 56.7s\tremaining: 2.24s\n",
      "962:\tlearn: 0.1559691\ttotal: 56.8s\tremaining: 2.18s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "963:\tlearn: 0.1559171\ttotal: 56.8s\tremaining: 2.12s\n",
      "964:\tlearn: 0.1558601\ttotal: 56.9s\tremaining: 2.06s\n",
      "965:\tlearn: 0.1558119\ttotal: 56.9s\tremaining: 2s\n",
      "966:\tlearn: 0.1557762\ttotal: 57s\tremaining: 1.94s\n",
      "967:\tlearn: 0.1557199\ttotal: 57s\tremaining: 1.89s\n",
      "968:\tlearn: 0.1556710\ttotal: 57.1s\tremaining: 1.82s\n",
      "969:\tlearn: 0.1556132\ttotal: 57.1s\tremaining: 1.77s\n",
      "970:\tlearn: 0.1555623\ttotal: 57.2s\tremaining: 1.71s\n",
      "971:\tlearn: 0.1555170\ttotal: 57.2s\tremaining: 1.65s\n",
      "972:\tlearn: 0.1554723\ttotal: 57.3s\tremaining: 1.59s\n",
      "973:\tlearn: 0.1554254\ttotal: 57.4s\tremaining: 1.53s\n",
      "974:\tlearn: 0.1553786\ttotal: 57.4s\tremaining: 1.47s\n",
      "975:\tlearn: 0.1553227\ttotal: 57.5s\tremaining: 1.41s\n",
      "976:\tlearn: 0.1552658\ttotal: 57.5s\tremaining: 1.35s\n",
      "977:\tlearn: 0.1552054\ttotal: 57.6s\tremaining: 1.29s\n",
      "978:\tlearn: 0.1551523\ttotal: 57.7s\tremaining: 1.24s\n",
      "979:\tlearn: 0.1551046\ttotal: 57.7s\tremaining: 1.18s\n",
      "980:\tlearn: 0.1550522\ttotal: 57.8s\tremaining: 1.12s\n",
      "981:\tlearn: 0.1550205\ttotal: 57.8s\tremaining: 1.06s\n",
      "982:\tlearn: 0.1549631\ttotal: 57.9s\tremaining: 1s\n",
      "983:\tlearn: 0.1549063\ttotal: 58s\tremaining: 942ms\n",
      "984:\tlearn: 0.1548511\ttotal: 58s\tremaining: 884ms\n",
      "985:\tlearn: 0.1548017\ttotal: 58.1s\tremaining: 825ms\n",
      "986:\tlearn: 0.1547541\ttotal: 58.1s\tremaining: 766ms\n",
      "987:\tlearn: 0.1546958\ttotal: 58.2s\tremaining: 707ms\n",
      "988:\tlearn: 0.1546442\ttotal: 58.3s\tremaining: 648ms\n",
      "989:\tlearn: 0.1545849\ttotal: 58.3s\tremaining: 589ms\n",
      "990:\tlearn: 0.1545384\ttotal: 58.4s\tremaining: 530ms\n",
      "991:\tlearn: 0.1544862\ttotal: 58.5s\tremaining: 471ms\n",
      "992:\tlearn: 0.1544326\ttotal: 58.5s\tremaining: 413ms\n",
      "993:\tlearn: 0.1543827\ttotal: 58.6s\tremaining: 354ms\n",
      "994:\tlearn: 0.1543279\ttotal: 58.7s\tremaining: 295ms\n",
      "995:\tlearn: 0.1542739\ttotal: 58.7s\tremaining: 236ms\n",
      "996:\tlearn: 0.1542125\ttotal: 58.8s\tremaining: 177ms\n",
      "997:\tlearn: 0.1541541\ttotal: 58.8s\tremaining: 118ms\n",
      "998:\tlearn: 0.1541036\ttotal: 58.9s\tremaining: 59ms\n",
      "999:\tlearn: 0.1540657\ttotal: 58.9s\tremaining: 0us\n",
      "Learning rate set to 0.09461\n",
      "0:\tlearn: 0.6142426\ttotal: 71.8ms\tremaining: 1m 11s\n",
      "1:\tlearn: 0.5517995\ttotal: 151ms\tremaining: 1m 15s\n",
      "2:\tlearn: 0.5025567\ttotal: 211ms\tremaining: 1m 10s\n",
      "3:\tlearn: 0.4648775\ttotal: 272ms\tremaining: 1m 7s\n",
      "4:\tlearn: 0.4340217\ttotal: 336ms\tremaining: 1m 6s\n",
      "5:\tlearn: 0.4087064\ttotal: 395ms\tremaining: 1m 5s\n",
      "6:\tlearn: 0.3885818\ttotal: 452ms\tremaining: 1m 4s\n",
      "7:\tlearn: 0.3729206\ttotal: 502ms\tremaining: 1m 2s\n",
      "8:\tlearn: 0.3599597\ttotal: 554ms\tremaining: 1m\n",
      "9:\tlearn: 0.3495273\ttotal: 607ms\tremaining: 1m\n",
      "10:\tlearn: 0.3408807\ttotal: 659ms\tremaining: 59.2s\n",
      "11:\tlearn: 0.3338431\ttotal: 709ms\tremaining: 58.4s\n",
      "12:\tlearn: 0.3276896\ttotal: 759ms\tremaining: 57.6s\n",
      "13:\tlearn: 0.3226004\ttotal: 806ms\tremaining: 56.8s\n",
      "14:\tlearn: 0.3186075\ttotal: 857ms\tremaining: 56.3s\n",
      "15:\tlearn: 0.3147224\ttotal: 906ms\tremaining: 55.7s\n",
      "16:\tlearn: 0.3116116\ttotal: 955ms\tremaining: 55.2s\n",
      "17:\tlearn: 0.3089014\ttotal: 1s\tremaining: 54.7s\n",
      "18:\tlearn: 0.3064894\ttotal: 1.05s\tremaining: 54.3s\n",
      "19:\tlearn: 0.3043540\ttotal: 1.11s\tremaining: 54.2s\n",
      "20:\tlearn: 0.3023683\ttotal: 1.16s\tremaining: 54.1s\n",
      "21:\tlearn: 0.3007439\ttotal: 1.22s\tremaining: 54.1s\n",
      "22:\tlearn: 0.2992494\ttotal: 1.27s\tremaining: 53.9s\n",
      "23:\tlearn: 0.2977281\ttotal: 1.31s\tremaining: 53.5s\n",
      "24:\tlearn: 0.2964232\ttotal: 1.36s\tremaining: 53.1s\n",
      "25:\tlearn: 0.2951621\ttotal: 1.41s\tremaining: 52.8s\n",
      "26:\tlearn: 0.2939460\ttotal: 1.46s\tremaining: 52.7s\n",
      "27:\tlearn: 0.2928332\ttotal: 1.52s\tremaining: 52.6s\n",
      "28:\tlearn: 0.2917133\ttotal: 1.57s\tremaining: 52.6s\n",
      "29:\tlearn: 0.2906739\ttotal: 1.63s\tremaining: 52.6s\n",
      "30:\tlearn: 0.2896595\ttotal: 1.68s\tremaining: 52.5s\n",
      "31:\tlearn: 0.2887253\ttotal: 1.73s\tremaining: 52.4s\n",
      "32:\tlearn: 0.2877823\ttotal: 1.78s\tremaining: 52.3s\n",
      "33:\tlearn: 0.2868606\ttotal: 1.83s\tremaining: 52.1s\n",
      "34:\tlearn: 0.2859860\ttotal: 1.89s\tremaining: 52.2s\n",
      "35:\tlearn: 0.2851606\ttotal: 1.94s\tremaining: 52s\n",
      "36:\tlearn: 0.2843767\ttotal: 1.99s\tremaining: 51.9s\n",
      "37:\tlearn: 0.2835847\ttotal: 2.04s\tremaining: 51.8s\n",
      "38:\tlearn: 0.2828028\ttotal: 2.1s\tremaining: 51.6s\n",
      "39:\tlearn: 0.2820610\ttotal: 2.15s\tremaining: 51.5s\n",
      "40:\tlearn: 0.2813003\ttotal: 2.2s\tremaining: 51.5s\n",
      "41:\tlearn: 0.2806024\ttotal: 2.26s\tremaining: 51.5s\n",
      "42:\tlearn: 0.2799109\ttotal: 2.31s\tremaining: 51.3s\n",
      "43:\tlearn: 0.2792039\ttotal: 2.36s\tremaining: 51.3s\n",
      "44:\tlearn: 0.2784987\ttotal: 2.42s\tremaining: 51.3s\n",
      "45:\tlearn: 0.2778428\ttotal: 2.47s\tremaining: 51.2s\n",
      "46:\tlearn: 0.2771961\ttotal: 2.52s\tremaining: 51.1s\n",
      "47:\tlearn: 0.2764983\ttotal: 2.57s\tremaining: 51s\n",
      "48:\tlearn: 0.2757651\ttotal: 2.63s\tremaining: 51s\n",
      "49:\tlearn: 0.2750454\ttotal: 2.69s\tremaining: 51s\n",
      "50:\tlearn: 0.2743702\ttotal: 2.74s\tremaining: 51.1s\n",
      "51:\tlearn: 0.2737082\ttotal: 2.79s\tremaining: 51s\n",
      "52:\tlearn: 0.2730614\ttotal: 2.85s\tremaining: 50.9s\n",
      "53:\tlearn: 0.2724665\ttotal: 2.9s\tremaining: 50.9s\n",
      "54:\tlearn: 0.2718307\ttotal: 2.96s\tremaining: 50.8s\n",
      "55:\tlearn: 0.2712535\ttotal: 3.01s\tremaining: 50.7s\n",
      "56:\tlearn: 0.2706553\ttotal: 3.06s\tremaining: 50.6s\n",
      "57:\tlearn: 0.2700754\ttotal: 3.11s\tremaining: 50.5s\n",
      "58:\tlearn: 0.2694687\ttotal: 3.17s\tremaining: 50.5s\n",
      "59:\tlearn: 0.2689177\ttotal: 3.22s\tremaining: 50.5s\n",
      "60:\tlearn: 0.2683441\ttotal: 3.28s\tremaining: 50.5s\n",
      "61:\tlearn: 0.2677862\ttotal: 3.33s\tremaining: 50.4s\n",
      "62:\tlearn: 0.2672251\ttotal: 3.39s\tremaining: 50.4s\n",
      "63:\tlearn: 0.2666586\ttotal: 3.44s\tremaining: 50.3s\n",
      "64:\tlearn: 0.2661098\ttotal: 3.5s\tremaining: 50.3s\n",
      "65:\tlearn: 0.2655800\ttotal: 3.55s\tremaining: 50.3s\n",
      "66:\tlearn: 0.2650968\ttotal: 3.6s\tremaining: 50.1s\n",
      "67:\tlearn: 0.2645602\ttotal: 3.65s\tremaining: 50.1s\n",
      "68:\tlearn: 0.2640928\ttotal: 3.7s\tremaining: 50s\n",
      "69:\tlearn: 0.2635738\ttotal: 3.76s\tremaining: 49.9s\n",
      "70:\tlearn: 0.2630875\ttotal: 3.81s\tremaining: 49.8s\n",
      "71:\tlearn: 0.2625559\ttotal: 3.87s\tremaining: 49.9s\n",
      "72:\tlearn: 0.2620889\ttotal: 3.92s\tremaining: 49.8s\n",
      "73:\tlearn: 0.2615983\ttotal: 3.98s\tremaining: 49.8s\n",
      "74:\tlearn: 0.2611356\ttotal: 4.05s\tremaining: 49.9s\n",
      "75:\tlearn: 0.2606458\ttotal: 4.1s\tremaining: 49.9s\n",
      "76:\tlearn: 0.2602053\ttotal: 4.16s\tremaining: 49.9s\n",
      "77:\tlearn: 0.2597545\ttotal: 4.22s\tremaining: 49.8s\n",
      "78:\tlearn: 0.2592782\ttotal: 4.28s\tremaining: 49.9s\n",
      "79:\tlearn: 0.2588004\ttotal: 4.34s\tremaining: 49.9s\n",
      "80:\tlearn: 0.2583882\ttotal: 4.39s\tremaining: 49.8s\n",
      "81:\tlearn: 0.2579495\ttotal: 4.45s\tremaining: 49.8s\n",
      "82:\tlearn: 0.2575309\ttotal: 4.5s\tremaining: 49.7s\n",
      "83:\tlearn: 0.2570947\ttotal: 4.55s\tremaining: 49.7s\n",
      "84:\tlearn: 0.2566461\ttotal: 4.61s\tremaining: 49.7s\n",
      "85:\tlearn: 0.2562407\ttotal: 4.67s\tremaining: 49.6s\n",
      "86:\tlearn: 0.2558588\ttotal: 4.72s\tremaining: 49.5s\n",
      "87:\tlearn: 0.2554540\ttotal: 4.77s\tremaining: 49.4s\n",
      "88:\tlearn: 0.2550650\ttotal: 4.81s\tremaining: 49.3s\n",
      "89:\tlearn: 0.2546367\ttotal: 4.87s\tremaining: 49.2s\n",
      "90:\tlearn: 0.2541862\ttotal: 4.93s\tremaining: 49.2s\n",
      "91:\tlearn: 0.2537928\ttotal: 4.98s\tremaining: 49.1s\n",
      "92:\tlearn: 0.2533967\ttotal: 5.04s\tremaining: 49.1s\n",
      "93:\tlearn: 0.2529974\ttotal: 5.09s\tremaining: 49.1s\n",
      "94:\tlearn: 0.2525832\ttotal: 5.14s\tremaining: 49s\n",
      "95:\tlearn: 0.2521953\ttotal: 5.19s\tremaining: 48.9s\n",
      "96:\tlearn: 0.2518087\ttotal: 5.25s\tremaining: 48.9s\n",
      "97:\tlearn: 0.2514123\ttotal: 5.31s\tremaining: 48.9s\n",
      "98:\tlearn: 0.2510447\ttotal: 5.36s\tremaining: 48.8s\n",
      "99:\tlearn: 0.2506898\ttotal: 5.42s\tremaining: 48.7s\n",
      "100:\tlearn: 0.2503285\ttotal: 5.46s\tremaining: 48.6s\n",
      "101:\tlearn: 0.2499741\ttotal: 5.52s\tremaining: 48.6s\n",
      "102:\tlearn: 0.2496266\ttotal: 5.57s\tremaining: 48.5s\n",
      "103:\tlearn: 0.2492963\ttotal: 5.62s\tremaining: 48.4s\n",
      "104:\tlearn: 0.2489719\ttotal: 5.68s\tremaining: 48.4s\n",
      "105:\tlearn: 0.2486170\ttotal: 5.75s\tremaining: 48.5s\n",
      "106:\tlearn: 0.2482620\ttotal: 5.8s\tremaining: 48.5s\n",
      "107:\tlearn: 0.2479176\ttotal: 5.86s\tremaining: 48.4s\n",
      "108:\tlearn: 0.2475602\ttotal: 5.92s\tremaining: 48.4s\n",
      "109:\tlearn: 0.2472250\ttotal: 5.97s\tremaining: 48.3s\n",
      "110:\tlearn: 0.2468808\ttotal: 6.03s\tremaining: 48.3s\n",
      "111:\tlearn: 0.2465654\ttotal: 6.08s\tremaining: 48.2s\n",
      "112:\tlearn: 0.2462354\ttotal: 6.14s\tremaining: 48.2s\n",
      "113:\tlearn: 0.2458833\ttotal: 6.21s\tremaining: 48.3s\n",
      "114:\tlearn: 0.2455356\ttotal: 6.28s\tremaining: 48.4s\n",
      "115:\tlearn: 0.2452002\ttotal: 6.36s\tremaining: 48.4s\n",
      "116:\tlearn: 0.2448800\ttotal: 6.42s\tremaining: 48.5s\n",
      "117:\tlearn: 0.2445946\ttotal: 6.47s\tremaining: 48.4s\n",
      "118:\tlearn: 0.2443127\ttotal: 6.52s\tremaining: 48.3s\n",
      "119:\tlearn: 0.2440029\ttotal: 6.58s\tremaining: 48.2s\n",
      "120:\tlearn: 0.2436689\ttotal: 6.64s\tremaining: 48.3s\n",
      "121:\tlearn: 0.2433640\ttotal: 6.7s\tremaining: 48.2s\n",
      "122:\tlearn: 0.2430357\ttotal: 6.75s\tremaining: 48.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123:\tlearn: 0.2427263\ttotal: 6.81s\tremaining: 48.1s\n",
      "124:\tlearn: 0.2424247\ttotal: 6.86s\tremaining: 48s\n",
      "125:\tlearn: 0.2421367\ttotal: 6.91s\tremaining: 47.9s\n",
      "126:\tlearn: 0.2418456\ttotal: 6.97s\tremaining: 47.9s\n",
      "127:\tlearn: 0.2415343\ttotal: 7.04s\tremaining: 47.9s\n",
      "128:\tlearn: 0.2412158\ttotal: 7.1s\tremaining: 47.9s\n",
      "129:\tlearn: 0.2409249\ttotal: 7.14s\tremaining: 47.8s\n",
      "130:\tlearn: 0.2406611\ttotal: 7.19s\tremaining: 47.7s\n",
      "131:\tlearn: 0.2403730\ttotal: 7.25s\tremaining: 47.7s\n",
      "132:\tlearn: 0.2400949\ttotal: 7.3s\tremaining: 47.6s\n",
      "133:\tlearn: 0.2398006\ttotal: 7.35s\tremaining: 47.5s\n",
      "134:\tlearn: 0.2394865\ttotal: 7.4s\tremaining: 47.4s\n",
      "135:\tlearn: 0.2391999\ttotal: 7.46s\tremaining: 47.4s\n",
      "136:\tlearn: 0.2389197\ttotal: 7.51s\tremaining: 47.3s\n",
      "137:\tlearn: 0.2386208\ttotal: 7.56s\tremaining: 47.2s\n",
      "138:\tlearn: 0.2383470\ttotal: 7.61s\tremaining: 47.1s\n",
      "139:\tlearn: 0.2380618\ttotal: 7.67s\tremaining: 47.1s\n",
      "140:\tlearn: 0.2377824\ttotal: 7.73s\tremaining: 47.1s\n",
      "141:\tlearn: 0.2374985\ttotal: 7.79s\tremaining: 47.1s\n",
      "142:\tlearn: 0.2372361\ttotal: 7.85s\tremaining: 47s\n",
      "143:\tlearn: 0.2369763\ttotal: 7.9s\tremaining: 47s\n",
      "144:\tlearn: 0.2366861\ttotal: 7.97s\tremaining: 47s\n",
      "145:\tlearn: 0.2364120\ttotal: 8.03s\tremaining: 47s\n",
      "146:\tlearn: 0.2361381\ttotal: 8.09s\tremaining: 46.9s\n",
      "147:\tlearn: 0.2358566\ttotal: 8.15s\tremaining: 46.9s\n",
      "148:\tlearn: 0.2355852\ttotal: 8.2s\tremaining: 46.8s\n",
      "149:\tlearn: 0.2353197\ttotal: 8.26s\tremaining: 46.8s\n",
      "150:\tlearn: 0.2350436\ttotal: 8.31s\tremaining: 46.7s\n",
      "151:\tlearn: 0.2347907\ttotal: 8.37s\tremaining: 46.7s\n",
      "152:\tlearn: 0.2345548\ttotal: 8.41s\tremaining: 46.6s\n",
      "153:\tlearn: 0.2343069\ttotal: 8.46s\tremaining: 46.5s\n",
      "154:\tlearn: 0.2340581\ttotal: 8.51s\tremaining: 46.4s\n",
      "155:\tlearn: 0.2338136\ttotal: 8.56s\tremaining: 46.3s\n",
      "156:\tlearn: 0.2335624\ttotal: 8.62s\tremaining: 46.3s\n",
      "157:\tlearn: 0.2333110\ttotal: 8.67s\tremaining: 46.2s\n",
      "158:\tlearn: 0.2330603\ttotal: 8.73s\tremaining: 46.2s\n",
      "159:\tlearn: 0.2328009\ttotal: 8.78s\tremaining: 46.1s\n",
      "160:\tlearn: 0.2325441\ttotal: 8.83s\tremaining: 46s\n",
      "161:\tlearn: 0.2322873\ttotal: 8.88s\tremaining: 46s\n",
      "162:\tlearn: 0.2320339\ttotal: 8.94s\tremaining: 45.9s\n",
      "163:\tlearn: 0.2317930\ttotal: 8.98s\tremaining: 45.8s\n",
      "164:\tlearn: 0.2315275\ttotal: 9.04s\tremaining: 45.8s\n",
      "165:\tlearn: 0.2312949\ttotal: 9.09s\tremaining: 45.7s\n",
      "166:\tlearn: 0.2310586\ttotal: 9.14s\tremaining: 45.6s\n",
      "167:\tlearn: 0.2308123\ttotal: 9.2s\tremaining: 45.6s\n",
      "168:\tlearn: 0.2305600\ttotal: 9.26s\tremaining: 45.5s\n",
      "169:\tlearn: 0.2303313\ttotal: 9.31s\tremaining: 45.4s\n",
      "170:\tlearn: 0.2300937\ttotal: 9.36s\tremaining: 45.4s\n",
      "171:\tlearn: 0.2298504\ttotal: 9.41s\tremaining: 45.3s\n",
      "172:\tlearn: 0.2296369\ttotal: 9.47s\tremaining: 45.3s\n",
      "173:\tlearn: 0.2294187\ttotal: 9.51s\tremaining: 45.2s\n",
      "174:\tlearn: 0.2291883\ttotal: 9.56s\tremaining: 45.1s\n",
      "175:\tlearn: 0.2289468\ttotal: 9.62s\tremaining: 45s\n",
      "176:\tlearn: 0.2287154\ttotal: 9.67s\tremaining: 45s\n",
      "177:\tlearn: 0.2284857\ttotal: 9.72s\tremaining: 44.9s\n",
      "178:\tlearn: 0.2282588\ttotal: 9.78s\tremaining: 44.9s\n",
      "179:\tlearn: 0.2280430\ttotal: 9.84s\tremaining: 44.8s\n",
      "180:\tlearn: 0.2278336\ttotal: 9.89s\tremaining: 44.7s\n",
      "181:\tlearn: 0.2276260\ttotal: 9.95s\tremaining: 44.7s\n",
      "182:\tlearn: 0.2274038\ttotal: 10s\tremaining: 44.7s\n",
      "183:\tlearn: 0.2271953\ttotal: 10.1s\tremaining: 44.7s\n",
      "184:\tlearn: 0.2269722\ttotal: 10.1s\tremaining: 44.6s\n",
      "185:\tlearn: 0.2267488\ttotal: 10.2s\tremaining: 44.6s\n",
      "186:\tlearn: 0.2265368\ttotal: 10.2s\tremaining: 44.6s\n",
      "187:\tlearn: 0.2263347\ttotal: 10.3s\tremaining: 44.5s\n",
      "188:\tlearn: 0.2261194\ttotal: 10.4s\tremaining: 44.5s\n",
      "189:\tlearn: 0.2258987\ttotal: 10.4s\tremaining: 44.4s\n",
      "190:\tlearn: 0.2256863\ttotal: 10.5s\tremaining: 44.4s\n",
      "191:\tlearn: 0.2254682\ttotal: 10.5s\tremaining: 44.4s\n",
      "192:\tlearn: 0.2252686\ttotal: 10.6s\tremaining: 44.3s\n",
      "193:\tlearn: 0.2250658\ttotal: 10.7s\tremaining: 44.3s\n",
      "194:\tlearn: 0.2248589\ttotal: 10.7s\tremaining: 44.2s\n",
      "195:\tlearn: 0.2246478\ttotal: 10.8s\tremaining: 44.2s\n",
      "196:\tlearn: 0.2244340\ttotal: 10.8s\tremaining: 44.2s\n",
      "197:\tlearn: 0.2242263\ttotal: 10.9s\tremaining: 44.1s\n",
      "198:\tlearn: 0.2240224\ttotal: 10.9s\tremaining: 44s\n",
      "199:\tlearn: 0.2238042\ttotal: 11s\tremaining: 44s\n",
      "200:\tlearn: 0.2235936\ttotal: 11.1s\tremaining: 44s\n",
      "201:\tlearn: 0.2233869\ttotal: 11.1s\tremaining: 43.9s\n",
      "202:\tlearn: 0.2231882\ttotal: 11.2s\tremaining: 43.9s\n",
      "203:\tlearn: 0.2229918\ttotal: 11.2s\tremaining: 43.8s\n",
      "204:\tlearn: 0.2227890\ttotal: 11.3s\tremaining: 43.8s\n",
      "205:\tlearn: 0.2225919\ttotal: 11.3s\tremaining: 43.7s\n",
      "206:\tlearn: 0.2223973\ttotal: 11.4s\tremaining: 43.6s\n",
      "207:\tlearn: 0.2222146\ttotal: 11.4s\tremaining: 43.6s\n",
      "208:\tlearn: 0.2220107\ttotal: 11.5s\tremaining: 43.5s\n",
      "209:\tlearn: 0.2218021\ttotal: 11.6s\tremaining: 43.5s\n",
      "210:\tlearn: 0.2216078\ttotal: 11.6s\tremaining: 43.4s\n",
      "211:\tlearn: 0.2214049\ttotal: 11.7s\tremaining: 43.4s\n",
      "212:\tlearn: 0.2211889\ttotal: 11.7s\tremaining: 43.4s\n",
      "213:\tlearn: 0.2210105\ttotal: 11.8s\tremaining: 43.3s\n",
      "214:\tlearn: 0.2208048\ttotal: 11.8s\tremaining: 43.3s\n",
      "215:\tlearn: 0.2206279\ttotal: 11.9s\tremaining: 43.2s\n",
      "216:\tlearn: 0.2204326\ttotal: 12s\tremaining: 43.2s\n",
      "217:\tlearn: 0.2202498\ttotal: 12s\tremaining: 43.2s\n",
      "218:\tlearn: 0.2200591\ttotal: 12.1s\tremaining: 43.1s\n",
      "219:\tlearn: 0.2198704\ttotal: 12.2s\tremaining: 43.1s\n",
      "220:\tlearn: 0.2196778\ttotal: 12.2s\tremaining: 43.1s\n",
      "221:\tlearn: 0.2194907\ttotal: 12.3s\tremaining: 43s\n",
      "222:\tlearn: 0.2192943\ttotal: 12.3s\tremaining: 43s\n",
      "223:\tlearn: 0.2191098\ttotal: 12.4s\tremaining: 42.9s\n",
      "224:\tlearn: 0.2189239\ttotal: 12.4s\tremaining: 42.9s\n",
      "225:\tlearn: 0.2187415\ttotal: 12.5s\tremaining: 42.8s\n",
      "226:\tlearn: 0.2185493\ttotal: 12.6s\tremaining: 42.8s\n",
      "227:\tlearn: 0.2183783\ttotal: 12.6s\tremaining: 42.8s\n",
      "228:\tlearn: 0.2182004\ttotal: 12.7s\tremaining: 42.8s\n",
      "229:\tlearn: 0.2180261\ttotal: 12.8s\tremaining: 42.7s\n",
      "230:\tlearn: 0.2178495\ttotal: 12.8s\tremaining: 42.6s\n",
      "231:\tlearn: 0.2176814\ttotal: 12.9s\tremaining: 42.5s\n",
      "232:\tlearn: 0.2174966\ttotal: 12.9s\tremaining: 42.5s\n",
      "233:\tlearn: 0.2173209\ttotal: 13s\tremaining: 42.5s\n",
      "234:\tlearn: 0.2171454\ttotal: 13s\tremaining: 42.4s\n",
      "235:\tlearn: 0.2169728\ttotal: 13.1s\tremaining: 42.4s\n",
      "236:\tlearn: 0.2168070\ttotal: 13.1s\tremaining: 42.3s\n",
      "237:\tlearn: 0.2166343\ttotal: 13.2s\tremaining: 42.3s\n",
      "238:\tlearn: 0.2164578\ttotal: 13.3s\tremaining: 42.2s\n",
      "239:\tlearn: 0.2162984\ttotal: 13.3s\tremaining: 42.1s\n",
      "240:\tlearn: 0.2161244\ttotal: 13.4s\tremaining: 42.1s\n",
      "241:\tlearn: 0.2159653\ttotal: 13.4s\tremaining: 42.1s\n",
      "242:\tlearn: 0.2157997\ttotal: 13.5s\tremaining: 42s\n",
      "243:\tlearn: 0.2156411\ttotal: 13.5s\tremaining: 42s\n",
      "244:\tlearn: 0.2154953\ttotal: 13.6s\tremaining: 41.9s\n",
      "245:\tlearn: 0.2153276\ttotal: 13.7s\tremaining: 41.9s\n",
      "246:\tlearn: 0.2151526\ttotal: 13.7s\tremaining: 41.8s\n",
      "247:\tlearn: 0.2149997\ttotal: 13.8s\tremaining: 41.7s\n",
      "248:\tlearn: 0.2148455\ttotal: 13.8s\tremaining: 41.7s\n",
      "249:\tlearn: 0.2146820\ttotal: 13.9s\tremaining: 41.6s\n",
      "250:\tlearn: 0.2145179\ttotal: 13.9s\tremaining: 41.6s\n",
      "251:\tlearn: 0.2143617\ttotal: 14s\tremaining: 41.5s\n",
      "252:\tlearn: 0.2141796\ttotal: 14.1s\tremaining: 41.5s\n",
      "253:\tlearn: 0.2140385\ttotal: 14.1s\tremaining: 41.5s\n",
      "254:\tlearn: 0.2138751\ttotal: 14.2s\tremaining: 41.4s\n",
      "255:\tlearn: 0.2137130\ttotal: 14.2s\tremaining: 41.4s\n",
      "256:\tlearn: 0.2135534\ttotal: 14.3s\tremaining: 41.3s\n",
      "257:\tlearn: 0.2133997\ttotal: 14.3s\tremaining: 41.3s\n",
      "258:\tlearn: 0.2132546\ttotal: 14.4s\tremaining: 41.2s\n",
      "259:\tlearn: 0.2131077\ttotal: 14.4s\tremaining: 41.1s\n",
      "260:\tlearn: 0.2129476\ttotal: 14.5s\tremaining: 41.1s\n",
      "261:\tlearn: 0.2127886\ttotal: 14.6s\tremaining: 41s\n",
      "262:\tlearn: 0.2126300\ttotal: 14.6s\tremaining: 41s\n",
      "263:\tlearn: 0.2124749\ttotal: 14.7s\tremaining: 40.9s\n",
      "264:\tlearn: 0.2123227\ttotal: 14.7s\tremaining: 40.9s\n",
      "265:\tlearn: 0.2121700\ttotal: 14.8s\tremaining: 40.8s\n",
      "266:\tlearn: 0.2120184\ttotal: 14.8s\tremaining: 40.7s\n",
      "267:\tlearn: 0.2118611\ttotal: 14.9s\tremaining: 40.7s\n",
      "268:\tlearn: 0.2117143\ttotal: 15s\tremaining: 40.6s\n",
      "269:\tlearn: 0.2115647\ttotal: 15s\tremaining: 40.6s\n",
      "270:\tlearn: 0.2114099\ttotal: 15.1s\tremaining: 40.5s\n",
      "271:\tlearn: 0.2112606\ttotal: 15.1s\tremaining: 40.5s\n",
      "272:\tlearn: 0.2111132\ttotal: 15.2s\tremaining: 40.4s\n",
      "273:\tlearn: 0.2109617\ttotal: 15.2s\tremaining: 40.4s\n",
      "274:\tlearn: 0.2108083\ttotal: 15.3s\tremaining: 40.3s\n",
      "275:\tlearn: 0.2106459\ttotal: 15.4s\tremaining: 40.3s\n",
      "276:\tlearn: 0.2105024\ttotal: 15.4s\tremaining: 40.2s\n",
      "277:\tlearn: 0.2103460\ttotal: 15.5s\tremaining: 40.1s\n",
      "278:\tlearn: 0.2101916\ttotal: 15.5s\tremaining: 40.1s\n",
      "279:\tlearn: 0.2100550\ttotal: 15.6s\tremaining: 40s\n",
      "280:\tlearn: 0.2099040\ttotal: 15.6s\tremaining: 40s\n",
      "281:\tlearn: 0.2097633\ttotal: 15.7s\tremaining: 39.9s\n",
      "282:\tlearn: 0.2096098\ttotal: 15.8s\tremaining: 39.9s\n",
      "283:\tlearn: 0.2094672\ttotal: 15.8s\tremaining: 39.9s\n",
      "284:\tlearn: 0.2093365\ttotal: 15.9s\tremaining: 39.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "285:\tlearn: 0.2092061\ttotal: 15.9s\tremaining: 39.8s\n",
      "286:\tlearn: 0.2090745\ttotal: 16s\tremaining: 39.7s\n",
      "287:\tlearn: 0.2089421\ttotal: 16.1s\tremaining: 39.7s\n",
      "288:\tlearn: 0.2087947\ttotal: 16.1s\tremaining: 39.7s\n",
      "289:\tlearn: 0.2086420\ttotal: 16.2s\tremaining: 39.6s\n",
      "290:\tlearn: 0.2084879\ttotal: 16.2s\tremaining: 39.6s\n",
      "291:\tlearn: 0.2083436\ttotal: 16.3s\tremaining: 39.5s\n",
      "292:\tlearn: 0.2082047\ttotal: 16.4s\tremaining: 39.5s\n",
      "293:\tlearn: 0.2080699\ttotal: 16.4s\tremaining: 39.4s\n",
      "294:\tlearn: 0.2079391\ttotal: 16.5s\tremaining: 39.4s\n",
      "295:\tlearn: 0.2078101\ttotal: 16.5s\tremaining: 39.3s\n",
      "296:\tlearn: 0.2076733\ttotal: 16.6s\tremaining: 39.2s\n",
      "297:\tlearn: 0.2075273\ttotal: 16.6s\tremaining: 39.2s\n",
      "298:\tlearn: 0.2073887\ttotal: 16.7s\tremaining: 39.1s\n",
      "299:\tlearn: 0.2072521\ttotal: 16.7s\tremaining: 39.1s\n",
      "300:\tlearn: 0.2071279\ttotal: 16.8s\tremaining: 39s\n",
      "301:\tlearn: 0.2069864\ttotal: 16.9s\tremaining: 39s\n",
      "302:\tlearn: 0.2068520\ttotal: 16.9s\tremaining: 38.9s\n",
      "303:\tlearn: 0.2067215\ttotal: 17s\tremaining: 38.9s\n",
      "304:\tlearn: 0.2065959\ttotal: 17s\tremaining: 38.8s\n",
      "305:\tlearn: 0.2064692\ttotal: 17.1s\tremaining: 38.8s\n",
      "306:\tlearn: 0.2063422\ttotal: 17.1s\tremaining: 38.7s\n",
      "307:\tlearn: 0.2062218\ttotal: 17.2s\tremaining: 38.6s\n",
      "308:\tlearn: 0.2060705\ttotal: 17.3s\tremaining: 38.6s\n",
      "309:\tlearn: 0.2059264\ttotal: 17.3s\tremaining: 38.6s\n",
      "310:\tlearn: 0.2057894\ttotal: 17.4s\tremaining: 38.5s\n",
      "311:\tlearn: 0.2056689\ttotal: 17.4s\tremaining: 38.4s\n",
      "312:\tlearn: 0.2055329\ttotal: 17.5s\tremaining: 38.4s\n",
      "313:\tlearn: 0.2054078\ttotal: 17.5s\tremaining: 38.3s\n",
      "314:\tlearn: 0.2052745\ttotal: 17.6s\tremaining: 38.3s\n",
      "315:\tlearn: 0.2051261\ttotal: 17.7s\tremaining: 38.3s\n",
      "316:\tlearn: 0.2049935\ttotal: 17.7s\tremaining: 38.2s\n",
      "317:\tlearn: 0.2048624\ttotal: 17.8s\tremaining: 38.2s\n",
      "318:\tlearn: 0.2047236\ttotal: 17.9s\tremaining: 38.1s\n",
      "319:\tlearn: 0.2045968\ttotal: 17.9s\tremaining: 38.1s\n",
      "320:\tlearn: 0.2044684\ttotal: 18s\tremaining: 38s\n",
      "321:\tlearn: 0.2043494\ttotal: 18s\tremaining: 38s\n",
      "322:\tlearn: 0.2042325\ttotal: 18.1s\tremaining: 37.9s\n",
      "323:\tlearn: 0.2041081\ttotal: 18.1s\tremaining: 37.9s\n",
      "324:\tlearn: 0.2039796\ttotal: 18.2s\tremaining: 37.8s\n",
      "325:\tlearn: 0.2038554\ttotal: 18.3s\tremaining: 37.8s\n",
      "326:\tlearn: 0.2037299\ttotal: 18.3s\tremaining: 37.8s\n",
      "327:\tlearn: 0.2036123\ttotal: 18.4s\tremaining: 37.7s\n",
      "328:\tlearn: 0.2034996\ttotal: 18.5s\tremaining: 37.7s\n",
      "329:\tlearn: 0.2033779\ttotal: 18.5s\tremaining: 37.6s\n",
      "330:\tlearn: 0.2032513\ttotal: 18.6s\tremaining: 37.6s\n",
      "331:\tlearn: 0.2031210\ttotal: 18.7s\tremaining: 37.5s\n",
      "332:\tlearn: 0.2029964\ttotal: 18.7s\tremaining: 37.5s\n",
      "333:\tlearn: 0.2028793\ttotal: 18.8s\tremaining: 37.4s\n",
      "334:\tlearn: 0.2027555\ttotal: 18.8s\tremaining: 37.4s\n",
      "335:\tlearn: 0.2026487\ttotal: 18.9s\tremaining: 37.3s\n",
      "336:\tlearn: 0.2025297\ttotal: 18.9s\tremaining: 37.2s\n",
      "337:\tlearn: 0.2024150\ttotal: 19s\tremaining: 37.2s\n",
      "338:\tlearn: 0.2022769\ttotal: 19s\tremaining: 37.1s\n",
      "339:\tlearn: 0.2021534\ttotal: 19.1s\tremaining: 37.1s\n",
      "340:\tlearn: 0.2020400\ttotal: 19.1s\tremaining: 37s\n",
      "341:\tlearn: 0.2019190\ttotal: 19.2s\tremaining: 36.9s\n",
      "342:\tlearn: 0.2018010\ttotal: 19.3s\tremaining: 36.9s\n",
      "343:\tlearn: 0.2016832\ttotal: 19.3s\tremaining: 36.8s\n",
      "344:\tlearn: 0.2015799\ttotal: 19.4s\tremaining: 36.8s\n",
      "345:\tlearn: 0.2014610\ttotal: 19.4s\tremaining: 36.7s\n",
      "346:\tlearn: 0.2013402\ttotal: 19.5s\tremaining: 36.7s\n",
      "347:\tlearn: 0.2012226\ttotal: 19.5s\tremaining: 36.6s\n",
      "348:\tlearn: 0.2011067\ttotal: 19.6s\tremaining: 36.6s\n",
      "349:\tlearn: 0.2009924\ttotal: 19.7s\tremaining: 36.5s\n",
      "350:\tlearn: 0.2008760\ttotal: 19.7s\tremaining: 36.5s\n",
      "351:\tlearn: 0.2007574\ttotal: 19.8s\tremaining: 36.4s\n",
      "352:\tlearn: 0.2006552\ttotal: 19.8s\tremaining: 36.4s\n",
      "353:\tlearn: 0.2005301\ttotal: 19.9s\tremaining: 36.3s\n",
      "354:\tlearn: 0.2004135\ttotal: 20s\tremaining: 36.3s\n",
      "355:\tlearn: 0.2002862\ttotal: 20s\tremaining: 36.2s\n",
      "356:\tlearn: 0.2001845\ttotal: 20.1s\tremaining: 36.1s\n",
      "357:\tlearn: 0.2000659\ttotal: 20.1s\tremaining: 36.1s\n",
      "358:\tlearn: 0.1999628\ttotal: 20.2s\tremaining: 36s\n",
      "359:\tlearn: 0.1998469\ttotal: 20.2s\tremaining: 36s\n",
      "360:\tlearn: 0.1997116\ttotal: 20.3s\tremaining: 36s\n",
      "361:\tlearn: 0.1996138\ttotal: 20.4s\tremaining: 35.9s\n",
      "362:\tlearn: 0.1994953\ttotal: 20.4s\tremaining: 35.9s\n",
      "363:\tlearn: 0.1993749\ttotal: 20.5s\tremaining: 35.8s\n",
      "364:\tlearn: 0.1992557\ttotal: 20.6s\tremaining: 35.8s\n",
      "365:\tlearn: 0.1991555\ttotal: 20.6s\tremaining: 35.7s\n",
      "366:\tlearn: 0.1990473\ttotal: 20.7s\tremaining: 35.7s\n",
      "367:\tlearn: 0.1989292\ttotal: 20.7s\tremaining: 35.6s\n",
      "368:\tlearn: 0.1988183\ttotal: 20.8s\tremaining: 35.5s\n",
      "369:\tlearn: 0.1986914\ttotal: 20.9s\tremaining: 35.5s\n",
      "370:\tlearn: 0.1985790\ttotal: 20.9s\tremaining: 35.4s\n",
      "371:\tlearn: 0.1984639\ttotal: 21s\tremaining: 35.4s\n",
      "372:\tlearn: 0.1983560\ttotal: 21s\tremaining: 35.3s\n",
      "373:\tlearn: 0.1982343\ttotal: 21.1s\tremaining: 35.3s\n",
      "374:\tlearn: 0.1981372\ttotal: 21.2s\tremaining: 35.3s\n",
      "375:\tlearn: 0.1980293\ttotal: 21.2s\tremaining: 35.2s\n",
      "376:\tlearn: 0.1979053\ttotal: 21.3s\tremaining: 35.2s\n",
      "377:\tlearn: 0.1977820\ttotal: 21.3s\tremaining: 35.1s\n",
      "378:\tlearn: 0.1976741\ttotal: 21.4s\tremaining: 35s\n",
      "379:\tlearn: 0.1975540\ttotal: 21.4s\tremaining: 35s\n",
      "380:\tlearn: 0.1974427\ttotal: 21.5s\tremaining: 34.9s\n",
      "381:\tlearn: 0.1973366\ttotal: 21.6s\tremaining: 34.9s\n",
      "382:\tlearn: 0.1972252\ttotal: 21.6s\tremaining: 34.8s\n",
      "383:\tlearn: 0.1971036\ttotal: 21.7s\tremaining: 34.8s\n",
      "384:\tlearn: 0.1969989\ttotal: 21.7s\tremaining: 34.7s\n",
      "385:\tlearn: 0.1968874\ttotal: 21.8s\tremaining: 34.7s\n",
      "386:\tlearn: 0.1967598\ttotal: 21.9s\tremaining: 34.6s\n",
      "387:\tlearn: 0.1966634\ttotal: 21.9s\tremaining: 34.6s\n",
      "388:\tlearn: 0.1965669\ttotal: 22s\tremaining: 34.5s\n",
      "389:\tlearn: 0.1964569\ttotal: 22s\tremaining: 34.5s\n",
      "390:\tlearn: 0.1963454\ttotal: 22.1s\tremaining: 34.4s\n",
      "391:\tlearn: 0.1962294\ttotal: 22.1s\tremaining: 34.3s\n",
      "392:\tlearn: 0.1961196\ttotal: 22.2s\tremaining: 34.3s\n",
      "393:\tlearn: 0.1960111\ttotal: 22.3s\tremaining: 34.2s\n",
      "394:\tlearn: 0.1959070\ttotal: 22.3s\tremaining: 34.2s\n",
      "395:\tlearn: 0.1957943\ttotal: 22.4s\tremaining: 34.2s\n",
      "396:\tlearn: 0.1956924\ttotal: 22.4s\tremaining: 34.1s\n",
      "397:\tlearn: 0.1955918\ttotal: 22.5s\tremaining: 34s\n",
      "398:\tlearn: 0.1954944\ttotal: 22.6s\tremaining: 34s\n",
      "399:\tlearn: 0.1954006\ttotal: 22.6s\tremaining: 33.9s\n",
      "400:\tlearn: 0.1952990\ttotal: 22.7s\tremaining: 33.9s\n",
      "401:\tlearn: 0.1951973\ttotal: 22.7s\tremaining: 33.8s\n",
      "402:\tlearn: 0.1950907\ttotal: 22.8s\tremaining: 33.7s\n",
      "403:\tlearn: 0.1949912\ttotal: 22.8s\tremaining: 33.7s\n",
      "404:\tlearn: 0.1948987\ttotal: 22.9s\tremaining: 33.6s\n",
      "405:\tlearn: 0.1947901\ttotal: 22.9s\tremaining: 33.6s\n",
      "406:\tlearn: 0.1946871\ttotal: 23s\tremaining: 33.5s\n",
      "407:\tlearn: 0.1945832\ttotal: 23s\tremaining: 33.4s\n",
      "408:\tlearn: 0.1944934\ttotal: 23.1s\tremaining: 33.4s\n",
      "409:\tlearn: 0.1943869\ttotal: 23.2s\tremaining: 33.3s\n",
      "410:\tlearn: 0.1942806\ttotal: 23.3s\tremaining: 33.3s\n",
      "411:\tlearn: 0.1941882\ttotal: 23.3s\tremaining: 33.3s\n",
      "412:\tlearn: 0.1940813\ttotal: 23.4s\tremaining: 33.2s\n",
      "413:\tlearn: 0.1939847\ttotal: 23.4s\tremaining: 33.2s\n",
      "414:\tlearn: 0.1938851\ttotal: 23.5s\tremaining: 33.1s\n",
      "415:\tlearn: 0.1937854\ttotal: 23.6s\tremaining: 33.1s\n",
      "416:\tlearn: 0.1936907\ttotal: 23.6s\tremaining: 33s\n",
      "417:\tlearn: 0.1935919\ttotal: 23.7s\tremaining: 33s\n",
      "418:\tlearn: 0.1934886\ttotal: 23.7s\tremaining: 32.9s\n",
      "419:\tlearn: 0.1933828\ttotal: 23.8s\tremaining: 32.8s\n",
      "420:\tlearn: 0.1932858\ttotal: 23.8s\tremaining: 32.8s\n",
      "421:\tlearn: 0.1931718\ttotal: 23.9s\tremaining: 32.7s\n",
      "422:\tlearn: 0.1930676\ttotal: 24s\tremaining: 32.7s\n",
      "423:\tlearn: 0.1929683\ttotal: 24s\tremaining: 32.6s\n",
      "424:\tlearn: 0.1928634\ttotal: 24.1s\tremaining: 32.6s\n",
      "425:\tlearn: 0.1927642\ttotal: 24.1s\tremaining: 32.5s\n",
      "426:\tlearn: 0.1926822\ttotal: 24.2s\tremaining: 32.5s\n",
      "427:\tlearn: 0.1925906\ttotal: 24.2s\tremaining: 32.4s\n",
      "428:\tlearn: 0.1924908\ttotal: 24.3s\tremaining: 32.4s\n",
      "429:\tlearn: 0.1924057\ttotal: 24.4s\tremaining: 32.3s\n",
      "430:\tlearn: 0.1922987\ttotal: 24.4s\tremaining: 32.2s\n",
      "431:\tlearn: 0.1922088\ttotal: 24.5s\tremaining: 32.2s\n",
      "432:\tlearn: 0.1921120\ttotal: 24.5s\tremaining: 32.1s\n",
      "433:\tlearn: 0.1920118\ttotal: 24.6s\tremaining: 32.1s\n",
      "434:\tlearn: 0.1919160\ttotal: 24.7s\tremaining: 32s\n",
      "435:\tlearn: 0.1918231\ttotal: 24.7s\tremaining: 32s\n",
      "436:\tlearn: 0.1917251\ttotal: 24.8s\tremaining: 31.9s\n",
      "437:\tlearn: 0.1916237\ttotal: 24.8s\tremaining: 31.8s\n",
      "438:\tlearn: 0.1915253\ttotal: 24.9s\tremaining: 31.8s\n",
      "439:\tlearn: 0.1914333\ttotal: 24.9s\tremaining: 31.7s\n",
      "440:\tlearn: 0.1913429\ttotal: 25s\tremaining: 31.7s\n",
      "441:\tlearn: 0.1912357\ttotal: 25.1s\tremaining: 31.6s\n",
      "442:\tlearn: 0.1911345\ttotal: 25.1s\tremaining: 31.6s\n",
      "443:\tlearn: 0.1910474\ttotal: 25.2s\tremaining: 31.5s\n",
      "444:\tlearn: 0.1909620\ttotal: 25.2s\tremaining: 31.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "445:\tlearn: 0.1908627\ttotal: 25.3s\tremaining: 31.4s\n",
      "446:\tlearn: 0.1907573\ttotal: 25.3s\tremaining: 31.4s\n",
      "447:\tlearn: 0.1906624\ttotal: 25.4s\tremaining: 31.3s\n",
      "448:\tlearn: 0.1905816\ttotal: 25.4s\tremaining: 31.2s\n",
      "449:\tlearn: 0.1904980\ttotal: 25.5s\tremaining: 31.2s\n",
      "450:\tlearn: 0.1904000\ttotal: 25.6s\tremaining: 31.1s\n",
      "451:\tlearn: 0.1903025\ttotal: 25.6s\tremaining: 31.1s\n",
      "452:\tlearn: 0.1902050\ttotal: 25.7s\tremaining: 31s\n",
      "453:\tlearn: 0.1901150\ttotal: 25.7s\tremaining: 31s\n",
      "454:\tlearn: 0.1900240\ttotal: 25.8s\tremaining: 30.9s\n",
      "455:\tlearn: 0.1899339\ttotal: 25.9s\tremaining: 30.9s\n",
      "456:\tlearn: 0.1898435\ttotal: 25.9s\tremaining: 30.8s\n",
      "457:\tlearn: 0.1897531\ttotal: 26s\tremaining: 30.7s\n",
      "458:\tlearn: 0.1896677\ttotal: 26s\tremaining: 30.7s\n",
      "459:\tlearn: 0.1895684\ttotal: 26.1s\tremaining: 30.6s\n",
      "460:\tlearn: 0.1894790\ttotal: 26.2s\tremaining: 30.6s\n",
      "461:\tlearn: 0.1893851\ttotal: 26.2s\tremaining: 30.5s\n",
      "462:\tlearn: 0.1892900\ttotal: 26.3s\tremaining: 30.5s\n",
      "463:\tlearn: 0.1891981\ttotal: 26.4s\tremaining: 30.5s\n",
      "464:\tlearn: 0.1891306\ttotal: 26.4s\tremaining: 30.4s\n",
      "465:\tlearn: 0.1890362\ttotal: 26.5s\tremaining: 30.3s\n",
      "466:\tlearn: 0.1889525\ttotal: 26.5s\tremaining: 30.3s\n",
      "467:\tlearn: 0.1888687\ttotal: 26.6s\tremaining: 30.2s\n",
      "468:\tlearn: 0.1887923\ttotal: 26.6s\tremaining: 30.1s\n",
      "469:\tlearn: 0.1887035\ttotal: 26.7s\tremaining: 30.1s\n",
      "470:\tlearn: 0.1886136\ttotal: 26.7s\tremaining: 30s\n",
      "471:\tlearn: 0.1885351\ttotal: 26.8s\tremaining: 30s\n",
      "472:\tlearn: 0.1884534\ttotal: 26.8s\tremaining: 29.9s\n",
      "473:\tlearn: 0.1883611\ttotal: 26.9s\tremaining: 29.9s\n",
      "474:\tlearn: 0.1882714\ttotal: 27s\tremaining: 29.8s\n",
      "475:\tlearn: 0.1881907\ttotal: 27s\tremaining: 29.7s\n",
      "476:\tlearn: 0.1881008\ttotal: 27.1s\tremaining: 29.7s\n",
      "477:\tlearn: 0.1880109\ttotal: 27.2s\tremaining: 29.6s\n",
      "478:\tlearn: 0.1879210\ttotal: 27.2s\tremaining: 29.6s\n",
      "479:\tlearn: 0.1878477\ttotal: 27.3s\tremaining: 29.5s\n",
      "480:\tlearn: 0.1877651\ttotal: 27.3s\tremaining: 29.5s\n",
      "481:\tlearn: 0.1876738\ttotal: 27.4s\tremaining: 29.4s\n",
      "482:\tlearn: 0.1875852\ttotal: 27.4s\tremaining: 29.4s\n",
      "483:\tlearn: 0.1875118\ttotal: 27.5s\tremaining: 29.3s\n",
      "484:\tlearn: 0.1874422\ttotal: 27.5s\tremaining: 29.2s\n",
      "485:\tlearn: 0.1873537\ttotal: 27.6s\tremaining: 29.2s\n",
      "486:\tlearn: 0.1872624\ttotal: 27.7s\tremaining: 29.1s\n",
      "487:\tlearn: 0.1871727\ttotal: 27.7s\tremaining: 29.1s\n",
      "488:\tlearn: 0.1870812\ttotal: 27.8s\tremaining: 29s\n",
      "489:\tlearn: 0.1869906\ttotal: 27.8s\tremaining: 29s\n",
      "490:\tlearn: 0.1869131\ttotal: 27.9s\tremaining: 28.9s\n",
      "491:\tlearn: 0.1868293\ttotal: 28s\tremaining: 28.9s\n",
      "492:\tlearn: 0.1867439\ttotal: 28s\tremaining: 28.8s\n",
      "493:\tlearn: 0.1866550\ttotal: 28.1s\tremaining: 28.8s\n",
      "494:\tlearn: 0.1865730\ttotal: 28.1s\tremaining: 28.7s\n",
      "495:\tlearn: 0.1864723\ttotal: 28.2s\tremaining: 28.7s\n",
      "496:\tlearn: 0.1863719\ttotal: 28.3s\tremaining: 28.6s\n",
      "497:\tlearn: 0.1862964\ttotal: 28.3s\tremaining: 28.6s\n",
      "498:\tlearn: 0.1862197\ttotal: 28.4s\tremaining: 28.5s\n",
      "499:\tlearn: 0.1861399\ttotal: 28.5s\tremaining: 28.5s\n",
      "500:\tlearn: 0.1860544\ttotal: 28.5s\tremaining: 28.4s\n",
      "501:\tlearn: 0.1859755\ttotal: 28.6s\tremaining: 28.3s\n",
      "502:\tlearn: 0.1858899\ttotal: 28.6s\tremaining: 28.3s\n",
      "503:\tlearn: 0.1858035\ttotal: 28.7s\tremaining: 28.2s\n",
      "504:\tlearn: 0.1857238\ttotal: 28.8s\tremaining: 28.2s\n",
      "505:\tlearn: 0.1856517\ttotal: 28.8s\tremaining: 28.1s\n",
      "506:\tlearn: 0.1855579\ttotal: 28.9s\tremaining: 28.1s\n",
      "507:\tlearn: 0.1854732\ttotal: 28.9s\tremaining: 28s\n",
      "508:\tlearn: 0.1853825\ttotal: 29s\tremaining: 28s\n",
      "509:\tlearn: 0.1852888\ttotal: 29.1s\tremaining: 27.9s\n",
      "510:\tlearn: 0.1852057\ttotal: 29.1s\tremaining: 27.9s\n",
      "511:\tlearn: 0.1851278\ttotal: 29.2s\tremaining: 27.8s\n",
      "512:\tlearn: 0.1850439\ttotal: 29.2s\tremaining: 27.7s\n",
      "513:\tlearn: 0.1849747\ttotal: 29.3s\tremaining: 27.7s\n",
      "514:\tlearn: 0.1848918\ttotal: 29.3s\tremaining: 27.6s\n",
      "515:\tlearn: 0.1848018\ttotal: 29.4s\tremaining: 27.5s\n",
      "516:\tlearn: 0.1847183\ttotal: 29.4s\tremaining: 27.5s\n",
      "517:\tlearn: 0.1846360\ttotal: 29.5s\tremaining: 27.4s\n",
      "518:\tlearn: 0.1845468\ttotal: 29.6s\tremaining: 27.4s\n",
      "519:\tlearn: 0.1844738\ttotal: 29.6s\tremaining: 27.4s\n",
      "520:\tlearn: 0.1843946\ttotal: 29.7s\tremaining: 27.3s\n",
      "521:\tlearn: 0.1843136\ttotal: 29.8s\tremaining: 27.2s\n",
      "522:\tlearn: 0.1842387\ttotal: 29.8s\tremaining: 27.2s\n",
      "523:\tlearn: 0.1841573\ttotal: 29.9s\tremaining: 27.1s\n",
      "524:\tlearn: 0.1840767\ttotal: 29.9s\tremaining: 27.1s\n",
      "525:\tlearn: 0.1839950\ttotal: 30s\tremaining: 27s\n",
      "526:\tlearn: 0.1839080\ttotal: 30.1s\tremaining: 27s\n",
      "527:\tlearn: 0.1838313\ttotal: 30.1s\tremaining: 26.9s\n",
      "528:\tlearn: 0.1837579\ttotal: 30.2s\tremaining: 26.9s\n",
      "529:\tlearn: 0.1836799\ttotal: 30.2s\tremaining: 26.8s\n",
      "530:\tlearn: 0.1835993\ttotal: 30.3s\tremaining: 26.8s\n",
      "531:\tlearn: 0.1835181\ttotal: 30.4s\tremaining: 26.7s\n",
      "532:\tlearn: 0.1834350\ttotal: 30.4s\tremaining: 26.6s\n",
      "533:\tlearn: 0.1833588\ttotal: 30.5s\tremaining: 26.6s\n",
      "534:\tlearn: 0.1832834\ttotal: 30.5s\tremaining: 26.5s\n",
      "535:\tlearn: 0.1832104\ttotal: 30.6s\tremaining: 26.5s\n",
      "536:\tlearn: 0.1831397\ttotal: 30.6s\tremaining: 26.4s\n",
      "537:\tlearn: 0.1830611\ttotal: 30.7s\tremaining: 26.3s\n",
      "538:\tlearn: 0.1829766\ttotal: 30.7s\tremaining: 26.3s\n",
      "539:\tlearn: 0.1829115\ttotal: 30.8s\tremaining: 26.2s\n",
      "540:\tlearn: 0.1828341\ttotal: 30.8s\tremaining: 26.2s\n",
      "541:\tlearn: 0.1827518\ttotal: 30.9s\tremaining: 26.1s\n",
      "542:\tlearn: 0.1826792\ttotal: 31s\tremaining: 26.1s\n",
      "543:\tlearn: 0.1826133\ttotal: 31s\tremaining: 26s\n",
      "544:\tlearn: 0.1825274\ttotal: 31.1s\tremaining: 25.9s\n",
      "545:\tlearn: 0.1824645\ttotal: 31.1s\tremaining: 25.9s\n",
      "546:\tlearn: 0.1823760\ttotal: 31.2s\tremaining: 25.8s\n",
      "547:\tlearn: 0.1822852\ttotal: 31.2s\tremaining: 25.8s\n",
      "548:\tlearn: 0.1822077\ttotal: 31.3s\tremaining: 25.7s\n",
      "549:\tlearn: 0.1821256\ttotal: 31.3s\tremaining: 25.6s\n",
      "550:\tlearn: 0.1820530\ttotal: 31.4s\tremaining: 25.6s\n",
      "551:\tlearn: 0.1819822\ttotal: 31.5s\tremaining: 25.5s\n",
      "552:\tlearn: 0.1819052\ttotal: 31.5s\tremaining: 25.5s\n",
      "553:\tlearn: 0.1818262\ttotal: 31.6s\tremaining: 25.4s\n",
      "554:\tlearn: 0.1817654\ttotal: 31.6s\tremaining: 25.4s\n",
      "555:\tlearn: 0.1816960\ttotal: 31.7s\tremaining: 25.3s\n",
      "556:\tlearn: 0.1816129\ttotal: 31.7s\tremaining: 25.2s\n",
      "557:\tlearn: 0.1815336\ttotal: 31.8s\tremaining: 25.2s\n",
      "558:\tlearn: 0.1814451\ttotal: 31.9s\tremaining: 25.1s\n",
      "559:\tlearn: 0.1813626\ttotal: 31.9s\tremaining: 25.1s\n",
      "560:\tlearn: 0.1812785\ttotal: 32s\tremaining: 25s\n",
      "561:\tlearn: 0.1811748\ttotal: 32s\tremaining: 25s\n",
      "562:\tlearn: 0.1810907\ttotal: 32.1s\tremaining: 24.9s\n",
      "563:\tlearn: 0.1810294\ttotal: 32.2s\tremaining: 24.9s\n",
      "564:\tlearn: 0.1809425\ttotal: 32.2s\tremaining: 24.8s\n",
      "565:\tlearn: 0.1808694\ttotal: 32.3s\tremaining: 24.8s\n",
      "566:\tlearn: 0.1807883\ttotal: 32.3s\tremaining: 24.7s\n",
      "567:\tlearn: 0.1807192\ttotal: 32.4s\tremaining: 24.6s\n",
      "568:\tlearn: 0.1806323\ttotal: 32.5s\tremaining: 24.6s\n",
      "569:\tlearn: 0.1805592\ttotal: 32.5s\tremaining: 24.5s\n",
      "570:\tlearn: 0.1804827\ttotal: 32.6s\tremaining: 24.5s\n",
      "571:\tlearn: 0.1803973\ttotal: 32.6s\tremaining: 24.4s\n",
      "572:\tlearn: 0.1803172\ttotal: 32.7s\tremaining: 24.4s\n",
      "573:\tlearn: 0.1802435\ttotal: 32.8s\tremaining: 24.3s\n",
      "574:\tlearn: 0.1801628\ttotal: 32.8s\tremaining: 24.3s\n",
      "575:\tlearn: 0.1800808\ttotal: 32.9s\tremaining: 24.2s\n",
      "576:\tlearn: 0.1800089\ttotal: 32.9s\tremaining: 24.1s\n",
      "577:\tlearn: 0.1799335\ttotal: 33s\tremaining: 24.1s\n",
      "578:\tlearn: 0.1798611\ttotal: 33s\tremaining: 24s\n",
      "579:\tlearn: 0.1797826\ttotal: 33.1s\tremaining: 24s\n",
      "580:\tlearn: 0.1797085\ttotal: 33.2s\tremaining: 23.9s\n",
      "581:\tlearn: 0.1796292\ttotal: 33.2s\tremaining: 23.9s\n",
      "582:\tlearn: 0.1795524\ttotal: 33.3s\tremaining: 23.8s\n",
      "583:\tlearn: 0.1794819\ttotal: 33.4s\tremaining: 23.8s\n",
      "584:\tlearn: 0.1794061\ttotal: 33.4s\tremaining: 23.7s\n",
      "585:\tlearn: 0.1793333\ttotal: 33.5s\tremaining: 23.7s\n",
      "586:\tlearn: 0.1792675\ttotal: 33.5s\tremaining: 23.6s\n",
      "587:\tlearn: 0.1791999\ttotal: 33.6s\tremaining: 23.5s\n",
      "588:\tlearn: 0.1791274\ttotal: 33.7s\tremaining: 23.5s\n",
      "589:\tlearn: 0.1790558\ttotal: 33.7s\tremaining: 23.4s\n",
      "590:\tlearn: 0.1789857\ttotal: 33.8s\tremaining: 23.4s\n",
      "591:\tlearn: 0.1789046\ttotal: 33.9s\tremaining: 23.3s\n",
      "592:\tlearn: 0.1788278\ttotal: 33.9s\tremaining: 23.3s\n",
      "593:\tlearn: 0.1787668\ttotal: 34s\tremaining: 23.2s\n",
      "594:\tlearn: 0.1786969\ttotal: 34s\tremaining: 23.2s\n",
      "595:\tlearn: 0.1786353\ttotal: 34.1s\tremaining: 23.1s\n",
      "596:\tlearn: 0.1785662\ttotal: 34.1s\tremaining: 23s\n",
      "597:\tlearn: 0.1784800\ttotal: 34.2s\tremaining: 23s\n",
      "598:\tlearn: 0.1784055\ttotal: 34.2s\tremaining: 22.9s\n",
      "599:\tlearn: 0.1783233\ttotal: 34.3s\tremaining: 22.9s\n",
      "600:\tlearn: 0.1782548\ttotal: 34.4s\tremaining: 22.8s\n",
      "601:\tlearn: 0.1781805\ttotal: 34.4s\tremaining: 22.7s\n",
      "602:\tlearn: 0.1781165\ttotal: 34.5s\tremaining: 22.7s\n",
      "603:\tlearn: 0.1780398\ttotal: 34.5s\tremaining: 22.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "604:\tlearn: 0.1779652\ttotal: 34.6s\tremaining: 22.6s\n",
      "605:\tlearn: 0.1778935\ttotal: 34.6s\tremaining: 22.5s\n",
      "606:\tlearn: 0.1778235\ttotal: 34.7s\tremaining: 22.5s\n",
      "607:\tlearn: 0.1777568\ttotal: 34.7s\tremaining: 22.4s\n",
      "608:\tlearn: 0.1776788\ttotal: 34.8s\tremaining: 22.4s\n",
      "609:\tlearn: 0.1775837\ttotal: 34.9s\tremaining: 22.3s\n",
      "610:\tlearn: 0.1775211\ttotal: 34.9s\tremaining: 22.2s\n",
      "611:\tlearn: 0.1774495\ttotal: 35s\tremaining: 22.2s\n",
      "612:\tlearn: 0.1773694\ttotal: 35s\tremaining: 22.1s\n",
      "613:\tlearn: 0.1772896\ttotal: 35.1s\tremaining: 22.1s\n",
      "614:\tlearn: 0.1772214\ttotal: 35.2s\tremaining: 22s\n",
      "615:\tlearn: 0.1771489\ttotal: 35.2s\tremaining: 22s\n",
      "616:\tlearn: 0.1770772\ttotal: 35.3s\tremaining: 21.9s\n",
      "617:\tlearn: 0.1770085\ttotal: 35.4s\tremaining: 21.9s\n",
      "618:\tlearn: 0.1769272\ttotal: 35.4s\tremaining: 21.8s\n",
      "619:\tlearn: 0.1768489\ttotal: 35.5s\tremaining: 21.7s\n",
      "620:\tlearn: 0.1767766\ttotal: 35.5s\tremaining: 21.7s\n",
      "621:\tlearn: 0.1767032\ttotal: 35.6s\tremaining: 21.6s\n",
      "622:\tlearn: 0.1766285\ttotal: 35.7s\tremaining: 21.6s\n",
      "623:\tlearn: 0.1765492\ttotal: 35.7s\tremaining: 21.5s\n",
      "624:\tlearn: 0.1764648\ttotal: 35.8s\tremaining: 21.5s\n",
      "625:\tlearn: 0.1763941\ttotal: 35.8s\tremaining: 21.4s\n",
      "626:\tlearn: 0.1763287\ttotal: 35.9s\tremaining: 21.4s\n",
      "627:\tlearn: 0.1762662\ttotal: 36s\tremaining: 21.3s\n",
      "628:\tlearn: 0.1761967\ttotal: 36s\tremaining: 21.2s\n",
      "629:\tlearn: 0.1761393\ttotal: 36.1s\tremaining: 21.2s\n",
      "630:\tlearn: 0.1760871\ttotal: 36.1s\tremaining: 21.1s\n",
      "631:\tlearn: 0.1760119\ttotal: 36.2s\tremaining: 21.1s\n",
      "632:\tlearn: 0.1759327\ttotal: 36.2s\tremaining: 21s\n",
      "633:\tlearn: 0.1758542\ttotal: 36.3s\tremaining: 20.9s\n",
      "634:\tlearn: 0.1757832\ttotal: 36.4s\tremaining: 20.9s\n",
      "635:\tlearn: 0.1757115\ttotal: 36.4s\tremaining: 20.8s\n",
      "636:\tlearn: 0.1756493\ttotal: 36.5s\tremaining: 20.8s\n",
      "637:\tlearn: 0.1755915\ttotal: 36.5s\tremaining: 20.7s\n",
      "638:\tlearn: 0.1755275\ttotal: 36.6s\tremaining: 20.7s\n",
      "639:\tlearn: 0.1754617\ttotal: 36.6s\tremaining: 20.6s\n",
      "640:\tlearn: 0.1753954\ttotal: 36.7s\tremaining: 20.6s\n",
      "641:\tlearn: 0.1753438\ttotal: 36.8s\tremaining: 20.5s\n",
      "642:\tlearn: 0.1752802\ttotal: 36.8s\tremaining: 20.4s\n",
      "643:\tlearn: 0.1752146\ttotal: 36.9s\tremaining: 20.4s\n",
      "644:\tlearn: 0.1751555\ttotal: 36.9s\tremaining: 20.3s\n",
      "645:\tlearn: 0.1750822\ttotal: 37s\tremaining: 20.3s\n",
      "646:\tlearn: 0.1750223\ttotal: 37s\tremaining: 20.2s\n",
      "647:\tlearn: 0.1749331\ttotal: 37.1s\tremaining: 20.2s\n",
      "648:\tlearn: 0.1748648\ttotal: 37.2s\tremaining: 20.1s\n",
      "649:\tlearn: 0.1747835\ttotal: 37.2s\tremaining: 20s\n",
      "650:\tlearn: 0.1747166\ttotal: 37.3s\tremaining: 20s\n",
      "651:\tlearn: 0.1746566\ttotal: 37.3s\tremaining: 19.9s\n",
      "652:\tlearn: 0.1745934\ttotal: 37.4s\tremaining: 19.9s\n",
      "653:\tlearn: 0.1745380\ttotal: 37.4s\tremaining: 19.8s\n",
      "654:\tlearn: 0.1744711\ttotal: 37.5s\tremaining: 19.8s\n",
      "655:\tlearn: 0.1744002\ttotal: 37.6s\tremaining: 19.7s\n",
      "656:\tlearn: 0.1743289\ttotal: 37.6s\tremaining: 19.6s\n",
      "657:\tlearn: 0.1742587\ttotal: 37.7s\tremaining: 19.6s\n",
      "658:\tlearn: 0.1741920\ttotal: 37.7s\tremaining: 19.5s\n",
      "659:\tlearn: 0.1741313\ttotal: 37.8s\tremaining: 19.5s\n",
      "660:\tlearn: 0.1740688\ttotal: 37.8s\tremaining: 19.4s\n",
      "661:\tlearn: 0.1740078\ttotal: 37.9s\tremaining: 19.3s\n",
      "662:\tlearn: 0.1739403\ttotal: 38s\tremaining: 19.3s\n",
      "663:\tlearn: 0.1738661\ttotal: 38s\tremaining: 19.2s\n",
      "664:\tlearn: 0.1738106\ttotal: 38.1s\tremaining: 19.2s\n",
      "665:\tlearn: 0.1737421\ttotal: 38.1s\tremaining: 19.1s\n",
      "666:\tlearn: 0.1736809\ttotal: 38.2s\tremaining: 19.1s\n",
      "667:\tlearn: 0.1736224\ttotal: 38.3s\tremaining: 19s\n",
      "668:\tlearn: 0.1735452\ttotal: 38.3s\tremaining: 19s\n",
      "669:\tlearn: 0.1734779\ttotal: 38.4s\tremaining: 18.9s\n",
      "670:\tlearn: 0.1734129\ttotal: 38.4s\tremaining: 18.9s\n",
      "671:\tlearn: 0.1733556\ttotal: 38.5s\tremaining: 18.8s\n",
      "672:\tlearn: 0.1732843\ttotal: 38.6s\tremaining: 18.7s\n",
      "673:\tlearn: 0.1732122\ttotal: 38.6s\tremaining: 18.7s\n",
      "674:\tlearn: 0.1731469\ttotal: 38.7s\tremaining: 18.6s\n",
      "675:\tlearn: 0.1730788\ttotal: 38.7s\tremaining: 18.6s\n",
      "676:\tlearn: 0.1730242\ttotal: 38.8s\tremaining: 18.5s\n",
      "677:\tlearn: 0.1729594\ttotal: 38.8s\tremaining: 18.4s\n",
      "678:\tlearn: 0.1728913\ttotal: 38.9s\tremaining: 18.4s\n",
      "679:\tlearn: 0.1728226\ttotal: 38.9s\tremaining: 18.3s\n",
      "680:\tlearn: 0.1727619\ttotal: 39s\tremaining: 18.3s\n",
      "681:\tlearn: 0.1726994\ttotal: 39.1s\tremaining: 18.2s\n",
      "682:\tlearn: 0.1726312\ttotal: 39.1s\tremaining: 18.2s\n",
      "683:\tlearn: 0.1725611\ttotal: 39.2s\tremaining: 18.1s\n",
      "684:\tlearn: 0.1725001\ttotal: 39.2s\tremaining: 18s\n",
      "685:\tlearn: 0.1724393\ttotal: 39.3s\tremaining: 18s\n",
      "686:\tlearn: 0.1723846\ttotal: 39.3s\tremaining: 17.9s\n",
      "687:\tlearn: 0.1723196\ttotal: 39.4s\tremaining: 17.9s\n",
      "688:\tlearn: 0.1722595\ttotal: 39.5s\tremaining: 17.8s\n",
      "689:\tlearn: 0.1721992\ttotal: 39.5s\tremaining: 17.8s\n",
      "690:\tlearn: 0.1721287\ttotal: 39.6s\tremaining: 17.7s\n",
      "691:\tlearn: 0.1720499\ttotal: 39.6s\tremaining: 17.6s\n",
      "692:\tlearn: 0.1719822\ttotal: 39.7s\tremaining: 17.6s\n",
      "693:\tlearn: 0.1719181\ttotal: 39.8s\tremaining: 17.5s\n",
      "694:\tlearn: 0.1718500\ttotal: 39.8s\tremaining: 17.5s\n",
      "695:\tlearn: 0.1717768\ttotal: 39.9s\tremaining: 17.4s\n",
      "696:\tlearn: 0.1717135\ttotal: 39.9s\tremaining: 17.4s\n",
      "697:\tlearn: 0.1716531\ttotal: 40s\tremaining: 17.3s\n",
      "698:\tlearn: 0.1715776\ttotal: 40.1s\tremaining: 17.2s\n",
      "699:\tlearn: 0.1715036\ttotal: 40.1s\tremaining: 17.2s\n",
      "700:\tlearn: 0.1714493\ttotal: 40.2s\tremaining: 17.1s\n",
      "701:\tlearn: 0.1713747\ttotal: 40.2s\tremaining: 17.1s\n",
      "702:\tlearn: 0.1713011\ttotal: 40.3s\tremaining: 17s\n",
      "703:\tlearn: 0.1712338\ttotal: 40.4s\tremaining: 17s\n",
      "704:\tlearn: 0.1711957\ttotal: 40.4s\tremaining: 16.9s\n",
      "705:\tlearn: 0.1711297\ttotal: 40.5s\tremaining: 16.9s\n",
      "706:\tlearn: 0.1710857\ttotal: 40.5s\tremaining: 16.8s\n",
      "707:\tlearn: 0.1710209\ttotal: 40.6s\tremaining: 16.7s\n",
      "708:\tlearn: 0.1709540\ttotal: 40.6s\tremaining: 16.7s\n",
      "709:\tlearn: 0.1708879\ttotal: 40.7s\tremaining: 16.6s\n",
      "710:\tlearn: 0.1708290\ttotal: 40.8s\tremaining: 16.6s\n",
      "711:\tlearn: 0.1707568\ttotal: 40.8s\tremaining: 16.5s\n",
      "712:\tlearn: 0.1706827\ttotal: 40.9s\tremaining: 16.4s\n",
      "713:\tlearn: 0.1706182\ttotal: 40.9s\tremaining: 16.4s\n",
      "714:\tlearn: 0.1705569\ttotal: 41s\tremaining: 16.3s\n",
      "715:\tlearn: 0.1704917\ttotal: 41s\tremaining: 16.3s\n",
      "716:\tlearn: 0.1704320\ttotal: 41.1s\tremaining: 16.2s\n",
      "717:\tlearn: 0.1703819\ttotal: 41.1s\tremaining: 16.2s\n",
      "718:\tlearn: 0.1703163\ttotal: 41.2s\tremaining: 16.1s\n",
      "719:\tlearn: 0.1702467\ttotal: 41.3s\tremaining: 16s\n",
      "720:\tlearn: 0.1701852\ttotal: 41.3s\tremaining: 16s\n",
      "721:\tlearn: 0.1701199\ttotal: 41.4s\tremaining: 15.9s\n",
      "722:\tlearn: 0.1700533\ttotal: 41.4s\tremaining: 15.9s\n",
      "723:\tlearn: 0.1699910\ttotal: 41.5s\tremaining: 15.8s\n",
      "724:\tlearn: 0.1699231\ttotal: 41.5s\tremaining: 15.8s\n",
      "725:\tlearn: 0.1698470\ttotal: 41.6s\tremaining: 15.7s\n",
      "726:\tlearn: 0.1697816\ttotal: 41.7s\tremaining: 15.6s\n",
      "727:\tlearn: 0.1697204\ttotal: 41.7s\tremaining: 15.6s\n",
      "728:\tlearn: 0.1696507\ttotal: 41.8s\tremaining: 15.5s\n",
      "729:\tlearn: 0.1695808\ttotal: 41.9s\tremaining: 15.5s\n",
      "730:\tlearn: 0.1695144\ttotal: 41.9s\tremaining: 15.4s\n",
      "731:\tlearn: 0.1694721\ttotal: 42s\tremaining: 15.4s\n",
      "732:\tlearn: 0.1694055\ttotal: 42s\tremaining: 15.3s\n",
      "733:\tlearn: 0.1693514\ttotal: 42.1s\tremaining: 15.3s\n",
      "734:\tlearn: 0.1692941\ttotal: 42.1s\tremaining: 15.2s\n",
      "735:\tlearn: 0.1692432\ttotal: 42.2s\tremaining: 15.1s\n",
      "736:\tlearn: 0.1691744\ttotal: 42.2s\tremaining: 15.1s\n",
      "737:\tlearn: 0.1691107\ttotal: 42.3s\tremaining: 15s\n",
      "738:\tlearn: 0.1690503\ttotal: 42.3s\tremaining: 15s\n",
      "739:\tlearn: 0.1689894\ttotal: 42.4s\tremaining: 14.9s\n",
      "740:\tlearn: 0.1689229\ttotal: 42.5s\tremaining: 14.8s\n",
      "741:\tlearn: 0.1688588\ttotal: 42.5s\tremaining: 14.8s\n",
      "742:\tlearn: 0.1688005\ttotal: 42.6s\tremaining: 14.7s\n",
      "743:\tlearn: 0.1687385\ttotal: 42.6s\tremaining: 14.7s\n",
      "744:\tlearn: 0.1686739\ttotal: 42.7s\tremaining: 14.6s\n",
      "745:\tlearn: 0.1686122\ttotal: 42.7s\tremaining: 14.6s\n",
      "746:\tlearn: 0.1685497\ttotal: 42.8s\tremaining: 14.5s\n",
      "747:\tlearn: 0.1684806\ttotal: 42.8s\tremaining: 14.4s\n",
      "748:\tlearn: 0.1684112\ttotal: 42.9s\tremaining: 14.4s\n",
      "749:\tlearn: 0.1683579\ttotal: 42.9s\tremaining: 14.3s\n",
      "750:\tlearn: 0.1682912\ttotal: 43s\tremaining: 14.3s\n",
      "751:\tlearn: 0.1682305\ttotal: 43.1s\tremaining: 14.2s\n",
      "752:\tlearn: 0.1681652\ttotal: 43.1s\tremaining: 14.1s\n",
      "753:\tlearn: 0.1681079\ttotal: 43.2s\tremaining: 14.1s\n",
      "754:\tlearn: 0.1680547\ttotal: 43.2s\tremaining: 14s\n",
      "755:\tlearn: 0.1679942\ttotal: 43.3s\tremaining: 14s\n",
      "756:\tlearn: 0.1679245\ttotal: 43.4s\tremaining: 13.9s\n",
      "757:\tlearn: 0.1678683\ttotal: 43.4s\tremaining: 13.9s\n",
      "758:\tlearn: 0.1677989\ttotal: 43.5s\tremaining: 13.8s\n",
      "759:\tlearn: 0.1677421\ttotal: 43.5s\tremaining: 13.7s\n",
      "760:\tlearn: 0.1676928\ttotal: 43.6s\tremaining: 13.7s\n",
      "761:\tlearn: 0.1676419\ttotal: 43.6s\tremaining: 13.6s\n",
      "762:\tlearn: 0.1675724\ttotal: 43.7s\tremaining: 13.6s\n",
      "763:\tlearn: 0.1675142\ttotal: 43.8s\tremaining: 13.5s\n",
      "764:\tlearn: 0.1674461\ttotal: 43.8s\tremaining: 13.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "765:\tlearn: 0.1673819\ttotal: 43.9s\tremaining: 13.4s\n",
      "766:\tlearn: 0.1673138\ttotal: 43.9s\tremaining: 13.3s\n",
      "767:\tlearn: 0.1672438\ttotal: 44s\tremaining: 13.3s\n",
      "768:\tlearn: 0.1671815\ttotal: 44.1s\tremaining: 13.2s\n",
      "769:\tlearn: 0.1671116\ttotal: 44.1s\tremaining: 13.2s\n",
      "770:\tlearn: 0.1670529\ttotal: 44.2s\tremaining: 13.1s\n",
      "771:\tlearn: 0.1669881\ttotal: 44.2s\tremaining: 13.1s\n",
      "772:\tlearn: 0.1669322\ttotal: 44.3s\tremaining: 13s\n",
      "773:\tlearn: 0.1668780\ttotal: 44.4s\tremaining: 13s\n",
      "774:\tlearn: 0.1668131\ttotal: 44.4s\tremaining: 12.9s\n",
      "775:\tlearn: 0.1667517\ttotal: 44.5s\tremaining: 12.8s\n",
      "776:\tlearn: 0.1666903\ttotal: 44.6s\tremaining: 12.8s\n",
      "777:\tlearn: 0.1666358\ttotal: 44.6s\tremaining: 12.7s\n",
      "778:\tlearn: 0.1665840\ttotal: 44.7s\tremaining: 12.7s\n",
      "779:\tlearn: 0.1665313\ttotal: 44.7s\tremaining: 12.6s\n",
      "780:\tlearn: 0.1664693\ttotal: 44.8s\tremaining: 12.6s\n",
      "781:\tlearn: 0.1664163\ttotal: 44.8s\tremaining: 12.5s\n",
      "782:\tlearn: 0.1663704\ttotal: 44.9s\tremaining: 12.4s\n",
      "783:\tlearn: 0.1662985\ttotal: 44.9s\tremaining: 12.4s\n",
      "784:\tlearn: 0.1662338\ttotal: 45s\tremaining: 12.3s\n",
      "785:\tlearn: 0.1661828\ttotal: 45.1s\tremaining: 12.3s\n",
      "786:\tlearn: 0.1661183\ttotal: 45.1s\tremaining: 12.2s\n",
      "787:\tlearn: 0.1660516\ttotal: 45.2s\tremaining: 12.2s\n",
      "788:\tlearn: 0.1660021\ttotal: 45.2s\tremaining: 12.1s\n",
      "789:\tlearn: 0.1659474\ttotal: 45.3s\tremaining: 12s\n",
      "790:\tlearn: 0.1658875\ttotal: 45.3s\tremaining: 12s\n",
      "791:\tlearn: 0.1658339\ttotal: 45.4s\tremaining: 11.9s\n",
      "792:\tlearn: 0.1657809\ttotal: 45.4s\tremaining: 11.9s\n",
      "793:\tlearn: 0.1657215\ttotal: 45.5s\tremaining: 11.8s\n",
      "794:\tlearn: 0.1656663\ttotal: 45.5s\tremaining: 11.7s\n",
      "795:\tlearn: 0.1656046\ttotal: 45.6s\tremaining: 11.7s\n",
      "796:\tlearn: 0.1655428\ttotal: 45.7s\tremaining: 11.6s\n",
      "797:\tlearn: 0.1654814\ttotal: 45.7s\tremaining: 11.6s\n",
      "798:\tlearn: 0.1654171\ttotal: 45.8s\tremaining: 11.5s\n",
      "799:\tlearn: 0.1653585\ttotal: 45.8s\tremaining: 11.5s\n",
      "800:\tlearn: 0.1653025\ttotal: 45.9s\tremaining: 11.4s\n",
      "801:\tlearn: 0.1652404\ttotal: 46s\tremaining: 11.3s\n",
      "802:\tlearn: 0.1651959\ttotal: 46s\tremaining: 11.3s\n",
      "803:\tlearn: 0.1651399\ttotal: 46.1s\tremaining: 11.2s\n",
      "804:\tlearn: 0.1650721\ttotal: 46.1s\tremaining: 11.2s\n",
      "805:\tlearn: 0.1650226\ttotal: 46.2s\tremaining: 11.1s\n",
      "806:\tlearn: 0.1649645\ttotal: 46.2s\tremaining: 11.1s\n",
      "807:\tlearn: 0.1649066\ttotal: 46.3s\tremaining: 11s\n",
      "808:\tlearn: 0.1648387\ttotal: 46.4s\tremaining: 10.9s\n",
      "809:\tlearn: 0.1647882\ttotal: 46.4s\tremaining: 10.9s\n",
      "810:\tlearn: 0.1647283\ttotal: 46.5s\tremaining: 10.8s\n",
      "811:\tlearn: 0.1646732\ttotal: 46.5s\tremaining: 10.8s\n",
      "812:\tlearn: 0.1646047\ttotal: 46.6s\tremaining: 10.7s\n",
      "813:\tlearn: 0.1645381\ttotal: 46.7s\tremaining: 10.7s\n",
      "814:\tlearn: 0.1644824\ttotal: 46.7s\tremaining: 10.6s\n",
      "815:\tlearn: 0.1644358\ttotal: 46.8s\tremaining: 10.5s\n",
      "816:\tlearn: 0.1643834\ttotal: 46.8s\tremaining: 10.5s\n",
      "817:\tlearn: 0.1643204\ttotal: 46.9s\tremaining: 10.4s\n",
      "818:\tlearn: 0.1642559\ttotal: 46.9s\tremaining: 10.4s\n",
      "819:\tlearn: 0.1642005\ttotal: 47s\tremaining: 10.3s\n",
      "820:\tlearn: 0.1641425\ttotal: 47.1s\tremaining: 10.3s\n",
      "821:\tlearn: 0.1640863\ttotal: 47.1s\tremaining: 10.2s\n",
      "822:\tlearn: 0.1640202\ttotal: 47.2s\tremaining: 10.1s\n",
      "823:\tlearn: 0.1639598\ttotal: 47.2s\tremaining: 10.1s\n",
      "824:\tlearn: 0.1638966\ttotal: 47.3s\tremaining: 10s\n",
      "825:\tlearn: 0.1638356\ttotal: 47.3s\tremaining: 9.97s\n",
      "826:\tlearn: 0.1637707\ttotal: 47.4s\tremaining: 9.91s\n",
      "827:\tlearn: 0.1637123\ttotal: 47.5s\tremaining: 9.86s\n",
      "828:\tlearn: 0.1636578\ttotal: 47.5s\tremaining: 9.8s\n",
      "829:\tlearn: 0.1636020\ttotal: 47.6s\tremaining: 9.74s\n",
      "830:\tlearn: 0.1635415\ttotal: 47.6s\tremaining: 9.69s\n",
      "831:\tlearn: 0.1634862\ttotal: 47.7s\tremaining: 9.63s\n",
      "832:\tlearn: 0.1634277\ttotal: 47.7s\tremaining: 9.57s\n",
      "833:\tlearn: 0.1633765\ttotal: 47.8s\tremaining: 9.51s\n",
      "834:\tlearn: 0.1633198\ttotal: 47.9s\tremaining: 9.46s\n",
      "835:\tlearn: 0.1632620\ttotal: 47.9s\tremaining: 9.4s\n",
      "836:\tlearn: 0.1632126\ttotal: 48s\tremaining: 9.35s\n",
      "837:\tlearn: 0.1631702\ttotal: 48s\tremaining: 9.29s\n",
      "838:\tlearn: 0.1631027\ttotal: 48.1s\tremaining: 9.23s\n",
      "839:\tlearn: 0.1630551\ttotal: 48.1s\tremaining: 9.17s\n",
      "840:\tlearn: 0.1629900\ttotal: 48.2s\tremaining: 9.11s\n",
      "841:\tlearn: 0.1629385\ttotal: 48.3s\tremaining: 9.06s\n",
      "842:\tlearn: 0.1628875\ttotal: 48.3s\tremaining: 9s\n",
      "843:\tlearn: 0.1628456\ttotal: 48.4s\tremaining: 8.94s\n",
      "844:\tlearn: 0.1627944\ttotal: 48.4s\tremaining: 8.88s\n",
      "845:\tlearn: 0.1627415\ttotal: 48.5s\tremaining: 8.83s\n",
      "846:\tlearn: 0.1626989\ttotal: 48.5s\tremaining: 8.77s\n",
      "847:\tlearn: 0.1626491\ttotal: 48.6s\tremaining: 8.71s\n",
      "848:\tlearn: 0.1625953\ttotal: 48.7s\tremaining: 8.65s\n",
      "849:\tlearn: 0.1625342\ttotal: 48.7s\tremaining: 8.6s\n",
      "850:\tlearn: 0.1624737\ttotal: 48.8s\tremaining: 8.54s\n",
      "851:\tlearn: 0.1624140\ttotal: 48.8s\tremaining: 8.48s\n",
      "852:\tlearn: 0.1623512\ttotal: 48.9s\tremaining: 8.43s\n",
      "853:\tlearn: 0.1622846\ttotal: 48.9s\tremaining: 8.37s\n",
      "854:\tlearn: 0.1622285\ttotal: 49s\tremaining: 8.31s\n",
      "855:\tlearn: 0.1621675\ttotal: 49.1s\tremaining: 8.25s\n",
      "856:\tlearn: 0.1621117\ttotal: 49.1s\tremaining: 8.2s\n",
      "857:\tlearn: 0.1620683\ttotal: 49.2s\tremaining: 8.14s\n",
      "858:\tlearn: 0.1620149\ttotal: 49.2s\tremaining: 8.08s\n",
      "859:\tlearn: 0.1619707\ttotal: 49.3s\tremaining: 8.02s\n",
      "860:\tlearn: 0.1619272\ttotal: 49.3s\tremaining: 7.96s\n",
      "861:\tlearn: 0.1618756\ttotal: 49.4s\tremaining: 7.9s\n",
      "862:\tlearn: 0.1618226\ttotal: 49.4s\tremaining: 7.85s\n",
      "863:\tlearn: 0.1617712\ttotal: 49.5s\tremaining: 7.79s\n",
      "864:\tlearn: 0.1617102\ttotal: 49.5s\tremaining: 7.73s\n",
      "865:\tlearn: 0.1616452\ttotal: 49.6s\tremaining: 7.67s\n",
      "866:\tlearn: 0.1616019\ttotal: 49.7s\tremaining: 7.62s\n",
      "867:\tlearn: 0.1615563\ttotal: 49.7s\tremaining: 7.56s\n",
      "868:\tlearn: 0.1615102\ttotal: 49.8s\tremaining: 7.5s\n",
      "869:\tlearn: 0.1614456\ttotal: 49.8s\tremaining: 7.45s\n",
      "870:\tlearn: 0.1613925\ttotal: 49.9s\tremaining: 7.39s\n",
      "871:\tlearn: 0.1613406\ttotal: 50s\tremaining: 7.34s\n",
      "872:\tlearn: 0.1612843\ttotal: 50s\tremaining: 7.28s\n",
      "873:\tlearn: 0.1612202\ttotal: 50.1s\tremaining: 7.22s\n",
      "874:\tlearn: 0.1611601\ttotal: 50.2s\tremaining: 7.17s\n",
      "875:\tlearn: 0.1610984\ttotal: 50.2s\tremaining: 7.11s\n",
      "876:\tlearn: 0.1610343\ttotal: 50.3s\tremaining: 7.05s\n",
      "877:\tlearn: 0.1609784\ttotal: 50.3s\tremaining: 6.99s\n",
      "878:\tlearn: 0.1609211\ttotal: 50.4s\tremaining: 6.94s\n",
      "879:\tlearn: 0.1608661\ttotal: 50.5s\tremaining: 6.88s\n",
      "880:\tlearn: 0.1608161\ttotal: 50.5s\tremaining: 6.82s\n",
      "881:\tlearn: 0.1607604\ttotal: 50.6s\tremaining: 6.77s\n",
      "882:\tlearn: 0.1606954\ttotal: 50.6s\tremaining: 6.71s\n",
      "883:\tlearn: 0.1606418\ttotal: 50.7s\tremaining: 6.65s\n",
      "884:\tlearn: 0.1605915\ttotal: 50.7s\tremaining: 6.59s\n",
      "885:\tlearn: 0.1605264\ttotal: 50.8s\tremaining: 6.54s\n",
      "886:\tlearn: 0.1604710\ttotal: 50.9s\tremaining: 6.48s\n",
      "887:\tlearn: 0.1604263\ttotal: 50.9s\tremaining: 6.42s\n",
      "888:\tlearn: 0.1603545\ttotal: 51s\tremaining: 6.37s\n",
      "889:\tlearn: 0.1603006\ttotal: 51s\tremaining: 6.31s\n",
      "890:\tlearn: 0.1602387\ttotal: 51.1s\tremaining: 6.25s\n",
      "891:\tlearn: 0.1601775\ttotal: 51.2s\tremaining: 6.2s\n",
      "892:\tlearn: 0.1601102\ttotal: 51.2s\tremaining: 6.14s\n",
      "893:\tlearn: 0.1600570\ttotal: 51.3s\tremaining: 6.08s\n",
      "894:\tlearn: 0.1599990\ttotal: 51.3s\tremaining: 6.02s\n",
      "895:\tlearn: 0.1599428\ttotal: 51.4s\tremaining: 5.96s\n",
      "896:\tlearn: 0.1598832\ttotal: 51.4s\tremaining: 5.91s\n",
      "897:\tlearn: 0.1598273\ttotal: 51.5s\tremaining: 5.85s\n",
      "898:\tlearn: 0.1597748\ttotal: 51.5s\tremaining: 5.79s\n",
      "899:\tlearn: 0.1597154\ttotal: 51.6s\tremaining: 5.73s\n",
      "900:\tlearn: 0.1596672\ttotal: 51.7s\tremaining: 5.67s\n",
      "901:\tlearn: 0.1596195\ttotal: 51.7s\tremaining: 5.62s\n",
      "902:\tlearn: 0.1595660\ttotal: 51.8s\tremaining: 5.56s\n",
      "903:\tlearn: 0.1595070\ttotal: 51.8s\tremaining: 5.5s\n",
      "904:\tlearn: 0.1594516\ttotal: 51.9s\tremaining: 5.45s\n",
      "905:\tlearn: 0.1593933\ttotal: 51.9s\tremaining: 5.39s\n",
      "906:\tlearn: 0.1593419\ttotal: 52s\tremaining: 5.33s\n",
      "907:\tlearn: 0.1592825\ttotal: 52.1s\tremaining: 5.28s\n",
      "908:\tlearn: 0.1592320\ttotal: 52.1s\tremaining: 5.22s\n",
      "909:\tlearn: 0.1591898\ttotal: 52.2s\tremaining: 5.16s\n",
      "910:\tlearn: 0.1591406\ttotal: 52.2s\tremaining: 5.1s\n",
      "911:\tlearn: 0.1590983\ttotal: 52.3s\tremaining: 5.05s\n",
      "912:\tlearn: 0.1590426\ttotal: 52.4s\tremaining: 4.99s\n",
      "913:\tlearn: 0.1589779\ttotal: 52.4s\tremaining: 4.93s\n",
      "914:\tlearn: 0.1589303\ttotal: 52.5s\tremaining: 4.88s\n",
      "915:\tlearn: 0.1588724\ttotal: 52.6s\tremaining: 4.82s\n",
      "916:\tlearn: 0.1588088\ttotal: 52.6s\tremaining: 4.76s\n",
      "917:\tlearn: 0.1587498\ttotal: 52.7s\tremaining: 4.71s\n",
      "918:\tlearn: 0.1586984\ttotal: 52.8s\tremaining: 4.65s\n",
      "919:\tlearn: 0.1586322\ttotal: 52.8s\tremaining: 4.59s\n",
      "920:\tlearn: 0.1585793\ttotal: 52.9s\tremaining: 4.54s\n",
      "921:\tlearn: 0.1585259\ttotal: 53s\tremaining: 4.48s\n",
      "922:\tlearn: 0.1584702\ttotal: 53s\tremaining: 4.42s\n",
      "923:\tlearn: 0.1584182\ttotal: 53.1s\tremaining: 4.37s\n",
      "924:\tlearn: 0.1583665\ttotal: 53.2s\tremaining: 4.31s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "925:\tlearn: 0.1583097\ttotal: 53.2s\tremaining: 4.25s\n",
      "926:\tlearn: 0.1582689\ttotal: 53.3s\tremaining: 4.2s\n",
      "927:\tlearn: 0.1582258\ttotal: 53.3s\tremaining: 4.14s\n",
      "928:\tlearn: 0.1581788\ttotal: 53.4s\tremaining: 4.08s\n",
      "929:\tlearn: 0.1581259\ttotal: 53.5s\tremaining: 4.02s\n",
      "930:\tlearn: 0.1580674\ttotal: 53.5s\tremaining: 3.97s\n",
      "931:\tlearn: 0.1580057\ttotal: 53.6s\tremaining: 3.91s\n",
      "932:\tlearn: 0.1579433\ttotal: 53.7s\tremaining: 3.85s\n",
      "933:\tlearn: 0.1578881\ttotal: 53.8s\tremaining: 3.8s\n",
      "934:\tlearn: 0.1578303\ttotal: 53.8s\tremaining: 3.74s\n",
      "935:\tlearn: 0.1577740\ttotal: 53.9s\tremaining: 3.69s\n",
      "936:\tlearn: 0.1577183\ttotal: 54s\tremaining: 3.63s\n",
      "937:\tlearn: 0.1576787\ttotal: 54s\tremaining: 3.57s\n",
      "938:\tlearn: 0.1576360\ttotal: 54.1s\tremaining: 3.51s\n",
      "939:\tlearn: 0.1575871\ttotal: 54.1s\tremaining: 3.46s\n",
      "940:\tlearn: 0.1575281\ttotal: 54.2s\tremaining: 3.4s\n",
      "941:\tlearn: 0.1574773\ttotal: 54.3s\tremaining: 3.34s\n",
      "942:\tlearn: 0.1574284\ttotal: 54.3s\tremaining: 3.28s\n",
      "943:\tlearn: 0.1573883\ttotal: 54.4s\tremaining: 3.23s\n",
      "944:\tlearn: 0.1573351\ttotal: 54.4s\tremaining: 3.17s\n",
      "945:\tlearn: 0.1572803\ttotal: 54.5s\tremaining: 3.11s\n",
      "946:\tlearn: 0.1572368\ttotal: 54.6s\tremaining: 3.05s\n",
      "947:\tlearn: 0.1571739\ttotal: 54.6s\tremaining: 3s\n",
      "948:\tlearn: 0.1571196\ttotal: 54.7s\tremaining: 2.94s\n",
      "949:\tlearn: 0.1570595\ttotal: 54.8s\tremaining: 2.88s\n",
      "950:\tlearn: 0.1570090\ttotal: 54.8s\tremaining: 2.83s\n",
      "951:\tlearn: 0.1569579\ttotal: 54.9s\tremaining: 2.77s\n",
      "952:\tlearn: 0.1569057\ttotal: 55s\tremaining: 2.71s\n",
      "953:\tlearn: 0.1568472\ttotal: 55s\tremaining: 2.65s\n",
      "954:\tlearn: 0.1567919\ttotal: 55.1s\tremaining: 2.6s\n",
      "955:\tlearn: 0.1567479\ttotal: 55.2s\tremaining: 2.54s\n",
      "956:\tlearn: 0.1566925\ttotal: 55.2s\tremaining: 2.48s\n",
      "957:\tlearn: 0.1566305\ttotal: 55.3s\tremaining: 2.42s\n",
      "958:\tlearn: 0.1565902\ttotal: 55.3s\tremaining: 2.37s\n",
      "959:\tlearn: 0.1565401\ttotal: 55.4s\tremaining: 2.31s\n",
      "960:\tlearn: 0.1564802\ttotal: 55.5s\tremaining: 2.25s\n",
      "961:\tlearn: 0.1564322\ttotal: 55.5s\tremaining: 2.19s\n",
      "962:\tlearn: 0.1563841\ttotal: 55.6s\tremaining: 2.13s\n",
      "963:\tlearn: 0.1563322\ttotal: 55.7s\tremaining: 2.08s\n",
      "964:\tlearn: 0.1562884\ttotal: 55.7s\tremaining: 2.02s\n",
      "965:\tlearn: 0.1562380\ttotal: 55.8s\tremaining: 1.96s\n",
      "966:\tlearn: 0.1561922\ttotal: 55.8s\tremaining: 1.9s\n",
      "967:\tlearn: 0.1561469\ttotal: 55.9s\tremaining: 1.85s\n",
      "968:\tlearn: 0.1560847\ttotal: 55.9s\tremaining: 1.79s\n",
      "969:\tlearn: 0.1560595\ttotal: 56s\tremaining: 1.73s\n",
      "970:\tlearn: 0.1560075\ttotal: 56s\tremaining: 1.67s\n",
      "971:\tlearn: 0.1559534\ttotal: 56.1s\tremaining: 1.62s\n",
      "972:\tlearn: 0.1559104\ttotal: 56.2s\tremaining: 1.56s\n",
      "973:\tlearn: 0.1558621\ttotal: 56.2s\tremaining: 1.5s\n",
      "974:\tlearn: 0.1558096\ttotal: 56.3s\tremaining: 1.44s\n",
      "975:\tlearn: 0.1557759\ttotal: 56.3s\tremaining: 1.39s\n",
      "976:\tlearn: 0.1557249\ttotal: 56.4s\tremaining: 1.33s\n",
      "977:\tlearn: 0.1556850\ttotal: 56.5s\tremaining: 1.27s\n",
      "978:\tlearn: 0.1556311\ttotal: 56.5s\tremaining: 1.21s\n",
      "979:\tlearn: 0.1555783\ttotal: 56.6s\tremaining: 1.15s\n",
      "980:\tlearn: 0.1555330\ttotal: 56.6s\tremaining: 1.1s\n",
      "981:\tlearn: 0.1554791\ttotal: 56.7s\tremaining: 1.04s\n",
      "982:\tlearn: 0.1554293\ttotal: 56.8s\tremaining: 981ms\n",
      "983:\tlearn: 0.1553939\ttotal: 56.8s\tremaining: 924ms\n",
      "984:\tlearn: 0.1553372\ttotal: 56.9s\tremaining: 866ms\n",
      "985:\tlearn: 0.1552999\ttotal: 56.9s\tremaining: 808ms\n",
      "986:\tlearn: 0.1552483\ttotal: 57s\tremaining: 750ms\n",
      "987:\tlearn: 0.1551944\ttotal: 57s\tremaining: 693ms\n",
      "988:\tlearn: 0.1551400\ttotal: 57.1s\tremaining: 635ms\n",
      "989:\tlearn: 0.1551034\ttotal: 57.1s\tremaining: 577ms\n",
      "990:\tlearn: 0.1550487\ttotal: 57.2s\tremaining: 519ms\n",
      "991:\tlearn: 0.1549842\ttotal: 57.3s\tremaining: 462ms\n",
      "992:\tlearn: 0.1549260\ttotal: 57.3s\tremaining: 404ms\n",
      "993:\tlearn: 0.1548807\ttotal: 57.4s\tremaining: 346ms\n",
      "994:\tlearn: 0.1548204\ttotal: 57.4s\tremaining: 289ms\n",
      "995:\tlearn: 0.1547728\ttotal: 57.5s\tremaining: 231ms\n",
      "996:\tlearn: 0.1547197\ttotal: 57.5s\tremaining: 173ms\n",
      "997:\tlearn: 0.1546736\ttotal: 57.6s\tremaining: 115ms\n",
      "998:\tlearn: 0.1546317\ttotal: 57.6s\tremaining: 57.7ms\n",
      "999:\tlearn: 0.1545775\ttotal: 57.7s\tremaining: 0us\n",
      "Learning rate set to 0.09461\n",
      "0:\tlearn: 0.6142474\ttotal: 66.1ms\tremaining: 1m 6s\n",
      "1:\tlearn: 0.5504179\ttotal: 128ms\tremaining: 1m 4s\n",
      "2:\tlearn: 0.5016513\ttotal: 191ms\tremaining: 1m 3s\n",
      "3:\tlearn: 0.4636061\ttotal: 254ms\tremaining: 1m 3s\n",
      "4:\tlearn: 0.4323873\ttotal: 320ms\tremaining: 1m 3s\n",
      "5:\tlearn: 0.4072110\ttotal: 373ms\tremaining: 1m 1s\n",
      "6:\tlearn: 0.3870111\ttotal: 428ms\tremaining: 1m\n",
      "7:\tlearn: 0.3708498\ttotal: 478ms\tremaining: 59.3s\n",
      "8:\tlearn: 0.3582224\ttotal: 535ms\tremaining: 58.9s\n",
      "9:\tlearn: 0.3480093\ttotal: 592ms\tremaining: 58.6s\n",
      "10:\tlearn: 0.3401476\ttotal: 655ms\tremaining: 58.9s\n",
      "11:\tlearn: 0.3326906\ttotal: 707ms\tremaining: 58.2s\n",
      "12:\tlearn: 0.3268440\ttotal: 768ms\tremaining: 58.3s\n",
      "13:\tlearn: 0.3217079\ttotal: 829ms\tremaining: 58.4s\n",
      "14:\tlearn: 0.3175571\ttotal: 887ms\tremaining: 58.3s\n",
      "15:\tlearn: 0.3139082\ttotal: 938ms\tremaining: 57.7s\n",
      "16:\tlearn: 0.3107009\ttotal: 994ms\tremaining: 57.5s\n",
      "17:\tlearn: 0.3081612\ttotal: 1.04s\tremaining: 57s\n",
      "18:\tlearn: 0.3058407\ttotal: 1.09s\tremaining: 56.6s\n",
      "19:\tlearn: 0.3036822\ttotal: 1.15s\tremaining: 56.1s\n",
      "20:\tlearn: 0.3017908\ttotal: 1.19s\tremaining: 55.7s\n",
      "21:\tlearn: 0.3001222\ttotal: 1.24s\tremaining: 55.3s\n",
      "22:\tlearn: 0.2984589\ttotal: 1.3s\tremaining: 55.1s\n",
      "23:\tlearn: 0.2970774\ttotal: 1.35s\tremaining: 54.8s\n",
      "24:\tlearn: 0.2957019\ttotal: 1.4s\tremaining: 54.6s\n",
      "25:\tlearn: 0.2944313\ttotal: 1.45s\tremaining: 54.4s\n",
      "26:\tlearn: 0.2932981\ttotal: 1.5s\tremaining: 54.1s\n",
      "27:\tlearn: 0.2921272\ttotal: 1.55s\tremaining: 54s\n",
      "28:\tlearn: 0.2909981\ttotal: 1.62s\tremaining: 54.3s\n",
      "29:\tlearn: 0.2899830\ttotal: 1.67s\tremaining: 54.1s\n",
      "30:\tlearn: 0.2890754\ttotal: 1.72s\tremaining: 53.9s\n",
      "31:\tlearn: 0.2881568\ttotal: 1.77s\tremaining: 53.6s\n",
      "32:\tlearn: 0.2871808\ttotal: 1.82s\tremaining: 53.5s\n",
      "33:\tlearn: 0.2863525\ttotal: 1.87s\tremaining: 53.3s\n",
      "34:\tlearn: 0.2854807\ttotal: 1.93s\tremaining: 53.3s\n",
      "35:\tlearn: 0.2846836\ttotal: 1.99s\tremaining: 53.4s\n",
      "36:\tlearn: 0.2838321\ttotal: 2.05s\tremaining: 53.3s\n",
      "37:\tlearn: 0.2829910\ttotal: 2.1s\tremaining: 53.3s\n",
      "38:\tlearn: 0.2822126\ttotal: 2.16s\tremaining: 53.2s\n",
      "39:\tlearn: 0.2814626\ttotal: 2.21s\tremaining: 53.2s\n",
      "40:\tlearn: 0.2807269\ttotal: 2.28s\tremaining: 53.3s\n",
      "41:\tlearn: 0.2800255\ttotal: 2.34s\tremaining: 53.3s\n",
      "42:\tlearn: 0.2792954\ttotal: 2.41s\tremaining: 53.6s\n",
      "43:\tlearn: 0.2785785\ttotal: 2.47s\tremaining: 53.7s\n",
      "44:\tlearn: 0.2778448\ttotal: 2.53s\tremaining: 53.6s\n",
      "45:\tlearn: 0.2771200\ttotal: 2.58s\tremaining: 53.6s\n",
      "46:\tlearn: 0.2764082\ttotal: 2.64s\tremaining: 53.5s\n",
      "47:\tlearn: 0.2757403\ttotal: 2.69s\tremaining: 53.4s\n",
      "48:\tlearn: 0.2750601\ttotal: 2.75s\tremaining: 53.3s\n",
      "49:\tlearn: 0.2743820\ttotal: 2.79s\tremaining: 53.1s\n",
      "50:\tlearn: 0.2737039\ttotal: 2.85s\tremaining: 53s\n",
      "51:\tlearn: 0.2730912\ttotal: 2.9s\tremaining: 52.9s\n",
      "52:\tlearn: 0.2724896\ttotal: 2.96s\tremaining: 52.9s\n",
      "53:\tlearn: 0.2718254\ttotal: 3.02s\tremaining: 52.9s\n",
      "54:\tlearn: 0.2711684\ttotal: 3.1s\tremaining: 53.2s\n",
      "55:\tlearn: 0.2705981\ttotal: 3.16s\tremaining: 53.3s\n",
      "56:\tlearn: 0.2699737\ttotal: 3.23s\tremaining: 53.5s\n",
      "57:\tlearn: 0.2693975\ttotal: 3.29s\tremaining: 53.4s\n",
      "58:\tlearn: 0.2688179\ttotal: 3.35s\tremaining: 53.5s\n",
      "59:\tlearn: 0.2682320\ttotal: 3.41s\tremaining: 53.4s\n",
      "60:\tlearn: 0.2676334\ttotal: 3.47s\tremaining: 53.4s\n",
      "61:\tlearn: 0.2670898\ttotal: 3.52s\tremaining: 53.3s\n",
      "62:\tlearn: 0.2665414\ttotal: 3.58s\tremaining: 53.3s\n",
      "63:\tlearn: 0.2660213\ttotal: 3.65s\tremaining: 53.3s\n",
      "64:\tlearn: 0.2655013\ttotal: 3.7s\tremaining: 53.2s\n",
      "65:\tlearn: 0.2649444\ttotal: 3.75s\tremaining: 53.1s\n",
      "66:\tlearn: 0.2643867\ttotal: 3.8s\tremaining: 53s\n",
      "67:\tlearn: 0.2639058\ttotal: 3.85s\tremaining: 52.8s\n",
      "68:\tlearn: 0.2633610\ttotal: 3.91s\tremaining: 52.7s\n",
      "69:\tlearn: 0.2628601\ttotal: 3.96s\tremaining: 52.7s\n",
      "70:\tlearn: 0.2623616\ttotal: 4.02s\tremaining: 52.6s\n",
      "71:\tlearn: 0.2618624\ttotal: 4.08s\tremaining: 52.6s\n",
      "72:\tlearn: 0.2614322\ttotal: 4.14s\tremaining: 52.5s\n",
      "73:\tlearn: 0.2609557\ttotal: 4.19s\tremaining: 52.4s\n",
      "74:\tlearn: 0.2604708\ttotal: 4.26s\tremaining: 52.5s\n",
      "75:\tlearn: 0.2599577\ttotal: 4.34s\tremaining: 52.8s\n",
      "76:\tlearn: 0.2594449\ttotal: 4.42s\tremaining: 53s\n",
      "77:\tlearn: 0.2589792\ttotal: 4.48s\tremaining: 52.9s\n",
      "78:\tlearn: 0.2585424\ttotal: 4.53s\tremaining: 52.8s\n",
      "79:\tlearn: 0.2581152\ttotal: 4.58s\tremaining: 52.7s\n",
      "80:\tlearn: 0.2576632\ttotal: 4.64s\tremaining: 52.6s\n",
      "81:\tlearn: 0.2572162\ttotal: 4.7s\tremaining: 52.6s\n",
      "82:\tlearn: 0.2567719\ttotal: 4.76s\tremaining: 52.6s\n",
      "83:\tlearn: 0.2563121\ttotal: 4.82s\tremaining: 52.5s\n",
      "84:\tlearn: 0.2558824\ttotal: 4.87s\tremaining: 52.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85:\tlearn: 0.2554491\ttotal: 4.92s\tremaining: 52.3s\n",
      "86:\tlearn: 0.2550522\ttotal: 4.97s\tremaining: 52.2s\n",
      "87:\tlearn: 0.2546785\ttotal: 5.02s\tremaining: 52.1s\n",
      "88:\tlearn: 0.2542706\ttotal: 5.08s\tremaining: 52s\n",
      "89:\tlearn: 0.2538921\ttotal: 5.13s\tremaining: 51.9s\n",
      "90:\tlearn: 0.2534733\ttotal: 5.18s\tremaining: 51.8s\n",
      "91:\tlearn: 0.2530452\ttotal: 5.25s\tremaining: 51.8s\n",
      "92:\tlearn: 0.2526353\ttotal: 5.31s\tremaining: 51.8s\n",
      "93:\tlearn: 0.2522648\ttotal: 5.37s\tremaining: 51.8s\n",
      "94:\tlearn: 0.2518576\ttotal: 5.42s\tremaining: 51.6s\n",
      "95:\tlearn: 0.2514745\ttotal: 5.48s\tremaining: 51.6s\n",
      "96:\tlearn: 0.2511097\ttotal: 5.54s\tremaining: 51.6s\n",
      "97:\tlearn: 0.2507293\ttotal: 5.61s\tremaining: 51.6s\n",
      "98:\tlearn: 0.2503806\ttotal: 5.67s\tremaining: 51.6s\n",
      "99:\tlearn: 0.2499884\ttotal: 5.73s\tremaining: 51.6s\n",
      "100:\tlearn: 0.2496021\ttotal: 5.78s\tremaining: 51.4s\n",
      "101:\tlearn: 0.2492797\ttotal: 5.83s\tremaining: 51.3s\n",
      "102:\tlearn: 0.2489093\ttotal: 5.89s\tremaining: 51.3s\n",
      "103:\tlearn: 0.2485818\ttotal: 5.95s\tremaining: 51.2s\n",
      "104:\tlearn: 0.2481992\ttotal: 6.01s\tremaining: 51.2s\n",
      "105:\tlearn: 0.2478559\ttotal: 6.07s\tremaining: 51.2s\n",
      "106:\tlearn: 0.2474595\ttotal: 6.14s\tremaining: 51.3s\n",
      "107:\tlearn: 0.2471125\ttotal: 6.21s\tremaining: 51.3s\n",
      "108:\tlearn: 0.2467560\ttotal: 6.26s\tremaining: 51.2s\n",
      "109:\tlearn: 0.2464378\ttotal: 6.32s\tremaining: 51.1s\n",
      "110:\tlearn: 0.2461013\ttotal: 6.38s\tremaining: 51.1s\n",
      "111:\tlearn: 0.2457460\ttotal: 6.43s\tremaining: 51s\n",
      "112:\tlearn: 0.2454098\ttotal: 6.49s\tremaining: 50.9s\n",
      "113:\tlearn: 0.2450863\ttotal: 6.54s\tremaining: 50.8s\n",
      "114:\tlearn: 0.2447649\ttotal: 6.6s\tremaining: 50.8s\n",
      "115:\tlearn: 0.2444427\ttotal: 6.65s\tremaining: 50.7s\n",
      "116:\tlearn: 0.2441193\ttotal: 6.71s\tremaining: 50.6s\n",
      "117:\tlearn: 0.2438127\ttotal: 6.75s\tremaining: 50.5s\n",
      "118:\tlearn: 0.2434777\ttotal: 6.81s\tremaining: 50.4s\n",
      "119:\tlearn: 0.2431787\ttotal: 6.86s\tremaining: 50.3s\n",
      "120:\tlearn: 0.2428975\ttotal: 6.92s\tremaining: 50.2s\n",
      "121:\tlearn: 0.2425993\ttotal: 6.97s\tremaining: 50.2s\n",
      "122:\tlearn: 0.2423138\ttotal: 7.02s\tremaining: 50.1s\n",
      "123:\tlearn: 0.2420277\ttotal: 7.07s\tremaining: 50s\n",
      "124:\tlearn: 0.2417233\ttotal: 7.12s\tremaining: 49.9s\n",
      "125:\tlearn: 0.2414407\ttotal: 7.17s\tremaining: 49.8s\n",
      "126:\tlearn: 0.2411477\ttotal: 7.23s\tremaining: 49.7s\n",
      "127:\tlearn: 0.2408335\ttotal: 7.29s\tremaining: 49.7s\n",
      "128:\tlearn: 0.2405301\ttotal: 7.34s\tremaining: 49.6s\n",
      "129:\tlearn: 0.2402460\ttotal: 7.4s\tremaining: 49.5s\n",
      "130:\tlearn: 0.2399570\ttotal: 7.45s\tremaining: 49.4s\n",
      "131:\tlearn: 0.2396604\ttotal: 7.5s\tremaining: 49.3s\n",
      "132:\tlearn: 0.2393529\ttotal: 7.57s\tremaining: 49.3s\n",
      "133:\tlearn: 0.2390645\ttotal: 7.62s\tremaining: 49.3s\n",
      "134:\tlearn: 0.2387912\ttotal: 7.68s\tremaining: 49.2s\n",
      "135:\tlearn: 0.2384928\ttotal: 7.74s\tremaining: 49.1s\n",
      "136:\tlearn: 0.2381935\ttotal: 7.79s\tremaining: 49.1s\n",
      "137:\tlearn: 0.2379250\ttotal: 7.84s\tremaining: 49s\n",
      "138:\tlearn: 0.2376653\ttotal: 7.89s\tremaining: 48.9s\n",
      "139:\tlearn: 0.2373931\ttotal: 7.94s\tremaining: 48.8s\n",
      "140:\tlearn: 0.2371064\ttotal: 7.99s\tremaining: 48.7s\n",
      "141:\tlearn: 0.2368353\ttotal: 8.05s\tremaining: 48.6s\n",
      "142:\tlearn: 0.2365553\ttotal: 8.11s\tremaining: 48.6s\n",
      "143:\tlearn: 0.2362974\ttotal: 8.17s\tremaining: 48.6s\n",
      "144:\tlearn: 0.2360321\ttotal: 8.22s\tremaining: 48.5s\n",
      "145:\tlearn: 0.2357716\ttotal: 8.27s\tremaining: 48.4s\n",
      "146:\tlearn: 0.2354993\ttotal: 8.33s\tremaining: 48.3s\n",
      "147:\tlearn: 0.2352216\ttotal: 8.38s\tremaining: 48.3s\n",
      "148:\tlearn: 0.2349630\ttotal: 8.44s\tremaining: 48.2s\n",
      "149:\tlearn: 0.2347292\ttotal: 8.49s\tremaining: 48.1s\n",
      "150:\tlearn: 0.2344790\ttotal: 8.54s\tremaining: 48s\n",
      "151:\tlearn: 0.2342131\ttotal: 8.59s\tremaining: 47.9s\n",
      "152:\tlearn: 0.2339502\ttotal: 8.66s\tremaining: 48s\n",
      "153:\tlearn: 0.2336935\ttotal: 8.72s\tremaining: 47.9s\n",
      "154:\tlearn: 0.2334124\ttotal: 8.79s\tremaining: 47.9s\n",
      "155:\tlearn: 0.2331770\ttotal: 8.85s\tremaining: 47.9s\n",
      "156:\tlearn: 0.2329106\ttotal: 8.92s\tremaining: 47.9s\n",
      "157:\tlearn: 0.2326649\ttotal: 8.98s\tremaining: 47.9s\n",
      "158:\tlearn: 0.2324174\ttotal: 9.04s\tremaining: 47.8s\n",
      "159:\tlearn: 0.2321783\ttotal: 9.11s\tremaining: 47.8s\n",
      "160:\tlearn: 0.2319195\ttotal: 9.18s\tremaining: 47.8s\n",
      "161:\tlearn: 0.2316629\ttotal: 9.25s\tremaining: 47.8s\n",
      "162:\tlearn: 0.2314075\ttotal: 9.32s\tremaining: 47.9s\n",
      "163:\tlearn: 0.2311669\ttotal: 9.38s\tremaining: 47.8s\n",
      "164:\tlearn: 0.2308866\ttotal: 9.47s\tremaining: 47.9s\n",
      "165:\tlearn: 0.2306417\ttotal: 9.54s\tremaining: 47.9s\n",
      "166:\tlearn: 0.2304109\ttotal: 9.6s\tremaining: 47.9s\n",
      "167:\tlearn: 0.2301592\ttotal: 9.67s\tremaining: 47.9s\n",
      "168:\tlearn: 0.2299216\ttotal: 9.73s\tremaining: 47.9s\n",
      "169:\tlearn: 0.2297030\ttotal: 9.79s\tremaining: 47.8s\n",
      "170:\tlearn: 0.2294481\ttotal: 9.85s\tremaining: 47.7s\n",
      "171:\tlearn: 0.2292051\ttotal: 9.91s\tremaining: 47.7s\n",
      "172:\tlearn: 0.2289761\ttotal: 9.97s\tremaining: 47.7s\n",
      "173:\tlearn: 0.2287334\ttotal: 10s\tremaining: 47.6s\n",
      "174:\tlearn: 0.2285067\ttotal: 10.1s\tremaining: 47.5s\n",
      "175:\tlearn: 0.2282752\ttotal: 10.1s\tremaining: 47.5s\n",
      "176:\tlearn: 0.2280262\ttotal: 10.2s\tremaining: 47.5s\n",
      "177:\tlearn: 0.2277974\ttotal: 10.3s\tremaining: 47.4s\n",
      "178:\tlearn: 0.2275734\ttotal: 10.3s\tremaining: 47.3s\n",
      "179:\tlearn: 0.2273598\ttotal: 10.4s\tremaining: 47.3s\n",
      "180:\tlearn: 0.2271314\ttotal: 10.4s\tremaining: 47.2s\n",
      "181:\tlearn: 0.2268934\ttotal: 10.5s\tremaining: 47.1s\n",
      "182:\tlearn: 0.2266775\ttotal: 10.5s\tremaining: 47.1s\n",
      "183:\tlearn: 0.2264493\ttotal: 10.6s\tremaining: 47s\n",
      "184:\tlearn: 0.2262276\ttotal: 10.7s\tremaining: 46.9s\n",
      "185:\tlearn: 0.2259945\ttotal: 10.7s\tremaining: 46.9s\n",
      "186:\tlearn: 0.2257837\ttotal: 10.8s\tremaining: 46.8s\n",
      "187:\tlearn: 0.2255552\ttotal: 10.8s\tremaining: 46.8s\n",
      "188:\tlearn: 0.2253151\ttotal: 10.9s\tremaining: 46.7s\n",
      "189:\tlearn: 0.2251177\ttotal: 10.9s\tremaining: 46.6s\n",
      "190:\tlearn: 0.2249193\ttotal: 11s\tremaining: 46.5s\n",
      "191:\tlearn: 0.2247143\ttotal: 11s\tremaining: 46.5s\n",
      "192:\tlearn: 0.2244841\ttotal: 11.1s\tremaining: 46.5s\n",
      "193:\tlearn: 0.2242724\ttotal: 11.2s\tremaining: 46.4s\n",
      "194:\tlearn: 0.2240707\ttotal: 11.2s\tremaining: 46.3s\n",
      "195:\tlearn: 0.2238715\ttotal: 11.3s\tremaining: 46.2s\n",
      "196:\tlearn: 0.2236697\ttotal: 11.3s\tremaining: 46.2s\n",
      "197:\tlearn: 0.2234589\ttotal: 11.4s\tremaining: 46.1s\n",
      "198:\tlearn: 0.2232417\ttotal: 11.4s\tremaining: 46.1s\n",
      "199:\tlearn: 0.2230463\ttotal: 11.5s\tremaining: 46s\n",
      "200:\tlearn: 0.2228405\ttotal: 11.6s\tremaining: 46s\n",
      "201:\tlearn: 0.2226392\ttotal: 11.6s\tremaining: 45.9s\n",
      "202:\tlearn: 0.2224249\ttotal: 11.7s\tremaining: 45.9s\n",
      "203:\tlearn: 0.2222188\ttotal: 11.7s\tremaining: 45.8s\n",
      "204:\tlearn: 0.2220125\ttotal: 11.8s\tremaining: 45.8s\n",
      "205:\tlearn: 0.2218072\ttotal: 11.9s\tremaining: 45.7s\n",
      "206:\tlearn: 0.2216096\ttotal: 11.9s\tremaining: 45.6s\n",
      "207:\tlearn: 0.2214067\ttotal: 12s\tremaining: 45.6s\n",
      "208:\tlearn: 0.2212171\ttotal: 12s\tremaining: 45.5s\n",
      "209:\tlearn: 0.2210168\ttotal: 12.1s\tremaining: 45.5s\n",
      "210:\tlearn: 0.2208230\ttotal: 12.2s\tremaining: 45.4s\n",
      "211:\tlearn: 0.2206297\ttotal: 12.2s\tremaining: 45.4s\n",
      "212:\tlearn: 0.2204296\ttotal: 12.3s\tremaining: 45.4s\n",
      "213:\tlearn: 0.2202504\ttotal: 12.3s\tremaining: 45.3s\n",
      "214:\tlearn: 0.2200638\ttotal: 12.4s\tremaining: 45.3s\n",
      "215:\tlearn: 0.2198808\ttotal: 12.5s\tremaining: 45.3s\n",
      "216:\tlearn: 0.2196898\ttotal: 12.5s\tremaining: 45.2s\n",
      "217:\tlearn: 0.2194993\ttotal: 12.6s\tremaining: 45.2s\n",
      "218:\tlearn: 0.2193056\ttotal: 12.7s\tremaining: 45.1s\n",
      "219:\tlearn: 0.2191148\ttotal: 12.7s\tremaining: 45.1s\n",
      "220:\tlearn: 0.2189405\ttotal: 12.8s\tremaining: 45s\n",
      "221:\tlearn: 0.2187648\ttotal: 12.8s\tremaining: 44.9s\n",
      "222:\tlearn: 0.2185738\ttotal: 12.9s\tremaining: 44.9s\n",
      "223:\tlearn: 0.2183933\ttotal: 13s\tremaining: 44.9s\n",
      "224:\tlearn: 0.2182089\ttotal: 13s\tremaining: 44.8s\n",
      "225:\tlearn: 0.2180329\ttotal: 13.1s\tremaining: 44.8s\n",
      "226:\tlearn: 0.2178663\ttotal: 13.1s\tremaining: 44.8s\n",
      "227:\tlearn: 0.2176895\ttotal: 13.2s\tremaining: 44.7s\n",
      "228:\tlearn: 0.2175175\ttotal: 13.3s\tremaining: 44.7s\n",
      "229:\tlearn: 0.2173496\ttotal: 13.3s\tremaining: 44.7s\n",
      "230:\tlearn: 0.2171731\ttotal: 13.4s\tremaining: 44.6s\n",
      "231:\tlearn: 0.2169975\ttotal: 13.5s\tremaining: 44.6s\n",
      "232:\tlearn: 0.2168327\ttotal: 13.5s\tremaining: 44.5s\n",
      "233:\tlearn: 0.2166519\ttotal: 13.6s\tremaining: 44.5s\n",
      "234:\tlearn: 0.2164779\ttotal: 13.7s\tremaining: 44.5s\n",
      "235:\tlearn: 0.2163078\ttotal: 13.7s\tremaining: 44.4s\n",
      "236:\tlearn: 0.2161409\ttotal: 13.8s\tremaining: 44.4s\n",
      "237:\tlearn: 0.2159721\ttotal: 13.8s\tremaining: 44.3s\n",
      "238:\tlearn: 0.2157844\ttotal: 13.9s\tremaining: 44.3s\n",
      "239:\tlearn: 0.2156153\ttotal: 14s\tremaining: 44.2s\n",
      "240:\tlearn: 0.2154345\ttotal: 14s\tremaining: 44.2s\n",
      "241:\tlearn: 0.2152698\ttotal: 14.1s\tremaining: 44.1s\n",
      "242:\tlearn: 0.2150985\ttotal: 14.1s\tremaining: 44.1s\n",
      "243:\tlearn: 0.2149252\ttotal: 14.2s\tremaining: 44s\n",
      "244:\tlearn: 0.2147486\ttotal: 14.3s\tremaining: 44s\n",
      "245:\tlearn: 0.2145730\ttotal: 14.3s\tremaining: 43.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246:\tlearn: 0.2144133\ttotal: 14.4s\tremaining: 43.9s\n",
      "247:\tlearn: 0.2142410\ttotal: 14.5s\tremaining: 43.8s\n",
      "248:\tlearn: 0.2140683\ttotal: 14.5s\tremaining: 43.8s\n",
      "249:\tlearn: 0.2139051\ttotal: 14.6s\tremaining: 43.8s\n",
      "250:\tlearn: 0.2137498\ttotal: 14.6s\tremaining: 43.7s\n",
      "251:\tlearn: 0.2135706\ttotal: 14.7s\tremaining: 43.7s\n",
      "252:\tlearn: 0.2134347\ttotal: 14.8s\tremaining: 43.6s\n",
      "253:\tlearn: 0.2132644\ttotal: 14.8s\tremaining: 43.6s\n",
      "254:\tlearn: 0.2130995\ttotal: 14.9s\tremaining: 43.5s\n",
      "255:\tlearn: 0.2129252\ttotal: 15s\tremaining: 43.5s\n",
      "256:\tlearn: 0.2127630\ttotal: 15s\tremaining: 43.5s\n",
      "257:\tlearn: 0.2125987\ttotal: 15.1s\tremaining: 43.5s\n",
      "258:\tlearn: 0.2124475\ttotal: 15.2s\tremaining: 43.4s\n",
      "259:\tlearn: 0.2122986\ttotal: 15.2s\tremaining: 43.4s\n",
      "260:\tlearn: 0.2121455\ttotal: 15.3s\tremaining: 43.3s\n",
      "261:\tlearn: 0.2120004\ttotal: 15.4s\tremaining: 43.3s\n",
      "262:\tlearn: 0.2118336\ttotal: 15.4s\tremaining: 43.2s\n",
      "263:\tlearn: 0.2116753\ttotal: 15.5s\tremaining: 43.2s\n",
      "264:\tlearn: 0.2115256\ttotal: 15.6s\tremaining: 43.2s\n",
      "265:\tlearn: 0.2113759\ttotal: 15.6s\tremaining: 43.1s\n",
      "266:\tlearn: 0.2112294\ttotal: 15.7s\tremaining: 43.1s\n",
      "267:\tlearn: 0.2110849\ttotal: 15.8s\tremaining: 43.1s\n",
      "268:\tlearn: 0.2109606\ttotal: 15.8s\tremaining: 43s\n",
      "269:\tlearn: 0.2108075\ttotal: 15.9s\tremaining: 42.9s\n",
      "270:\tlearn: 0.2106642\ttotal: 15.9s\tremaining: 42.9s\n",
      "271:\tlearn: 0.2105222\ttotal: 16s\tremaining: 42.8s\n",
      "272:\tlearn: 0.2103683\ttotal: 16.1s\tremaining: 42.8s\n",
      "273:\tlearn: 0.2102139\ttotal: 16.1s\tremaining: 42.7s\n",
      "274:\tlearn: 0.2100568\ttotal: 16.2s\tremaining: 42.7s\n",
      "275:\tlearn: 0.2099172\ttotal: 16.3s\tremaining: 42.6s\n",
      "276:\tlearn: 0.2097721\ttotal: 16.3s\tremaining: 42.6s\n",
      "277:\tlearn: 0.2096261\ttotal: 16.4s\tremaining: 42.5s\n",
      "278:\tlearn: 0.2094866\ttotal: 16.4s\tremaining: 42.5s\n",
      "279:\tlearn: 0.2093233\ttotal: 16.5s\tremaining: 42.4s\n",
      "280:\tlearn: 0.2091893\ttotal: 16.6s\tremaining: 42.4s\n",
      "281:\tlearn: 0.2090379\ttotal: 16.6s\tremaining: 42.3s\n",
      "282:\tlearn: 0.2088910\ttotal: 16.7s\tremaining: 42.3s\n",
      "283:\tlearn: 0.2087386\ttotal: 16.8s\tremaining: 42.3s\n",
      "284:\tlearn: 0.2086014\ttotal: 16.8s\tremaining: 42.2s\n",
      "285:\tlearn: 0.2084468\ttotal: 16.9s\tremaining: 42.2s\n",
      "286:\tlearn: 0.2082991\ttotal: 17s\tremaining: 42.1s\n",
      "287:\tlearn: 0.2081467\ttotal: 17s\tremaining: 42.1s\n",
      "288:\tlearn: 0.2080096\ttotal: 17.1s\tremaining: 42s\n",
      "289:\tlearn: 0.2078610\ttotal: 17.2s\tremaining: 42s\n",
      "290:\tlearn: 0.2077152\ttotal: 17.2s\tremaining: 42s\n",
      "291:\tlearn: 0.2075763\ttotal: 17.3s\tremaining: 41.9s\n",
      "292:\tlearn: 0.2074303\ttotal: 17.4s\tremaining: 41.9s\n",
      "293:\tlearn: 0.2072893\ttotal: 17.4s\tremaining: 41.8s\n",
      "294:\tlearn: 0.2071483\ttotal: 17.5s\tremaining: 41.8s\n",
      "295:\tlearn: 0.2070236\ttotal: 17.5s\tremaining: 41.7s\n",
      "296:\tlearn: 0.2068762\ttotal: 17.6s\tremaining: 41.7s\n",
      "297:\tlearn: 0.2067317\ttotal: 17.7s\tremaining: 41.6s\n",
      "298:\tlearn: 0.2065875\ttotal: 17.7s\tremaining: 41.6s\n",
      "299:\tlearn: 0.2064559\ttotal: 17.8s\tremaining: 41.5s\n",
      "300:\tlearn: 0.2063137\ttotal: 17.9s\tremaining: 41.5s\n",
      "301:\tlearn: 0.2061896\ttotal: 17.9s\tremaining: 41.4s\n",
      "302:\tlearn: 0.2060453\ttotal: 18s\tremaining: 41.4s\n",
      "303:\tlearn: 0.2059071\ttotal: 18.1s\tremaining: 41.4s\n",
      "304:\tlearn: 0.2057799\ttotal: 18.1s\tremaining: 41.3s\n",
      "305:\tlearn: 0.2056419\ttotal: 18.2s\tremaining: 41.2s\n",
      "306:\tlearn: 0.2055129\ttotal: 18.2s\tremaining: 41.2s\n",
      "307:\tlearn: 0.2053917\ttotal: 18.3s\tremaining: 41.1s\n",
      "308:\tlearn: 0.2052568\ttotal: 18.4s\tremaining: 41.1s\n",
      "309:\tlearn: 0.2051331\ttotal: 18.4s\tremaining: 41s\n",
      "310:\tlearn: 0.2049990\ttotal: 18.5s\tremaining: 41s\n",
      "311:\tlearn: 0.2048678\ttotal: 18.6s\tremaining: 40.9s\n",
      "312:\tlearn: 0.2047364\ttotal: 18.6s\tremaining: 40.9s\n",
      "313:\tlearn: 0.2046056\ttotal: 18.7s\tremaining: 40.8s\n",
      "314:\tlearn: 0.2044637\ttotal: 18.7s\tremaining: 40.7s\n",
      "315:\tlearn: 0.2043372\ttotal: 18.8s\tremaining: 40.7s\n",
      "316:\tlearn: 0.2042100\ttotal: 18.9s\tremaining: 40.7s\n",
      "317:\tlearn: 0.2040748\ttotal: 18.9s\tremaining: 40.6s\n",
      "318:\tlearn: 0.2039456\ttotal: 19s\tremaining: 40.6s\n",
      "319:\tlearn: 0.2038177\ttotal: 19.1s\tremaining: 40.5s\n",
      "320:\tlearn: 0.2036864\ttotal: 19.1s\tremaining: 40.5s\n",
      "321:\tlearn: 0.2035580\ttotal: 19.2s\tremaining: 40.4s\n",
      "322:\tlearn: 0.2034287\ttotal: 19.2s\tremaining: 40.3s\n",
      "323:\tlearn: 0.2032949\ttotal: 19.3s\tremaining: 40.3s\n",
      "324:\tlearn: 0.2031786\ttotal: 19.4s\tremaining: 40.2s\n",
      "325:\tlearn: 0.2030445\ttotal: 19.4s\tremaining: 40.1s\n",
      "326:\tlearn: 0.2029238\ttotal: 19.5s\tremaining: 40.1s\n",
      "327:\tlearn: 0.2027915\ttotal: 19.5s\tremaining: 40s\n",
      "328:\tlearn: 0.2026582\ttotal: 19.6s\tremaining: 40s\n",
      "329:\tlearn: 0.2025310\ttotal: 19.7s\tremaining: 39.9s\n",
      "330:\tlearn: 0.2023954\ttotal: 19.7s\tremaining: 39.9s\n",
      "331:\tlearn: 0.2022742\ttotal: 19.8s\tremaining: 39.8s\n",
      "332:\tlearn: 0.2021567\ttotal: 19.8s\tremaining: 39.7s\n",
      "333:\tlearn: 0.2020307\ttotal: 19.9s\tremaining: 39.7s\n",
      "334:\tlearn: 0.2019165\ttotal: 19.9s\tremaining: 39.6s\n",
      "335:\tlearn: 0.2017866\ttotal: 20s\tremaining: 39.5s\n",
      "336:\tlearn: 0.2016733\ttotal: 20.1s\tremaining: 39.5s\n",
      "337:\tlearn: 0.2015493\ttotal: 20.1s\tremaining: 39.4s\n",
      "338:\tlearn: 0.2014355\ttotal: 20.2s\tremaining: 39.3s\n",
      "339:\tlearn: 0.2013238\ttotal: 20.2s\tremaining: 39.3s\n",
      "340:\tlearn: 0.2012051\ttotal: 20.3s\tremaining: 39.2s\n",
      "341:\tlearn: 0.2010794\ttotal: 20.3s\tremaining: 39.1s\n",
      "342:\tlearn: 0.2009642\ttotal: 20.4s\tremaining: 39s\n",
      "343:\tlearn: 0.2008541\ttotal: 20.4s\tremaining: 39s\n",
      "344:\tlearn: 0.2007296\ttotal: 20.5s\tremaining: 38.9s\n",
      "345:\tlearn: 0.2005941\ttotal: 20.6s\tremaining: 38.9s\n",
      "346:\tlearn: 0.2004670\ttotal: 20.6s\tremaining: 38.8s\n",
      "347:\tlearn: 0.2003533\ttotal: 20.7s\tremaining: 38.8s\n",
      "348:\tlearn: 0.2002406\ttotal: 20.7s\tremaining: 38.7s\n",
      "349:\tlearn: 0.2001326\ttotal: 20.8s\tremaining: 38.6s\n",
      "350:\tlearn: 0.2000079\ttotal: 20.9s\tremaining: 38.6s\n",
      "351:\tlearn: 0.1998865\ttotal: 20.9s\tremaining: 38.5s\n",
      "352:\tlearn: 0.1997585\ttotal: 21s\tremaining: 38.5s\n",
      "353:\tlearn: 0.1996410\ttotal: 21.1s\tremaining: 38.4s\n",
      "354:\tlearn: 0.1995321\ttotal: 21.1s\tremaining: 38.4s\n",
      "355:\tlearn: 0.1994262\ttotal: 21.2s\tremaining: 38.3s\n",
      "356:\tlearn: 0.1993107\ttotal: 21.2s\tremaining: 38.2s\n",
      "357:\tlearn: 0.1992021\ttotal: 21.3s\tremaining: 38.2s\n",
      "358:\tlearn: 0.1990891\ttotal: 21.4s\tremaining: 38.1s\n",
      "359:\tlearn: 0.1989752\ttotal: 21.4s\tremaining: 38.1s\n",
      "360:\tlearn: 0.1988532\ttotal: 21.5s\tremaining: 38s\n",
      "361:\tlearn: 0.1987436\ttotal: 21.5s\tremaining: 38s\n",
      "362:\tlearn: 0.1986359\ttotal: 21.6s\tremaining: 37.9s\n",
      "363:\tlearn: 0.1985233\ttotal: 21.7s\tremaining: 37.9s\n",
      "364:\tlearn: 0.1984139\ttotal: 21.7s\tremaining: 37.8s\n",
      "365:\tlearn: 0.1983062\ttotal: 21.8s\tremaining: 37.8s\n",
      "366:\tlearn: 0.1981939\ttotal: 21.9s\tremaining: 37.7s\n",
      "367:\tlearn: 0.1980805\ttotal: 21.9s\tremaining: 37.6s\n",
      "368:\tlearn: 0.1979817\ttotal: 22s\tremaining: 37.6s\n",
      "369:\tlearn: 0.1978749\ttotal: 22s\tremaining: 37.5s\n",
      "370:\tlearn: 0.1977687\ttotal: 22.1s\tremaining: 37.4s\n",
      "371:\tlearn: 0.1976457\ttotal: 22.1s\tremaining: 37.4s\n",
      "372:\tlearn: 0.1975368\ttotal: 22.2s\tremaining: 37.3s\n",
      "373:\tlearn: 0.1974319\ttotal: 22.3s\tremaining: 37.3s\n",
      "374:\tlearn: 0.1973339\ttotal: 22.3s\tremaining: 37.2s\n",
      "375:\tlearn: 0.1972199\ttotal: 22.4s\tremaining: 37.2s\n",
      "376:\tlearn: 0.1971022\ttotal: 22.5s\tremaining: 37.2s\n",
      "377:\tlearn: 0.1970002\ttotal: 22.6s\tremaining: 37.1s\n",
      "378:\tlearn: 0.1968914\ttotal: 22.6s\tremaining: 37.1s\n",
      "379:\tlearn: 0.1967833\ttotal: 22.7s\tremaining: 37.1s\n",
      "380:\tlearn: 0.1966803\ttotal: 22.8s\tremaining: 37s\n",
      "381:\tlearn: 0.1965612\ttotal: 22.9s\tremaining: 37s\n",
      "382:\tlearn: 0.1964545\ttotal: 23s\tremaining: 37s\n",
      "383:\tlearn: 0.1963446\ttotal: 23s\tremaining: 36.9s\n",
      "384:\tlearn: 0.1962346\ttotal: 23.1s\tremaining: 36.9s\n",
      "385:\tlearn: 0.1961262\ttotal: 23.2s\tremaining: 36.8s\n",
      "386:\tlearn: 0.1960137\ttotal: 23.2s\tremaining: 36.8s\n",
      "387:\tlearn: 0.1958964\ttotal: 23.3s\tremaining: 36.7s\n",
      "388:\tlearn: 0.1957804\ttotal: 23.3s\tremaining: 36.7s\n",
      "389:\tlearn: 0.1956763\ttotal: 23.4s\tremaining: 36.6s\n",
      "390:\tlearn: 0.1955636\ttotal: 23.5s\tremaining: 36.6s\n",
      "391:\tlearn: 0.1954606\ttotal: 23.6s\tremaining: 36.5s\n",
      "392:\tlearn: 0.1953486\ttotal: 23.6s\tremaining: 36.5s\n",
      "393:\tlearn: 0.1952474\ttotal: 23.7s\tremaining: 36.4s\n",
      "394:\tlearn: 0.1951549\ttotal: 23.8s\tremaining: 36.4s\n",
      "395:\tlearn: 0.1950569\ttotal: 23.8s\tremaining: 36.4s\n",
      "396:\tlearn: 0.1949496\ttotal: 23.9s\tremaining: 36.3s\n",
      "397:\tlearn: 0.1948396\ttotal: 24s\tremaining: 36.3s\n",
      "398:\tlearn: 0.1947293\ttotal: 24.1s\tremaining: 36.3s\n",
      "399:\tlearn: 0.1946210\ttotal: 24.1s\tremaining: 36.2s\n",
      "400:\tlearn: 0.1945043\ttotal: 24.2s\tremaining: 36.1s\n",
      "401:\tlearn: 0.1943924\ttotal: 24.3s\tremaining: 36.1s\n",
      "402:\tlearn: 0.1942913\ttotal: 24.3s\tremaining: 36s\n",
      "403:\tlearn: 0.1941859\ttotal: 24.4s\tremaining: 36s\n",
      "404:\tlearn: 0.1940954\ttotal: 24.5s\tremaining: 35.9s\n",
      "405:\tlearn: 0.1939962\ttotal: 24.5s\tremaining: 35.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "406:\tlearn: 0.1939016\ttotal: 24.6s\tremaining: 35.8s\n",
      "407:\tlearn: 0.1938079\ttotal: 24.6s\tremaining: 35.7s\n",
      "408:\tlearn: 0.1937102\ttotal: 24.7s\tremaining: 35.7s\n",
      "409:\tlearn: 0.1936058\ttotal: 24.7s\tremaining: 35.6s\n",
      "410:\tlearn: 0.1935062\ttotal: 24.8s\tremaining: 35.5s\n",
      "411:\tlearn: 0.1934130\ttotal: 24.9s\tremaining: 35.5s\n",
      "412:\tlearn: 0.1933213\ttotal: 24.9s\tremaining: 35.4s\n",
      "413:\tlearn: 0.1932199\ttotal: 25s\tremaining: 35.4s\n",
      "414:\tlearn: 0.1931285\ttotal: 25.1s\tremaining: 35.3s\n",
      "415:\tlearn: 0.1930251\ttotal: 25.1s\tremaining: 35.3s\n",
      "416:\tlearn: 0.1929191\ttotal: 25.2s\tremaining: 35.2s\n",
      "417:\tlearn: 0.1928118\ttotal: 25.3s\tremaining: 35.2s\n",
      "418:\tlearn: 0.1927184\ttotal: 25.3s\tremaining: 35.1s\n",
      "419:\tlearn: 0.1926095\ttotal: 25.4s\tremaining: 35.1s\n",
      "420:\tlearn: 0.1925170\ttotal: 25.4s\tremaining: 35s\n",
      "421:\tlearn: 0.1924093\ttotal: 25.5s\tremaining: 34.9s\n",
      "422:\tlearn: 0.1923043\ttotal: 25.6s\tremaining: 34.9s\n",
      "423:\tlearn: 0.1921988\ttotal: 25.6s\tremaining: 34.8s\n",
      "424:\tlearn: 0.1920970\ttotal: 25.7s\tremaining: 34.8s\n",
      "425:\tlearn: 0.1920030\ttotal: 25.8s\tremaining: 34.7s\n",
      "426:\tlearn: 0.1919052\ttotal: 25.8s\tremaining: 34.6s\n",
      "427:\tlearn: 0.1918190\ttotal: 25.9s\tremaining: 34.6s\n",
      "428:\tlearn: 0.1917328\ttotal: 25.9s\tremaining: 34.5s\n",
      "429:\tlearn: 0.1916420\ttotal: 26s\tremaining: 34.4s\n",
      "430:\tlearn: 0.1915402\ttotal: 26s\tremaining: 34.4s\n",
      "431:\tlearn: 0.1914505\ttotal: 26.1s\tremaining: 34.3s\n",
      "432:\tlearn: 0.1913566\ttotal: 26.1s\tremaining: 34.2s\n",
      "433:\tlearn: 0.1912563\ttotal: 26.2s\tremaining: 34.2s\n",
      "434:\tlearn: 0.1911470\ttotal: 26.3s\tremaining: 34.1s\n",
      "435:\tlearn: 0.1910447\ttotal: 26.3s\tremaining: 34s\n",
      "436:\tlearn: 0.1909487\ttotal: 26.4s\tremaining: 34s\n",
      "437:\tlearn: 0.1908537\ttotal: 26.4s\tremaining: 33.9s\n",
      "438:\tlearn: 0.1907612\ttotal: 26.5s\tremaining: 33.9s\n",
      "439:\tlearn: 0.1906715\ttotal: 26.5s\tremaining: 33.8s\n",
      "440:\tlearn: 0.1905815\ttotal: 26.6s\tremaining: 33.7s\n",
      "441:\tlearn: 0.1904821\ttotal: 26.7s\tremaining: 33.7s\n",
      "442:\tlearn: 0.1903907\ttotal: 26.7s\tremaining: 33.6s\n",
      "443:\tlearn: 0.1902881\ttotal: 26.8s\tremaining: 33.5s\n",
      "444:\tlearn: 0.1901980\ttotal: 26.8s\tremaining: 33.5s\n",
      "445:\tlearn: 0.1901144\ttotal: 26.9s\tremaining: 33.4s\n",
      "446:\tlearn: 0.1900168\ttotal: 26.9s\tremaining: 33.3s\n",
      "447:\tlearn: 0.1899191\ttotal: 27s\tremaining: 33.3s\n",
      "448:\tlearn: 0.1898334\ttotal: 27.1s\tremaining: 33.2s\n",
      "449:\tlearn: 0.1897337\ttotal: 27.1s\tremaining: 33.1s\n",
      "450:\tlearn: 0.1896438\ttotal: 27.2s\tremaining: 33.1s\n",
      "451:\tlearn: 0.1895432\ttotal: 27.2s\tremaining: 33s\n",
      "452:\tlearn: 0.1894447\ttotal: 27.3s\tremaining: 33s\n",
      "453:\tlearn: 0.1893524\ttotal: 27.4s\tremaining: 32.9s\n",
      "454:\tlearn: 0.1892508\ttotal: 27.4s\tremaining: 32.8s\n",
      "455:\tlearn: 0.1891520\ttotal: 27.5s\tremaining: 32.8s\n",
      "456:\tlearn: 0.1890600\ttotal: 27.5s\tremaining: 32.7s\n",
      "457:\tlearn: 0.1889708\ttotal: 27.6s\tremaining: 32.7s\n",
      "458:\tlearn: 0.1888768\ttotal: 27.7s\tremaining: 32.6s\n",
      "459:\tlearn: 0.1887652\ttotal: 27.7s\tremaining: 32.5s\n",
      "460:\tlearn: 0.1886784\ttotal: 27.8s\tremaining: 32.5s\n",
      "461:\tlearn: 0.1885839\ttotal: 27.8s\tremaining: 32.4s\n",
      "462:\tlearn: 0.1884967\ttotal: 27.9s\tremaining: 32.4s\n",
      "463:\tlearn: 0.1884226\ttotal: 28s\tremaining: 32.3s\n",
      "464:\tlearn: 0.1883310\ttotal: 28s\tremaining: 32.2s\n",
      "465:\tlearn: 0.1882431\ttotal: 28.1s\tremaining: 32.2s\n",
      "466:\tlearn: 0.1881658\ttotal: 28.1s\tremaining: 32.1s\n",
      "467:\tlearn: 0.1880832\ttotal: 28.2s\tremaining: 32.1s\n",
      "468:\tlearn: 0.1879889\ttotal: 28.3s\tremaining: 32s\n",
      "469:\tlearn: 0.1879053\ttotal: 28.3s\tremaining: 31.9s\n",
      "470:\tlearn: 0.1878146\ttotal: 28.4s\tremaining: 31.9s\n",
      "471:\tlearn: 0.1877194\ttotal: 28.4s\tremaining: 31.8s\n",
      "472:\tlearn: 0.1876324\ttotal: 28.5s\tremaining: 31.8s\n",
      "473:\tlearn: 0.1875409\ttotal: 28.6s\tremaining: 31.7s\n",
      "474:\tlearn: 0.1874587\ttotal: 28.6s\tremaining: 31.6s\n",
      "475:\tlearn: 0.1873772\ttotal: 28.7s\tremaining: 31.6s\n",
      "476:\tlearn: 0.1872921\ttotal: 28.7s\tremaining: 31.5s\n",
      "477:\tlearn: 0.1872028\ttotal: 28.8s\tremaining: 31.4s\n",
      "478:\tlearn: 0.1871224\ttotal: 28.8s\tremaining: 31.4s\n",
      "479:\tlearn: 0.1870263\ttotal: 28.9s\tremaining: 31.3s\n",
      "480:\tlearn: 0.1869268\ttotal: 29s\tremaining: 31.3s\n",
      "481:\tlearn: 0.1868318\ttotal: 29s\tremaining: 31.2s\n",
      "482:\tlearn: 0.1867479\ttotal: 29.1s\tremaining: 31.1s\n",
      "483:\tlearn: 0.1866703\ttotal: 29.1s\tremaining: 31.1s\n",
      "484:\tlearn: 0.1865869\ttotal: 29.2s\tremaining: 31s\n",
      "485:\tlearn: 0.1864927\ttotal: 29.3s\tremaining: 31s\n",
      "486:\tlearn: 0.1863998\ttotal: 29.4s\tremaining: 30.9s\n",
      "487:\tlearn: 0.1863159\ttotal: 29.4s\tremaining: 30.9s\n",
      "488:\tlearn: 0.1862353\ttotal: 29.5s\tremaining: 30.8s\n",
      "489:\tlearn: 0.1861579\ttotal: 29.5s\tremaining: 30.8s\n",
      "490:\tlearn: 0.1860667\ttotal: 29.6s\tremaining: 30.7s\n",
      "491:\tlearn: 0.1859825\ttotal: 29.7s\tremaining: 30.6s\n",
      "492:\tlearn: 0.1858913\ttotal: 29.7s\tremaining: 30.6s\n",
      "493:\tlearn: 0.1858082\ttotal: 29.8s\tremaining: 30.5s\n",
      "494:\tlearn: 0.1857272\ttotal: 29.9s\tremaining: 30.5s\n",
      "495:\tlearn: 0.1856333\ttotal: 29.9s\tremaining: 30.4s\n",
      "496:\tlearn: 0.1855462\ttotal: 30s\tremaining: 30.3s\n",
      "497:\tlearn: 0.1854574\ttotal: 30s\tremaining: 30.3s\n",
      "498:\tlearn: 0.1853720\ttotal: 30.1s\tremaining: 30.2s\n",
      "499:\tlearn: 0.1852815\ttotal: 30.1s\tremaining: 30.1s\n",
      "500:\tlearn: 0.1852024\ttotal: 30.2s\tremaining: 30.1s\n",
      "501:\tlearn: 0.1851142\ttotal: 30.2s\tremaining: 30s\n",
      "502:\tlearn: 0.1850243\ttotal: 30.3s\tremaining: 29.9s\n",
      "503:\tlearn: 0.1849534\ttotal: 30.4s\tremaining: 29.9s\n",
      "504:\tlearn: 0.1848613\ttotal: 30.4s\tremaining: 29.8s\n",
      "505:\tlearn: 0.1847773\ttotal: 30.5s\tremaining: 29.8s\n",
      "506:\tlearn: 0.1846899\ttotal: 30.6s\tremaining: 29.7s\n",
      "507:\tlearn: 0.1846135\ttotal: 30.6s\tremaining: 29.6s\n",
      "508:\tlearn: 0.1845343\ttotal: 30.7s\tremaining: 29.6s\n",
      "509:\tlearn: 0.1844637\ttotal: 30.7s\tremaining: 29.5s\n",
      "510:\tlearn: 0.1843767\ttotal: 30.8s\tremaining: 29.5s\n",
      "511:\tlearn: 0.1842974\ttotal: 30.9s\tremaining: 29.4s\n",
      "512:\tlearn: 0.1842168\ttotal: 30.9s\tremaining: 29.4s\n",
      "513:\tlearn: 0.1841349\ttotal: 31s\tremaining: 29.3s\n",
      "514:\tlearn: 0.1840441\ttotal: 31s\tremaining: 29.2s\n",
      "515:\tlearn: 0.1839617\ttotal: 31.1s\tremaining: 29.2s\n",
      "516:\tlearn: 0.1838806\ttotal: 31.2s\tremaining: 29.1s\n",
      "517:\tlearn: 0.1837895\ttotal: 31.2s\tremaining: 29s\n",
      "518:\tlearn: 0.1837084\ttotal: 31.3s\tremaining: 29s\n",
      "519:\tlearn: 0.1836241\ttotal: 31.3s\tremaining: 28.9s\n",
      "520:\tlearn: 0.1835457\ttotal: 31.4s\tremaining: 28.9s\n",
      "521:\tlearn: 0.1834620\ttotal: 31.4s\tremaining: 28.8s\n",
      "522:\tlearn: 0.1833875\ttotal: 31.5s\tremaining: 28.7s\n",
      "523:\tlearn: 0.1833064\ttotal: 31.6s\tremaining: 28.7s\n",
      "524:\tlearn: 0.1832331\ttotal: 31.6s\tremaining: 28.6s\n",
      "525:\tlearn: 0.1831474\ttotal: 31.7s\tremaining: 28.6s\n",
      "526:\tlearn: 0.1830638\ttotal: 31.8s\tremaining: 28.5s\n",
      "527:\tlearn: 0.1829911\ttotal: 31.8s\tremaining: 28.4s\n",
      "528:\tlearn: 0.1829212\ttotal: 31.9s\tremaining: 28.4s\n",
      "529:\tlearn: 0.1828455\ttotal: 31.9s\tremaining: 28.3s\n",
      "530:\tlearn: 0.1827725\ttotal: 32s\tremaining: 28.2s\n",
      "531:\tlearn: 0.1826940\ttotal: 32s\tremaining: 28.2s\n",
      "532:\tlearn: 0.1826028\ttotal: 32.1s\tremaining: 28.1s\n",
      "533:\tlearn: 0.1825113\ttotal: 32.1s\tremaining: 28s\n",
      "534:\tlearn: 0.1824319\ttotal: 32.2s\tremaining: 28s\n",
      "535:\tlearn: 0.1823555\ttotal: 32.2s\tremaining: 27.9s\n",
      "536:\tlearn: 0.1822767\ttotal: 32.3s\tremaining: 27.9s\n",
      "537:\tlearn: 0.1821866\ttotal: 32.4s\tremaining: 27.8s\n",
      "538:\tlearn: 0.1821012\ttotal: 32.4s\tremaining: 27.7s\n",
      "539:\tlearn: 0.1820231\ttotal: 32.5s\tremaining: 27.7s\n",
      "540:\tlearn: 0.1819478\ttotal: 32.5s\tremaining: 27.6s\n",
      "541:\tlearn: 0.1818708\ttotal: 32.6s\tremaining: 27.5s\n",
      "542:\tlearn: 0.1817875\ttotal: 32.6s\tremaining: 27.5s\n",
      "543:\tlearn: 0.1817146\ttotal: 32.7s\tremaining: 27.4s\n",
      "544:\tlearn: 0.1816390\ttotal: 32.8s\tremaining: 27.4s\n",
      "545:\tlearn: 0.1815679\ttotal: 32.8s\tremaining: 27.3s\n",
      "546:\tlearn: 0.1814825\ttotal: 32.9s\tremaining: 27.2s\n",
      "547:\tlearn: 0.1814035\ttotal: 32.9s\tremaining: 27.2s\n",
      "548:\tlearn: 0.1813108\ttotal: 33s\tremaining: 27.1s\n",
      "549:\tlearn: 0.1812327\ttotal: 33.1s\tremaining: 27s\n",
      "550:\tlearn: 0.1811484\ttotal: 33.1s\tremaining: 27s\n",
      "551:\tlearn: 0.1810749\ttotal: 33.2s\tremaining: 26.9s\n",
      "552:\tlearn: 0.1810006\ttotal: 33.2s\tremaining: 26.9s\n",
      "553:\tlearn: 0.1809179\ttotal: 33.3s\tremaining: 26.8s\n",
      "554:\tlearn: 0.1808335\ttotal: 33.3s\tremaining: 26.7s\n",
      "555:\tlearn: 0.1807480\ttotal: 33.4s\tremaining: 26.7s\n",
      "556:\tlearn: 0.1806748\ttotal: 33.5s\tremaining: 26.6s\n",
      "557:\tlearn: 0.1805979\ttotal: 33.5s\tremaining: 26.5s\n",
      "558:\tlearn: 0.1805213\ttotal: 33.6s\tremaining: 26.5s\n",
      "559:\tlearn: 0.1804426\ttotal: 33.6s\tremaining: 26.4s\n",
      "560:\tlearn: 0.1803712\ttotal: 33.7s\tremaining: 26.4s\n",
      "561:\tlearn: 0.1803002\ttotal: 33.8s\tremaining: 26.3s\n",
      "562:\tlearn: 0.1802143\ttotal: 33.8s\tremaining: 26.2s\n",
      "563:\tlearn: 0.1801239\ttotal: 33.9s\tremaining: 26.2s\n",
      "564:\tlearn: 0.1800545\ttotal: 33.9s\tremaining: 26.1s\n",
      "565:\tlearn: 0.1799818\ttotal: 34s\tremaining: 26.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "566:\tlearn: 0.1799051\ttotal: 34s\tremaining: 26s\n",
      "567:\tlearn: 0.1798399\ttotal: 34.1s\tremaining: 25.9s\n",
      "568:\tlearn: 0.1797646\ttotal: 34.2s\tremaining: 25.9s\n",
      "569:\tlearn: 0.1796834\ttotal: 34.2s\tremaining: 25.8s\n",
      "570:\tlearn: 0.1796110\ttotal: 34.3s\tremaining: 25.8s\n",
      "571:\tlearn: 0.1795427\ttotal: 34.3s\tremaining: 25.7s\n",
      "572:\tlearn: 0.1794746\ttotal: 34.4s\tremaining: 25.6s\n",
      "573:\tlearn: 0.1793939\ttotal: 34.5s\tremaining: 25.6s\n",
      "574:\tlearn: 0.1793226\ttotal: 34.5s\tremaining: 25.5s\n",
      "575:\tlearn: 0.1792587\ttotal: 34.6s\tremaining: 25.4s\n",
      "576:\tlearn: 0.1791757\ttotal: 34.6s\tremaining: 25.4s\n",
      "577:\tlearn: 0.1790936\ttotal: 34.7s\tremaining: 25.3s\n",
      "578:\tlearn: 0.1790177\ttotal: 34.8s\tremaining: 25.3s\n",
      "579:\tlearn: 0.1789488\ttotal: 34.8s\tremaining: 25.2s\n",
      "580:\tlearn: 0.1788797\ttotal: 34.9s\tremaining: 25.1s\n",
      "581:\tlearn: 0.1788045\ttotal: 34.9s\tremaining: 25.1s\n",
      "582:\tlearn: 0.1787186\ttotal: 35s\tremaining: 25s\n",
      "583:\tlearn: 0.1786634\ttotal: 35s\tremaining: 25s\n",
      "584:\tlearn: 0.1785877\ttotal: 35.1s\tremaining: 24.9s\n",
      "585:\tlearn: 0.1785028\ttotal: 35.2s\tremaining: 24.8s\n",
      "586:\tlearn: 0.1784170\ttotal: 35.2s\tremaining: 24.8s\n",
      "587:\tlearn: 0.1783414\ttotal: 35.3s\tremaining: 24.7s\n",
      "588:\tlearn: 0.1782656\ttotal: 35.3s\tremaining: 24.7s\n",
      "589:\tlearn: 0.1782078\ttotal: 35.4s\tremaining: 24.6s\n",
      "590:\tlearn: 0.1781378\ttotal: 35.5s\tremaining: 24.5s\n",
      "591:\tlearn: 0.1780550\ttotal: 35.5s\tremaining: 24.5s\n",
      "592:\tlearn: 0.1779719\ttotal: 35.6s\tremaining: 24.4s\n",
      "593:\tlearn: 0.1779110\ttotal: 35.6s\tremaining: 24.4s\n",
      "594:\tlearn: 0.1778447\ttotal: 35.7s\tremaining: 24.3s\n",
      "595:\tlearn: 0.1777712\ttotal: 35.8s\tremaining: 24.2s\n",
      "596:\tlearn: 0.1777025\ttotal: 35.8s\tremaining: 24.2s\n",
      "597:\tlearn: 0.1776279\ttotal: 35.9s\tremaining: 24.1s\n",
      "598:\tlearn: 0.1775579\ttotal: 35.9s\tremaining: 24s\n",
      "599:\tlearn: 0.1774883\ttotal: 36s\tremaining: 24s\n",
      "600:\tlearn: 0.1774159\ttotal: 36s\tremaining: 23.9s\n",
      "601:\tlearn: 0.1773422\ttotal: 36.1s\tremaining: 23.9s\n",
      "602:\tlearn: 0.1772665\ttotal: 36.1s\tremaining: 23.8s\n",
      "603:\tlearn: 0.1771940\ttotal: 36.2s\tremaining: 23.7s\n",
      "604:\tlearn: 0.1771229\ttotal: 36.3s\tremaining: 23.7s\n",
      "605:\tlearn: 0.1770484\ttotal: 36.3s\tremaining: 23.6s\n",
      "606:\tlearn: 0.1769785\ttotal: 36.4s\tremaining: 23.5s\n",
      "607:\tlearn: 0.1769041\ttotal: 36.4s\tremaining: 23.5s\n",
      "608:\tlearn: 0.1768322\ttotal: 36.5s\tremaining: 23.4s\n",
      "609:\tlearn: 0.1767571\ttotal: 36.5s\tremaining: 23.4s\n",
      "610:\tlearn: 0.1766727\ttotal: 36.6s\tremaining: 23.3s\n",
      "611:\tlearn: 0.1765881\ttotal: 36.6s\tremaining: 23.2s\n",
      "612:\tlearn: 0.1765016\ttotal: 36.7s\tremaining: 23.2s\n",
      "613:\tlearn: 0.1764410\ttotal: 36.8s\tremaining: 23.1s\n",
      "614:\tlearn: 0.1763806\ttotal: 36.8s\tremaining: 23s\n",
      "615:\tlearn: 0.1763044\ttotal: 36.9s\tremaining: 23s\n",
      "616:\tlearn: 0.1762336\ttotal: 36.9s\tremaining: 22.9s\n",
      "617:\tlearn: 0.1761693\ttotal: 37s\tremaining: 22.9s\n",
      "618:\tlearn: 0.1761081\ttotal: 37.1s\tremaining: 22.8s\n",
      "619:\tlearn: 0.1760465\ttotal: 37.1s\tremaining: 22.7s\n",
      "620:\tlearn: 0.1759660\ttotal: 37.2s\tremaining: 22.7s\n",
      "621:\tlearn: 0.1758817\ttotal: 37.2s\tremaining: 22.6s\n",
      "622:\tlearn: 0.1757989\ttotal: 37.3s\tremaining: 22.6s\n",
      "623:\tlearn: 0.1757212\ttotal: 37.4s\tremaining: 22.5s\n",
      "624:\tlearn: 0.1756573\ttotal: 37.4s\tremaining: 22.5s\n",
      "625:\tlearn: 0.1755952\ttotal: 37.5s\tremaining: 22.4s\n",
      "626:\tlearn: 0.1755187\ttotal: 37.6s\tremaining: 22.4s\n",
      "627:\tlearn: 0.1754544\ttotal: 37.6s\tremaining: 22.3s\n",
      "628:\tlearn: 0.1753895\ttotal: 37.7s\tremaining: 22.2s\n",
      "629:\tlearn: 0.1753202\ttotal: 37.7s\tremaining: 22.2s\n",
      "630:\tlearn: 0.1752533\ttotal: 37.8s\tremaining: 22.1s\n",
      "631:\tlearn: 0.1751665\ttotal: 37.9s\tremaining: 22s\n",
      "632:\tlearn: 0.1751011\ttotal: 37.9s\tremaining: 22s\n",
      "633:\tlearn: 0.1750248\ttotal: 38s\tremaining: 21.9s\n",
      "634:\tlearn: 0.1749580\ttotal: 38s\tremaining: 21.9s\n",
      "635:\tlearn: 0.1748893\ttotal: 38.1s\tremaining: 21.8s\n",
      "636:\tlearn: 0.1748116\ttotal: 38.2s\tremaining: 21.8s\n",
      "637:\tlearn: 0.1747375\ttotal: 38.2s\tremaining: 21.7s\n",
      "638:\tlearn: 0.1746707\ttotal: 38.3s\tremaining: 21.6s\n",
      "639:\tlearn: 0.1746069\ttotal: 38.3s\tremaining: 21.6s\n",
      "640:\tlearn: 0.1745376\ttotal: 38.4s\tremaining: 21.5s\n",
      "641:\tlearn: 0.1744655\ttotal: 38.5s\tremaining: 21.4s\n",
      "642:\tlearn: 0.1743991\ttotal: 38.5s\tremaining: 21.4s\n",
      "643:\tlearn: 0.1743217\ttotal: 38.6s\tremaining: 21.3s\n",
      "644:\tlearn: 0.1742443\ttotal: 38.6s\tremaining: 21.3s\n",
      "645:\tlearn: 0.1741719\ttotal: 38.7s\tremaining: 21.2s\n",
      "646:\tlearn: 0.1741048\ttotal: 38.7s\tremaining: 21.1s\n",
      "647:\tlearn: 0.1740378\ttotal: 38.8s\tremaining: 21.1s\n",
      "648:\tlearn: 0.1739812\ttotal: 38.9s\tremaining: 21s\n",
      "649:\tlearn: 0.1739159\ttotal: 38.9s\tremaining: 21s\n",
      "650:\tlearn: 0.1738482\ttotal: 39s\tremaining: 20.9s\n",
      "651:\tlearn: 0.1737717\ttotal: 39s\tremaining: 20.8s\n",
      "652:\tlearn: 0.1737063\ttotal: 39.1s\tremaining: 20.8s\n",
      "653:\tlearn: 0.1736557\ttotal: 39.1s\tremaining: 20.7s\n",
      "654:\tlearn: 0.1735825\ttotal: 39.2s\tremaining: 20.7s\n",
      "655:\tlearn: 0.1735311\ttotal: 39.3s\tremaining: 20.6s\n",
      "656:\tlearn: 0.1734690\ttotal: 39.3s\tremaining: 20.5s\n",
      "657:\tlearn: 0.1734010\ttotal: 39.4s\tremaining: 20.5s\n",
      "658:\tlearn: 0.1733247\ttotal: 39.5s\tremaining: 20.4s\n",
      "659:\tlearn: 0.1732646\ttotal: 39.5s\tremaining: 20.4s\n",
      "660:\tlearn: 0.1731881\ttotal: 39.6s\tremaining: 20.3s\n",
      "661:\tlearn: 0.1731229\ttotal: 39.7s\tremaining: 20.3s\n",
      "662:\tlearn: 0.1730655\ttotal: 39.7s\tremaining: 20.2s\n",
      "663:\tlearn: 0.1729918\ttotal: 39.8s\tremaining: 20.1s\n",
      "664:\tlearn: 0.1729340\ttotal: 39.8s\tremaining: 20.1s\n",
      "665:\tlearn: 0.1728524\ttotal: 39.9s\tremaining: 20s\n",
      "666:\tlearn: 0.1727887\ttotal: 40s\tremaining: 19.9s\n",
      "667:\tlearn: 0.1727159\ttotal: 40s\tremaining: 19.9s\n",
      "668:\tlearn: 0.1726534\ttotal: 40.1s\tremaining: 19.8s\n",
      "669:\tlearn: 0.1725961\ttotal: 40.1s\tremaining: 19.8s\n",
      "670:\tlearn: 0.1725391\ttotal: 40.2s\tremaining: 19.7s\n",
      "671:\tlearn: 0.1724761\ttotal: 40.2s\tremaining: 19.6s\n",
      "672:\tlearn: 0.1724046\ttotal: 40.3s\tremaining: 19.6s\n",
      "673:\tlearn: 0.1723397\ttotal: 40.4s\tremaining: 19.5s\n",
      "674:\tlearn: 0.1722713\ttotal: 40.4s\tremaining: 19.5s\n",
      "675:\tlearn: 0.1722022\ttotal: 40.5s\tremaining: 19.4s\n",
      "676:\tlearn: 0.1721396\ttotal: 40.6s\tremaining: 19.4s\n",
      "677:\tlearn: 0.1720675\ttotal: 40.6s\tremaining: 19.3s\n",
      "678:\tlearn: 0.1719990\ttotal: 40.7s\tremaining: 19.2s\n",
      "679:\tlearn: 0.1719323\ttotal: 40.8s\tremaining: 19.2s\n",
      "680:\tlearn: 0.1718695\ttotal: 40.8s\tremaining: 19.1s\n",
      "681:\tlearn: 0.1718131\ttotal: 40.9s\tremaining: 19.1s\n",
      "682:\tlearn: 0.1717486\ttotal: 40.9s\tremaining: 19s\n",
      "683:\tlearn: 0.1716759\ttotal: 41s\tremaining: 18.9s\n",
      "684:\tlearn: 0.1716180\ttotal: 41s\tremaining: 18.9s\n",
      "685:\tlearn: 0.1715589\ttotal: 41.1s\tremaining: 18.8s\n",
      "686:\tlearn: 0.1714929\ttotal: 41.2s\tremaining: 18.8s\n",
      "687:\tlearn: 0.1714320\ttotal: 41.2s\tremaining: 18.7s\n",
      "688:\tlearn: 0.1713768\ttotal: 41.3s\tremaining: 18.6s\n",
      "689:\tlearn: 0.1713035\ttotal: 41.4s\tremaining: 18.6s\n",
      "690:\tlearn: 0.1712310\ttotal: 41.4s\tremaining: 18.5s\n",
      "691:\tlearn: 0.1711640\ttotal: 41.5s\tremaining: 18.5s\n",
      "692:\tlearn: 0.1711070\ttotal: 41.5s\tremaining: 18.4s\n",
      "693:\tlearn: 0.1710437\ttotal: 41.6s\tremaining: 18.3s\n",
      "694:\tlearn: 0.1709762\ttotal: 41.7s\tremaining: 18.3s\n",
      "695:\tlearn: 0.1709130\ttotal: 41.7s\tremaining: 18.2s\n",
      "696:\tlearn: 0.1708624\ttotal: 41.8s\tremaining: 18.2s\n",
      "697:\tlearn: 0.1707930\ttotal: 41.8s\tremaining: 18.1s\n",
      "698:\tlearn: 0.1707377\ttotal: 41.9s\tremaining: 18s\n",
      "699:\tlearn: 0.1706612\ttotal: 41.9s\tremaining: 18s\n",
      "700:\tlearn: 0.1705939\ttotal: 42s\tremaining: 17.9s\n",
      "701:\tlearn: 0.1705278\ttotal: 42.1s\tremaining: 17.9s\n",
      "702:\tlearn: 0.1704700\ttotal: 42.1s\tremaining: 17.8s\n",
      "703:\tlearn: 0.1704170\ttotal: 42.2s\tremaining: 17.7s\n",
      "704:\tlearn: 0.1703612\ttotal: 42.2s\tremaining: 17.7s\n",
      "705:\tlearn: 0.1702975\ttotal: 42.3s\tremaining: 17.6s\n",
      "706:\tlearn: 0.1702384\ttotal: 42.3s\tremaining: 17.5s\n",
      "707:\tlearn: 0.1701739\ttotal: 42.4s\tremaining: 17.5s\n",
      "708:\tlearn: 0.1701089\ttotal: 42.5s\tremaining: 17.4s\n",
      "709:\tlearn: 0.1700460\ttotal: 42.5s\tremaining: 17.4s\n",
      "710:\tlearn: 0.1699856\ttotal: 42.6s\tremaining: 17.3s\n",
      "711:\tlearn: 0.1699208\ttotal: 42.6s\tremaining: 17.2s\n",
      "712:\tlearn: 0.1698617\ttotal: 42.7s\tremaining: 17.2s\n",
      "713:\tlearn: 0.1697971\ttotal: 42.8s\tremaining: 17.1s\n",
      "714:\tlearn: 0.1697351\ttotal: 42.8s\tremaining: 17.1s\n",
      "715:\tlearn: 0.1696819\ttotal: 42.9s\tremaining: 17s\n",
      "716:\tlearn: 0.1696181\ttotal: 42.9s\tremaining: 16.9s\n",
      "717:\tlearn: 0.1695684\ttotal: 43s\tremaining: 16.9s\n",
      "718:\tlearn: 0.1695031\ttotal: 43s\tremaining: 16.8s\n",
      "719:\tlearn: 0.1694348\ttotal: 43.1s\tremaining: 16.8s\n",
      "720:\tlearn: 0.1693667\ttotal: 43.2s\tremaining: 16.7s\n",
      "721:\tlearn: 0.1693090\ttotal: 43.2s\tremaining: 16.6s\n",
      "722:\tlearn: 0.1692439\ttotal: 43.3s\tremaining: 16.6s\n",
      "723:\tlearn: 0.1691740\ttotal: 43.4s\tremaining: 16.6s\n",
      "724:\tlearn: 0.1691237\ttotal: 43.5s\tremaining: 16.5s\n",
      "725:\tlearn: 0.1690676\ttotal: 43.5s\tremaining: 16.4s\n",
      "726:\tlearn: 0.1690100\ttotal: 43.6s\tremaining: 16.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "727:\tlearn: 0.1689417\ttotal: 43.7s\tremaining: 16.3s\n",
      "728:\tlearn: 0.1688768\ttotal: 43.7s\tremaining: 16.3s\n",
      "729:\tlearn: 0.1688088\ttotal: 43.8s\tremaining: 16.2s\n",
      "730:\tlearn: 0.1687482\ttotal: 43.8s\tremaining: 16.1s\n",
      "731:\tlearn: 0.1686840\ttotal: 43.9s\tremaining: 16.1s\n",
      "732:\tlearn: 0.1686139\ttotal: 44s\tremaining: 16s\n",
      "733:\tlearn: 0.1685596\ttotal: 44s\tremaining: 15.9s\n",
      "734:\tlearn: 0.1685050\ttotal: 44.1s\tremaining: 15.9s\n",
      "735:\tlearn: 0.1684444\ttotal: 44.1s\tremaining: 15.8s\n",
      "736:\tlearn: 0.1683857\ttotal: 44.2s\tremaining: 15.8s\n",
      "737:\tlearn: 0.1683337\ttotal: 44.3s\tremaining: 15.7s\n",
      "738:\tlearn: 0.1682743\ttotal: 44.3s\tremaining: 15.7s\n",
      "739:\tlearn: 0.1682014\ttotal: 44.4s\tremaining: 15.6s\n",
      "740:\tlearn: 0.1681396\ttotal: 44.5s\tremaining: 15.5s\n",
      "741:\tlearn: 0.1680691\ttotal: 44.5s\tremaining: 15.5s\n",
      "742:\tlearn: 0.1680061\ttotal: 44.6s\tremaining: 15.4s\n",
      "743:\tlearn: 0.1679376\ttotal: 44.7s\tremaining: 15.4s\n",
      "744:\tlearn: 0.1678782\ttotal: 44.7s\tremaining: 15.3s\n",
      "745:\tlearn: 0.1678095\ttotal: 44.8s\tremaining: 15.3s\n",
      "746:\tlearn: 0.1677429\ttotal: 44.9s\tremaining: 15.2s\n",
      "747:\tlearn: 0.1676737\ttotal: 44.9s\tremaining: 15.1s\n",
      "748:\tlearn: 0.1676292\ttotal: 45s\tremaining: 15.1s\n",
      "749:\tlearn: 0.1675781\ttotal: 45.1s\tremaining: 15s\n",
      "750:\tlearn: 0.1675150\ttotal: 45.1s\tremaining: 15s\n",
      "751:\tlearn: 0.1674622\ttotal: 45.2s\tremaining: 14.9s\n",
      "752:\tlearn: 0.1674034\ttotal: 45.2s\tremaining: 14.8s\n",
      "753:\tlearn: 0.1673410\ttotal: 45.3s\tremaining: 14.8s\n",
      "754:\tlearn: 0.1672828\ttotal: 45.3s\tremaining: 14.7s\n",
      "755:\tlearn: 0.1672294\ttotal: 45.4s\tremaining: 14.7s\n",
      "756:\tlearn: 0.1671835\ttotal: 45.5s\tremaining: 14.6s\n",
      "757:\tlearn: 0.1671300\ttotal: 45.5s\tremaining: 14.5s\n",
      "758:\tlearn: 0.1670675\ttotal: 45.6s\tremaining: 14.5s\n",
      "759:\tlearn: 0.1669942\ttotal: 45.7s\tremaining: 14.4s\n",
      "760:\tlearn: 0.1669243\ttotal: 45.7s\tremaining: 14.4s\n",
      "761:\tlearn: 0.1668462\ttotal: 45.8s\tremaining: 14.3s\n",
      "762:\tlearn: 0.1667832\ttotal: 45.8s\tremaining: 14.2s\n",
      "763:\tlearn: 0.1667210\ttotal: 45.9s\tremaining: 14.2s\n",
      "764:\tlearn: 0.1666573\ttotal: 45.9s\tremaining: 14.1s\n",
      "765:\tlearn: 0.1665927\ttotal: 46s\tremaining: 14.1s\n",
      "766:\tlearn: 0.1665303\ttotal: 46.1s\tremaining: 14s\n",
      "767:\tlearn: 0.1664625\ttotal: 46.1s\tremaining: 13.9s\n",
      "768:\tlearn: 0.1664082\ttotal: 46.2s\tremaining: 13.9s\n",
      "769:\tlearn: 0.1663588\ttotal: 46.2s\tremaining: 13.8s\n",
      "770:\tlearn: 0.1662876\ttotal: 46.3s\tremaining: 13.8s\n",
      "771:\tlearn: 0.1662217\ttotal: 46.4s\tremaining: 13.7s\n",
      "772:\tlearn: 0.1661594\ttotal: 46.4s\tremaining: 13.6s\n",
      "773:\tlearn: 0.1660846\ttotal: 46.5s\tremaining: 13.6s\n",
      "774:\tlearn: 0.1660251\ttotal: 46.5s\tremaining: 13.5s\n",
      "775:\tlearn: 0.1659731\ttotal: 46.6s\tremaining: 13.4s\n",
      "776:\tlearn: 0.1658991\ttotal: 46.7s\tremaining: 13.4s\n",
      "777:\tlearn: 0.1658341\ttotal: 46.7s\tremaining: 13.3s\n",
      "778:\tlearn: 0.1657711\ttotal: 46.8s\tremaining: 13.3s\n",
      "779:\tlearn: 0.1657040\ttotal: 46.8s\tremaining: 13.2s\n",
      "780:\tlearn: 0.1656387\ttotal: 46.9s\tremaining: 13.2s\n",
      "781:\tlearn: 0.1655782\ttotal: 47s\tremaining: 13.1s\n",
      "782:\tlearn: 0.1655172\ttotal: 47s\tremaining: 13s\n",
      "783:\tlearn: 0.1654525\ttotal: 47.1s\tremaining: 13s\n",
      "784:\tlearn: 0.1654013\ttotal: 47.1s\tremaining: 12.9s\n",
      "785:\tlearn: 0.1653491\ttotal: 47.2s\tremaining: 12.8s\n",
      "786:\tlearn: 0.1652831\ttotal: 47.3s\tremaining: 12.8s\n",
      "787:\tlearn: 0.1652162\ttotal: 47.3s\tremaining: 12.7s\n",
      "788:\tlearn: 0.1651472\ttotal: 47.4s\tremaining: 12.7s\n",
      "789:\tlearn: 0.1650948\ttotal: 47.4s\tremaining: 12.6s\n",
      "790:\tlearn: 0.1650450\ttotal: 47.5s\tremaining: 12.5s\n",
      "791:\tlearn: 0.1649801\ttotal: 47.5s\tremaining: 12.5s\n",
      "792:\tlearn: 0.1649270\ttotal: 47.6s\tremaining: 12.4s\n",
      "793:\tlearn: 0.1648664\ttotal: 47.7s\tremaining: 12.4s\n",
      "794:\tlearn: 0.1648046\ttotal: 47.7s\tremaining: 12.3s\n",
      "795:\tlearn: 0.1647525\ttotal: 47.8s\tremaining: 12.2s\n",
      "796:\tlearn: 0.1646933\ttotal: 47.8s\tremaining: 12.2s\n",
      "797:\tlearn: 0.1646309\ttotal: 47.9s\tremaining: 12.1s\n",
      "798:\tlearn: 0.1645704\ttotal: 47.9s\tremaining: 12.1s\n",
      "799:\tlearn: 0.1645023\ttotal: 48s\tremaining: 12s\n",
      "800:\tlearn: 0.1644511\ttotal: 48s\tremaining: 11.9s\n",
      "801:\tlearn: 0.1643892\ttotal: 48.1s\tremaining: 11.9s\n",
      "802:\tlearn: 0.1643194\ttotal: 48.2s\tremaining: 11.8s\n",
      "803:\tlearn: 0.1642656\ttotal: 48.2s\tremaining: 11.8s\n",
      "804:\tlearn: 0.1642016\ttotal: 48.3s\tremaining: 11.7s\n",
      "805:\tlearn: 0.1641403\ttotal: 48.3s\tremaining: 11.6s\n",
      "806:\tlearn: 0.1640897\ttotal: 48.4s\tremaining: 11.6s\n",
      "807:\tlearn: 0.1640324\ttotal: 48.5s\tremaining: 11.5s\n",
      "808:\tlearn: 0.1639771\ttotal: 48.5s\tremaining: 11.5s\n",
      "809:\tlearn: 0.1639144\ttotal: 48.6s\tremaining: 11.4s\n",
      "810:\tlearn: 0.1638517\ttotal: 48.6s\tremaining: 11.3s\n",
      "811:\tlearn: 0.1637991\ttotal: 48.7s\tremaining: 11.3s\n",
      "812:\tlearn: 0.1637473\ttotal: 48.8s\tremaining: 11.2s\n",
      "813:\tlearn: 0.1636793\ttotal: 48.8s\tremaining: 11.2s\n",
      "814:\tlearn: 0.1636171\ttotal: 48.9s\tremaining: 11.1s\n",
      "815:\tlearn: 0.1635404\ttotal: 48.9s\tremaining: 11s\n",
      "816:\tlearn: 0.1634762\ttotal: 49s\tremaining: 11s\n",
      "817:\tlearn: 0.1634092\ttotal: 49.1s\tremaining: 10.9s\n",
      "818:\tlearn: 0.1633331\ttotal: 49.1s\tremaining: 10.9s\n",
      "819:\tlearn: 0.1632685\ttotal: 49.2s\tremaining: 10.8s\n",
      "820:\tlearn: 0.1632074\ttotal: 49.3s\tremaining: 10.7s\n",
      "821:\tlearn: 0.1631402\ttotal: 49.3s\tremaining: 10.7s\n",
      "822:\tlearn: 0.1630756\ttotal: 49.4s\tremaining: 10.6s\n",
      "823:\tlearn: 0.1630235\ttotal: 49.5s\tremaining: 10.6s\n",
      "824:\tlearn: 0.1629527\ttotal: 49.5s\tremaining: 10.5s\n",
      "825:\tlearn: 0.1628949\ttotal: 49.6s\tremaining: 10.5s\n",
      "826:\tlearn: 0.1628472\ttotal: 49.7s\tremaining: 10.4s\n",
      "827:\tlearn: 0.1627918\ttotal: 49.8s\tremaining: 10.3s\n",
      "828:\tlearn: 0.1627418\ttotal: 49.8s\tremaining: 10.3s\n",
      "829:\tlearn: 0.1626874\ttotal: 49.9s\tremaining: 10.2s\n",
      "830:\tlearn: 0.1626355\ttotal: 50s\tremaining: 10.2s\n",
      "831:\tlearn: 0.1625731\ttotal: 50s\tremaining: 10.1s\n",
      "832:\tlearn: 0.1625333\ttotal: 50.1s\tremaining: 10s\n",
      "833:\tlearn: 0.1624666\ttotal: 50.1s\tremaining: 9.98s\n",
      "834:\tlearn: 0.1624052\ttotal: 50.2s\tremaining: 9.92s\n",
      "835:\tlearn: 0.1623518\ttotal: 50.2s\tremaining: 9.86s\n",
      "836:\tlearn: 0.1622957\ttotal: 50.3s\tremaining: 9.79s\n",
      "837:\tlearn: 0.1622403\ttotal: 50.4s\tremaining: 9.73s\n",
      "838:\tlearn: 0.1621931\ttotal: 50.4s\tremaining: 9.67s\n",
      "839:\tlearn: 0.1621387\ttotal: 50.5s\tremaining: 9.61s\n",
      "840:\tlearn: 0.1620879\ttotal: 50.5s\tremaining: 9.55s\n",
      "841:\tlearn: 0.1620312\ttotal: 50.6s\tremaining: 9.49s\n",
      "842:\tlearn: 0.1619822\ttotal: 50.6s\tremaining: 9.43s\n",
      "843:\tlearn: 0.1619374\ttotal: 50.7s\tremaining: 9.37s\n",
      "844:\tlearn: 0.1618747\ttotal: 50.7s\tremaining: 9.31s\n",
      "845:\tlearn: 0.1618264\ttotal: 50.8s\tremaining: 9.24s\n",
      "846:\tlearn: 0.1617718\ttotal: 50.9s\tremaining: 9.19s\n",
      "847:\tlearn: 0.1617200\ttotal: 50.9s\tremaining: 9.13s\n",
      "848:\tlearn: 0.1616693\ttotal: 51s\tremaining: 9.06s\n",
      "849:\tlearn: 0.1616089\ttotal: 51.1s\tremaining: 9.01s\n",
      "850:\tlearn: 0.1615621\ttotal: 51.1s\tremaining: 8.95s\n",
      "851:\tlearn: 0.1615116\ttotal: 51.2s\tremaining: 8.89s\n",
      "852:\tlearn: 0.1614473\ttotal: 51.2s\tremaining: 8.83s\n",
      "853:\tlearn: 0.1613976\ttotal: 51.3s\tremaining: 8.77s\n",
      "854:\tlearn: 0.1613375\ttotal: 51.4s\tremaining: 8.71s\n",
      "855:\tlearn: 0.1612936\ttotal: 51.4s\tremaining: 8.65s\n",
      "856:\tlearn: 0.1612342\ttotal: 51.5s\tremaining: 8.59s\n",
      "857:\tlearn: 0.1611829\ttotal: 51.6s\tremaining: 8.53s\n",
      "858:\tlearn: 0.1611233\ttotal: 51.6s\tremaining: 8.47s\n",
      "859:\tlearn: 0.1610600\ttotal: 51.7s\tremaining: 8.41s\n",
      "860:\tlearn: 0.1610126\ttotal: 51.7s\tremaining: 8.35s\n",
      "861:\tlearn: 0.1609495\ttotal: 51.8s\tremaining: 8.29s\n",
      "862:\tlearn: 0.1609115\ttotal: 51.9s\tremaining: 8.23s\n",
      "863:\tlearn: 0.1608535\ttotal: 51.9s\tremaining: 8.18s\n",
      "864:\tlearn: 0.1608072\ttotal: 52s\tremaining: 8.12s\n",
      "865:\tlearn: 0.1607542\ttotal: 52.1s\tremaining: 8.05s\n",
      "866:\tlearn: 0.1606981\ttotal: 52.1s\tremaining: 7.99s\n",
      "867:\tlearn: 0.1606468\ttotal: 52.2s\tremaining: 7.93s\n",
      "868:\tlearn: 0.1606007\ttotal: 52.2s\tremaining: 7.87s\n",
      "869:\tlearn: 0.1605461\ttotal: 52.3s\tremaining: 7.81s\n",
      "870:\tlearn: 0.1604901\ttotal: 52.3s\tremaining: 7.75s\n",
      "871:\tlearn: 0.1604326\ttotal: 52.4s\tremaining: 7.69s\n",
      "872:\tlearn: 0.1603833\ttotal: 52.5s\tremaining: 7.63s\n",
      "873:\tlearn: 0.1603274\ttotal: 52.5s\tremaining: 7.57s\n",
      "874:\tlearn: 0.1602836\ttotal: 52.6s\tremaining: 7.51s\n",
      "875:\tlearn: 0.1602299\ttotal: 52.6s\tremaining: 7.45s\n",
      "876:\tlearn: 0.1601763\ttotal: 52.7s\tremaining: 7.39s\n",
      "877:\tlearn: 0.1601241\ttotal: 52.8s\tremaining: 7.33s\n",
      "878:\tlearn: 0.1600646\ttotal: 52.8s\tremaining: 7.27s\n",
      "879:\tlearn: 0.1599974\ttotal: 52.9s\tremaining: 7.21s\n",
      "880:\tlearn: 0.1599307\ttotal: 53s\tremaining: 7.15s\n",
      "881:\tlearn: 0.1598802\ttotal: 53s\tremaining: 7.09s\n",
      "882:\tlearn: 0.1598270\ttotal: 53.1s\tremaining: 7.03s\n",
      "883:\tlearn: 0.1597659\ttotal: 53.1s\tremaining: 6.97s\n",
      "884:\tlearn: 0.1596997\ttotal: 53.2s\tremaining: 6.91s\n",
      "885:\tlearn: 0.1596433\ttotal: 53.3s\tremaining: 6.85s\n",
      "886:\tlearn: 0.1595915\ttotal: 53.3s\tremaining: 6.79s\n",
      "887:\tlearn: 0.1595317\ttotal: 53.4s\tremaining: 6.73s\n",
      "888:\tlearn: 0.1594766\ttotal: 53.5s\tremaining: 6.67s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "889:\tlearn: 0.1594179\ttotal: 53.5s\tremaining: 6.61s\n",
      "890:\tlearn: 0.1593706\ttotal: 53.6s\tremaining: 6.55s\n",
      "891:\tlearn: 0.1593134\ttotal: 53.6s\tremaining: 6.49s\n",
      "892:\tlearn: 0.1592588\ttotal: 53.7s\tremaining: 6.43s\n",
      "893:\tlearn: 0.1591950\ttotal: 53.7s\tremaining: 6.37s\n",
      "894:\tlearn: 0.1591412\ttotal: 53.8s\tremaining: 6.31s\n",
      "895:\tlearn: 0.1590912\ttotal: 53.9s\tremaining: 6.25s\n",
      "896:\tlearn: 0.1590174\ttotal: 53.9s\tremaining: 6.19s\n",
      "897:\tlearn: 0.1589675\ttotal: 54s\tremaining: 6.13s\n",
      "898:\tlearn: 0.1589234\ttotal: 54.1s\tremaining: 6.07s\n",
      "899:\tlearn: 0.1588775\ttotal: 54.1s\tremaining: 6.01s\n",
      "900:\tlearn: 0.1588260\ttotal: 54.2s\tremaining: 5.95s\n",
      "901:\tlearn: 0.1587841\ttotal: 54.2s\tremaining: 5.89s\n",
      "902:\tlearn: 0.1587222\ttotal: 54.3s\tremaining: 5.83s\n",
      "903:\tlearn: 0.1586778\ttotal: 54.4s\tremaining: 5.77s\n",
      "904:\tlearn: 0.1586110\ttotal: 54.4s\tremaining: 5.71s\n",
      "905:\tlearn: 0.1585629\ttotal: 54.5s\tremaining: 5.65s\n",
      "906:\tlearn: 0.1585109\ttotal: 54.5s\tremaining: 5.59s\n",
      "907:\tlearn: 0.1584537\ttotal: 54.6s\tremaining: 5.53s\n",
      "908:\tlearn: 0.1584036\ttotal: 54.6s\tremaining: 5.47s\n",
      "909:\tlearn: 0.1583553\ttotal: 54.7s\tremaining: 5.41s\n",
      "910:\tlearn: 0.1583136\ttotal: 54.7s\tremaining: 5.34s\n",
      "911:\tlearn: 0.1582586\ttotal: 54.8s\tremaining: 5.28s\n",
      "912:\tlearn: 0.1582047\ttotal: 54.8s\tremaining: 5.22s\n",
      "913:\tlearn: 0.1581469\ttotal: 54.9s\tremaining: 5.16s\n",
      "914:\tlearn: 0.1580855\ttotal: 55s\tremaining: 5.11s\n",
      "915:\tlearn: 0.1580265\ttotal: 55s\tremaining: 5.04s\n",
      "916:\tlearn: 0.1579771\ttotal: 55.1s\tremaining: 4.99s\n",
      "917:\tlearn: 0.1579277\ttotal: 55.1s\tremaining: 4.92s\n",
      "918:\tlearn: 0.1578850\ttotal: 55.2s\tremaining: 4.86s\n",
      "919:\tlearn: 0.1578277\ttotal: 55.3s\tremaining: 4.8s\n",
      "920:\tlearn: 0.1577645\ttotal: 55.3s\tremaining: 4.74s\n",
      "921:\tlearn: 0.1576994\ttotal: 55.4s\tremaining: 4.68s\n",
      "922:\tlearn: 0.1576511\ttotal: 55.4s\tremaining: 4.62s\n",
      "923:\tlearn: 0.1576041\ttotal: 55.5s\tremaining: 4.56s\n",
      "924:\tlearn: 0.1575566\ttotal: 55.5s\tremaining: 4.5s\n",
      "925:\tlearn: 0.1574954\ttotal: 55.6s\tremaining: 4.44s\n",
      "926:\tlearn: 0.1574472\ttotal: 55.7s\tremaining: 4.38s\n",
      "927:\tlearn: 0.1574194\ttotal: 55.7s\tremaining: 4.32s\n",
      "928:\tlearn: 0.1573718\ttotal: 55.8s\tremaining: 4.26s\n",
      "929:\tlearn: 0.1573137\ttotal: 55.8s\tremaining: 4.2s\n",
      "930:\tlearn: 0.1572614\ttotal: 55.9s\tremaining: 4.14s\n",
      "931:\tlearn: 0.1572153\ttotal: 55.9s\tremaining: 4.08s\n",
      "932:\tlearn: 0.1571623\ttotal: 56s\tremaining: 4.02s\n",
      "933:\tlearn: 0.1571082\ttotal: 56s\tremaining: 3.96s\n",
      "934:\tlearn: 0.1570623\ttotal: 56.1s\tremaining: 3.9s\n",
      "935:\tlearn: 0.1570097\ttotal: 56.1s\tremaining: 3.84s\n",
      "936:\tlearn: 0.1569547\ttotal: 56.2s\tremaining: 3.78s\n",
      "937:\tlearn: 0.1569106\ttotal: 56.3s\tremaining: 3.72s\n",
      "938:\tlearn: 0.1568509\ttotal: 56.3s\tremaining: 3.66s\n",
      "939:\tlearn: 0.1568056\ttotal: 56.4s\tremaining: 3.6s\n",
      "940:\tlearn: 0.1567510\ttotal: 56.4s\tremaining: 3.54s\n",
      "941:\tlearn: 0.1567004\ttotal: 56.5s\tremaining: 3.48s\n",
      "942:\tlearn: 0.1566567\ttotal: 56.5s\tremaining: 3.42s\n",
      "943:\tlearn: 0.1566075\ttotal: 56.6s\tremaining: 3.36s\n",
      "944:\tlearn: 0.1565517\ttotal: 56.7s\tremaining: 3.3s\n",
      "945:\tlearn: 0.1564955\ttotal: 56.7s\tremaining: 3.24s\n",
      "946:\tlearn: 0.1564456\ttotal: 56.8s\tremaining: 3.18s\n",
      "947:\tlearn: 0.1564042\ttotal: 56.9s\tremaining: 3.12s\n",
      "948:\tlearn: 0.1563558\ttotal: 56.9s\tremaining: 3.06s\n",
      "949:\tlearn: 0.1562993\ttotal: 57s\tremaining: 3s\n",
      "950:\tlearn: 0.1562555\ttotal: 57s\tremaining: 2.94s\n",
      "951:\tlearn: 0.1562027\ttotal: 57.1s\tremaining: 2.88s\n",
      "952:\tlearn: 0.1561680\ttotal: 57.1s\tremaining: 2.82s\n",
      "953:\tlearn: 0.1561257\ttotal: 57.2s\tremaining: 2.76s\n",
      "954:\tlearn: 0.1560664\ttotal: 57.3s\tremaining: 2.7s\n",
      "955:\tlearn: 0.1560066\ttotal: 57.3s\tremaining: 2.64s\n",
      "956:\tlearn: 0.1559599\ttotal: 57.4s\tremaining: 2.58s\n",
      "957:\tlearn: 0.1559124\ttotal: 57.5s\tremaining: 2.52s\n",
      "958:\tlearn: 0.1558606\ttotal: 57.5s\tremaining: 2.46s\n",
      "959:\tlearn: 0.1558109\ttotal: 57.6s\tremaining: 2.4s\n",
      "960:\tlearn: 0.1557628\ttotal: 57.6s\tremaining: 2.34s\n",
      "961:\tlearn: 0.1557295\ttotal: 57.7s\tremaining: 2.28s\n",
      "962:\tlearn: 0.1556837\ttotal: 57.7s\tremaining: 2.22s\n",
      "963:\tlearn: 0.1556443\ttotal: 57.8s\tremaining: 2.16s\n",
      "964:\tlearn: 0.1555934\ttotal: 57.8s\tremaining: 2.1s\n",
      "965:\tlearn: 0.1555471\ttotal: 57.9s\tremaining: 2.04s\n",
      "966:\tlearn: 0.1554859\ttotal: 58s\tremaining: 1.98s\n",
      "967:\tlearn: 0.1554316\ttotal: 58.1s\tremaining: 1.92s\n",
      "968:\tlearn: 0.1553773\ttotal: 58.1s\tremaining: 1.86s\n",
      "969:\tlearn: 0.1553176\ttotal: 58.2s\tremaining: 1.8s\n",
      "970:\tlearn: 0.1552547\ttotal: 58.3s\tremaining: 1.74s\n",
      "971:\tlearn: 0.1552011\ttotal: 58.3s\tremaining: 1.68s\n",
      "972:\tlearn: 0.1551473\ttotal: 58.4s\tremaining: 1.62s\n",
      "973:\tlearn: 0.1550885\ttotal: 58.5s\tremaining: 1.56s\n",
      "974:\tlearn: 0.1550371\ttotal: 58.5s\tremaining: 1.5s\n",
      "975:\tlearn: 0.1549805\ttotal: 58.6s\tremaining: 1.44s\n",
      "976:\tlearn: 0.1549178\ttotal: 58.6s\tremaining: 1.38s\n",
      "977:\tlearn: 0.1548582\ttotal: 58.7s\tremaining: 1.32s\n",
      "978:\tlearn: 0.1548156\ttotal: 58.7s\tremaining: 1.26s\n",
      "979:\tlearn: 0.1547693\ttotal: 58.8s\tremaining: 1.2s\n",
      "980:\tlearn: 0.1547289\ttotal: 58.9s\tremaining: 1.14s\n",
      "981:\tlearn: 0.1546852\ttotal: 58.9s\tremaining: 1.08s\n",
      "982:\tlearn: 0.1546338\ttotal: 59s\tremaining: 1.02s\n",
      "983:\tlearn: 0.1545860\ttotal: 59.1s\tremaining: 960ms\n",
      "984:\tlearn: 0.1545329\ttotal: 59.1s\tremaining: 900ms\n",
      "985:\tlearn: 0.1544830\ttotal: 59.2s\tremaining: 840ms\n",
      "986:\tlearn: 0.1544287\ttotal: 59.3s\tremaining: 780ms\n",
      "987:\tlearn: 0.1543750\ttotal: 59.3s\tremaining: 720ms\n",
      "988:\tlearn: 0.1543473\ttotal: 59.4s\tremaining: 660ms\n",
      "989:\tlearn: 0.1543040\ttotal: 59.4s\tremaining: 600ms\n",
      "990:\tlearn: 0.1542508\ttotal: 59.5s\tremaining: 540ms\n",
      "991:\tlearn: 0.1542045\ttotal: 59.5s\tremaining: 480ms\n",
      "992:\tlearn: 0.1541497\ttotal: 59.6s\tremaining: 420ms\n",
      "993:\tlearn: 0.1540878\ttotal: 59.7s\tremaining: 360ms\n",
      "994:\tlearn: 0.1540255\ttotal: 59.7s\tremaining: 300ms\n",
      "995:\tlearn: 0.1539842\ttotal: 59.8s\tremaining: 240ms\n",
      "996:\tlearn: 0.1539242\ttotal: 59.8s\tremaining: 180ms\n",
      "997:\tlearn: 0.1538842\ttotal: 59.9s\tremaining: 120ms\n",
      "998:\tlearn: 0.1538336\ttotal: 59.9s\tremaining: 60ms\n",
      "999:\tlearn: 0.1537940\ttotal: 60s\tremaining: 0us\n",
      "Learning rate set to 0.09461\n",
      "0:\tlearn: 0.6141866\ttotal: 66.6ms\tremaining: 1m 6s\n",
      "1:\tlearn: 0.5502918\ttotal: 135ms\tremaining: 1m 7s\n",
      "2:\tlearn: 0.5015076\ttotal: 205ms\tremaining: 1m 8s\n",
      "3:\tlearn: 0.4634770\ttotal: 270ms\tremaining: 1m 7s\n",
      "4:\tlearn: 0.4325339\ttotal: 342ms\tremaining: 1m 7s\n",
      "5:\tlearn: 0.4083870\ttotal: 417ms\tremaining: 1m 9s\n",
      "6:\tlearn: 0.3883002\ttotal: 485ms\tremaining: 1m 8s\n",
      "7:\tlearn: 0.3726380\ttotal: 545ms\tremaining: 1m 7s\n",
      "8:\tlearn: 0.3596837\ttotal: 604ms\tremaining: 1m 6s\n",
      "9:\tlearn: 0.3494026\ttotal: 660ms\tremaining: 1m 5s\n",
      "10:\tlearn: 0.3405226\ttotal: 718ms\tremaining: 1m 4s\n",
      "11:\tlearn: 0.3335023\ttotal: 781ms\tremaining: 1m 4s\n",
      "12:\tlearn: 0.3272753\ttotal: 832ms\tremaining: 1m 3s\n",
      "13:\tlearn: 0.3221631\ttotal: 886ms\tremaining: 1m 2s\n",
      "14:\tlearn: 0.3180735\ttotal: 937ms\tremaining: 1m 1s\n",
      "15:\tlearn: 0.3142086\ttotal: 987ms\tremaining: 1m\n",
      "16:\tlearn: 0.3109289\ttotal: 1.04s\tremaining: 1m\n",
      "17:\tlearn: 0.3082381\ttotal: 1.09s\tremaining: 59.8s\n",
      "18:\tlearn: 0.3057931\ttotal: 1.15s\tremaining: 59.3s\n",
      "19:\tlearn: 0.3035506\ttotal: 1.21s\tremaining: 59.2s\n",
      "20:\tlearn: 0.3016709\ttotal: 1.27s\tremaining: 59.2s\n",
      "21:\tlearn: 0.2999934\ttotal: 1.32s\tremaining: 58.9s\n",
      "22:\tlearn: 0.2985039\ttotal: 1.38s\tremaining: 58.7s\n",
      "23:\tlearn: 0.2970629\ttotal: 1.44s\tremaining: 58.4s\n",
      "24:\tlearn: 0.2957595\ttotal: 1.5s\tremaining: 58.4s\n",
      "25:\tlearn: 0.2945015\ttotal: 1.55s\tremaining: 58.2s\n",
      "26:\tlearn: 0.2932969\ttotal: 1.6s\tremaining: 57.8s\n",
      "27:\tlearn: 0.2921694\ttotal: 1.65s\tremaining: 57.4s\n",
      "28:\tlearn: 0.2910570\ttotal: 1.71s\tremaining: 57.1s\n",
      "29:\tlearn: 0.2899712\ttotal: 1.76s\tremaining: 56.9s\n",
      "30:\tlearn: 0.2890081\ttotal: 1.82s\tremaining: 56.8s\n",
      "31:\tlearn: 0.2880872\ttotal: 1.87s\tremaining: 56.7s\n",
      "32:\tlearn: 0.2871474\ttotal: 1.95s\tremaining: 57s\n",
      "33:\tlearn: 0.2861483\ttotal: 2.01s\tremaining: 57.2s\n",
      "34:\tlearn: 0.2852980\ttotal: 2.07s\tremaining: 57.1s\n",
      "35:\tlearn: 0.2844532\ttotal: 2.14s\tremaining: 57.2s\n",
      "36:\tlearn: 0.2836087\ttotal: 2.2s\tremaining: 57.2s\n",
      "37:\tlearn: 0.2828078\ttotal: 2.26s\tremaining: 57.2s\n",
      "38:\tlearn: 0.2820341\ttotal: 2.32s\tremaining: 57.1s\n",
      "39:\tlearn: 0.2812370\ttotal: 2.38s\tremaining: 57.1s\n",
      "40:\tlearn: 0.2804466\ttotal: 2.43s\tremaining: 56.9s\n",
      "41:\tlearn: 0.2797182\ttotal: 2.49s\tremaining: 56.7s\n",
      "42:\tlearn: 0.2790238\ttotal: 2.54s\tremaining: 56.5s\n",
      "43:\tlearn: 0.2783080\ttotal: 2.6s\tremaining: 56.4s\n",
      "44:\tlearn: 0.2775933\ttotal: 2.68s\tremaining: 56.9s\n",
      "45:\tlearn: 0.2768906\ttotal: 2.75s\tremaining: 57s\n",
      "46:\tlearn: 0.2762337\ttotal: 2.81s\tremaining: 56.9s\n",
      "47:\tlearn: 0.2756087\ttotal: 2.86s\tremaining: 56.7s\n",
      "48:\tlearn: 0.2749054\ttotal: 2.92s\tremaining: 56.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49:\tlearn: 0.2742560\ttotal: 2.99s\tremaining: 56.8s\n",
      "50:\tlearn: 0.2736127\ttotal: 3.05s\tremaining: 56.7s\n",
      "51:\tlearn: 0.2729680\ttotal: 3.1s\tremaining: 56.5s\n",
      "52:\tlearn: 0.2723145\ttotal: 3.16s\tremaining: 56.4s\n",
      "53:\tlearn: 0.2716861\ttotal: 3.22s\tremaining: 56.5s\n",
      "54:\tlearn: 0.2711235\ttotal: 3.28s\tremaining: 56.4s\n",
      "55:\tlearn: 0.2705212\ttotal: 3.34s\tremaining: 56.4s\n",
      "56:\tlearn: 0.2699571\ttotal: 3.4s\tremaining: 56.3s\n",
      "57:\tlearn: 0.2693478\ttotal: 3.46s\tremaining: 56.3s\n",
      "58:\tlearn: 0.2687959\ttotal: 3.51s\tremaining: 56.1s\n",
      "59:\tlearn: 0.2681934\ttotal: 3.57s\tremaining: 55.9s\n",
      "60:\tlearn: 0.2676953\ttotal: 3.62s\tremaining: 55.7s\n",
      "61:\tlearn: 0.2671124\ttotal: 3.68s\tremaining: 55.7s\n",
      "62:\tlearn: 0.2665708\ttotal: 3.74s\tremaining: 55.7s\n",
      "63:\tlearn: 0.2659971\ttotal: 3.8s\tremaining: 55.6s\n",
      "64:\tlearn: 0.2654335\ttotal: 3.86s\tremaining: 55.6s\n",
      "65:\tlearn: 0.2648955\ttotal: 3.92s\tremaining: 55.5s\n",
      "66:\tlearn: 0.2643477\ttotal: 3.98s\tremaining: 55.4s\n",
      "67:\tlearn: 0.2638237\ttotal: 4.04s\tremaining: 55.4s\n",
      "68:\tlearn: 0.2632889\ttotal: 4.1s\tremaining: 55.4s\n",
      "69:\tlearn: 0.2627639\ttotal: 4.17s\tremaining: 55.4s\n",
      "70:\tlearn: 0.2622817\ttotal: 4.23s\tremaining: 55.4s\n",
      "71:\tlearn: 0.2617534\ttotal: 4.3s\tremaining: 55.4s\n",
      "72:\tlearn: 0.2612219\ttotal: 4.37s\tremaining: 55.4s\n",
      "73:\tlearn: 0.2607450\ttotal: 4.42s\tremaining: 55.3s\n",
      "74:\tlearn: 0.2602971\ttotal: 4.48s\tremaining: 55.2s\n",
      "75:\tlearn: 0.2598044\ttotal: 4.54s\tremaining: 55.2s\n",
      "76:\tlearn: 0.2593324\ttotal: 4.6s\tremaining: 55.2s\n",
      "77:\tlearn: 0.2588566\ttotal: 4.66s\tremaining: 55.1s\n",
      "78:\tlearn: 0.2584466\ttotal: 4.71s\tremaining: 54.9s\n",
      "79:\tlearn: 0.2579929\ttotal: 4.75s\tremaining: 54.7s\n",
      "80:\tlearn: 0.2575233\ttotal: 4.81s\tremaining: 54.6s\n",
      "81:\tlearn: 0.2570910\ttotal: 4.86s\tremaining: 54.4s\n",
      "82:\tlearn: 0.2565868\ttotal: 4.95s\tremaining: 54.6s\n",
      "83:\tlearn: 0.2561628\ttotal: 5s\tremaining: 54.5s\n",
      "84:\tlearn: 0.2557393\ttotal: 5.05s\tremaining: 54.4s\n",
      "85:\tlearn: 0.2553045\ttotal: 5.11s\tremaining: 54.3s\n",
      "86:\tlearn: 0.2549103\ttotal: 5.18s\tremaining: 54.4s\n",
      "87:\tlearn: 0.2544916\ttotal: 5.24s\tremaining: 54.3s\n",
      "88:\tlearn: 0.2540846\ttotal: 5.3s\tremaining: 54.2s\n",
      "89:\tlearn: 0.2536663\ttotal: 5.35s\tremaining: 54.1s\n",
      "90:\tlearn: 0.2532689\ttotal: 5.41s\tremaining: 54.1s\n",
      "91:\tlearn: 0.2528934\ttotal: 5.47s\tremaining: 54s\n",
      "92:\tlearn: 0.2525010\ttotal: 5.53s\tremaining: 53.9s\n",
      "93:\tlearn: 0.2520856\ttotal: 5.59s\tremaining: 53.9s\n",
      "94:\tlearn: 0.2517183\ttotal: 5.64s\tremaining: 53.7s\n",
      "95:\tlearn: 0.2513154\ttotal: 5.7s\tremaining: 53.7s\n",
      "96:\tlearn: 0.2509657\ttotal: 5.75s\tremaining: 53.6s\n",
      "97:\tlearn: 0.2505743\ttotal: 5.82s\tremaining: 53.6s\n",
      "98:\tlearn: 0.2502055\ttotal: 5.88s\tremaining: 53.6s\n",
      "99:\tlearn: 0.2498531\ttotal: 5.95s\tremaining: 53.6s\n",
      "100:\tlearn: 0.2495004\ttotal: 6s\tremaining: 53.4s\n",
      "101:\tlearn: 0.2491433\ttotal: 6.07s\tremaining: 53.4s\n",
      "102:\tlearn: 0.2487394\ttotal: 6.13s\tremaining: 53.4s\n",
      "103:\tlearn: 0.2483987\ttotal: 6.18s\tremaining: 53.3s\n",
      "104:\tlearn: 0.2480457\ttotal: 6.26s\tremaining: 53.3s\n",
      "105:\tlearn: 0.2476949\ttotal: 6.31s\tremaining: 53.3s\n",
      "106:\tlearn: 0.2473180\ttotal: 6.38s\tremaining: 53.2s\n",
      "107:\tlearn: 0.2469909\ttotal: 6.44s\tremaining: 53.2s\n",
      "108:\tlearn: 0.2466421\ttotal: 6.49s\tremaining: 53.1s\n",
      "109:\tlearn: 0.2463023\ttotal: 6.55s\tremaining: 53s\n",
      "110:\tlearn: 0.2459916\ttotal: 6.61s\tremaining: 52.9s\n",
      "111:\tlearn: 0.2456534\ttotal: 6.67s\tremaining: 52.8s\n",
      "112:\tlearn: 0.2452896\ttotal: 6.72s\tremaining: 52.8s\n",
      "113:\tlearn: 0.2449829\ttotal: 6.77s\tremaining: 52.6s\n",
      "114:\tlearn: 0.2446570\ttotal: 6.83s\tremaining: 52.5s\n",
      "115:\tlearn: 0.2443483\ttotal: 6.87s\tremaining: 52.4s\n",
      "116:\tlearn: 0.2440588\ttotal: 6.92s\tremaining: 52.2s\n",
      "117:\tlearn: 0.2437632\ttotal: 6.97s\tremaining: 52.1s\n",
      "118:\tlearn: 0.2434972\ttotal: 7.02s\tremaining: 52s\n",
      "119:\tlearn: 0.2431879\ttotal: 7.08s\tremaining: 51.9s\n",
      "120:\tlearn: 0.2428691\ttotal: 7.14s\tremaining: 51.8s\n",
      "121:\tlearn: 0.2425456\ttotal: 7.19s\tremaining: 51.8s\n",
      "122:\tlearn: 0.2422208\ttotal: 7.24s\tremaining: 51.6s\n",
      "123:\tlearn: 0.2419190\ttotal: 7.29s\tremaining: 51.5s\n",
      "124:\tlearn: 0.2415945\ttotal: 7.35s\tremaining: 51.5s\n",
      "125:\tlearn: 0.2412858\ttotal: 7.41s\tremaining: 51.4s\n",
      "126:\tlearn: 0.2409788\ttotal: 7.46s\tremaining: 51.3s\n",
      "127:\tlearn: 0.2406874\ttotal: 7.51s\tremaining: 51.2s\n",
      "128:\tlearn: 0.2403910\ttotal: 7.56s\tremaining: 51.1s\n",
      "129:\tlearn: 0.2401040\ttotal: 7.61s\tremaining: 51s\n",
      "130:\tlearn: 0.2398037\ttotal: 7.68s\tremaining: 50.9s\n",
      "131:\tlearn: 0.2394908\ttotal: 7.74s\tremaining: 50.9s\n",
      "132:\tlearn: 0.2391895\ttotal: 7.8s\tremaining: 50.8s\n",
      "133:\tlearn: 0.2389068\ttotal: 7.86s\tremaining: 50.8s\n",
      "134:\tlearn: 0.2386174\ttotal: 7.91s\tremaining: 50.7s\n",
      "135:\tlearn: 0.2383238\ttotal: 7.97s\tremaining: 50.7s\n",
      "136:\tlearn: 0.2380346\ttotal: 8.04s\tremaining: 50.6s\n",
      "137:\tlearn: 0.2377722\ttotal: 8.09s\tremaining: 50.5s\n",
      "138:\tlearn: 0.2375005\ttotal: 8.14s\tremaining: 50.4s\n",
      "139:\tlearn: 0.2371957\ttotal: 8.2s\tremaining: 50.4s\n",
      "140:\tlearn: 0.2369409\ttotal: 8.26s\tremaining: 50.3s\n",
      "141:\tlearn: 0.2366598\ttotal: 8.32s\tremaining: 50.3s\n",
      "142:\tlearn: 0.2363801\ttotal: 8.37s\tremaining: 50.2s\n",
      "143:\tlearn: 0.2360901\ttotal: 8.44s\tremaining: 50.1s\n",
      "144:\tlearn: 0.2358215\ttotal: 8.48s\tremaining: 50s\n",
      "145:\tlearn: 0.2355617\ttotal: 8.54s\tremaining: 50s\n",
      "146:\tlearn: 0.2352770\ttotal: 8.61s\tremaining: 50s\n",
      "147:\tlearn: 0.2350276\ttotal: 8.66s\tremaining: 49.9s\n",
      "148:\tlearn: 0.2347650\ttotal: 8.71s\tremaining: 49.7s\n",
      "149:\tlearn: 0.2344759\ttotal: 8.77s\tremaining: 49.7s\n",
      "150:\tlearn: 0.2342131\ttotal: 8.81s\tremaining: 49.6s\n",
      "151:\tlearn: 0.2339624\ttotal: 8.87s\tremaining: 49.5s\n",
      "152:\tlearn: 0.2337129\ttotal: 8.92s\tremaining: 49.4s\n",
      "153:\tlearn: 0.2334439\ttotal: 8.97s\tremaining: 49.3s\n",
      "154:\tlearn: 0.2331917\ttotal: 9.02s\tremaining: 49.2s\n",
      "155:\tlearn: 0.2329384\ttotal: 9.07s\tremaining: 49.1s\n",
      "156:\tlearn: 0.2326779\ttotal: 9.13s\tremaining: 49s\n",
      "157:\tlearn: 0.2324208\ttotal: 9.18s\tremaining: 48.9s\n",
      "158:\tlearn: 0.2321442\ttotal: 9.24s\tremaining: 48.9s\n",
      "159:\tlearn: 0.2318740\ttotal: 9.31s\tremaining: 48.9s\n",
      "160:\tlearn: 0.2316402\ttotal: 9.36s\tremaining: 48.8s\n",
      "161:\tlearn: 0.2313583\ttotal: 9.41s\tremaining: 48.7s\n",
      "162:\tlearn: 0.2311077\ttotal: 9.47s\tremaining: 48.6s\n",
      "163:\tlearn: 0.2308714\ttotal: 9.52s\tremaining: 48.5s\n",
      "164:\tlearn: 0.2306353\ttotal: 9.58s\tremaining: 48.5s\n",
      "165:\tlearn: 0.2304103\ttotal: 9.63s\tremaining: 48.4s\n",
      "166:\tlearn: 0.2301938\ttotal: 9.68s\tremaining: 48.3s\n",
      "167:\tlearn: 0.2299564\ttotal: 9.73s\tremaining: 48.2s\n",
      "168:\tlearn: 0.2297101\ttotal: 9.79s\tremaining: 48.2s\n",
      "169:\tlearn: 0.2294832\ttotal: 9.84s\tremaining: 48.1s\n",
      "170:\tlearn: 0.2292308\ttotal: 9.91s\tremaining: 48s\n",
      "171:\tlearn: 0.2289819\ttotal: 9.98s\tremaining: 48.1s\n",
      "172:\tlearn: 0.2287457\ttotal: 10s\tremaining: 48s\n",
      "173:\tlearn: 0.2285022\ttotal: 10.1s\tremaining: 48s\n",
      "174:\tlearn: 0.2282768\ttotal: 10.2s\tremaining: 47.9s\n",
      "175:\tlearn: 0.2280437\ttotal: 10.2s\tremaining: 47.9s\n",
      "176:\tlearn: 0.2278262\ttotal: 10.3s\tremaining: 47.8s\n",
      "177:\tlearn: 0.2276051\ttotal: 10.3s\tremaining: 47.8s\n",
      "178:\tlearn: 0.2274063\ttotal: 10.4s\tremaining: 47.7s\n",
      "179:\tlearn: 0.2271803\ttotal: 10.5s\tremaining: 47.6s\n",
      "180:\tlearn: 0.2269595\ttotal: 10.5s\tremaining: 47.5s\n",
      "181:\tlearn: 0.2267430\ttotal: 10.6s\tremaining: 47.5s\n",
      "182:\tlearn: 0.2265388\ttotal: 10.6s\tremaining: 47.4s\n",
      "183:\tlearn: 0.2263232\ttotal: 10.7s\tremaining: 47.3s\n",
      "184:\tlearn: 0.2260931\ttotal: 10.7s\tremaining: 47.3s\n",
      "185:\tlearn: 0.2258788\ttotal: 10.8s\tremaining: 47.2s\n",
      "186:\tlearn: 0.2256585\ttotal: 10.8s\tremaining: 47.1s\n",
      "187:\tlearn: 0.2254320\ttotal: 10.9s\tremaining: 47.1s\n",
      "188:\tlearn: 0.2252301\ttotal: 11s\tremaining: 47.1s\n",
      "189:\tlearn: 0.2249990\ttotal: 11s\tremaining: 47s\n",
      "190:\tlearn: 0.2247859\ttotal: 11.1s\tremaining: 46.9s\n",
      "191:\tlearn: 0.2245713\ttotal: 11.1s\tremaining: 46.8s\n",
      "192:\tlearn: 0.2243718\ttotal: 11.2s\tremaining: 46.8s\n",
      "193:\tlearn: 0.2241374\ttotal: 11.3s\tremaining: 46.8s\n",
      "194:\tlearn: 0.2239288\ttotal: 11.3s\tremaining: 46.7s\n",
      "195:\tlearn: 0.2237348\ttotal: 11.4s\tremaining: 46.6s\n",
      "196:\tlearn: 0.2235442\ttotal: 11.4s\tremaining: 46.6s\n",
      "197:\tlearn: 0.2233281\ttotal: 11.5s\tremaining: 46.5s\n",
      "198:\tlearn: 0.2231372\ttotal: 11.5s\tremaining: 46.4s\n",
      "199:\tlearn: 0.2229283\ttotal: 11.6s\tremaining: 46.3s\n",
      "200:\tlearn: 0.2227283\ttotal: 11.6s\tremaining: 46.3s\n",
      "201:\tlearn: 0.2225298\ttotal: 11.7s\tremaining: 46.2s\n",
      "202:\tlearn: 0.2223237\ttotal: 11.8s\tremaining: 46.2s\n",
      "203:\tlearn: 0.2221344\ttotal: 11.8s\tremaining: 46.1s\n",
      "204:\tlearn: 0.2219309\ttotal: 11.9s\tremaining: 46s\n",
      "205:\tlearn: 0.2217328\ttotal: 11.9s\tremaining: 45.9s\n",
      "206:\tlearn: 0.2215428\ttotal: 12s\tremaining: 45.8s\n",
      "207:\tlearn: 0.2213518\ttotal: 12s\tremaining: 45.8s\n",
      "208:\tlearn: 0.2211760\ttotal: 12.1s\tremaining: 45.7s\n",
      "209:\tlearn: 0.2209920\ttotal: 12.1s\tremaining: 45.7s\n",
      "210:\tlearn: 0.2208093\ttotal: 12.2s\tremaining: 45.6s\n",
      "211:\tlearn: 0.2206223\ttotal: 12.3s\tremaining: 45.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "212:\tlearn: 0.2204321\ttotal: 12.3s\tremaining: 45.5s\n",
      "213:\tlearn: 0.2202307\ttotal: 12.4s\tremaining: 45.4s\n",
      "214:\tlearn: 0.2200440\ttotal: 12.4s\tremaining: 45.4s\n",
      "215:\tlearn: 0.2198539\ttotal: 12.5s\tremaining: 45.3s\n",
      "216:\tlearn: 0.2196780\ttotal: 12.5s\tremaining: 45.2s\n",
      "217:\tlearn: 0.2194851\ttotal: 12.6s\tremaining: 45.2s\n",
      "218:\tlearn: 0.2192765\ttotal: 12.7s\tremaining: 45.1s\n",
      "219:\tlearn: 0.2190777\ttotal: 12.7s\tremaining: 45.1s\n",
      "220:\tlearn: 0.2189032\ttotal: 12.8s\tremaining: 45s\n",
      "221:\tlearn: 0.2187047\ttotal: 12.8s\tremaining: 45s\n",
      "222:\tlearn: 0.2185336\ttotal: 12.9s\tremaining: 44.9s\n",
      "223:\tlearn: 0.2183510\ttotal: 13s\tremaining: 44.9s\n",
      "224:\tlearn: 0.2181730\ttotal: 13s\tremaining: 44.8s\n",
      "225:\tlearn: 0.2179871\ttotal: 13.1s\tremaining: 44.8s\n",
      "226:\tlearn: 0.2178117\ttotal: 13.1s\tremaining: 44.7s\n",
      "227:\tlearn: 0.2176189\ttotal: 13.2s\tremaining: 44.6s\n",
      "228:\tlearn: 0.2174402\ttotal: 13.2s\tremaining: 44.6s\n",
      "229:\tlearn: 0.2172744\ttotal: 13.3s\tremaining: 44.5s\n",
      "230:\tlearn: 0.2170935\ttotal: 13.4s\tremaining: 44.5s\n",
      "231:\tlearn: 0.2169138\ttotal: 13.4s\tremaining: 44.4s\n",
      "232:\tlearn: 0.2167508\ttotal: 13.5s\tremaining: 44.3s\n",
      "233:\tlearn: 0.2165823\ttotal: 13.5s\tremaining: 44.3s\n",
      "234:\tlearn: 0.2163960\ttotal: 13.6s\tremaining: 44.2s\n",
      "235:\tlearn: 0.2162235\ttotal: 13.6s\tremaining: 44.1s\n",
      "236:\tlearn: 0.2160700\ttotal: 13.7s\tremaining: 44.1s\n",
      "237:\tlearn: 0.2159011\ttotal: 13.7s\tremaining: 44s\n",
      "238:\tlearn: 0.2157306\ttotal: 13.8s\tremaining: 44s\n",
      "239:\tlearn: 0.2155490\ttotal: 13.9s\tremaining: 43.9s\n",
      "240:\tlearn: 0.2153965\ttotal: 13.9s\tremaining: 43.8s\n",
      "241:\tlearn: 0.2152364\ttotal: 14s\tremaining: 43.8s\n",
      "242:\tlearn: 0.2150599\ttotal: 14s\tremaining: 43.7s\n",
      "243:\tlearn: 0.2149020\ttotal: 14.1s\tremaining: 43.7s\n",
      "244:\tlearn: 0.2147166\ttotal: 14.2s\tremaining: 43.7s\n",
      "245:\tlearn: 0.2145477\ttotal: 14.2s\tremaining: 43.7s\n",
      "246:\tlearn: 0.2143739\ttotal: 14.3s\tremaining: 43.6s\n",
      "247:\tlearn: 0.2142053\ttotal: 14.4s\tremaining: 43.6s\n",
      "248:\tlearn: 0.2140347\ttotal: 14.4s\tremaining: 43.6s\n",
      "249:\tlearn: 0.2138791\ttotal: 14.5s\tremaining: 43.5s\n",
      "250:\tlearn: 0.2137105\ttotal: 14.6s\tremaining: 43.5s\n",
      "251:\tlearn: 0.2135692\ttotal: 14.6s\tremaining: 43.4s\n",
      "252:\tlearn: 0.2134050\ttotal: 14.7s\tremaining: 43.4s\n",
      "253:\tlearn: 0.2132489\ttotal: 14.8s\tremaining: 43.3s\n",
      "254:\tlearn: 0.2130915\ttotal: 14.8s\tremaining: 43.3s\n",
      "255:\tlearn: 0.2129469\ttotal: 14.9s\tremaining: 43.2s\n",
      "256:\tlearn: 0.2127864\ttotal: 14.9s\tremaining: 43.2s\n",
      "257:\tlearn: 0.2126291\ttotal: 15s\tremaining: 43.1s\n",
      "258:\tlearn: 0.2124656\ttotal: 15s\tremaining: 43s\n",
      "259:\tlearn: 0.2123052\ttotal: 15.1s\tremaining: 43s\n",
      "260:\tlearn: 0.2121372\ttotal: 15.2s\tremaining: 42.9s\n",
      "261:\tlearn: 0.2119769\ttotal: 15.2s\tremaining: 42.9s\n",
      "262:\tlearn: 0.2118154\ttotal: 15.3s\tremaining: 42.8s\n",
      "263:\tlearn: 0.2116623\ttotal: 15.3s\tremaining: 42.7s\n",
      "264:\tlearn: 0.2115167\ttotal: 15.4s\tremaining: 42.7s\n",
      "265:\tlearn: 0.2113688\ttotal: 15.4s\tremaining: 42.6s\n",
      "266:\tlearn: 0.2112169\ttotal: 15.5s\tremaining: 42.5s\n",
      "267:\tlearn: 0.2110751\ttotal: 15.5s\tremaining: 42.5s\n",
      "268:\tlearn: 0.2109130\ttotal: 15.6s\tremaining: 42.4s\n",
      "269:\tlearn: 0.2107586\ttotal: 15.7s\tremaining: 42.4s\n",
      "270:\tlearn: 0.2106111\ttotal: 15.7s\tremaining: 42.3s\n",
      "271:\tlearn: 0.2104712\ttotal: 15.8s\tremaining: 42.2s\n",
      "272:\tlearn: 0.2103236\ttotal: 15.8s\tremaining: 42.2s\n",
      "273:\tlearn: 0.2101810\ttotal: 15.9s\tremaining: 42.1s\n",
      "274:\tlearn: 0.2100292\ttotal: 15.9s\tremaining: 42s\n",
      "275:\tlearn: 0.2098711\ttotal: 16s\tremaining: 42s\n",
      "276:\tlearn: 0.2097012\ttotal: 16.1s\tremaining: 41.9s\n",
      "277:\tlearn: 0.2095672\ttotal: 16.1s\tremaining: 41.9s\n",
      "278:\tlearn: 0.2094203\ttotal: 16.2s\tremaining: 41.9s\n",
      "279:\tlearn: 0.2092752\ttotal: 16.3s\tremaining: 41.8s\n",
      "280:\tlearn: 0.2091332\ttotal: 16.3s\tremaining: 41.8s\n",
      "281:\tlearn: 0.2089928\ttotal: 16.4s\tremaining: 41.7s\n",
      "282:\tlearn: 0.2088474\ttotal: 16.4s\tremaining: 41.6s\n",
      "283:\tlearn: 0.2087010\ttotal: 16.5s\tremaining: 41.6s\n",
      "284:\tlearn: 0.2085760\ttotal: 16.5s\tremaining: 41.5s\n",
      "285:\tlearn: 0.2084227\ttotal: 16.6s\tremaining: 41.5s\n",
      "286:\tlearn: 0.2082818\ttotal: 16.7s\tremaining: 41.4s\n",
      "287:\tlearn: 0.2081238\ttotal: 16.7s\tremaining: 41.3s\n",
      "288:\tlearn: 0.2079898\ttotal: 16.8s\tremaining: 41.2s\n",
      "289:\tlearn: 0.2078518\ttotal: 16.8s\tremaining: 41.2s\n",
      "290:\tlearn: 0.2077248\ttotal: 16.9s\tremaining: 41.1s\n",
      "291:\tlearn: 0.2075901\ttotal: 16.9s\tremaining: 41.1s\n",
      "292:\tlearn: 0.2074622\ttotal: 17s\tremaining: 41s\n",
      "293:\tlearn: 0.2073223\ttotal: 17.1s\tremaining: 41s\n",
      "294:\tlearn: 0.2071769\ttotal: 17.1s\tremaining: 40.9s\n",
      "295:\tlearn: 0.2070363\ttotal: 17.2s\tremaining: 40.9s\n",
      "296:\tlearn: 0.2069193\ttotal: 17.2s\tremaining: 40.8s\n",
      "297:\tlearn: 0.2067913\ttotal: 17.3s\tremaining: 40.7s\n",
      "298:\tlearn: 0.2066600\ttotal: 17.3s\tremaining: 40.7s\n",
      "299:\tlearn: 0.2065100\ttotal: 17.4s\tremaining: 40.6s\n",
      "300:\tlearn: 0.2063813\ttotal: 17.5s\tremaining: 40.6s\n",
      "301:\tlearn: 0.2062500\ttotal: 17.5s\tremaining: 40.5s\n",
      "302:\tlearn: 0.2061183\ttotal: 17.6s\tremaining: 40.4s\n",
      "303:\tlearn: 0.2059849\ttotal: 17.6s\tremaining: 40.4s\n",
      "304:\tlearn: 0.2058424\ttotal: 17.7s\tremaining: 40.3s\n",
      "305:\tlearn: 0.2057028\ttotal: 17.8s\tremaining: 40.3s\n",
      "306:\tlearn: 0.2055691\ttotal: 17.8s\tremaining: 40.2s\n",
      "307:\tlearn: 0.2054354\ttotal: 17.9s\tremaining: 40.2s\n",
      "308:\tlearn: 0.2053076\ttotal: 17.9s\tremaining: 40.1s\n",
      "309:\tlearn: 0.2051807\ttotal: 18s\tremaining: 40s\n",
      "310:\tlearn: 0.2050492\ttotal: 18.1s\tremaining: 40s\n",
      "311:\tlearn: 0.2049236\ttotal: 18.1s\tremaining: 39.9s\n",
      "312:\tlearn: 0.2047910\ttotal: 18.2s\tremaining: 39.9s\n",
      "313:\tlearn: 0.2046786\ttotal: 18.2s\tremaining: 39.8s\n",
      "314:\tlearn: 0.2045427\ttotal: 18.3s\tremaining: 39.7s\n",
      "315:\tlearn: 0.2044308\ttotal: 18.3s\tremaining: 39.7s\n",
      "316:\tlearn: 0.2043036\ttotal: 18.4s\tremaining: 39.6s\n",
      "317:\tlearn: 0.2041747\ttotal: 18.4s\tremaining: 39.6s\n",
      "318:\tlearn: 0.2040410\ttotal: 18.5s\tremaining: 39.5s\n",
      "319:\tlearn: 0.2039186\ttotal: 18.6s\tremaining: 39.4s\n",
      "320:\tlearn: 0.2037806\ttotal: 18.6s\tremaining: 39.4s\n",
      "321:\tlearn: 0.2036634\ttotal: 18.7s\tremaining: 39.3s\n",
      "322:\tlearn: 0.2035379\ttotal: 18.7s\tremaining: 39.2s\n",
      "323:\tlearn: 0.2034162\ttotal: 18.8s\tremaining: 39.2s\n",
      "324:\tlearn: 0.2032920\ttotal: 18.8s\tremaining: 39.1s\n",
      "325:\tlearn: 0.2031716\ttotal: 18.9s\tremaining: 39.1s\n",
      "326:\tlearn: 0.2030469\ttotal: 18.9s\tremaining: 39s\n",
      "327:\tlearn: 0.2029155\ttotal: 19s\tremaining: 38.9s\n",
      "328:\tlearn: 0.2027993\ttotal: 19.1s\tremaining: 38.9s\n",
      "329:\tlearn: 0.2026820\ttotal: 19.1s\tremaining: 38.8s\n",
      "330:\tlearn: 0.2025677\ttotal: 19.2s\tremaining: 38.7s\n",
      "331:\tlearn: 0.2024386\ttotal: 19.2s\tremaining: 38.7s\n",
      "332:\tlearn: 0.2023150\ttotal: 19.3s\tremaining: 38.6s\n",
      "333:\tlearn: 0.2021931\ttotal: 19.3s\tremaining: 38.5s\n",
      "334:\tlearn: 0.2020743\ttotal: 19.4s\tremaining: 38.5s\n",
      "335:\tlearn: 0.2019549\ttotal: 19.4s\tremaining: 38.4s\n",
      "336:\tlearn: 0.2018197\ttotal: 19.5s\tremaining: 38.4s\n",
      "337:\tlearn: 0.2016970\ttotal: 19.6s\tremaining: 38.3s\n",
      "338:\tlearn: 0.2015810\ttotal: 19.6s\tremaining: 38.3s\n",
      "339:\tlearn: 0.2014609\ttotal: 19.7s\tremaining: 38.2s\n",
      "340:\tlearn: 0.2013406\ttotal: 19.8s\tremaining: 38.2s\n",
      "341:\tlearn: 0.2012232\ttotal: 19.8s\tremaining: 38.1s\n",
      "342:\tlearn: 0.2011076\ttotal: 19.9s\tremaining: 38.1s\n",
      "343:\tlearn: 0.2009875\ttotal: 19.9s\tremaining: 38s\n",
      "344:\tlearn: 0.2008726\ttotal: 20s\tremaining: 37.9s\n",
      "345:\tlearn: 0.2007544\ttotal: 20s\tremaining: 37.9s\n",
      "346:\tlearn: 0.2006518\ttotal: 20.1s\tremaining: 37.8s\n",
      "347:\tlearn: 0.2005388\ttotal: 20.1s\tremaining: 37.7s\n",
      "348:\tlearn: 0.2004174\ttotal: 20.2s\tremaining: 37.7s\n",
      "349:\tlearn: 0.2003143\ttotal: 20.3s\tremaining: 37.6s\n",
      "350:\tlearn: 0.2002043\ttotal: 20.3s\tremaining: 37.6s\n",
      "351:\tlearn: 0.2000979\ttotal: 20.4s\tremaining: 37.5s\n",
      "352:\tlearn: 0.1999827\ttotal: 20.4s\tremaining: 37.5s\n",
      "353:\tlearn: 0.1998626\ttotal: 20.5s\tremaining: 37.4s\n",
      "354:\tlearn: 0.1997405\ttotal: 20.6s\tremaining: 37.4s\n",
      "355:\tlearn: 0.1996286\ttotal: 20.6s\tremaining: 37.3s\n",
      "356:\tlearn: 0.1995131\ttotal: 20.7s\tremaining: 37.3s\n",
      "357:\tlearn: 0.1993986\ttotal: 20.7s\tremaining: 37.2s\n",
      "358:\tlearn: 0.1992726\ttotal: 20.8s\tremaining: 37.1s\n",
      "359:\tlearn: 0.1991636\ttotal: 20.8s\tremaining: 37.1s\n",
      "360:\tlearn: 0.1990599\ttotal: 20.9s\tremaining: 37s\n",
      "361:\tlearn: 0.1989424\ttotal: 21s\tremaining: 36.9s\n",
      "362:\tlearn: 0.1988210\ttotal: 21s\tremaining: 36.9s\n",
      "363:\tlearn: 0.1986992\ttotal: 21.1s\tremaining: 36.8s\n",
      "364:\tlearn: 0.1985908\ttotal: 21.1s\tremaining: 36.8s\n",
      "365:\tlearn: 0.1984710\ttotal: 21.2s\tremaining: 36.7s\n",
      "366:\tlearn: 0.1983549\ttotal: 21.3s\tremaining: 36.7s\n",
      "367:\tlearn: 0.1982283\ttotal: 21.3s\tremaining: 36.6s\n",
      "368:\tlearn: 0.1981052\ttotal: 21.4s\tremaining: 36.5s\n",
      "369:\tlearn: 0.1979992\ttotal: 21.4s\tremaining: 36.5s\n",
      "370:\tlearn: 0.1978955\ttotal: 21.5s\tremaining: 36.4s\n",
      "371:\tlearn: 0.1977820\ttotal: 21.5s\tremaining: 36.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "372:\tlearn: 0.1976740\ttotal: 21.6s\tremaining: 36.3s\n",
      "373:\tlearn: 0.1975512\ttotal: 21.7s\tremaining: 36.2s\n",
      "374:\tlearn: 0.1974411\ttotal: 21.7s\tremaining: 36.2s\n",
      "375:\tlearn: 0.1973213\ttotal: 21.8s\tremaining: 36.1s\n",
      "376:\tlearn: 0.1972189\ttotal: 21.8s\tremaining: 36.1s\n",
      "377:\tlearn: 0.1971037\ttotal: 21.9s\tremaining: 36s\n",
      "378:\tlearn: 0.1969980\ttotal: 21.9s\tremaining: 35.9s\n",
      "379:\tlearn: 0.1968983\ttotal: 22s\tremaining: 35.9s\n",
      "380:\tlearn: 0.1967868\ttotal: 22.1s\tremaining: 35.8s\n",
      "381:\tlearn: 0.1966797\ttotal: 22.1s\tremaining: 35.8s\n",
      "382:\tlearn: 0.1965711\ttotal: 22.2s\tremaining: 35.7s\n",
      "383:\tlearn: 0.1964698\ttotal: 22.2s\tremaining: 35.7s\n",
      "384:\tlearn: 0.1963562\ttotal: 22.3s\tremaining: 35.6s\n",
      "385:\tlearn: 0.1962329\ttotal: 22.4s\tremaining: 35.6s\n",
      "386:\tlearn: 0.1961343\ttotal: 22.4s\tremaining: 35.5s\n",
      "387:\tlearn: 0.1960216\ttotal: 22.5s\tremaining: 35.4s\n",
      "388:\tlearn: 0.1959090\ttotal: 22.5s\tremaining: 35.4s\n",
      "389:\tlearn: 0.1957982\ttotal: 22.6s\tremaining: 35.4s\n",
      "390:\tlearn: 0.1956810\ttotal: 22.7s\tremaining: 35.3s\n",
      "391:\tlearn: 0.1955804\ttotal: 22.8s\tremaining: 35.3s\n",
      "392:\tlearn: 0.1954713\ttotal: 22.8s\tremaining: 35.2s\n",
      "393:\tlearn: 0.1953743\ttotal: 22.9s\tremaining: 35.2s\n",
      "394:\tlearn: 0.1952630\ttotal: 22.9s\tremaining: 35.1s\n",
      "395:\tlearn: 0.1951436\ttotal: 23s\tremaining: 35.1s\n",
      "396:\tlearn: 0.1950335\ttotal: 23.1s\tremaining: 35s\n",
      "397:\tlearn: 0.1949334\ttotal: 23.1s\tremaining: 35s\n",
      "398:\tlearn: 0.1948266\ttotal: 23.2s\tremaining: 34.9s\n",
      "399:\tlearn: 0.1947164\ttotal: 23.2s\tremaining: 34.9s\n",
      "400:\tlearn: 0.1946202\ttotal: 23.3s\tremaining: 34.8s\n",
      "401:\tlearn: 0.1945248\ttotal: 23.4s\tremaining: 34.7s\n",
      "402:\tlearn: 0.1944125\ttotal: 23.4s\tremaining: 34.7s\n",
      "403:\tlearn: 0.1943048\ttotal: 23.5s\tremaining: 34.7s\n",
      "404:\tlearn: 0.1942062\ttotal: 23.6s\tremaining: 34.6s\n",
      "405:\tlearn: 0.1941015\ttotal: 23.6s\tremaining: 34.6s\n",
      "406:\tlearn: 0.1939881\ttotal: 23.7s\tremaining: 34.6s\n",
      "407:\tlearn: 0.1938813\ttotal: 23.8s\tremaining: 34.5s\n",
      "408:\tlearn: 0.1937691\ttotal: 23.9s\tremaining: 34.5s\n",
      "409:\tlearn: 0.1936664\ttotal: 23.9s\tremaining: 34.5s\n",
      "410:\tlearn: 0.1935666\ttotal: 24s\tremaining: 34.4s\n",
      "411:\tlearn: 0.1934735\ttotal: 24.1s\tremaining: 34.4s\n",
      "412:\tlearn: 0.1933745\ttotal: 24.1s\tremaining: 34.3s\n",
      "413:\tlearn: 0.1932695\ttotal: 24.2s\tremaining: 34.3s\n",
      "414:\tlearn: 0.1931818\ttotal: 24.3s\tremaining: 34.2s\n",
      "415:\tlearn: 0.1930882\ttotal: 24.3s\tremaining: 34.1s\n",
      "416:\tlearn: 0.1929902\ttotal: 24.4s\tremaining: 34.1s\n",
      "417:\tlearn: 0.1928920\ttotal: 24.4s\tremaining: 34s\n",
      "418:\tlearn: 0.1927913\ttotal: 24.5s\tremaining: 34s\n",
      "419:\tlearn: 0.1926807\ttotal: 24.6s\tremaining: 33.9s\n",
      "420:\tlearn: 0.1925783\ttotal: 24.6s\tremaining: 33.9s\n",
      "421:\tlearn: 0.1924775\ttotal: 24.7s\tremaining: 33.8s\n",
      "422:\tlearn: 0.1923650\ttotal: 24.8s\tremaining: 33.8s\n",
      "423:\tlearn: 0.1922660\ttotal: 24.8s\tremaining: 33.7s\n",
      "424:\tlearn: 0.1921605\ttotal: 24.9s\tremaining: 33.6s\n",
      "425:\tlearn: 0.1920682\ttotal: 24.9s\tremaining: 33.6s\n",
      "426:\tlearn: 0.1919755\ttotal: 25s\tremaining: 33.5s\n",
      "427:\tlearn: 0.1918876\ttotal: 25s\tremaining: 33.4s\n",
      "428:\tlearn: 0.1917876\ttotal: 25.1s\tremaining: 33.4s\n",
      "429:\tlearn: 0.1916876\ttotal: 25.1s\tremaining: 33.3s\n",
      "430:\tlearn: 0.1915967\ttotal: 25.2s\tremaining: 33.2s\n",
      "431:\tlearn: 0.1914882\ttotal: 25.3s\tremaining: 33.2s\n",
      "432:\tlearn: 0.1913856\ttotal: 25.3s\tremaining: 33.2s\n",
      "433:\tlearn: 0.1912895\ttotal: 25.4s\tremaining: 33.1s\n",
      "434:\tlearn: 0.1911897\ttotal: 25.4s\tremaining: 33s\n",
      "435:\tlearn: 0.1911050\ttotal: 25.5s\tremaining: 33s\n",
      "436:\tlearn: 0.1910103\ttotal: 25.5s\tremaining: 32.9s\n",
      "437:\tlearn: 0.1909170\ttotal: 25.6s\tremaining: 32.8s\n",
      "438:\tlearn: 0.1908233\ttotal: 25.7s\tremaining: 32.8s\n",
      "439:\tlearn: 0.1907237\ttotal: 25.7s\tremaining: 32.7s\n",
      "440:\tlearn: 0.1906167\ttotal: 25.8s\tremaining: 32.7s\n",
      "441:\tlearn: 0.1905256\ttotal: 25.8s\tremaining: 32.6s\n",
      "442:\tlearn: 0.1904314\ttotal: 25.9s\tremaining: 32.6s\n",
      "443:\tlearn: 0.1903375\ttotal: 26s\tremaining: 32.5s\n",
      "444:\tlearn: 0.1902435\ttotal: 26s\tremaining: 32.5s\n",
      "445:\tlearn: 0.1901508\ttotal: 26.1s\tremaining: 32.4s\n",
      "446:\tlearn: 0.1900653\ttotal: 26.2s\tremaining: 32.4s\n",
      "447:\tlearn: 0.1899786\ttotal: 26.2s\tremaining: 32.3s\n",
      "448:\tlearn: 0.1898739\ttotal: 26.3s\tremaining: 32.2s\n",
      "449:\tlearn: 0.1897862\ttotal: 26.3s\tremaining: 32.2s\n",
      "450:\tlearn: 0.1896981\ttotal: 26.4s\tremaining: 32.1s\n",
      "451:\tlearn: 0.1896035\ttotal: 26.5s\tremaining: 32.1s\n",
      "452:\tlearn: 0.1895097\ttotal: 26.5s\tremaining: 32s\n",
      "453:\tlearn: 0.1894267\ttotal: 26.6s\tremaining: 32s\n",
      "454:\tlearn: 0.1893321\ttotal: 26.6s\tremaining: 31.9s\n",
      "455:\tlearn: 0.1892355\ttotal: 26.7s\tremaining: 31.8s\n",
      "456:\tlearn: 0.1891430\ttotal: 26.7s\tremaining: 31.8s\n",
      "457:\tlearn: 0.1890592\ttotal: 26.8s\tremaining: 31.7s\n",
      "458:\tlearn: 0.1889716\ttotal: 26.9s\tremaining: 31.7s\n",
      "459:\tlearn: 0.1888817\ttotal: 26.9s\tremaining: 31.6s\n",
      "460:\tlearn: 0.1888014\ttotal: 27s\tremaining: 31.5s\n",
      "461:\tlearn: 0.1887009\ttotal: 27s\tremaining: 31.5s\n",
      "462:\tlearn: 0.1885975\ttotal: 27.1s\tremaining: 31.4s\n",
      "463:\tlearn: 0.1884988\ttotal: 27.2s\tremaining: 31.4s\n",
      "464:\tlearn: 0.1884108\ttotal: 27.2s\tremaining: 31.3s\n",
      "465:\tlearn: 0.1883296\ttotal: 27.3s\tremaining: 31.3s\n",
      "466:\tlearn: 0.1882430\ttotal: 27.3s\tremaining: 31.2s\n",
      "467:\tlearn: 0.1881585\ttotal: 27.4s\tremaining: 31.1s\n",
      "468:\tlearn: 0.1880642\ttotal: 27.5s\tremaining: 31.1s\n",
      "469:\tlearn: 0.1879610\ttotal: 27.5s\tremaining: 31s\n",
      "470:\tlearn: 0.1878715\ttotal: 27.6s\tremaining: 31s\n",
      "471:\tlearn: 0.1877841\ttotal: 27.7s\tremaining: 30.9s\n",
      "472:\tlearn: 0.1876975\ttotal: 27.7s\tremaining: 30.9s\n",
      "473:\tlearn: 0.1876154\ttotal: 27.8s\tremaining: 30.8s\n",
      "474:\tlearn: 0.1875290\ttotal: 27.8s\tremaining: 30.8s\n",
      "475:\tlearn: 0.1874396\ttotal: 27.9s\tremaining: 30.7s\n",
      "476:\tlearn: 0.1873474\ttotal: 27.9s\tremaining: 30.6s\n",
      "477:\tlearn: 0.1872659\ttotal: 28s\tremaining: 30.6s\n",
      "478:\tlearn: 0.1871789\ttotal: 28.1s\tremaining: 30.5s\n",
      "479:\tlearn: 0.1871181\ttotal: 28.1s\tremaining: 30.5s\n",
      "480:\tlearn: 0.1870265\ttotal: 28.2s\tremaining: 30.4s\n",
      "481:\tlearn: 0.1869376\ttotal: 28.3s\tremaining: 30.4s\n",
      "482:\tlearn: 0.1868406\ttotal: 28.3s\tremaining: 30.3s\n",
      "483:\tlearn: 0.1867507\ttotal: 28.4s\tremaining: 30.3s\n",
      "484:\tlearn: 0.1866712\ttotal: 28.5s\tremaining: 30.2s\n",
      "485:\tlearn: 0.1865788\ttotal: 28.6s\tremaining: 30.2s\n",
      "486:\tlearn: 0.1864884\ttotal: 28.6s\tremaining: 30.1s\n",
      "487:\tlearn: 0.1863936\ttotal: 28.7s\tremaining: 30.1s\n",
      "488:\tlearn: 0.1863094\ttotal: 28.7s\tremaining: 30s\n",
      "489:\tlearn: 0.1862317\ttotal: 28.8s\tremaining: 30s\n",
      "490:\tlearn: 0.1861342\ttotal: 28.9s\tremaining: 29.9s\n",
      "491:\tlearn: 0.1860445\ttotal: 28.9s\tremaining: 29.9s\n",
      "492:\tlearn: 0.1859598\ttotal: 29s\tremaining: 29.8s\n",
      "493:\tlearn: 0.1858659\ttotal: 29s\tremaining: 29.7s\n",
      "494:\tlearn: 0.1857811\ttotal: 29.1s\tremaining: 29.7s\n",
      "495:\tlearn: 0.1856836\ttotal: 29.2s\tremaining: 29.6s\n",
      "496:\tlearn: 0.1855898\ttotal: 29.2s\tremaining: 29.6s\n",
      "497:\tlearn: 0.1855020\ttotal: 29.3s\tremaining: 29.5s\n",
      "498:\tlearn: 0.1854077\ttotal: 29.4s\tremaining: 29.5s\n",
      "499:\tlearn: 0.1853292\ttotal: 29.4s\tremaining: 29.4s\n",
      "500:\tlearn: 0.1852459\ttotal: 29.5s\tremaining: 29.4s\n",
      "501:\tlearn: 0.1851761\ttotal: 29.6s\tremaining: 29.3s\n",
      "502:\tlearn: 0.1850919\ttotal: 29.6s\tremaining: 29.3s\n",
      "503:\tlearn: 0.1850114\ttotal: 29.7s\tremaining: 29.2s\n",
      "504:\tlearn: 0.1849382\ttotal: 29.7s\tremaining: 29.1s\n",
      "505:\tlearn: 0.1848519\ttotal: 29.8s\tremaining: 29.1s\n",
      "506:\tlearn: 0.1847632\ttotal: 29.9s\tremaining: 29.1s\n",
      "507:\tlearn: 0.1846783\ttotal: 30s\tremaining: 29s\n",
      "508:\tlearn: 0.1845890\ttotal: 30s\tremaining: 29s\n",
      "509:\tlearn: 0.1845054\ttotal: 30.1s\tremaining: 28.9s\n",
      "510:\tlearn: 0.1844208\ttotal: 30.1s\tremaining: 28.8s\n",
      "511:\tlearn: 0.1843242\ttotal: 30.2s\tremaining: 28.8s\n",
      "512:\tlearn: 0.1842366\ttotal: 30.3s\tremaining: 28.7s\n",
      "513:\tlearn: 0.1841636\ttotal: 30.3s\tremaining: 28.7s\n",
      "514:\tlearn: 0.1840779\ttotal: 30.4s\tremaining: 28.6s\n",
      "515:\tlearn: 0.1839854\ttotal: 30.4s\tremaining: 28.5s\n",
      "516:\tlearn: 0.1838990\ttotal: 30.5s\tremaining: 28.5s\n",
      "517:\tlearn: 0.1838054\ttotal: 30.6s\tremaining: 28.4s\n",
      "518:\tlearn: 0.1837221\ttotal: 30.6s\tremaining: 28.4s\n",
      "519:\tlearn: 0.1836326\ttotal: 30.7s\tremaining: 28.3s\n",
      "520:\tlearn: 0.1835455\ttotal: 30.7s\tremaining: 28.3s\n",
      "521:\tlearn: 0.1834646\ttotal: 30.8s\tremaining: 28.2s\n",
      "522:\tlearn: 0.1833669\ttotal: 30.9s\tremaining: 28.1s\n",
      "523:\tlearn: 0.1832870\ttotal: 30.9s\tremaining: 28.1s\n",
      "524:\tlearn: 0.1832097\ttotal: 31s\tremaining: 28s\n",
      "525:\tlearn: 0.1831287\ttotal: 31s\tremaining: 28s\n",
      "526:\tlearn: 0.1830468\ttotal: 31.1s\tremaining: 27.9s\n",
      "527:\tlearn: 0.1829586\ttotal: 31.2s\tremaining: 27.8s\n",
      "528:\tlearn: 0.1828704\ttotal: 31.2s\tremaining: 27.8s\n",
      "529:\tlearn: 0.1827880\ttotal: 31.3s\tremaining: 27.7s\n",
      "530:\tlearn: 0.1827145\ttotal: 31.3s\tremaining: 27.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "531:\tlearn: 0.1826363\ttotal: 31.4s\tremaining: 27.6s\n",
      "532:\tlearn: 0.1825536\ttotal: 31.4s\tremaining: 27.5s\n",
      "533:\tlearn: 0.1824763\ttotal: 31.5s\tremaining: 27.5s\n",
      "534:\tlearn: 0.1823867\ttotal: 31.5s\tremaining: 27.4s\n",
      "535:\tlearn: 0.1823082\ttotal: 31.6s\tremaining: 27.4s\n",
      "536:\tlearn: 0.1822171\ttotal: 31.7s\tremaining: 27.3s\n",
      "537:\tlearn: 0.1821334\ttotal: 31.7s\tremaining: 27.2s\n",
      "538:\tlearn: 0.1820557\ttotal: 31.8s\tremaining: 27.2s\n",
      "539:\tlearn: 0.1819727\ttotal: 31.8s\tremaining: 27.1s\n",
      "540:\tlearn: 0.1818945\ttotal: 31.9s\tremaining: 27.1s\n",
      "541:\tlearn: 0.1818265\ttotal: 32s\tremaining: 27s\n",
      "542:\tlearn: 0.1817422\ttotal: 32s\tremaining: 27s\n",
      "543:\tlearn: 0.1816651\ttotal: 32.1s\tremaining: 26.9s\n",
      "544:\tlearn: 0.1815880\ttotal: 32.2s\tremaining: 26.9s\n",
      "545:\tlearn: 0.1815150\ttotal: 32.2s\tremaining: 26.8s\n",
      "546:\tlearn: 0.1814229\ttotal: 32.3s\tremaining: 26.7s\n",
      "547:\tlearn: 0.1813471\ttotal: 32.4s\tremaining: 26.7s\n",
      "548:\tlearn: 0.1812711\ttotal: 32.4s\tremaining: 26.6s\n",
      "549:\tlearn: 0.1811975\ttotal: 32.5s\tremaining: 26.6s\n",
      "550:\tlearn: 0.1811160\ttotal: 32.6s\tremaining: 26.5s\n",
      "551:\tlearn: 0.1810389\ttotal: 32.6s\tremaining: 26.5s\n",
      "552:\tlearn: 0.1809558\ttotal: 32.7s\tremaining: 26.4s\n",
      "553:\tlearn: 0.1808751\ttotal: 32.7s\tremaining: 26.4s\n",
      "554:\tlearn: 0.1808015\ttotal: 32.8s\tremaining: 26.3s\n",
      "555:\tlearn: 0.1807084\ttotal: 32.9s\tremaining: 26.3s\n",
      "556:\tlearn: 0.1806270\ttotal: 32.9s\tremaining: 26.2s\n",
      "557:\tlearn: 0.1805508\ttotal: 33s\tremaining: 26.1s\n",
      "558:\tlearn: 0.1804691\ttotal: 33.1s\tremaining: 26.1s\n",
      "559:\tlearn: 0.1804055\ttotal: 33.1s\tremaining: 26s\n",
      "560:\tlearn: 0.1803404\ttotal: 33.2s\tremaining: 25.9s\n",
      "561:\tlearn: 0.1802583\ttotal: 33.2s\tremaining: 25.9s\n",
      "562:\tlearn: 0.1801922\ttotal: 33.3s\tremaining: 25.8s\n",
      "563:\tlearn: 0.1801216\ttotal: 33.3s\tremaining: 25.8s\n",
      "564:\tlearn: 0.1800561\ttotal: 33.4s\tremaining: 25.7s\n",
      "565:\tlearn: 0.1799825\ttotal: 33.4s\tremaining: 25.6s\n",
      "566:\tlearn: 0.1799058\ttotal: 33.5s\tremaining: 25.6s\n",
      "567:\tlearn: 0.1798390\ttotal: 33.6s\tremaining: 25.5s\n",
      "568:\tlearn: 0.1797573\ttotal: 33.6s\tremaining: 25.5s\n",
      "569:\tlearn: 0.1796829\ttotal: 33.7s\tremaining: 25.4s\n",
      "570:\tlearn: 0.1796130\ttotal: 33.8s\tremaining: 25.4s\n",
      "571:\tlearn: 0.1795458\ttotal: 33.8s\tremaining: 25.3s\n",
      "572:\tlearn: 0.1794751\ttotal: 33.9s\tremaining: 25.2s\n",
      "573:\tlearn: 0.1794073\ttotal: 33.9s\tremaining: 25.2s\n",
      "574:\tlearn: 0.1793335\ttotal: 34s\tremaining: 25.1s\n",
      "575:\tlearn: 0.1792626\ttotal: 34.1s\tremaining: 25.1s\n",
      "576:\tlearn: 0.1791984\ttotal: 34.1s\tremaining: 25s\n",
      "577:\tlearn: 0.1791267\ttotal: 34.2s\tremaining: 24.9s\n",
      "578:\tlearn: 0.1790498\ttotal: 34.2s\tremaining: 24.9s\n",
      "579:\tlearn: 0.1789845\ttotal: 34.3s\tremaining: 24.8s\n",
      "580:\tlearn: 0.1789013\ttotal: 34.4s\tremaining: 24.8s\n",
      "581:\tlearn: 0.1788108\ttotal: 34.4s\tremaining: 24.7s\n",
      "582:\tlearn: 0.1787329\ttotal: 34.5s\tremaining: 24.7s\n",
      "583:\tlearn: 0.1786500\ttotal: 34.5s\tremaining: 24.6s\n",
      "584:\tlearn: 0.1785786\ttotal: 34.6s\tremaining: 24.5s\n",
      "585:\tlearn: 0.1785023\ttotal: 34.7s\tremaining: 24.5s\n",
      "586:\tlearn: 0.1784306\ttotal: 34.7s\tremaining: 24.4s\n",
      "587:\tlearn: 0.1783569\ttotal: 34.8s\tremaining: 24.4s\n",
      "588:\tlearn: 0.1782813\ttotal: 34.8s\tremaining: 24.3s\n",
      "589:\tlearn: 0.1782244\ttotal: 34.9s\tremaining: 24.2s\n",
      "590:\tlearn: 0.1781471\ttotal: 34.9s\tremaining: 24.2s\n",
      "591:\tlearn: 0.1780712\ttotal: 35s\tremaining: 24.1s\n",
      "592:\tlearn: 0.1779869\ttotal: 35s\tremaining: 24.1s\n",
      "593:\tlearn: 0.1779241\ttotal: 35.1s\tremaining: 24s\n",
      "594:\tlearn: 0.1778596\ttotal: 35.2s\tremaining: 23.9s\n",
      "595:\tlearn: 0.1777951\ttotal: 35.2s\tremaining: 23.9s\n",
      "596:\tlearn: 0.1777296\ttotal: 35.3s\tremaining: 23.8s\n",
      "597:\tlearn: 0.1776568\ttotal: 35.3s\tremaining: 23.7s\n",
      "598:\tlearn: 0.1775809\ttotal: 35.4s\tremaining: 23.7s\n",
      "599:\tlearn: 0.1775061\ttotal: 35.4s\tremaining: 23.6s\n",
      "600:\tlearn: 0.1774444\ttotal: 35.5s\tremaining: 23.6s\n",
      "601:\tlearn: 0.1773827\ttotal: 35.6s\tremaining: 23.5s\n",
      "602:\tlearn: 0.1773239\ttotal: 35.6s\tremaining: 23.4s\n",
      "603:\tlearn: 0.1772734\ttotal: 35.7s\tremaining: 23.4s\n",
      "604:\tlearn: 0.1772027\ttotal: 35.7s\tremaining: 23.3s\n",
      "605:\tlearn: 0.1771437\ttotal: 35.8s\tremaining: 23.3s\n",
      "606:\tlearn: 0.1770698\ttotal: 35.8s\tremaining: 23.2s\n",
      "607:\tlearn: 0.1769978\ttotal: 35.9s\tremaining: 23.2s\n",
      "608:\tlearn: 0.1769284\ttotal: 36s\tremaining: 23.1s\n",
      "609:\tlearn: 0.1768533\ttotal: 36s\tremaining: 23s\n",
      "610:\tlearn: 0.1767792\ttotal: 36.1s\tremaining: 23s\n",
      "611:\tlearn: 0.1767008\ttotal: 36.2s\tremaining: 22.9s\n",
      "612:\tlearn: 0.1766377\ttotal: 36.2s\tremaining: 22.9s\n",
      "613:\tlearn: 0.1765675\ttotal: 36.3s\tremaining: 22.8s\n",
      "614:\tlearn: 0.1765055\ttotal: 36.3s\tremaining: 22.7s\n",
      "615:\tlearn: 0.1764254\ttotal: 36.4s\tremaining: 22.7s\n",
      "616:\tlearn: 0.1763653\ttotal: 36.4s\tremaining: 22.6s\n",
      "617:\tlearn: 0.1762950\ttotal: 36.5s\tremaining: 22.6s\n",
      "618:\tlearn: 0.1762156\ttotal: 36.6s\tremaining: 22.5s\n",
      "619:\tlearn: 0.1761445\ttotal: 36.6s\tremaining: 22.5s\n",
      "620:\tlearn: 0.1760752\ttotal: 36.7s\tremaining: 22.4s\n",
      "621:\tlearn: 0.1760109\ttotal: 36.7s\tremaining: 22.3s\n",
      "622:\tlearn: 0.1759321\ttotal: 36.8s\tremaining: 22.3s\n",
      "623:\tlearn: 0.1758709\ttotal: 36.9s\tremaining: 22.2s\n",
      "624:\tlearn: 0.1758000\ttotal: 36.9s\tremaining: 22.2s\n",
      "625:\tlearn: 0.1757208\ttotal: 37s\tremaining: 22.1s\n",
      "626:\tlearn: 0.1756576\ttotal: 37.1s\tremaining: 22s\n",
      "627:\tlearn: 0.1755781\ttotal: 37.1s\tremaining: 22s\n",
      "628:\tlearn: 0.1755164\ttotal: 37.2s\tremaining: 21.9s\n",
      "629:\tlearn: 0.1754455\ttotal: 37.2s\tremaining: 21.9s\n",
      "630:\tlearn: 0.1753794\ttotal: 37.3s\tremaining: 21.8s\n",
      "631:\tlearn: 0.1753034\ttotal: 37.4s\tremaining: 21.8s\n",
      "632:\tlearn: 0.1752409\ttotal: 37.4s\tremaining: 21.7s\n",
      "633:\tlearn: 0.1751723\ttotal: 37.5s\tremaining: 21.6s\n",
      "634:\tlearn: 0.1751157\ttotal: 37.5s\tremaining: 21.6s\n",
      "635:\tlearn: 0.1750432\ttotal: 37.6s\tremaining: 21.5s\n",
      "636:\tlearn: 0.1749684\ttotal: 37.6s\tremaining: 21.5s\n",
      "637:\tlearn: 0.1748875\ttotal: 37.7s\tremaining: 21.4s\n",
      "638:\tlearn: 0.1748175\ttotal: 37.8s\tremaining: 21.3s\n",
      "639:\tlearn: 0.1747475\ttotal: 37.8s\tremaining: 21.3s\n",
      "640:\tlearn: 0.1746793\ttotal: 37.9s\tremaining: 21.2s\n",
      "641:\tlearn: 0.1746079\ttotal: 37.9s\tremaining: 21.2s\n",
      "642:\tlearn: 0.1745395\ttotal: 38s\tremaining: 21.1s\n",
      "643:\tlearn: 0.1744748\ttotal: 38.1s\tremaining: 21s\n",
      "644:\tlearn: 0.1744080\ttotal: 38.1s\tremaining: 21s\n",
      "645:\tlearn: 0.1743489\ttotal: 38.2s\tremaining: 20.9s\n",
      "646:\tlearn: 0.1742899\ttotal: 38.2s\tremaining: 20.9s\n",
      "647:\tlearn: 0.1742334\ttotal: 38.3s\tremaining: 20.8s\n",
      "648:\tlearn: 0.1741669\ttotal: 38.4s\tremaining: 20.8s\n",
      "649:\tlearn: 0.1740938\ttotal: 38.4s\tremaining: 20.7s\n",
      "650:\tlearn: 0.1740218\ttotal: 38.5s\tremaining: 20.6s\n",
      "651:\tlearn: 0.1739504\ttotal: 38.6s\tremaining: 20.6s\n",
      "652:\tlearn: 0.1738939\ttotal: 38.6s\tremaining: 20.5s\n",
      "653:\tlearn: 0.1738310\ttotal: 38.7s\tremaining: 20.5s\n",
      "654:\tlearn: 0.1737780\ttotal: 38.7s\tremaining: 20.4s\n",
      "655:\tlearn: 0.1737074\ttotal: 38.8s\tremaining: 20.3s\n",
      "656:\tlearn: 0.1736453\ttotal: 38.8s\tremaining: 20.3s\n",
      "657:\tlearn: 0.1735746\ttotal: 38.9s\tremaining: 20.2s\n",
      "658:\tlearn: 0.1735028\ttotal: 39s\tremaining: 20.2s\n",
      "659:\tlearn: 0.1734405\ttotal: 39s\tremaining: 20.1s\n",
      "660:\tlearn: 0.1733861\ttotal: 39.1s\tremaining: 20s\n",
      "661:\tlearn: 0.1733180\ttotal: 39.1s\tremaining: 20s\n",
      "662:\tlearn: 0.1732423\ttotal: 39.2s\tremaining: 19.9s\n",
      "663:\tlearn: 0.1731892\ttotal: 39.2s\tremaining: 19.9s\n",
      "664:\tlearn: 0.1731163\ttotal: 39.3s\tremaining: 19.8s\n",
      "665:\tlearn: 0.1730484\ttotal: 39.3s\tremaining: 19.7s\n",
      "666:\tlearn: 0.1729761\ttotal: 39.4s\tremaining: 19.7s\n",
      "667:\tlearn: 0.1729136\ttotal: 39.5s\tremaining: 19.6s\n",
      "668:\tlearn: 0.1728493\ttotal: 39.5s\tremaining: 19.6s\n",
      "669:\tlearn: 0.1727901\ttotal: 39.6s\tremaining: 19.5s\n",
      "670:\tlearn: 0.1727197\ttotal: 39.6s\tremaining: 19.4s\n",
      "671:\tlearn: 0.1726818\ttotal: 39.7s\tremaining: 19.4s\n",
      "672:\tlearn: 0.1726066\ttotal: 39.8s\tremaining: 19.3s\n",
      "673:\tlearn: 0.1725269\ttotal: 39.8s\tremaining: 19.3s\n",
      "674:\tlearn: 0.1724604\ttotal: 39.9s\tremaining: 19.2s\n",
      "675:\tlearn: 0.1724021\ttotal: 39.9s\tremaining: 19.1s\n",
      "676:\tlearn: 0.1723501\ttotal: 40s\tremaining: 19.1s\n",
      "677:\tlearn: 0.1722866\ttotal: 40s\tremaining: 19s\n",
      "678:\tlearn: 0.1722282\ttotal: 40.1s\tremaining: 19s\n",
      "679:\tlearn: 0.1721593\ttotal: 40.2s\tremaining: 18.9s\n",
      "680:\tlearn: 0.1720985\ttotal: 40.2s\tremaining: 18.8s\n",
      "681:\tlearn: 0.1720326\ttotal: 40.3s\tremaining: 18.8s\n",
      "682:\tlearn: 0.1719636\ttotal: 40.3s\tremaining: 18.7s\n",
      "683:\tlearn: 0.1718942\ttotal: 40.4s\tremaining: 18.7s\n",
      "684:\tlearn: 0.1718271\ttotal: 40.5s\tremaining: 18.6s\n",
      "685:\tlearn: 0.1717543\ttotal: 40.5s\tremaining: 18.5s\n",
      "686:\tlearn: 0.1716918\ttotal: 40.6s\tremaining: 18.5s\n",
      "687:\tlearn: 0.1716205\ttotal: 40.6s\tremaining: 18.4s\n",
      "688:\tlearn: 0.1715582\ttotal: 40.7s\tremaining: 18.4s\n",
      "689:\tlearn: 0.1714981\ttotal: 40.7s\tremaining: 18.3s\n",
      "690:\tlearn: 0.1714451\ttotal: 40.8s\tremaining: 18.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "691:\tlearn: 0.1713814\ttotal: 40.8s\tremaining: 18.2s\n",
      "692:\tlearn: 0.1713098\ttotal: 40.9s\tremaining: 18.1s\n",
      "693:\tlearn: 0.1712439\ttotal: 41s\tremaining: 18.1s\n",
      "694:\tlearn: 0.1711731\ttotal: 41s\tremaining: 18s\n",
      "695:\tlearn: 0.1711173\ttotal: 41.1s\tremaining: 17.9s\n",
      "696:\tlearn: 0.1710436\ttotal: 41.1s\tremaining: 17.9s\n",
      "697:\tlearn: 0.1709750\ttotal: 41.2s\tremaining: 17.8s\n",
      "698:\tlearn: 0.1709177\ttotal: 41.3s\tremaining: 17.8s\n",
      "699:\tlearn: 0.1708528\ttotal: 41.3s\tremaining: 17.7s\n",
      "700:\tlearn: 0.1707832\ttotal: 41.4s\tremaining: 17.6s\n",
      "701:\tlearn: 0.1707216\ttotal: 41.4s\tremaining: 17.6s\n",
      "702:\tlearn: 0.1706595\ttotal: 41.5s\tremaining: 17.5s\n",
      "703:\tlearn: 0.1705928\ttotal: 41.5s\tremaining: 17.5s\n",
      "704:\tlearn: 0.1705152\ttotal: 41.6s\tremaining: 17.4s\n",
      "705:\tlearn: 0.1704523\ttotal: 41.7s\tremaining: 17.3s\n",
      "706:\tlearn: 0.1703766\ttotal: 41.7s\tremaining: 17.3s\n",
      "707:\tlearn: 0.1703109\ttotal: 41.8s\tremaining: 17.2s\n",
      "708:\tlearn: 0.1702469\ttotal: 41.8s\tremaining: 17.2s\n",
      "709:\tlearn: 0.1701888\ttotal: 41.9s\tremaining: 17.1s\n",
      "710:\tlearn: 0.1701254\ttotal: 41.9s\tremaining: 17s\n",
      "711:\tlearn: 0.1700554\ttotal: 42s\tremaining: 17s\n",
      "712:\tlearn: 0.1699896\ttotal: 42s\tremaining: 16.9s\n",
      "713:\tlearn: 0.1699324\ttotal: 42.1s\tremaining: 16.9s\n",
      "714:\tlearn: 0.1698664\ttotal: 42.2s\tremaining: 16.8s\n",
      "715:\tlearn: 0.1698045\ttotal: 42.2s\tremaining: 16.7s\n",
      "716:\tlearn: 0.1697462\ttotal: 42.3s\tremaining: 16.7s\n",
      "717:\tlearn: 0.1696784\ttotal: 42.3s\tremaining: 16.6s\n",
      "718:\tlearn: 0.1696083\ttotal: 42.4s\tremaining: 16.6s\n",
      "719:\tlearn: 0.1695494\ttotal: 42.4s\tremaining: 16.5s\n",
      "720:\tlearn: 0.1694835\ttotal: 42.5s\tremaining: 16.4s\n",
      "721:\tlearn: 0.1694321\ttotal: 42.6s\tremaining: 16.4s\n",
      "722:\tlearn: 0.1693635\ttotal: 42.6s\tremaining: 16.3s\n",
      "723:\tlearn: 0.1693045\ttotal: 42.7s\tremaining: 16.3s\n",
      "724:\tlearn: 0.1692577\ttotal: 42.7s\tremaining: 16.2s\n",
      "725:\tlearn: 0.1691906\ttotal: 42.8s\tremaining: 16.1s\n",
      "726:\tlearn: 0.1691208\ttotal: 42.8s\tremaining: 16.1s\n",
      "727:\tlearn: 0.1690672\ttotal: 42.9s\tremaining: 16s\n",
      "728:\tlearn: 0.1690008\ttotal: 42.9s\tremaining: 16s\n",
      "729:\tlearn: 0.1689469\ttotal: 43s\tremaining: 15.9s\n",
      "730:\tlearn: 0.1688916\ttotal: 43.1s\tremaining: 15.8s\n",
      "731:\tlearn: 0.1688269\ttotal: 43.1s\tremaining: 15.8s\n",
      "732:\tlearn: 0.1687625\ttotal: 43.2s\tremaining: 15.7s\n",
      "733:\tlearn: 0.1687116\ttotal: 43.2s\tremaining: 15.7s\n",
      "734:\tlearn: 0.1686481\ttotal: 43.3s\tremaining: 15.6s\n",
      "735:\tlearn: 0.1685782\ttotal: 43.4s\tremaining: 15.6s\n",
      "736:\tlearn: 0.1685160\ttotal: 43.4s\tremaining: 15.5s\n",
      "737:\tlearn: 0.1684484\ttotal: 43.5s\tremaining: 15.4s\n",
      "738:\tlearn: 0.1683806\ttotal: 43.6s\tremaining: 15.4s\n",
      "739:\tlearn: 0.1683139\ttotal: 43.6s\tremaining: 15.3s\n",
      "740:\tlearn: 0.1682577\ttotal: 43.7s\tremaining: 15.3s\n",
      "741:\tlearn: 0.1681973\ttotal: 43.7s\tremaining: 15.2s\n",
      "742:\tlearn: 0.1681327\ttotal: 43.8s\tremaining: 15.2s\n",
      "743:\tlearn: 0.1680710\ttotal: 43.9s\tremaining: 15.1s\n",
      "744:\tlearn: 0.1680019\ttotal: 44s\tremaining: 15s\n",
      "745:\tlearn: 0.1679320\ttotal: 44s\tremaining: 15s\n",
      "746:\tlearn: 0.1678710\ttotal: 44.1s\tremaining: 14.9s\n",
      "747:\tlearn: 0.1678016\ttotal: 44.2s\tremaining: 14.9s\n",
      "748:\tlearn: 0.1677381\ttotal: 44.2s\tremaining: 14.8s\n",
      "749:\tlearn: 0.1676778\ttotal: 44.3s\tremaining: 14.8s\n",
      "750:\tlearn: 0.1676195\ttotal: 44.4s\tremaining: 14.7s\n",
      "751:\tlearn: 0.1675635\ttotal: 44.4s\tremaining: 14.7s\n",
      "752:\tlearn: 0.1674973\ttotal: 44.5s\tremaining: 14.6s\n",
      "753:\tlearn: 0.1674422\ttotal: 44.6s\tremaining: 14.5s\n",
      "754:\tlearn: 0.1673940\ttotal: 44.7s\tremaining: 14.5s\n",
      "755:\tlearn: 0.1673504\ttotal: 44.7s\tremaining: 14.4s\n",
      "756:\tlearn: 0.1673059\ttotal: 44.8s\tremaining: 14.4s\n",
      "757:\tlearn: 0.1672639\ttotal: 44.9s\tremaining: 14.3s\n",
      "758:\tlearn: 0.1672172\ttotal: 44.9s\tremaining: 14.3s\n",
      "759:\tlearn: 0.1671455\ttotal: 45s\tremaining: 14.2s\n",
      "760:\tlearn: 0.1670969\ttotal: 45s\tremaining: 14.1s\n",
      "761:\tlearn: 0.1670277\ttotal: 45.1s\tremaining: 14.1s\n",
      "762:\tlearn: 0.1669703\ttotal: 45.2s\tremaining: 14s\n",
      "763:\tlearn: 0.1668947\ttotal: 45.3s\tremaining: 14s\n",
      "764:\tlearn: 0.1668371\ttotal: 45.3s\tremaining: 13.9s\n",
      "765:\tlearn: 0.1667764\ttotal: 45.4s\tremaining: 13.9s\n",
      "766:\tlearn: 0.1667226\ttotal: 45.5s\tremaining: 13.8s\n",
      "767:\tlearn: 0.1666579\ttotal: 45.5s\tremaining: 13.8s\n",
      "768:\tlearn: 0.1665958\ttotal: 45.6s\tremaining: 13.7s\n",
      "769:\tlearn: 0.1665323\ttotal: 45.7s\tremaining: 13.6s\n",
      "770:\tlearn: 0.1664729\ttotal: 45.7s\tremaining: 13.6s\n",
      "771:\tlearn: 0.1664115\ttotal: 45.8s\tremaining: 13.5s\n",
      "772:\tlearn: 0.1663451\ttotal: 45.8s\tremaining: 13.5s\n",
      "773:\tlearn: 0.1662870\ttotal: 45.9s\tremaining: 13.4s\n",
      "774:\tlearn: 0.1662300\ttotal: 46s\tremaining: 13.3s\n",
      "775:\tlearn: 0.1661856\ttotal: 46s\tremaining: 13.3s\n",
      "776:\tlearn: 0.1661225\ttotal: 46.1s\tremaining: 13.2s\n",
      "777:\tlearn: 0.1660667\ttotal: 46.2s\tremaining: 13.2s\n",
      "778:\tlearn: 0.1659971\ttotal: 46.3s\tremaining: 13.1s\n",
      "779:\tlearn: 0.1659264\ttotal: 46.3s\tremaining: 13.1s\n",
      "780:\tlearn: 0.1658736\ttotal: 46.4s\tremaining: 13s\n",
      "781:\tlearn: 0.1658135\ttotal: 46.4s\tremaining: 12.9s\n",
      "782:\tlearn: 0.1657546\ttotal: 46.5s\tremaining: 12.9s\n",
      "783:\tlearn: 0.1656870\ttotal: 46.6s\tremaining: 12.8s\n",
      "784:\tlearn: 0.1656223\ttotal: 46.6s\tremaining: 12.8s\n",
      "785:\tlearn: 0.1655707\ttotal: 46.7s\tremaining: 12.7s\n",
      "786:\tlearn: 0.1655063\ttotal: 46.7s\tremaining: 12.7s\n",
      "787:\tlearn: 0.1654420\ttotal: 46.8s\tremaining: 12.6s\n",
      "788:\tlearn: 0.1653815\ttotal: 46.9s\tremaining: 12.5s\n",
      "789:\tlearn: 0.1653243\ttotal: 46.9s\tremaining: 12.5s\n",
      "790:\tlearn: 0.1652453\ttotal: 47s\tremaining: 12.4s\n",
      "791:\tlearn: 0.1652009\ttotal: 47s\tremaining: 12.4s\n",
      "792:\tlearn: 0.1651431\ttotal: 47.1s\tremaining: 12.3s\n",
      "793:\tlearn: 0.1650911\ttotal: 47.1s\tremaining: 12.2s\n",
      "794:\tlearn: 0.1650512\ttotal: 47.2s\tremaining: 12.2s\n",
      "795:\tlearn: 0.1649962\ttotal: 47.3s\tremaining: 12.1s\n",
      "796:\tlearn: 0.1649429\ttotal: 47.3s\tremaining: 12.1s\n",
      "797:\tlearn: 0.1648986\ttotal: 47.4s\tremaining: 12s\n",
      "798:\tlearn: 0.1648425\ttotal: 47.4s\tremaining: 11.9s\n",
      "799:\tlearn: 0.1647863\ttotal: 47.5s\tremaining: 11.9s\n",
      "800:\tlearn: 0.1647373\ttotal: 47.6s\tremaining: 11.8s\n",
      "801:\tlearn: 0.1646744\ttotal: 47.6s\tremaining: 11.8s\n",
      "802:\tlearn: 0.1646356\ttotal: 47.7s\tremaining: 11.7s\n",
      "803:\tlearn: 0.1645829\ttotal: 47.7s\tremaining: 11.6s\n",
      "804:\tlearn: 0.1645347\ttotal: 47.8s\tremaining: 11.6s\n",
      "805:\tlearn: 0.1644733\ttotal: 47.9s\tremaining: 11.5s\n",
      "806:\tlearn: 0.1644127\ttotal: 47.9s\tremaining: 11.5s\n",
      "807:\tlearn: 0.1643567\ttotal: 48s\tremaining: 11.4s\n",
      "808:\tlearn: 0.1643084\ttotal: 48s\tremaining: 11.3s\n",
      "809:\tlearn: 0.1642443\ttotal: 48.1s\tremaining: 11.3s\n",
      "810:\tlearn: 0.1641840\ttotal: 48.2s\tremaining: 11.2s\n",
      "811:\tlearn: 0.1641177\ttotal: 48.3s\tremaining: 11.2s\n",
      "812:\tlearn: 0.1640497\ttotal: 48.3s\tremaining: 11.1s\n",
      "813:\tlearn: 0.1639851\ttotal: 48.4s\tremaining: 11.1s\n",
      "814:\tlearn: 0.1639287\ttotal: 48.5s\tremaining: 11s\n",
      "815:\tlearn: 0.1638710\ttotal: 48.5s\tremaining: 10.9s\n",
      "816:\tlearn: 0.1638191\ttotal: 48.6s\tremaining: 10.9s\n",
      "817:\tlearn: 0.1637585\ttotal: 48.7s\tremaining: 10.8s\n",
      "818:\tlearn: 0.1637084\ttotal: 48.7s\tremaining: 10.8s\n",
      "819:\tlearn: 0.1636521\ttotal: 48.8s\tremaining: 10.7s\n",
      "820:\tlearn: 0.1635872\ttotal: 48.8s\tremaining: 10.6s\n",
      "821:\tlearn: 0.1635283\ttotal: 48.9s\tremaining: 10.6s\n",
      "822:\tlearn: 0.1634809\ttotal: 48.9s\tremaining: 10.5s\n",
      "823:\tlearn: 0.1634398\ttotal: 49s\tremaining: 10.5s\n",
      "824:\tlearn: 0.1633892\ttotal: 49.1s\tremaining: 10.4s\n",
      "825:\tlearn: 0.1633289\ttotal: 49.1s\tremaining: 10.3s\n",
      "826:\tlearn: 0.1632705\ttotal: 49.2s\tremaining: 10.3s\n",
      "827:\tlearn: 0.1632100\ttotal: 49.3s\tremaining: 10.2s\n",
      "828:\tlearn: 0.1631611\ttotal: 49.3s\tremaining: 10.2s\n",
      "829:\tlearn: 0.1630956\ttotal: 49.4s\tremaining: 10.1s\n",
      "830:\tlearn: 0.1630288\ttotal: 49.4s\tremaining: 10.1s\n",
      "831:\tlearn: 0.1629894\ttotal: 49.5s\tremaining: 10s\n",
      "832:\tlearn: 0.1629202\ttotal: 49.6s\tremaining: 9.94s\n",
      "833:\tlearn: 0.1628617\ttotal: 49.6s\tremaining: 9.88s\n",
      "834:\tlearn: 0.1628205\ttotal: 49.7s\tremaining: 9.82s\n",
      "835:\tlearn: 0.1627494\ttotal: 49.8s\tremaining: 9.77s\n",
      "836:\tlearn: 0.1626840\ttotal: 49.9s\tremaining: 9.71s\n",
      "837:\tlearn: 0.1626239\ttotal: 49.9s\tremaining: 9.65s\n",
      "838:\tlearn: 0.1625756\ttotal: 50s\tremaining: 9.6s\n",
      "839:\tlearn: 0.1625283\ttotal: 50.1s\tremaining: 9.54s\n",
      "840:\tlearn: 0.1624869\ttotal: 50.1s\tremaining: 9.48s\n",
      "841:\tlearn: 0.1624183\ttotal: 50.2s\tremaining: 9.42s\n",
      "842:\tlearn: 0.1623466\ttotal: 50.3s\tremaining: 9.37s\n",
      "843:\tlearn: 0.1622852\ttotal: 50.4s\tremaining: 9.31s\n",
      "844:\tlearn: 0.1622372\ttotal: 50.4s\tremaining: 9.25s\n",
      "845:\tlearn: 0.1621739\ttotal: 50.5s\tremaining: 9.2s\n",
      "846:\tlearn: 0.1621216\ttotal: 50.6s\tremaining: 9.14s\n",
      "847:\tlearn: 0.1620648\ttotal: 50.7s\tremaining: 9.08s\n",
      "848:\tlearn: 0.1620105\ttotal: 50.7s\tremaining: 9.02s\n",
      "849:\tlearn: 0.1619611\ttotal: 50.8s\tremaining: 8.97s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "850:\tlearn: 0.1618947\ttotal: 50.9s\tremaining: 8.91s\n",
      "851:\tlearn: 0.1618403\ttotal: 50.9s\tremaining: 8.85s\n",
      "852:\tlearn: 0.1617948\ttotal: 51s\tremaining: 8.79s\n",
      "853:\tlearn: 0.1617434\ttotal: 51.1s\tremaining: 8.73s\n",
      "854:\tlearn: 0.1616821\ttotal: 51.1s\tremaining: 8.67s\n",
      "855:\tlearn: 0.1616285\ttotal: 51.2s\tremaining: 8.61s\n",
      "856:\tlearn: 0.1615731\ttotal: 51.2s\tremaining: 8.55s\n",
      "857:\tlearn: 0.1615141\ttotal: 51.3s\tremaining: 8.49s\n",
      "858:\tlearn: 0.1614490\ttotal: 51.4s\tremaining: 8.43s\n",
      "859:\tlearn: 0.1613872\ttotal: 51.4s\tremaining: 8.38s\n",
      "860:\tlearn: 0.1613257\ttotal: 51.5s\tremaining: 8.32s\n",
      "861:\tlearn: 0.1612744\ttotal: 51.6s\tremaining: 8.26s\n",
      "862:\tlearn: 0.1612273\ttotal: 51.6s\tremaining: 8.2s\n",
      "863:\tlearn: 0.1611729\ttotal: 51.7s\tremaining: 8.14s\n",
      "864:\tlearn: 0.1611082\ttotal: 51.8s\tremaining: 8.09s\n",
      "865:\tlearn: 0.1610447\ttotal: 51.9s\tremaining: 8.03s\n",
      "866:\tlearn: 0.1609861\ttotal: 52s\tremaining: 7.97s\n",
      "867:\tlearn: 0.1609334\ttotal: 52s\tremaining: 7.91s\n",
      "868:\tlearn: 0.1608783\ttotal: 52.1s\tremaining: 7.86s\n",
      "869:\tlearn: 0.1608190\ttotal: 52.2s\tremaining: 7.8s\n",
      "870:\tlearn: 0.1607650\ttotal: 52.3s\tremaining: 7.74s\n",
      "871:\tlearn: 0.1607068\ttotal: 52.3s\tremaining: 7.68s\n",
      "872:\tlearn: 0.1606464\ttotal: 52.4s\tremaining: 7.62s\n",
      "873:\tlearn: 0.1605976\ttotal: 52.5s\tremaining: 7.56s\n",
      "874:\tlearn: 0.1605426\ttotal: 52.5s\tremaining: 7.5s\n",
      "875:\tlearn: 0.1604823\ttotal: 52.6s\tremaining: 7.45s\n",
      "876:\tlearn: 0.1604268\ttotal: 52.7s\tremaining: 7.39s\n",
      "877:\tlearn: 0.1603671\ttotal: 52.8s\tremaining: 7.33s\n",
      "878:\tlearn: 0.1603019\ttotal: 52.9s\tremaining: 7.28s\n",
      "879:\tlearn: 0.1602507\ttotal: 52.9s\tremaining: 7.22s\n",
      "880:\tlearn: 0.1601961\ttotal: 53s\tremaining: 7.16s\n",
      "881:\tlearn: 0.1601380\ttotal: 53.1s\tremaining: 7.11s\n",
      "882:\tlearn: 0.1600877\ttotal: 53.2s\tremaining: 7.05s\n",
      "883:\tlearn: 0.1600298\ttotal: 53.3s\tremaining: 6.99s\n",
      "884:\tlearn: 0.1599844\ttotal: 53.4s\tremaining: 6.93s\n",
      "885:\tlearn: 0.1599325\ttotal: 53.4s\tremaining: 6.87s\n",
      "886:\tlearn: 0.1598902\ttotal: 53.5s\tremaining: 6.81s\n",
      "887:\tlearn: 0.1598345\ttotal: 53.6s\tremaining: 6.76s\n",
      "888:\tlearn: 0.1597780\ttotal: 53.7s\tremaining: 6.7s\n",
      "889:\tlearn: 0.1597165\ttotal: 53.7s\tremaining: 6.64s\n",
      "890:\tlearn: 0.1596819\ttotal: 53.8s\tremaining: 6.58s\n",
      "891:\tlearn: 0.1596257\ttotal: 53.9s\tremaining: 6.53s\n",
      "892:\tlearn: 0.1595849\ttotal: 54s\tremaining: 6.47s\n",
      "893:\tlearn: 0.1595446\ttotal: 54.1s\tremaining: 6.41s\n",
      "894:\tlearn: 0.1594836\ttotal: 54.1s\tremaining: 6.35s\n",
      "895:\tlearn: 0.1594298\ttotal: 54.2s\tremaining: 6.29s\n",
      "896:\tlearn: 0.1593686\ttotal: 54.3s\tremaining: 6.24s\n",
      "897:\tlearn: 0.1593127\ttotal: 54.4s\tremaining: 6.18s\n",
      "898:\tlearn: 0.1592571\ttotal: 54.5s\tremaining: 6.12s\n",
      "899:\tlearn: 0.1592028\ttotal: 54.6s\tremaining: 6.07s\n",
      "900:\tlearn: 0.1591353\ttotal: 54.7s\tremaining: 6.01s\n",
      "901:\tlearn: 0.1590717\ttotal: 54.8s\tremaining: 5.95s\n",
      "902:\tlearn: 0.1590210\ttotal: 54.8s\tremaining: 5.89s\n",
      "903:\tlearn: 0.1589613\ttotal: 54.9s\tremaining: 5.83s\n",
      "904:\tlearn: 0.1589058\ttotal: 55s\tremaining: 5.77s\n",
      "905:\tlearn: 0.1588449\ttotal: 55.1s\tremaining: 5.71s\n",
      "906:\tlearn: 0.1587891\ttotal: 55.1s\tremaining: 5.65s\n",
      "907:\tlearn: 0.1587397\ttotal: 55.2s\tremaining: 5.59s\n",
      "908:\tlearn: 0.1586825\ttotal: 55.3s\tremaining: 5.54s\n",
      "909:\tlearn: 0.1586389\ttotal: 55.4s\tremaining: 5.48s\n",
      "910:\tlearn: 0.1585904\ttotal: 55.5s\tremaining: 5.42s\n",
      "911:\tlearn: 0.1585341\ttotal: 55.5s\tremaining: 5.36s\n",
      "912:\tlearn: 0.1584973\ttotal: 55.6s\tremaining: 5.3s\n",
      "913:\tlearn: 0.1584385\ttotal: 55.7s\tremaining: 5.24s\n",
      "914:\tlearn: 0.1583789\ttotal: 55.8s\tremaining: 5.18s\n",
      "915:\tlearn: 0.1583319\ttotal: 55.9s\tremaining: 5.13s\n",
      "916:\tlearn: 0.1582638\ttotal: 56s\tremaining: 5.07s\n",
      "917:\tlearn: 0.1582182\ttotal: 56s\tremaining: 5.01s\n",
      "918:\tlearn: 0.1581724\ttotal: 56.1s\tremaining: 4.95s\n",
      "919:\tlearn: 0.1581176\ttotal: 56.2s\tremaining: 4.89s\n",
      "920:\tlearn: 0.1580619\ttotal: 56.3s\tremaining: 4.83s\n",
      "921:\tlearn: 0.1579994\ttotal: 56.4s\tremaining: 4.77s\n",
      "922:\tlearn: 0.1579449\ttotal: 56.5s\tremaining: 4.71s\n",
      "923:\tlearn: 0.1578964\ttotal: 56.5s\tremaining: 4.65s\n",
      "924:\tlearn: 0.1578536\ttotal: 56.6s\tremaining: 4.59s\n",
      "925:\tlearn: 0.1577944\ttotal: 56.7s\tremaining: 4.53s\n",
      "926:\tlearn: 0.1577568\ttotal: 56.7s\tremaining: 4.47s\n",
      "927:\tlearn: 0.1577171\ttotal: 56.8s\tremaining: 4.41s\n",
      "928:\tlearn: 0.1576679\ttotal: 56.9s\tremaining: 4.35s\n",
      "929:\tlearn: 0.1576245\ttotal: 57s\tremaining: 4.29s\n",
      "930:\tlearn: 0.1575756\ttotal: 57s\tremaining: 4.23s\n",
      "931:\tlearn: 0.1575176\ttotal: 57.1s\tremaining: 4.17s\n",
      "932:\tlearn: 0.1574555\ttotal: 57.2s\tremaining: 4.11s\n",
      "933:\tlearn: 0.1574064\ttotal: 57.2s\tremaining: 4.04s\n",
      "934:\tlearn: 0.1573525\ttotal: 57.3s\tremaining: 3.98s\n",
      "935:\tlearn: 0.1572997\ttotal: 57.4s\tremaining: 3.92s\n",
      "936:\tlearn: 0.1572430\ttotal: 57.4s\tremaining: 3.86s\n",
      "937:\tlearn: 0.1572025\ttotal: 57.5s\tremaining: 3.8s\n",
      "938:\tlearn: 0.1571549\ttotal: 57.6s\tremaining: 3.74s\n",
      "939:\tlearn: 0.1571042\ttotal: 57.6s\tremaining: 3.68s\n",
      "940:\tlearn: 0.1570543\ttotal: 57.7s\tremaining: 3.62s\n",
      "941:\tlearn: 0.1569885\ttotal: 57.8s\tremaining: 3.56s\n",
      "942:\tlearn: 0.1569315\ttotal: 57.8s\tremaining: 3.5s\n",
      "943:\tlearn: 0.1568708\ttotal: 57.9s\tremaining: 3.44s\n",
      "944:\tlearn: 0.1568110\ttotal: 58s\tremaining: 3.38s\n",
      "945:\tlearn: 0.1567640\ttotal: 58.1s\tremaining: 3.31s\n",
      "946:\tlearn: 0.1567041\ttotal: 58.2s\tremaining: 3.25s\n",
      "947:\tlearn: 0.1566520\ttotal: 58.2s\tremaining: 3.19s\n",
      "948:\tlearn: 0.1566021\ttotal: 58.3s\tremaining: 3.13s\n",
      "949:\tlearn: 0.1565545\ttotal: 58.4s\tremaining: 3.07s\n",
      "950:\tlearn: 0.1564919\ttotal: 58.5s\tremaining: 3.01s\n",
      "951:\tlearn: 0.1564419\ttotal: 58.6s\tremaining: 2.95s\n",
      "952:\tlearn: 0.1563858\ttotal: 58.7s\tremaining: 2.89s\n",
      "953:\tlearn: 0.1563357\ttotal: 58.7s\tremaining: 2.83s\n",
      "954:\tlearn: 0.1562842\ttotal: 58.8s\tremaining: 2.77s\n",
      "955:\tlearn: 0.1562224\ttotal: 58.9s\tremaining: 2.71s\n",
      "956:\tlearn: 0.1561647\ttotal: 59s\tremaining: 2.65s\n",
      "957:\tlearn: 0.1561080\ttotal: 59.1s\tremaining: 2.59s\n",
      "958:\tlearn: 0.1560489\ttotal: 59.1s\tremaining: 2.53s\n",
      "959:\tlearn: 0.1560017\ttotal: 59.2s\tremaining: 2.47s\n",
      "960:\tlearn: 0.1559580\ttotal: 59.3s\tremaining: 2.4s\n",
      "961:\tlearn: 0.1558933\ttotal: 59.3s\tremaining: 2.34s\n",
      "962:\tlearn: 0.1558363\ttotal: 59.4s\tremaining: 2.28s\n",
      "963:\tlearn: 0.1557892\ttotal: 59.5s\tremaining: 2.22s\n",
      "964:\tlearn: 0.1557439\ttotal: 59.6s\tremaining: 2.16s\n",
      "965:\tlearn: 0.1557088\ttotal: 59.6s\tremaining: 2.1s\n",
      "966:\tlearn: 0.1556734\ttotal: 59.7s\tremaining: 2.04s\n",
      "967:\tlearn: 0.1556158\ttotal: 59.8s\tremaining: 1.98s\n",
      "968:\tlearn: 0.1555661\ttotal: 59.8s\tremaining: 1.91s\n",
      "969:\tlearn: 0.1555310\ttotal: 59.9s\tremaining: 1.85s\n",
      "970:\tlearn: 0.1554810\ttotal: 60s\tremaining: 1.79s\n",
      "971:\tlearn: 0.1554236\ttotal: 1m\tremaining: 1.73s\n",
      "972:\tlearn: 0.1553750\ttotal: 1m\tremaining: 1.67s\n",
      "973:\tlearn: 0.1553142\ttotal: 1m\tremaining: 1.61s\n",
      "974:\tlearn: 0.1552604\ttotal: 1m\tremaining: 1.55s\n",
      "975:\tlearn: 0.1552088\ttotal: 1m\tremaining: 1.49s\n",
      "976:\tlearn: 0.1551503\ttotal: 1m\tremaining: 1.42s\n",
      "977:\tlearn: 0.1550962\ttotal: 1m\tremaining: 1.36s\n",
      "978:\tlearn: 0.1550371\ttotal: 1m\tremaining: 1.3s\n",
      "979:\tlearn: 0.1549848\ttotal: 1m\tremaining: 1.24s\n",
      "980:\tlearn: 0.1549411\ttotal: 1m\tremaining: 1.18s\n",
      "981:\tlearn: 0.1548885\ttotal: 1m\tremaining: 1.11s\n",
      "982:\tlearn: 0.1548363\ttotal: 1m\tremaining: 1.05s\n",
      "983:\tlearn: 0.1547846\ttotal: 1m\tremaining: 991ms\n",
      "984:\tlearn: 0.1547175\ttotal: 1m 1s\tremaining: 930ms\n",
      "985:\tlearn: 0.1546680\ttotal: 1m 1s\tremaining: 868ms\n",
      "986:\tlearn: 0.1546188\ttotal: 1m 1s\tremaining: 806ms\n",
      "987:\tlearn: 0.1545685\ttotal: 1m 1s\tremaining: 744ms\n",
      "988:\tlearn: 0.1545310\ttotal: 1m 1s\tremaining: 682ms\n",
      "989:\tlearn: 0.1544797\ttotal: 1m 1s\tremaining: 620ms\n",
      "990:\tlearn: 0.1544388\ttotal: 1m 1s\tremaining: 558ms\n",
      "991:\tlearn: 0.1543925\ttotal: 1m 1s\tremaining: 496ms\n",
      "992:\tlearn: 0.1543519\ttotal: 1m 1s\tremaining: 434ms\n",
      "993:\tlearn: 0.1542969\ttotal: 1m 1s\tremaining: 372ms\n",
      "994:\tlearn: 0.1542475\ttotal: 1m 1s\tremaining: 310ms\n",
      "995:\tlearn: 0.1541684\ttotal: 1m 1s\tremaining: 248ms\n",
      "996:\tlearn: 0.1541182\ttotal: 1m 1s\tremaining: 186ms\n",
      "997:\tlearn: 0.1540578\ttotal: 1m 1s\tremaining: 124ms\n",
      "998:\tlearn: 0.1540189\ttotal: 1m 2s\tremaining: 62.1ms\n",
      "999:\tlearn: 0.1539828\ttotal: 1m 2s\tremaining: 0us\n",
      "Learning rate set to 0.09461\n",
      "0:\tlearn: 0.6142334\ttotal: 79.4ms\tremaining: 1m 19s\n",
      "1:\tlearn: 0.5524877\ttotal: 150ms\tremaining: 1m 15s\n",
      "2:\tlearn: 0.5032853\ttotal: 217ms\tremaining: 1m 12s\n",
      "3:\tlearn: 0.4642816\ttotal: 284ms\tremaining: 1m 10s\n",
      "4:\tlearn: 0.4327745\ttotal: 350ms\tremaining: 1m 9s\n",
      "5:\tlearn: 0.4077125\ttotal: 411ms\tremaining: 1m 8s\n",
      "6:\tlearn: 0.3881432\ttotal: 480ms\tremaining: 1m 8s\n",
      "7:\tlearn: 0.3724770\ttotal: 543ms\tremaining: 1m 7s\n",
      "8:\tlearn: 0.3592090\ttotal: 598ms\tremaining: 1m 5s\n",
      "9:\tlearn: 0.3483285\ttotal: 658ms\tremaining: 1m 5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10:\tlearn: 0.3397098\ttotal: 718ms\tremaining: 1m 4s\n",
      "11:\tlearn: 0.3326173\ttotal: 775ms\tremaining: 1m 3s\n",
      "12:\tlearn: 0.3263741\ttotal: 836ms\tremaining: 1m 3s\n",
      "13:\tlearn: 0.3214446\ttotal: 895ms\tremaining: 1m 3s\n",
      "14:\tlearn: 0.3170721\ttotal: 955ms\tremaining: 1m 2s\n",
      "15:\tlearn: 0.3134654\ttotal: 1s\tremaining: 1m 1s\n",
      "16:\tlearn: 0.3104490\ttotal: 1.06s\tremaining: 1m 1s\n",
      "17:\tlearn: 0.3078266\ttotal: 1.13s\tremaining: 1m 1s\n",
      "18:\tlearn: 0.3055784\ttotal: 1.2s\tremaining: 1m 2s\n",
      "19:\tlearn: 0.3033881\ttotal: 1.27s\tremaining: 1m 2s\n",
      "20:\tlearn: 0.3014284\ttotal: 1.33s\tremaining: 1m 2s\n",
      "21:\tlearn: 0.2996163\ttotal: 1.4s\tremaining: 1m 2s\n",
      "22:\tlearn: 0.2980693\ttotal: 1.46s\tremaining: 1m 2s\n",
      "23:\tlearn: 0.2966224\ttotal: 1.52s\tremaining: 1m 1s\n",
      "24:\tlearn: 0.2952576\ttotal: 1.58s\tremaining: 1m 1s\n",
      "25:\tlearn: 0.2940880\ttotal: 1.64s\tremaining: 1m 1s\n",
      "26:\tlearn: 0.2929742\ttotal: 1.7s\tremaining: 1m 1s\n",
      "27:\tlearn: 0.2918673\ttotal: 1.75s\tremaining: 1m\n",
      "28:\tlearn: 0.2907328\ttotal: 1.81s\tremaining: 1m\n",
      "29:\tlearn: 0.2896725\ttotal: 1.87s\tremaining: 1m\n",
      "30:\tlearn: 0.2887220\ttotal: 1.92s\tremaining: 60s\n",
      "31:\tlearn: 0.2877513\ttotal: 1.97s\tremaining: 59.6s\n",
      "32:\tlearn: 0.2868556\ttotal: 2.02s\tremaining: 59.2s\n",
      "33:\tlearn: 0.2859191\ttotal: 2.08s\tremaining: 59.1s\n",
      "34:\tlearn: 0.2850425\ttotal: 2.13s\tremaining: 58.9s\n",
      "35:\tlearn: 0.2841537\ttotal: 2.19s\tremaining: 58.7s\n",
      "36:\tlearn: 0.2833397\ttotal: 2.26s\tremaining: 58.8s\n",
      "37:\tlearn: 0.2824528\ttotal: 2.34s\tremaining: 59.2s\n",
      "38:\tlearn: 0.2816595\ttotal: 2.42s\tremaining: 59.6s\n",
      "39:\tlearn: 0.2809225\ttotal: 2.49s\tremaining: 59.8s\n",
      "40:\tlearn: 0.2801482\ttotal: 2.57s\tremaining: 1m\n",
      "41:\tlearn: 0.2793687\ttotal: 2.64s\tremaining: 1m\n",
      "42:\tlearn: 0.2786668\ttotal: 2.71s\tremaining: 1m\n",
      "43:\tlearn: 0.2779221\ttotal: 2.78s\tremaining: 1m\n",
      "44:\tlearn: 0.2772694\ttotal: 2.85s\tremaining: 1m\n",
      "45:\tlearn: 0.2765343\ttotal: 2.92s\tremaining: 1m\n",
      "46:\tlearn: 0.2758717\ttotal: 2.99s\tremaining: 1m\n",
      "47:\tlearn: 0.2751413\ttotal: 3.07s\tremaining: 1m\n",
      "48:\tlearn: 0.2744528\ttotal: 3.13s\tremaining: 1m\n",
      "49:\tlearn: 0.2737509\ttotal: 3.19s\tremaining: 1m\n",
      "50:\tlearn: 0.2731166\ttotal: 3.26s\tremaining: 1m\n",
      "51:\tlearn: 0.2724908\ttotal: 3.33s\tremaining: 1m\n",
      "52:\tlearn: 0.2718964\ttotal: 3.4s\tremaining: 1m\n",
      "53:\tlearn: 0.2712536\ttotal: 3.46s\tremaining: 1m\n",
      "54:\tlearn: 0.2706442\ttotal: 3.52s\tremaining: 1m\n",
      "55:\tlearn: 0.2700581\ttotal: 3.58s\tremaining: 1m\n",
      "56:\tlearn: 0.2694594\ttotal: 3.64s\tremaining: 1m\n",
      "57:\tlearn: 0.2689041\ttotal: 3.7s\tremaining: 1m\n",
      "58:\tlearn: 0.2683240\ttotal: 3.77s\tremaining: 1m\n",
      "59:\tlearn: 0.2677678\ttotal: 3.85s\tremaining: 1m\n",
      "60:\tlearn: 0.2671840\ttotal: 3.92s\tremaining: 1m\n",
      "61:\tlearn: 0.2666391\ttotal: 4s\tremaining: 1m\n",
      "62:\tlearn: 0.2661100\ttotal: 4.07s\tremaining: 1m\n",
      "63:\tlearn: 0.2655865\ttotal: 4.13s\tremaining: 1m\n",
      "64:\tlearn: 0.2651014\ttotal: 4.19s\tremaining: 1m\n",
      "65:\tlearn: 0.2645890\ttotal: 4.25s\tremaining: 1m\n",
      "66:\tlearn: 0.2640641\ttotal: 4.31s\tremaining: 1m\n",
      "67:\tlearn: 0.2635351\ttotal: 4.37s\tremaining: 59.9s\n",
      "68:\tlearn: 0.2630083\ttotal: 4.44s\tremaining: 59.9s\n",
      "69:\tlearn: 0.2625581\ttotal: 4.5s\tremaining: 59.8s\n",
      "70:\tlearn: 0.2620813\ttotal: 4.57s\tremaining: 59.8s\n",
      "71:\tlearn: 0.2615461\ttotal: 4.63s\tremaining: 59.8s\n",
      "72:\tlearn: 0.2610279\ttotal: 4.7s\tremaining: 59.6s\n",
      "73:\tlearn: 0.2605386\ttotal: 4.75s\tremaining: 59.5s\n",
      "74:\tlearn: 0.2600810\ttotal: 4.81s\tremaining: 59.3s\n",
      "75:\tlearn: 0.2596123\ttotal: 4.87s\tremaining: 59.2s\n",
      "76:\tlearn: 0.2591451\ttotal: 4.93s\tremaining: 59.1s\n",
      "77:\tlearn: 0.2586506\ttotal: 5s\tremaining: 59.1s\n",
      "78:\tlearn: 0.2582215\ttotal: 5.07s\tremaining: 59.1s\n",
      "79:\tlearn: 0.2577510\ttotal: 5.17s\tremaining: 59.4s\n",
      "80:\tlearn: 0.2573138\ttotal: 5.23s\tremaining: 59.4s\n",
      "81:\tlearn: 0.2568732\ttotal: 5.3s\tremaining: 59.4s\n",
      "82:\tlearn: 0.2564910\ttotal: 5.36s\tremaining: 59.3s\n",
      "83:\tlearn: 0.2560714\ttotal: 5.43s\tremaining: 59.3s\n",
      "84:\tlearn: 0.2556880\ttotal: 5.5s\tremaining: 59.2s\n",
      "85:\tlearn: 0.2552776\ttotal: 5.57s\tremaining: 59.2s\n",
      "86:\tlearn: 0.2548671\ttotal: 5.63s\tremaining: 59.1s\n",
      "87:\tlearn: 0.2544659\ttotal: 5.7s\tremaining: 59.1s\n",
      "88:\tlearn: 0.2540334\ttotal: 5.78s\tremaining: 59.1s\n",
      "89:\tlearn: 0.2536149\ttotal: 5.85s\tremaining: 59.1s\n",
      "90:\tlearn: 0.2532137\ttotal: 5.92s\tremaining: 59.1s\n",
      "91:\tlearn: 0.2528029\ttotal: 6s\tremaining: 59.2s\n",
      "92:\tlearn: 0.2524012\ttotal: 6.07s\tremaining: 59.2s\n",
      "93:\tlearn: 0.2519844\ttotal: 6.13s\tremaining: 59.1s\n",
      "94:\tlearn: 0.2516008\ttotal: 6.2s\tremaining: 59.1s\n",
      "95:\tlearn: 0.2511958\ttotal: 6.27s\tremaining: 59.1s\n",
      "96:\tlearn: 0.2508575\ttotal: 6.34s\tremaining: 59s\n",
      "97:\tlearn: 0.2504774\ttotal: 6.41s\tremaining: 59s\n",
      "98:\tlearn: 0.2501452\ttotal: 6.49s\tremaining: 59.1s\n",
      "99:\tlearn: 0.2497708\ttotal: 6.56s\tremaining: 59.1s\n",
      "100:\tlearn: 0.2494170\ttotal: 6.63s\tremaining: 59s\n",
      "101:\tlearn: 0.2490642\ttotal: 6.7s\tremaining: 59s\n",
      "102:\tlearn: 0.2486975\ttotal: 6.78s\tremaining: 59.1s\n",
      "103:\tlearn: 0.2483226\ttotal: 6.86s\tremaining: 59.1s\n",
      "104:\tlearn: 0.2479730\ttotal: 6.94s\tremaining: 59.1s\n",
      "105:\tlearn: 0.2476170\ttotal: 7.01s\tremaining: 59.1s\n",
      "106:\tlearn: 0.2472414\ttotal: 7.1s\tremaining: 59.2s\n",
      "107:\tlearn: 0.2468890\ttotal: 7.16s\tremaining: 59.2s\n",
      "108:\tlearn: 0.2465577\ttotal: 7.24s\tremaining: 59.2s\n",
      "109:\tlearn: 0.2462502\ttotal: 7.31s\tremaining: 59.1s\n",
      "110:\tlearn: 0.2459014\ttotal: 7.38s\tremaining: 59.1s\n",
      "111:\tlearn: 0.2455884\ttotal: 7.44s\tremaining: 59s\n",
      "112:\tlearn: 0.2452489\ttotal: 7.5s\tremaining: 58.9s\n",
      "113:\tlearn: 0.2449347\ttotal: 7.56s\tremaining: 58.7s\n",
      "114:\tlearn: 0.2446143\ttotal: 7.63s\tremaining: 58.7s\n",
      "115:\tlearn: 0.2443149\ttotal: 7.7s\tremaining: 58.6s\n",
      "116:\tlearn: 0.2440079\ttotal: 7.76s\tremaining: 58.5s\n",
      "117:\tlearn: 0.2437044\ttotal: 7.82s\tremaining: 58.4s\n",
      "118:\tlearn: 0.2434132\ttotal: 7.87s\tremaining: 58.3s\n",
      "119:\tlearn: 0.2430728\ttotal: 7.93s\tremaining: 58.2s\n",
      "120:\tlearn: 0.2427730\ttotal: 7.99s\tremaining: 58.1s\n",
      "121:\tlearn: 0.2424819\ttotal: 8.04s\tremaining: 57.9s\n",
      "122:\tlearn: 0.2422064\ttotal: 8.09s\tremaining: 57.7s\n",
      "123:\tlearn: 0.2418714\ttotal: 8.15s\tremaining: 57.6s\n",
      "124:\tlearn: 0.2415581\ttotal: 8.21s\tremaining: 57.4s\n",
      "125:\tlearn: 0.2412448\ttotal: 8.26s\tremaining: 57.3s\n",
      "126:\tlearn: 0.2409402\ttotal: 8.32s\tremaining: 57.2s\n",
      "127:\tlearn: 0.2406561\ttotal: 8.38s\tremaining: 57.1s\n",
      "128:\tlearn: 0.2403709\ttotal: 8.44s\tremaining: 57s\n",
      "129:\tlearn: 0.2400815\ttotal: 8.5s\tremaining: 56.9s\n",
      "130:\tlearn: 0.2397817\ttotal: 8.57s\tremaining: 56.9s\n",
      "131:\tlearn: 0.2394912\ttotal: 8.64s\tremaining: 56.8s\n",
      "132:\tlearn: 0.2391849\ttotal: 8.71s\tremaining: 56.8s\n",
      "133:\tlearn: 0.2388959\ttotal: 8.77s\tremaining: 56.7s\n",
      "134:\tlearn: 0.2386168\ttotal: 8.83s\tremaining: 56.6s\n",
      "135:\tlearn: 0.2383242\ttotal: 8.89s\tremaining: 56.5s\n",
      "136:\tlearn: 0.2380481\ttotal: 8.95s\tremaining: 56.4s\n",
      "137:\tlearn: 0.2377807\ttotal: 9.01s\tremaining: 56.3s\n",
      "138:\tlearn: 0.2375065\ttotal: 9.06s\tremaining: 56.1s\n",
      "139:\tlearn: 0.2372379\ttotal: 9.12s\tremaining: 56s\n",
      "140:\tlearn: 0.2369695\ttotal: 9.18s\tremaining: 55.9s\n",
      "141:\tlearn: 0.2367116\ttotal: 9.23s\tremaining: 55.8s\n",
      "142:\tlearn: 0.2364559\ttotal: 9.28s\tremaining: 55.6s\n",
      "143:\tlearn: 0.2361954\ttotal: 9.33s\tremaining: 55.5s\n",
      "144:\tlearn: 0.2359532\ttotal: 9.38s\tremaining: 55.3s\n",
      "145:\tlearn: 0.2357089\ttotal: 9.44s\tremaining: 55.2s\n",
      "146:\tlearn: 0.2353960\ttotal: 9.51s\tremaining: 55.2s\n",
      "147:\tlearn: 0.2351019\ttotal: 9.57s\tremaining: 55.1s\n",
      "148:\tlearn: 0.2348502\ttotal: 9.62s\tremaining: 55s\n",
      "149:\tlearn: 0.2345940\ttotal: 9.69s\tremaining: 54.9s\n",
      "150:\tlearn: 0.2343533\ttotal: 9.76s\tremaining: 54.9s\n",
      "151:\tlearn: 0.2340620\ttotal: 9.82s\tremaining: 54.8s\n",
      "152:\tlearn: 0.2337889\ttotal: 9.89s\tremaining: 54.8s\n",
      "153:\tlearn: 0.2335202\ttotal: 9.96s\tremaining: 54.7s\n",
      "154:\tlearn: 0.2332499\ttotal: 10s\tremaining: 54.7s\n",
      "155:\tlearn: 0.2329915\ttotal: 10.1s\tremaining: 54.6s\n",
      "156:\tlearn: 0.2327424\ttotal: 10.1s\tremaining: 54.4s\n",
      "157:\tlearn: 0.2324734\ttotal: 10.2s\tremaining: 54.4s\n",
      "158:\tlearn: 0.2322219\ttotal: 10.3s\tremaining: 54.3s\n",
      "159:\tlearn: 0.2319835\ttotal: 10.3s\tremaining: 54.2s\n",
      "160:\tlearn: 0.2317240\ttotal: 10.4s\tremaining: 54.1s\n",
      "161:\tlearn: 0.2314775\ttotal: 10.5s\tremaining: 54.1s\n",
      "162:\tlearn: 0.2312282\ttotal: 10.5s\tremaining: 54s\n",
      "163:\tlearn: 0.2309751\ttotal: 10.6s\tremaining: 54s\n",
      "164:\tlearn: 0.2307221\ttotal: 10.6s\tremaining: 53.9s\n",
      "165:\tlearn: 0.2304812\ttotal: 10.7s\tremaining: 53.9s\n",
      "166:\tlearn: 0.2302242\ttotal: 10.8s\tremaining: 53.8s\n",
      "167:\tlearn: 0.2299774\ttotal: 10.9s\tremaining: 53.8s\n",
      "168:\tlearn: 0.2297246\ttotal: 10.9s\tremaining: 53.8s\n",
      "169:\tlearn: 0.2295136\ttotal: 11s\tremaining: 53.7s\n",
      "170:\tlearn: 0.2292739\ttotal: 11.1s\tremaining: 53.7s\n",
      "171:\tlearn: 0.2290291\ttotal: 11.1s\tremaining: 53.6s\n",
      "172:\tlearn: 0.2287928\ttotal: 11.2s\tremaining: 53.5s\n",
      "173:\tlearn: 0.2285857\ttotal: 11.2s\tremaining: 53.4s\n",
      "174:\tlearn: 0.2283649\ttotal: 11.3s\tremaining: 53.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175:\tlearn: 0.2281321\ttotal: 11.4s\tremaining: 53.3s\n",
      "176:\tlearn: 0.2278982\ttotal: 11.4s\tremaining: 53.2s\n",
      "177:\tlearn: 0.2276622\ttotal: 11.5s\tremaining: 53.1s\n",
      "178:\tlearn: 0.2274420\ttotal: 11.6s\tremaining: 53s\n",
      "179:\tlearn: 0.2272125\ttotal: 11.6s\tremaining: 52.9s\n",
      "180:\tlearn: 0.2269929\ttotal: 11.7s\tremaining: 52.8s\n",
      "181:\tlearn: 0.2267810\ttotal: 11.7s\tremaining: 52.7s\n",
      "182:\tlearn: 0.2265606\ttotal: 11.8s\tremaining: 52.6s\n",
      "183:\tlearn: 0.2263300\ttotal: 11.9s\tremaining: 52.6s\n",
      "184:\tlearn: 0.2261013\ttotal: 11.9s\tremaining: 52.5s\n",
      "185:\tlearn: 0.2258910\ttotal: 12s\tremaining: 52.4s\n",
      "186:\tlearn: 0.2256639\ttotal: 12s\tremaining: 52.4s\n",
      "187:\tlearn: 0.2254421\ttotal: 12.1s\tremaining: 52.3s\n",
      "188:\tlearn: 0.2252286\ttotal: 12.2s\tremaining: 52.2s\n",
      "189:\tlearn: 0.2250043\ttotal: 12.2s\tremaining: 52.2s\n",
      "190:\tlearn: 0.2247732\ttotal: 12.3s\tremaining: 52.2s\n",
      "191:\tlearn: 0.2245719\ttotal: 12.4s\tremaining: 52.1s\n",
      "192:\tlearn: 0.2243611\ttotal: 12.4s\tremaining: 52s\n",
      "193:\tlearn: 0.2241603\ttotal: 12.5s\tremaining: 52s\n",
      "194:\tlearn: 0.2239369\ttotal: 12.6s\tremaining: 51.9s\n",
      "195:\tlearn: 0.2237317\ttotal: 12.6s\tremaining: 51.9s\n",
      "196:\tlearn: 0.2235100\ttotal: 12.7s\tremaining: 51.8s\n",
      "197:\tlearn: 0.2233069\ttotal: 12.8s\tremaining: 51.8s\n",
      "198:\tlearn: 0.2231134\ttotal: 12.8s\tremaining: 51.7s\n",
      "199:\tlearn: 0.2229065\ttotal: 12.9s\tremaining: 51.6s\n",
      "200:\tlearn: 0.2227133\ttotal: 12.9s\tremaining: 51.5s\n",
      "201:\tlearn: 0.2225127\ttotal: 13s\tremaining: 51.4s\n",
      "202:\tlearn: 0.2223051\ttotal: 13.1s\tremaining: 51.3s\n",
      "203:\tlearn: 0.2221075\ttotal: 13.1s\tremaining: 51.3s\n",
      "204:\tlearn: 0.2219028\ttotal: 13.2s\tremaining: 51.2s\n",
      "205:\tlearn: 0.2217051\ttotal: 13.3s\tremaining: 51.1s\n",
      "206:\tlearn: 0.2215131\ttotal: 13.3s\tremaining: 51s\n",
      "207:\tlearn: 0.2213334\ttotal: 13.4s\tremaining: 50.9s\n",
      "208:\tlearn: 0.2211407\ttotal: 13.4s\tremaining: 50.9s\n",
      "209:\tlearn: 0.2209470\ttotal: 13.5s\tremaining: 50.8s\n",
      "210:\tlearn: 0.2207598\ttotal: 13.6s\tremaining: 50.8s\n",
      "211:\tlearn: 0.2205532\ttotal: 13.7s\tremaining: 50.7s\n",
      "212:\tlearn: 0.2203896\ttotal: 13.7s\tremaining: 50.7s\n",
      "213:\tlearn: 0.2202050\ttotal: 13.8s\tremaining: 50.6s\n",
      "214:\tlearn: 0.2200197\ttotal: 13.8s\tremaining: 50.6s\n",
      "215:\tlearn: 0.2198439\ttotal: 13.9s\tremaining: 50.5s\n",
      "216:\tlearn: 0.2196592\ttotal: 14s\tremaining: 50.4s\n",
      "217:\tlearn: 0.2194859\ttotal: 14s\tremaining: 50.3s\n",
      "218:\tlearn: 0.2193014\ttotal: 14.1s\tremaining: 50.2s\n",
      "219:\tlearn: 0.2191124\ttotal: 14.2s\tremaining: 50.2s\n",
      "220:\tlearn: 0.2189302\ttotal: 14.2s\tremaining: 50.1s\n",
      "221:\tlearn: 0.2187419\ttotal: 14.3s\tremaining: 50.1s\n",
      "222:\tlearn: 0.2185447\ttotal: 14.4s\tremaining: 50s\n",
      "223:\tlearn: 0.2183600\ttotal: 14.4s\tremaining: 50s\n",
      "224:\tlearn: 0.2181642\ttotal: 14.5s\tremaining: 49.9s\n",
      "225:\tlearn: 0.2179803\ttotal: 14.6s\tremaining: 49.9s\n",
      "226:\tlearn: 0.2178016\ttotal: 14.6s\tremaining: 49.9s\n",
      "227:\tlearn: 0.2175913\ttotal: 14.7s\tremaining: 49.9s\n",
      "228:\tlearn: 0.2174126\ttotal: 14.8s\tremaining: 49.8s\n",
      "229:\tlearn: 0.2172461\ttotal: 14.9s\tremaining: 49.8s\n",
      "230:\tlearn: 0.2170692\ttotal: 14.9s\tremaining: 49.7s\n",
      "231:\tlearn: 0.2169029\ttotal: 15s\tremaining: 49.7s\n",
      "232:\tlearn: 0.2167356\ttotal: 15.1s\tremaining: 49.6s\n",
      "233:\tlearn: 0.2165782\ttotal: 15.1s\tremaining: 49.5s\n",
      "234:\tlearn: 0.2164103\ttotal: 15.2s\tremaining: 49.5s\n",
      "235:\tlearn: 0.2162415\ttotal: 15.3s\tremaining: 49.4s\n",
      "236:\tlearn: 0.2160551\ttotal: 15.3s\tremaining: 49.3s\n",
      "237:\tlearn: 0.2159037\ttotal: 15.4s\tremaining: 49.2s\n",
      "238:\tlearn: 0.2157343\ttotal: 15.4s\tremaining: 49.2s\n",
      "239:\tlearn: 0.2155707\ttotal: 15.5s\tremaining: 49.1s\n",
      "240:\tlearn: 0.2154113\ttotal: 15.6s\tremaining: 49s\n",
      "241:\tlearn: 0.2152412\ttotal: 15.6s\tremaining: 48.9s\n",
      "242:\tlearn: 0.2150842\ttotal: 15.7s\tremaining: 48.9s\n",
      "243:\tlearn: 0.2149123\ttotal: 15.8s\tremaining: 48.8s\n",
      "244:\tlearn: 0.2147458\ttotal: 15.8s\tremaining: 48.8s\n",
      "245:\tlearn: 0.2145807\ttotal: 15.9s\tremaining: 48.7s\n",
      "246:\tlearn: 0.2144229\ttotal: 15.9s\tremaining: 48.6s\n",
      "247:\tlearn: 0.2142529\ttotal: 16s\tremaining: 48.6s\n",
      "248:\tlearn: 0.2140845\ttotal: 16.1s\tremaining: 48.5s\n",
      "249:\tlearn: 0.2139159\ttotal: 16.2s\tremaining: 48.5s\n",
      "250:\tlearn: 0.2137572\ttotal: 16.2s\tremaining: 48.4s\n",
      "251:\tlearn: 0.2135907\ttotal: 16.3s\tremaining: 48.3s\n",
      "252:\tlearn: 0.2134499\ttotal: 16.3s\tremaining: 48.3s\n",
      "253:\tlearn: 0.2132935\ttotal: 16.4s\tremaining: 48.2s\n",
      "254:\tlearn: 0.2131441\ttotal: 16.5s\tremaining: 48.1s\n",
      "255:\tlearn: 0.2129825\ttotal: 16.5s\tremaining: 48.1s\n",
      "256:\tlearn: 0.2128318\ttotal: 16.6s\tremaining: 48s\n",
      "257:\tlearn: 0.2126774\ttotal: 16.7s\tremaining: 47.9s\n",
      "258:\tlearn: 0.2125268\ttotal: 16.7s\tremaining: 47.9s\n",
      "259:\tlearn: 0.2123657\ttotal: 16.8s\tremaining: 47.8s\n",
      "260:\tlearn: 0.2122116\ttotal: 16.9s\tremaining: 47.7s\n",
      "261:\tlearn: 0.2120495\ttotal: 16.9s\tremaining: 47.7s\n",
      "262:\tlearn: 0.2118921\ttotal: 17s\tremaining: 47.6s\n",
      "263:\tlearn: 0.2117252\ttotal: 17.1s\tremaining: 47.6s\n",
      "264:\tlearn: 0.2115700\ttotal: 17.1s\tremaining: 47.5s\n",
      "265:\tlearn: 0.2114147\ttotal: 17.2s\tremaining: 47.4s\n",
      "266:\tlearn: 0.2112740\ttotal: 17.2s\tremaining: 47.3s\n",
      "267:\tlearn: 0.2111295\ttotal: 17.3s\tremaining: 47.2s\n",
      "268:\tlearn: 0.2109621\ttotal: 17.4s\tremaining: 47.2s\n",
      "269:\tlearn: 0.2108192\ttotal: 17.4s\tremaining: 47.1s\n",
      "270:\tlearn: 0.2106626\ttotal: 17.5s\tremaining: 47s\n",
      "271:\tlearn: 0.2105124\ttotal: 17.5s\tremaining: 46.9s\n",
      "272:\tlearn: 0.2103761\ttotal: 17.6s\tremaining: 46.8s\n",
      "273:\tlearn: 0.2102157\ttotal: 17.7s\tremaining: 46.8s\n",
      "274:\tlearn: 0.2100639\ttotal: 17.7s\tremaining: 46.7s\n",
      "275:\tlearn: 0.2099186\ttotal: 17.8s\tremaining: 46.7s\n",
      "276:\tlearn: 0.2097785\ttotal: 17.8s\tremaining: 46.6s\n",
      "277:\tlearn: 0.2096333\ttotal: 17.9s\tremaining: 46.5s\n",
      "278:\tlearn: 0.2094764\ttotal: 18s\tremaining: 46.4s\n",
      "279:\tlearn: 0.2093124\ttotal: 18s\tremaining: 46.4s\n",
      "280:\tlearn: 0.2091753\ttotal: 18.1s\tremaining: 46.3s\n",
      "281:\tlearn: 0.2090466\ttotal: 18.2s\tremaining: 46.2s\n",
      "282:\tlearn: 0.2088957\ttotal: 18.2s\tremaining: 46.2s\n",
      "283:\tlearn: 0.2087573\ttotal: 18.3s\tremaining: 46.1s\n",
      "284:\tlearn: 0.2086265\ttotal: 18.3s\tremaining: 46s\n",
      "285:\tlearn: 0.2084850\ttotal: 18.4s\tremaining: 45.9s\n",
      "286:\tlearn: 0.2083450\ttotal: 18.4s\tremaining: 45.8s\n",
      "287:\tlearn: 0.2082053\ttotal: 18.5s\tremaining: 45.8s\n",
      "288:\tlearn: 0.2080630\ttotal: 18.6s\tremaining: 45.7s\n",
      "289:\tlearn: 0.2079376\ttotal: 18.6s\tremaining: 45.6s\n",
      "290:\tlearn: 0.2078082\ttotal: 18.7s\tremaining: 45.5s\n",
      "291:\tlearn: 0.2076629\ttotal: 18.8s\tremaining: 45.5s\n",
      "292:\tlearn: 0.2075248\ttotal: 18.8s\tremaining: 45.4s\n",
      "293:\tlearn: 0.2073731\ttotal: 18.9s\tremaining: 45.4s\n",
      "294:\tlearn: 0.2072324\ttotal: 19s\tremaining: 45.3s\n",
      "295:\tlearn: 0.2071036\ttotal: 19s\tremaining: 45.3s\n",
      "296:\tlearn: 0.2069609\ttotal: 19.1s\tremaining: 45.2s\n",
      "297:\tlearn: 0.2068229\ttotal: 19.2s\tremaining: 45.1s\n",
      "298:\tlearn: 0.2066848\ttotal: 19.2s\tremaining: 45.1s\n",
      "299:\tlearn: 0.2065464\ttotal: 19.3s\tremaining: 45s\n",
      "300:\tlearn: 0.2064129\ttotal: 19.3s\tremaining: 44.9s\n",
      "301:\tlearn: 0.2062957\ttotal: 19.4s\tremaining: 44.9s\n",
      "302:\tlearn: 0.2061729\ttotal: 19.5s\tremaining: 44.8s\n",
      "303:\tlearn: 0.2060276\ttotal: 19.5s\tremaining: 44.7s\n",
      "304:\tlearn: 0.2058938\ttotal: 19.6s\tremaining: 44.6s\n",
      "305:\tlearn: 0.2057562\ttotal: 19.7s\tremaining: 44.6s\n",
      "306:\tlearn: 0.2056262\ttotal: 19.7s\tremaining: 44.5s\n",
      "307:\tlearn: 0.2054899\ttotal: 19.8s\tremaining: 44.5s\n",
      "308:\tlearn: 0.2053647\ttotal: 19.9s\tremaining: 44.4s\n",
      "309:\tlearn: 0.2052300\ttotal: 19.9s\tremaining: 44.4s\n",
      "310:\tlearn: 0.2051082\ttotal: 20s\tremaining: 44.3s\n",
      "311:\tlearn: 0.2049858\ttotal: 20s\tremaining: 44.2s\n",
      "312:\tlearn: 0.2048535\ttotal: 20.1s\tremaining: 44.2s\n",
      "313:\tlearn: 0.2047318\ttotal: 20.2s\tremaining: 44.1s\n",
      "314:\tlearn: 0.2045992\ttotal: 20.3s\tremaining: 44s\n",
      "315:\tlearn: 0.2044700\ttotal: 20.3s\tremaining: 44s\n",
      "316:\tlearn: 0.2043407\ttotal: 20.4s\tremaining: 43.9s\n",
      "317:\tlearn: 0.2042122\ttotal: 20.5s\tremaining: 43.9s\n",
      "318:\tlearn: 0.2040962\ttotal: 20.5s\tremaining: 43.8s\n",
      "319:\tlearn: 0.2039497\ttotal: 20.6s\tremaining: 43.7s\n",
      "320:\tlearn: 0.2038272\ttotal: 20.6s\tremaining: 43.7s\n",
      "321:\tlearn: 0.2037085\ttotal: 20.7s\tremaining: 43.6s\n",
      "322:\tlearn: 0.2035825\ttotal: 20.8s\tremaining: 43.5s\n",
      "323:\tlearn: 0.2034619\ttotal: 20.8s\tremaining: 43.5s\n",
      "324:\tlearn: 0.2033435\ttotal: 20.9s\tremaining: 43.4s\n",
      "325:\tlearn: 0.2032321\ttotal: 21s\tremaining: 43.4s\n",
      "326:\tlearn: 0.2031062\ttotal: 21s\tremaining: 43.3s\n",
      "327:\tlearn: 0.2029848\ttotal: 21.1s\tremaining: 43.3s\n",
      "328:\tlearn: 0.2028519\ttotal: 21.2s\tremaining: 43.2s\n",
      "329:\tlearn: 0.2027193\ttotal: 21.3s\tremaining: 43.2s\n",
      "330:\tlearn: 0.2025854\ttotal: 21.3s\tremaining: 43.1s\n",
      "331:\tlearn: 0.2024594\ttotal: 21.4s\tremaining: 43s\n",
      "332:\tlearn: 0.2023348\ttotal: 21.4s\tremaining: 43s\n",
      "333:\tlearn: 0.2021976\ttotal: 21.5s\tremaining: 42.9s\n",
      "334:\tlearn: 0.2020724\ttotal: 21.6s\tremaining: 42.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "335:\tlearn: 0.2019626\ttotal: 21.7s\tremaining: 42.8s\n",
      "336:\tlearn: 0.2018387\ttotal: 21.7s\tremaining: 42.7s\n",
      "337:\tlearn: 0.2017154\ttotal: 21.8s\tremaining: 42.7s\n",
      "338:\tlearn: 0.2015928\ttotal: 21.9s\tremaining: 42.6s\n",
      "339:\tlearn: 0.2014615\ttotal: 21.9s\tremaining: 42.5s\n",
      "340:\tlearn: 0.2013358\ttotal: 22s\tremaining: 42.5s\n",
      "341:\tlearn: 0.2012132\ttotal: 22.1s\tremaining: 42.4s\n",
      "342:\tlearn: 0.2010832\ttotal: 22.1s\tremaining: 42.4s\n",
      "343:\tlearn: 0.2009546\ttotal: 22.2s\tremaining: 42.3s\n",
      "344:\tlearn: 0.2008455\ttotal: 22.3s\tremaining: 42.3s\n",
      "345:\tlearn: 0.2007301\ttotal: 22.3s\tremaining: 42.2s\n",
      "346:\tlearn: 0.2006030\ttotal: 22.4s\tremaining: 42.1s\n",
      "347:\tlearn: 0.2004875\ttotal: 22.4s\tremaining: 42s\n",
      "348:\tlearn: 0.2003666\ttotal: 22.5s\tremaining: 42s\n",
      "349:\tlearn: 0.2002399\ttotal: 22.6s\tremaining: 41.9s\n",
      "350:\tlearn: 0.2001173\ttotal: 22.7s\tremaining: 41.9s\n",
      "351:\tlearn: 0.1999943\ttotal: 22.7s\tremaining: 41.8s\n",
      "352:\tlearn: 0.1998843\ttotal: 22.8s\tremaining: 41.8s\n",
      "353:\tlearn: 0.1997859\ttotal: 22.8s\tremaining: 41.7s\n",
      "354:\tlearn: 0.1996667\ttotal: 22.9s\tremaining: 41.6s\n",
      "355:\tlearn: 0.1995439\ttotal: 23s\tremaining: 41.5s\n",
      "356:\tlearn: 0.1994267\ttotal: 23s\tremaining: 41.5s\n",
      "357:\tlearn: 0.1993090\ttotal: 23.1s\tremaining: 41.4s\n",
      "358:\tlearn: 0.1991912\ttotal: 23.1s\tremaining: 41.3s\n",
      "359:\tlearn: 0.1990651\ttotal: 23.2s\tremaining: 41.3s\n",
      "360:\tlearn: 0.1989427\ttotal: 23.3s\tremaining: 41.3s\n",
      "361:\tlearn: 0.1988118\ttotal: 23.4s\tremaining: 41.2s\n",
      "362:\tlearn: 0.1986995\ttotal: 23.4s\tremaining: 41.1s\n",
      "363:\tlearn: 0.1985883\ttotal: 23.5s\tremaining: 41.1s\n",
      "364:\tlearn: 0.1984823\ttotal: 23.6s\tremaining: 41s\n",
      "365:\tlearn: 0.1983704\ttotal: 23.6s\tremaining: 40.9s\n",
      "366:\tlearn: 0.1982627\ttotal: 23.7s\tremaining: 40.8s\n",
      "367:\tlearn: 0.1981493\ttotal: 23.7s\tremaining: 40.7s\n",
      "368:\tlearn: 0.1980479\ttotal: 23.8s\tremaining: 40.7s\n",
      "369:\tlearn: 0.1979371\ttotal: 23.8s\tremaining: 40.6s\n",
      "370:\tlearn: 0.1978179\ttotal: 23.9s\tremaining: 40.6s\n",
      "371:\tlearn: 0.1977140\ttotal: 24s\tremaining: 40.5s\n",
      "372:\tlearn: 0.1976078\ttotal: 24.1s\tremaining: 40.4s\n",
      "373:\tlearn: 0.1974891\ttotal: 24.1s\tremaining: 40.4s\n",
      "374:\tlearn: 0.1973759\ttotal: 24.2s\tremaining: 40.3s\n",
      "375:\tlearn: 0.1972594\ttotal: 24.3s\tremaining: 40.3s\n",
      "376:\tlearn: 0.1971402\ttotal: 24.3s\tremaining: 40.2s\n",
      "377:\tlearn: 0.1970368\ttotal: 24.4s\tremaining: 40.1s\n",
      "378:\tlearn: 0.1969326\ttotal: 24.4s\tremaining: 40s\n",
      "379:\tlearn: 0.1968177\ttotal: 24.5s\tremaining: 40s\n",
      "380:\tlearn: 0.1967073\ttotal: 24.6s\tremaining: 39.9s\n",
      "381:\tlearn: 0.1965959\ttotal: 24.6s\tremaining: 39.9s\n",
      "382:\tlearn: 0.1964907\ttotal: 24.7s\tremaining: 39.8s\n",
      "383:\tlearn: 0.1963836\ttotal: 24.8s\tremaining: 39.7s\n",
      "384:\tlearn: 0.1962981\ttotal: 24.8s\tremaining: 39.7s\n",
      "385:\tlearn: 0.1962091\ttotal: 24.9s\tremaining: 39.6s\n",
      "386:\tlearn: 0.1961054\ttotal: 25s\tremaining: 39.5s\n",
      "387:\tlearn: 0.1960006\ttotal: 25s\tremaining: 39.5s\n",
      "388:\tlearn: 0.1958832\ttotal: 25.1s\tremaining: 39.4s\n",
      "389:\tlearn: 0.1957902\ttotal: 25.2s\tremaining: 39.4s\n",
      "390:\tlearn: 0.1956962\ttotal: 25.2s\tremaining: 39.3s\n",
      "391:\tlearn: 0.1955947\ttotal: 25.3s\tremaining: 39.3s\n",
      "392:\tlearn: 0.1954950\ttotal: 25.4s\tremaining: 39.2s\n",
      "393:\tlearn: 0.1953910\ttotal: 25.4s\tremaining: 39.1s\n",
      "394:\tlearn: 0.1952788\ttotal: 25.5s\tremaining: 39.1s\n",
      "395:\tlearn: 0.1951733\ttotal: 25.6s\tremaining: 39s\n",
      "396:\tlearn: 0.1950730\ttotal: 25.7s\tremaining: 39s\n",
      "397:\tlearn: 0.1949670\ttotal: 25.7s\tremaining: 38.9s\n",
      "398:\tlearn: 0.1948541\ttotal: 25.8s\tremaining: 38.9s\n",
      "399:\tlearn: 0.1947608\ttotal: 25.9s\tremaining: 38.8s\n",
      "400:\tlearn: 0.1946559\ttotal: 25.9s\tremaining: 38.8s\n",
      "401:\tlearn: 0.1945499\ttotal: 26s\tremaining: 38.7s\n",
      "402:\tlearn: 0.1944436\ttotal: 26.1s\tremaining: 38.6s\n",
      "403:\tlearn: 0.1943349\ttotal: 26.1s\tremaining: 38.6s\n",
      "404:\tlearn: 0.1942364\ttotal: 26.2s\tremaining: 38.5s\n",
      "405:\tlearn: 0.1941402\ttotal: 26.3s\tremaining: 38.4s\n",
      "406:\tlearn: 0.1940386\ttotal: 26.3s\tremaining: 38.4s\n",
      "407:\tlearn: 0.1939236\ttotal: 26.4s\tremaining: 38.3s\n",
      "408:\tlearn: 0.1938212\ttotal: 26.5s\tremaining: 38.2s\n",
      "409:\tlearn: 0.1937129\ttotal: 26.5s\tremaining: 38.2s\n",
      "410:\tlearn: 0.1936073\ttotal: 26.6s\tremaining: 38.1s\n",
      "411:\tlearn: 0.1934978\ttotal: 26.7s\tremaining: 38.1s\n",
      "412:\tlearn: 0.1933942\ttotal: 26.8s\tremaining: 38s\n",
      "413:\tlearn: 0.1933064\ttotal: 26.8s\tremaining: 38s\n",
      "414:\tlearn: 0.1931973\ttotal: 26.9s\tremaining: 37.9s\n",
      "415:\tlearn: 0.1930945\ttotal: 27s\tremaining: 37.9s\n",
      "416:\tlearn: 0.1929971\ttotal: 27s\tremaining: 37.8s\n",
      "417:\tlearn: 0.1928886\ttotal: 27.1s\tremaining: 37.8s\n",
      "418:\tlearn: 0.1927939\ttotal: 27.2s\tremaining: 37.7s\n",
      "419:\tlearn: 0.1926991\ttotal: 27.2s\tremaining: 37.6s\n",
      "420:\tlearn: 0.1925948\ttotal: 27.3s\tremaining: 37.6s\n",
      "421:\tlearn: 0.1924998\ttotal: 27.4s\tremaining: 37.5s\n",
      "422:\tlearn: 0.1924020\ttotal: 27.4s\tremaining: 37.4s\n",
      "423:\tlearn: 0.1922931\ttotal: 27.5s\tremaining: 37.3s\n",
      "424:\tlearn: 0.1921988\ttotal: 27.6s\tremaining: 37.3s\n",
      "425:\tlearn: 0.1921070\ttotal: 27.6s\tremaining: 37.2s\n",
      "426:\tlearn: 0.1920064\ttotal: 27.7s\tremaining: 37.1s\n",
      "427:\tlearn: 0.1919041\ttotal: 27.8s\tremaining: 37.1s\n",
      "428:\tlearn: 0.1917880\ttotal: 27.8s\tremaining: 37s\n",
      "429:\tlearn: 0.1916900\ttotal: 27.9s\tremaining: 37s\n",
      "430:\tlearn: 0.1915908\ttotal: 28s\tremaining: 36.9s\n",
      "431:\tlearn: 0.1914924\ttotal: 28s\tremaining: 36.9s\n",
      "432:\tlearn: 0.1913966\ttotal: 28.1s\tremaining: 36.8s\n",
      "433:\tlearn: 0.1912921\ttotal: 28.2s\tremaining: 36.8s\n",
      "434:\tlearn: 0.1911984\ttotal: 28.3s\tremaining: 36.7s\n",
      "435:\tlearn: 0.1911033\ttotal: 28.3s\tremaining: 36.7s\n",
      "436:\tlearn: 0.1910114\ttotal: 28.4s\tremaining: 36.6s\n",
      "437:\tlearn: 0.1909111\ttotal: 28.5s\tremaining: 36.5s\n",
      "438:\tlearn: 0.1908125\ttotal: 28.6s\tremaining: 36.5s\n",
      "439:\tlearn: 0.1907129\ttotal: 28.6s\tremaining: 36.5s\n",
      "440:\tlearn: 0.1906201\ttotal: 28.7s\tremaining: 36.4s\n",
      "441:\tlearn: 0.1905263\ttotal: 28.8s\tremaining: 36.3s\n",
      "442:\tlearn: 0.1904337\ttotal: 28.9s\tremaining: 36.3s\n",
      "443:\tlearn: 0.1903354\ttotal: 28.9s\tremaining: 36.2s\n",
      "444:\tlearn: 0.1902536\ttotal: 29s\tremaining: 36.2s\n",
      "445:\tlearn: 0.1901562\ttotal: 29.1s\tremaining: 36.1s\n",
      "446:\tlearn: 0.1900583\ttotal: 29.1s\tremaining: 36s\n",
      "447:\tlearn: 0.1899667\ttotal: 29.2s\tremaining: 36s\n",
      "448:\tlearn: 0.1898696\ttotal: 29.3s\tremaining: 35.9s\n",
      "449:\tlearn: 0.1897757\ttotal: 29.3s\tremaining: 35.9s\n",
      "450:\tlearn: 0.1896984\ttotal: 29.4s\tremaining: 35.8s\n",
      "451:\tlearn: 0.1896046\ttotal: 29.5s\tremaining: 35.7s\n",
      "452:\tlearn: 0.1895101\ttotal: 29.5s\tremaining: 35.7s\n",
      "453:\tlearn: 0.1894135\ttotal: 29.6s\tremaining: 35.6s\n",
      "454:\tlearn: 0.1893303\ttotal: 29.7s\tremaining: 35.5s\n",
      "455:\tlearn: 0.1892422\ttotal: 29.7s\tremaining: 35.5s\n",
      "456:\tlearn: 0.1891558\ttotal: 29.8s\tremaining: 35.4s\n",
      "457:\tlearn: 0.1890684\ttotal: 29.9s\tremaining: 35.3s\n",
      "458:\tlearn: 0.1889895\ttotal: 29.9s\tremaining: 35.3s\n",
      "459:\tlearn: 0.1889045\ttotal: 30s\tremaining: 35.2s\n",
      "460:\tlearn: 0.1888138\ttotal: 30s\tremaining: 35.1s\n",
      "461:\tlearn: 0.1887143\ttotal: 30.1s\tremaining: 35.1s\n",
      "462:\tlearn: 0.1886154\ttotal: 30.2s\tremaining: 35s\n",
      "463:\tlearn: 0.1885383\ttotal: 30.2s\tremaining: 34.9s\n",
      "464:\tlearn: 0.1884413\ttotal: 30.3s\tremaining: 34.9s\n",
      "465:\tlearn: 0.1883485\ttotal: 30.4s\tremaining: 34.8s\n",
      "466:\tlearn: 0.1882625\ttotal: 30.4s\tremaining: 34.7s\n",
      "467:\tlearn: 0.1881669\ttotal: 30.5s\tremaining: 34.7s\n",
      "468:\tlearn: 0.1880784\ttotal: 30.6s\tremaining: 34.6s\n",
      "469:\tlearn: 0.1879733\ttotal: 30.6s\tremaining: 34.5s\n",
      "470:\tlearn: 0.1878825\ttotal: 30.7s\tremaining: 34.5s\n",
      "471:\tlearn: 0.1878063\ttotal: 30.7s\tremaining: 34.4s\n",
      "472:\tlearn: 0.1877142\ttotal: 30.8s\tremaining: 34.3s\n",
      "473:\tlearn: 0.1876204\ttotal: 30.9s\tremaining: 34.3s\n",
      "474:\tlearn: 0.1875296\ttotal: 30.9s\tremaining: 34.2s\n",
      "475:\tlearn: 0.1874276\ttotal: 31s\tremaining: 34.1s\n",
      "476:\tlearn: 0.1873279\ttotal: 31.1s\tremaining: 34.1s\n",
      "477:\tlearn: 0.1872430\ttotal: 31.1s\tremaining: 34s\n",
      "478:\tlearn: 0.1871492\ttotal: 31.2s\tremaining: 33.9s\n",
      "479:\tlearn: 0.1870614\ttotal: 31.3s\tremaining: 33.9s\n",
      "480:\tlearn: 0.1869722\ttotal: 31.3s\tremaining: 33.8s\n",
      "481:\tlearn: 0.1868896\ttotal: 31.4s\tremaining: 33.7s\n",
      "482:\tlearn: 0.1868047\ttotal: 31.4s\tremaining: 33.7s\n",
      "483:\tlearn: 0.1867126\ttotal: 31.5s\tremaining: 33.6s\n",
      "484:\tlearn: 0.1866338\ttotal: 31.6s\tremaining: 33.5s\n",
      "485:\tlearn: 0.1865527\ttotal: 31.6s\tremaining: 33.4s\n",
      "486:\tlearn: 0.1864657\ttotal: 31.7s\tremaining: 33.4s\n",
      "487:\tlearn: 0.1863747\ttotal: 31.7s\tremaining: 33.3s\n",
      "488:\tlearn: 0.1862726\ttotal: 31.8s\tremaining: 33.2s\n",
      "489:\tlearn: 0.1861974\ttotal: 31.8s\tremaining: 33.1s\n",
      "490:\tlearn: 0.1861107\ttotal: 31.9s\tremaining: 33.1s\n",
      "491:\tlearn: 0.1860259\ttotal: 32s\tremaining: 33s\n",
      "492:\tlearn: 0.1859512\ttotal: 32s\tremaining: 32.9s\n",
      "493:\tlearn: 0.1858612\ttotal: 32.1s\tremaining: 32.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "494:\tlearn: 0.1857770\ttotal: 32.1s\tremaining: 32.8s\n",
      "495:\tlearn: 0.1856852\ttotal: 32.2s\tremaining: 32.7s\n",
      "496:\tlearn: 0.1855945\ttotal: 32.3s\tremaining: 32.7s\n",
      "497:\tlearn: 0.1854965\ttotal: 32.3s\tremaining: 32.6s\n",
      "498:\tlearn: 0.1854222\ttotal: 32.4s\tremaining: 32.5s\n",
      "499:\tlearn: 0.1853448\ttotal: 32.5s\tremaining: 32.5s\n",
      "500:\tlearn: 0.1852622\ttotal: 32.5s\tremaining: 32.4s\n",
      "501:\tlearn: 0.1851783\ttotal: 32.6s\tremaining: 32.3s\n",
      "502:\tlearn: 0.1850925\ttotal: 32.6s\tremaining: 32.2s\n",
      "503:\tlearn: 0.1850007\ttotal: 32.7s\tremaining: 32.2s\n",
      "504:\tlearn: 0.1849141\ttotal: 32.8s\tremaining: 32.1s\n",
      "505:\tlearn: 0.1848301\ttotal: 32.8s\tremaining: 32s\n",
      "506:\tlearn: 0.1847489\ttotal: 32.9s\tremaining: 32s\n",
      "507:\tlearn: 0.1846670\ttotal: 32.9s\tremaining: 31.9s\n",
      "508:\tlearn: 0.1845854\ttotal: 33s\tremaining: 31.8s\n",
      "509:\tlearn: 0.1845042\ttotal: 33s\tremaining: 31.8s\n",
      "510:\tlearn: 0.1844337\ttotal: 33.1s\tremaining: 31.7s\n",
      "511:\tlearn: 0.1843446\ttotal: 33.2s\tremaining: 31.6s\n",
      "512:\tlearn: 0.1842481\ttotal: 33.2s\tremaining: 31.5s\n",
      "513:\tlearn: 0.1841640\ttotal: 33.3s\tremaining: 31.5s\n",
      "514:\tlearn: 0.1840859\ttotal: 33.3s\tremaining: 31.4s\n",
      "515:\tlearn: 0.1839971\ttotal: 33.4s\tremaining: 31.3s\n",
      "516:\tlearn: 0.1839223\ttotal: 33.5s\tremaining: 31.3s\n",
      "517:\tlearn: 0.1838450\ttotal: 33.5s\tremaining: 31.2s\n",
      "518:\tlearn: 0.1837720\ttotal: 33.6s\tremaining: 31.1s\n",
      "519:\tlearn: 0.1836860\ttotal: 33.6s\tremaining: 31.1s\n",
      "520:\tlearn: 0.1835969\ttotal: 33.7s\tremaining: 31s\n",
      "521:\tlearn: 0.1835138\ttotal: 33.8s\tremaining: 30.9s\n",
      "522:\tlearn: 0.1834295\ttotal: 33.8s\tremaining: 30.8s\n",
      "523:\tlearn: 0.1833556\ttotal: 33.9s\tremaining: 30.8s\n",
      "524:\tlearn: 0.1832626\ttotal: 34s\tremaining: 30.7s\n",
      "525:\tlearn: 0.1831794\ttotal: 34s\tremaining: 30.7s\n",
      "526:\tlearn: 0.1830964\ttotal: 34.1s\tremaining: 30.6s\n",
      "527:\tlearn: 0.1830103\ttotal: 34.1s\tremaining: 30.5s\n",
      "528:\tlearn: 0.1829331\ttotal: 34.2s\tremaining: 30.4s\n",
      "529:\tlearn: 0.1828544\ttotal: 34.3s\tremaining: 30.4s\n",
      "530:\tlearn: 0.1827666\ttotal: 34.3s\tremaining: 30.3s\n",
      "531:\tlearn: 0.1826889\ttotal: 34.4s\tremaining: 30.3s\n",
      "532:\tlearn: 0.1826007\ttotal: 34.5s\tremaining: 30.2s\n",
      "533:\tlearn: 0.1825283\ttotal: 34.5s\tremaining: 30.1s\n",
      "534:\tlearn: 0.1824372\ttotal: 34.6s\tremaining: 30.1s\n",
      "535:\tlearn: 0.1823536\ttotal: 34.7s\tremaining: 30s\n",
      "536:\tlearn: 0.1822717\ttotal: 34.7s\tremaining: 29.9s\n",
      "537:\tlearn: 0.1821913\ttotal: 34.8s\tremaining: 29.9s\n",
      "538:\tlearn: 0.1821158\ttotal: 34.9s\tremaining: 29.8s\n",
      "539:\tlearn: 0.1820337\ttotal: 34.9s\tremaining: 29.8s\n",
      "540:\tlearn: 0.1819484\ttotal: 35s\tremaining: 29.7s\n",
      "541:\tlearn: 0.1818740\ttotal: 35.1s\tremaining: 29.6s\n",
      "542:\tlearn: 0.1818009\ttotal: 35.1s\tremaining: 29.6s\n",
      "543:\tlearn: 0.1817136\ttotal: 35.2s\tremaining: 29.5s\n",
      "544:\tlearn: 0.1816408\ttotal: 35.2s\tremaining: 29.4s\n",
      "545:\tlearn: 0.1815570\ttotal: 35.3s\tremaining: 29.4s\n",
      "546:\tlearn: 0.1814799\ttotal: 35.4s\tremaining: 29.3s\n",
      "547:\tlearn: 0.1814040\ttotal: 35.4s\tremaining: 29.2s\n",
      "548:\tlearn: 0.1813129\ttotal: 35.5s\tremaining: 29.2s\n",
      "549:\tlearn: 0.1812347\ttotal: 35.5s\tremaining: 29.1s\n",
      "550:\tlearn: 0.1811612\ttotal: 35.6s\tremaining: 29s\n",
      "551:\tlearn: 0.1810745\ttotal: 35.7s\tremaining: 28.9s\n",
      "552:\tlearn: 0.1810077\ttotal: 35.7s\tremaining: 28.9s\n",
      "553:\tlearn: 0.1809115\ttotal: 35.8s\tremaining: 28.8s\n",
      "554:\tlearn: 0.1808364\ttotal: 35.8s\tremaining: 28.7s\n",
      "555:\tlearn: 0.1807617\ttotal: 35.9s\tremaining: 28.7s\n",
      "556:\tlearn: 0.1806730\ttotal: 36s\tremaining: 28.6s\n",
      "557:\tlearn: 0.1805866\ttotal: 36.1s\tremaining: 28.6s\n",
      "558:\tlearn: 0.1805127\ttotal: 36.1s\tremaining: 28.5s\n",
      "559:\tlearn: 0.1804435\ttotal: 36.2s\tremaining: 28.4s\n",
      "560:\tlearn: 0.1803729\ttotal: 36.2s\tremaining: 28.4s\n",
      "561:\tlearn: 0.1802973\ttotal: 36.3s\tremaining: 28.3s\n",
      "562:\tlearn: 0.1802265\ttotal: 36.4s\tremaining: 28.2s\n",
      "563:\tlearn: 0.1801645\ttotal: 36.4s\tremaining: 28.2s\n",
      "564:\tlearn: 0.1800801\ttotal: 36.5s\tremaining: 28.1s\n",
      "565:\tlearn: 0.1800063\ttotal: 36.6s\tremaining: 28s\n",
      "566:\tlearn: 0.1799356\ttotal: 36.6s\tremaining: 28s\n",
      "567:\tlearn: 0.1798595\ttotal: 36.7s\tremaining: 27.9s\n",
      "568:\tlearn: 0.1797871\ttotal: 36.7s\tremaining: 27.8s\n",
      "569:\tlearn: 0.1797103\ttotal: 36.8s\tremaining: 27.8s\n",
      "570:\tlearn: 0.1796453\ttotal: 36.9s\tremaining: 27.7s\n",
      "571:\tlearn: 0.1795674\ttotal: 37s\tremaining: 27.6s\n",
      "572:\tlearn: 0.1794951\ttotal: 37s\tremaining: 27.6s\n",
      "573:\tlearn: 0.1793971\ttotal: 37.1s\tremaining: 27.5s\n",
      "574:\tlearn: 0.1793149\ttotal: 37.2s\tremaining: 27.5s\n",
      "575:\tlearn: 0.1792397\ttotal: 37.2s\tremaining: 27.4s\n",
      "576:\tlearn: 0.1791647\ttotal: 37.3s\tremaining: 27.3s\n",
      "577:\tlearn: 0.1790773\ttotal: 37.3s\tremaining: 27.3s\n",
      "578:\tlearn: 0.1789977\ttotal: 37.4s\tremaining: 27.2s\n",
      "579:\tlearn: 0.1789174\ttotal: 37.5s\tremaining: 27.1s\n",
      "580:\tlearn: 0.1788337\ttotal: 37.5s\tremaining: 27.1s\n",
      "581:\tlearn: 0.1787563\ttotal: 37.6s\tremaining: 27s\n",
      "582:\tlearn: 0.1786839\ttotal: 37.7s\tremaining: 27s\n",
      "583:\tlearn: 0.1786104\ttotal: 37.8s\tremaining: 26.9s\n",
      "584:\tlearn: 0.1785340\ttotal: 37.8s\tremaining: 26.8s\n",
      "585:\tlearn: 0.1784628\ttotal: 37.9s\tremaining: 26.8s\n",
      "586:\tlearn: 0.1783952\ttotal: 37.9s\tremaining: 26.7s\n",
      "587:\tlearn: 0.1783135\ttotal: 38s\tremaining: 26.6s\n",
      "588:\tlearn: 0.1782284\ttotal: 38.1s\tremaining: 26.6s\n",
      "589:\tlearn: 0.1781564\ttotal: 38.1s\tremaining: 26.5s\n",
      "590:\tlearn: 0.1780790\ttotal: 38.2s\tremaining: 26.4s\n",
      "591:\tlearn: 0.1779913\ttotal: 38.3s\tremaining: 26.4s\n",
      "592:\tlearn: 0.1779211\ttotal: 38.3s\tremaining: 26.3s\n",
      "593:\tlearn: 0.1778565\ttotal: 38.4s\tremaining: 26.2s\n",
      "594:\tlearn: 0.1777856\ttotal: 38.5s\tremaining: 26.2s\n",
      "595:\tlearn: 0.1777091\ttotal: 38.5s\tremaining: 26.1s\n",
      "596:\tlearn: 0.1776408\ttotal: 38.6s\tremaining: 26s\n",
      "597:\tlearn: 0.1775620\ttotal: 38.6s\tremaining: 26s\n",
      "598:\tlearn: 0.1774844\ttotal: 38.7s\tremaining: 25.9s\n",
      "599:\tlearn: 0.1774094\ttotal: 38.8s\tremaining: 25.8s\n",
      "600:\tlearn: 0.1773473\ttotal: 38.8s\tremaining: 25.8s\n",
      "601:\tlearn: 0.1772676\ttotal: 38.9s\tremaining: 25.7s\n",
      "602:\tlearn: 0.1772023\ttotal: 38.9s\tremaining: 25.6s\n",
      "603:\tlearn: 0.1771238\ttotal: 39s\tremaining: 25.6s\n",
      "604:\tlearn: 0.1770565\ttotal: 39.1s\tremaining: 25.5s\n",
      "605:\tlearn: 0.1769792\ttotal: 39.1s\tremaining: 25.4s\n",
      "606:\tlearn: 0.1769128\ttotal: 39.2s\tremaining: 25.4s\n",
      "607:\tlearn: 0.1768365\ttotal: 39.2s\tremaining: 25.3s\n",
      "608:\tlearn: 0.1767626\ttotal: 39.3s\tremaining: 25.2s\n",
      "609:\tlearn: 0.1766841\ttotal: 39.4s\tremaining: 25.2s\n",
      "610:\tlearn: 0.1766089\ttotal: 39.4s\tremaining: 25.1s\n",
      "611:\tlearn: 0.1765445\ttotal: 39.5s\tremaining: 25s\n",
      "612:\tlearn: 0.1764680\ttotal: 39.5s\tremaining: 25s\n",
      "613:\tlearn: 0.1763901\ttotal: 39.6s\tremaining: 24.9s\n",
      "614:\tlearn: 0.1763202\ttotal: 39.7s\tremaining: 24.8s\n",
      "615:\tlearn: 0.1762604\ttotal: 39.7s\tremaining: 24.8s\n",
      "616:\tlearn: 0.1761873\ttotal: 39.8s\tremaining: 24.7s\n",
      "617:\tlearn: 0.1761233\ttotal: 39.9s\tremaining: 24.6s\n",
      "618:\tlearn: 0.1760434\ttotal: 40s\tremaining: 24.6s\n",
      "619:\tlearn: 0.1759694\ttotal: 40s\tremaining: 24.5s\n",
      "620:\tlearn: 0.1758937\ttotal: 40.1s\tremaining: 24.5s\n",
      "621:\tlearn: 0.1758429\ttotal: 40.1s\tremaining: 24.4s\n",
      "622:\tlearn: 0.1757717\ttotal: 40.2s\tremaining: 24.3s\n",
      "623:\tlearn: 0.1757061\ttotal: 40.3s\tremaining: 24.3s\n",
      "624:\tlearn: 0.1756456\ttotal: 40.3s\tremaining: 24.2s\n",
      "625:\tlearn: 0.1755847\ttotal: 40.4s\tremaining: 24.1s\n",
      "626:\tlearn: 0.1755052\ttotal: 40.4s\tremaining: 24.1s\n",
      "627:\tlearn: 0.1754428\ttotal: 40.5s\tremaining: 24s\n",
      "628:\tlearn: 0.1753831\ttotal: 40.5s\tremaining: 23.9s\n",
      "629:\tlearn: 0.1753111\ttotal: 40.6s\tremaining: 23.8s\n",
      "630:\tlearn: 0.1752439\ttotal: 40.7s\tremaining: 23.8s\n",
      "631:\tlearn: 0.1751733\ttotal: 40.7s\tremaining: 23.7s\n",
      "632:\tlearn: 0.1751044\ttotal: 40.8s\tremaining: 23.7s\n",
      "633:\tlearn: 0.1750233\ttotal: 40.9s\tremaining: 23.6s\n",
      "634:\tlearn: 0.1749422\ttotal: 40.9s\tremaining: 23.5s\n",
      "635:\tlearn: 0.1748681\ttotal: 41s\tremaining: 23.5s\n",
      "636:\tlearn: 0.1747889\ttotal: 41s\tremaining: 23.4s\n",
      "637:\tlearn: 0.1747164\ttotal: 41.1s\tremaining: 23.3s\n",
      "638:\tlearn: 0.1746381\ttotal: 41.2s\tremaining: 23.3s\n",
      "639:\tlearn: 0.1745652\ttotal: 41.2s\tremaining: 23.2s\n",
      "640:\tlearn: 0.1744935\ttotal: 41.3s\tremaining: 23.1s\n",
      "641:\tlearn: 0.1744298\ttotal: 41.4s\tremaining: 23.1s\n",
      "642:\tlearn: 0.1743696\ttotal: 41.4s\tremaining: 23s\n",
      "643:\tlearn: 0.1742987\ttotal: 41.5s\tremaining: 22.9s\n",
      "644:\tlearn: 0.1742327\ttotal: 41.6s\tremaining: 22.9s\n",
      "645:\tlearn: 0.1741603\ttotal: 41.6s\tremaining: 22.8s\n",
      "646:\tlearn: 0.1740880\ttotal: 41.7s\tremaining: 22.7s\n",
      "647:\tlearn: 0.1740232\ttotal: 41.8s\tremaining: 22.7s\n",
      "648:\tlearn: 0.1739510\ttotal: 41.8s\tremaining: 22.6s\n",
      "649:\tlearn: 0.1738794\ttotal: 41.9s\tremaining: 22.6s\n",
      "650:\tlearn: 0.1738193\ttotal: 41.9s\tremaining: 22.5s\n",
      "651:\tlearn: 0.1737569\ttotal: 42s\tremaining: 22.4s\n",
      "652:\tlearn: 0.1736958\ttotal: 42.1s\tremaining: 22.4s\n",
      "653:\tlearn: 0.1736358\ttotal: 42.1s\tremaining: 22.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "654:\tlearn: 0.1735638\ttotal: 42.2s\tremaining: 22.2s\n",
      "655:\tlearn: 0.1734942\ttotal: 42.3s\tremaining: 22.2s\n",
      "656:\tlearn: 0.1734182\ttotal: 42.3s\tremaining: 22.1s\n",
      "657:\tlearn: 0.1733528\ttotal: 42.4s\tremaining: 22s\n",
      "658:\tlearn: 0.1732856\ttotal: 42.4s\tremaining: 22s\n",
      "659:\tlearn: 0.1732177\ttotal: 42.5s\tremaining: 21.9s\n",
      "660:\tlearn: 0.1731532\ttotal: 42.6s\tremaining: 21.8s\n",
      "661:\tlearn: 0.1730783\ttotal: 42.6s\tremaining: 21.8s\n",
      "662:\tlearn: 0.1730176\ttotal: 42.7s\tremaining: 21.7s\n",
      "663:\tlearn: 0.1729451\ttotal: 42.8s\tremaining: 21.6s\n",
      "664:\tlearn: 0.1728819\ttotal: 42.8s\tremaining: 21.6s\n",
      "665:\tlearn: 0.1728155\ttotal: 42.9s\tremaining: 21.5s\n",
      "666:\tlearn: 0.1727557\ttotal: 42.9s\tremaining: 21.4s\n",
      "667:\tlearn: 0.1726818\ttotal: 43s\tremaining: 21.4s\n",
      "668:\tlearn: 0.1726241\ttotal: 43.1s\tremaining: 21.3s\n",
      "669:\tlearn: 0.1725522\ttotal: 43.1s\tremaining: 21.2s\n",
      "670:\tlearn: 0.1724823\ttotal: 43.2s\tremaining: 21.2s\n",
      "671:\tlearn: 0.1724034\ttotal: 43.3s\tremaining: 21.1s\n",
      "672:\tlearn: 0.1723364\ttotal: 43.3s\tremaining: 21.1s\n",
      "673:\tlearn: 0.1722492\ttotal: 43.4s\tremaining: 21s\n",
      "674:\tlearn: 0.1721930\ttotal: 43.5s\tremaining: 20.9s\n",
      "675:\tlearn: 0.1721154\ttotal: 43.5s\tremaining: 20.9s\n",
      "676:\tlearn: 0.1720402\ttotal: 43.6s\tremaining: 20.8s\n",
      "677:\tlearn: 0.1719773\ttotal: 43.6s\tremaining: 20.7s\n",
      "678:\tlearn: 0.1719140\ttotal: 43.7s\tremaining: 20.7s\n",
      "679:\tlearn: 0.1718475\ttotal: 43.8s\tremaining: 20.6s\n",
      "680:\tlearn: 0.1717838\ttotal: 43.8s\tremaining: 20.5s\n",
      "681:\tlearn: 0.1717225\ttotal: 43.9s\tremaining: 20.5s\n",
      "682:\tlearn: 0.1716559\ttotal: 43.9s\tremaining: 20.4s\n",
      "683:\tlearn: 0.1715989\ttotal: 44s\tremaining: 20.3s\n",
      "684:\tlearn: 0.1715237\ttotal: 44.1s\tremaining: 20.3s\n",
      "685:\tlearn: 0.1714611\ttotal: 44.1s\tremaining: 20.2s\n",
      "686:\tlearn: 0.1714027\ttotal: 44.2s\tremaining: 20.1s\n",
      "687:\tlearn: 0.1713237\ttotal: 44.2s\tremaining: 20.1s\n",
      "688:\tlearn: 0.1712564\ttotal: 44.3s\tremaining: 20s\n",
      "689:\tlearn: 0.1711774\ttotal: 44.4s\tremaining: 19.9s\n",
      "690:\tlearn: 0.1711156\ttotal: 44.4s\tremaining: 19.9s\n",
      "691:\tlearn: 0.1710459\ttotal: 44.5s\tremaining: 19.8s\n",
      "692:\tlearn: 0.1709789\ttotal: 44.6s\tremaining: 19.7s\n",
      "693:\tlearn: 0.1709140\ttotal: 44.6s\tremaining: 19.7s\n",
      "694:\tlearn: 0.1708500\ttotal: 44.7s\tremaining: 19.6s\n",
      "695:\tlearn: 0.1707957\ttotal: 44.8s\tremaining: 19.6s\n",
      "696:\tlearn: 0.1707410\ttotal: 44.8s\tremaining: 19.5s\n",
      "697:\tlearn: 0.1706747\ttotal: 44.9s\tremaining: 19.4s\n",
      "698:\tlearn: 0.1706013\ttotal: 44.9s\tremaining: 19.4s\n",
      "699:\tlearn: 0.1705437\ttotal: 45s\tremaining: 19.3s\n",
      "700:\tlearn: 0.1704835\ttotal: 45.1s\tremaining: 19.2s\n",
      "701:\tlearn: 0.1704320\ttotal: 45.2s\tremaining: 19.2s\n",
      "702:\tlearn: 0.1703670\ttotal: 45.2s\tremaining: 19.1s\n",
      "703:\tlearn: 0.1703059\ttotal: 45.3s\tremaining: 19s\n",
      "704:\tlearn: 0.1702378\ttotal: 45.4s\tremaining: 19s\n",
      "705:\tlearn: 0.1701733\ttotal: 45.4s\tremaining: 18.9s\n",
      "706:\tlearn: 0.1700988\ttotal: 45.5s\tremaining: 18.9s\n",
      "707:\tlearn: 0.1700394\ttotal: 45.5s\tremaining: 18.8s\n",
      "708:\tlearn: 0.1699926\ttotal: 45.6s\tremaining: 18.7s\n",
      "709:\tlearn: 0.1699385\ttotal: 45.7s\tremaining: 18.6s\n",
      "710:\tlearn: 0.1698776\ttotal: 45.7s\tremaining: 18.6s\n",
      "711:\tlearn: 0.1698163\ttotal: 45.8s\tremaining: 18.5s\n",
      "712:\tlearn: 0.1697543\ttotal: 45.8s\tremaining: 18.4s\n",
      "713:\tlearn: 0.1696832\ttotal: 45.9s\tremaining: 18.4s\n",
      "714:\tlearn: 0.1696301\ttotal: 46s\tremaining: 18.3s\n",
      "715:\tlearn: 0.1695725\ttotal: 46s\tremaining: 18.3s\n",
      "716:\tlearn: 0.1695174\ttotal: 46.1s\tremaining: 18.2s\n",
      "717:\tlearn: 0.1694486\ttotal: 46.1s\tremaining: 18.1s\n",
      "718:\tlearn: 0.1693818\ttotal: 46.2s\tremaining: 18.1s\n",
      "719:\tlearn: 0.1693078\ttotal: 46.3s\tremaining: 18s\n",
      "720:\tlearn: 0.1692345\ttotal: 46.3s\tremaining: 17.9s\n",
      "721:\tlearn: 0.1691787\ttotal: 46.4s\tremaining: 17.9s\n",
      "722:\tlearn: 0.1691177\ttotal: 46.5s\tremaining: 17.8s\n",
      "723:\tlearn: 0.1690574\ttotal: 46.5s\tremaining: 17.7s\n",
      "724:\tlearn: 0.1689969\ttotal: 46.6s\tremaining: 17.7s\n",
      "725:\tlearn: 0.1689375\ttotal: 46.6s\tremaining: 17.6s\n",
      "726:\tlearn: 0.1688665\ttotal: 46.7s\tremaining: 17.5s\n",
      "727:\tlearn: 0.1688120\ttotal: 46.8s\tremaining: 17.5s\n",
      "728:\tlearn: 0.1687423\ttotal: 46.8s\tremaining: 17.4s\n",
      "729:\tlearn: 0.1686798\ttotal: 46.9s\tremaining: 17.4s\n",
      "730:\tlearn: 0.1686147\ttotal: 47s\tremaining: 17.3s\n",
      "731:\tlearn: 0.1685444\ttotal: 47.1s\tremaining: 17.2s\n",
      "732:\tlearn: 0.1684779\ttotal: 47.1s\tremaining: 17.2s\n",
      "733:\tlearn: 0.1684125\ttotal: 47.2s\tremaining: 17.1s\n",
      "734:\tlearn: 0.1683575\ttotal: 47.2s\tremaining: 17s\n",
      "735:\tlearn: 0.1683013\ttotal: 47.3s\tremaining: 17s\n",
      "736:\tlearn: 0.1682368\ttotal: 47.4s\tremaining: 16.9s\n",
      "737:\tlearn: 0.1681645\ttotal: 47.4s\tremaining: 16.8s\n",
      "738:\tlearn: 0.1681040\ttotal: 47.5s\tremaining: 16.8s\n",
      "739:\tlearn: 0.1680450\ttotal: 47.5s\tremaining: 16.7s\n",
      "740:\tlearn: 0.1679945\ttotal: 47.6s\tremaining: 16.6s\n",
      "741:\tlearn: 0.1679341\ttotal: 47.7s\tremaining: 16.6s\n",
      "742:\tlearn: 0.1678758\ttotal: 47.7s\tremaining: 16.5s\n",
      "743:\tlearn: 0.1678029\ttotal: 47.8s\tremaining: 16.4s\n",
      "744:\tlearn: 0.1677454\ttotal: 47.9s\tremaining: 16.4s\n",
      "745:\tlearn: 0.1676837\ttotal: 47.9s\tremaining: 16.3s\n",
      "746:\tlearn: 0.1676281\ttotal: 48s\tremaining: 16.3s\n",
      "747:\tlearn: 0.1675627\ttotal: 48.1s\tremaining: 16.2s\n",
      "748:\tlearn: 0.1674995\ttotal: 48.1s\tremaining: 16.1s\n",
      "749:\tlearn: 0.1674448\ttotal: 48.2s\tremaining: 16.1s\n",
      "750:\tlearn: 0.1673845\ttotal: 48.3s\tremaining: 16s\n",
      "751:\tlearn: 0.1673201\ttotal: 48.3s\tremaining: 15.9s\n",
      "752:\tlearn: 0.1672562\ttotal: 48.4s\tremaining: 15.9s\n",
      "753:\tlearn: 0.1671917\ttotal: 48.5s\tremaining: 15.8s\n",
      "754:\tlearn: 0.1671350\ttotal: 48.5s\tremaining: 15.8s\n",
      "755:\tlearn: 0.1670799\ttotal: 48.6s\tremaining: 15.7s\n",
      "756:\tlearn: 0.1670225\ttotal: 48.7s\tremaining: 15.6s\n",
      "757:\tlearn: 0.1669724\ttotal: 48.7s\tremaining: 15.6s\n",
      "758:\tlearn: 0.1669128\ttotal: 48.8s\tremaining: 15.5s\n",
      "759:\tlearn: 0.1668510\ttotal: 48.9s\tremaining: 15.4s\n",
      "760:\tlearn: 0.1667798\ttotal: 49s\tremaining: 15.4s\n",
      "761:\tlearn: 0.1667237\ttotal: 49s\tremaining: 15.3s\n",
      "762:\tlearn: 0.1666538\ttotal: 49.1s\tremaining: 15.3s\n",
      "763:\tlearn: 0.1665886\ttotal: 49.2s\tremaining: 15.2s\n",
      "764:\tlearn: 0.1665256\ttotal: 49.3s\tremaining: 15.1s\n",
      "765:\tlearn: 0.1664748\ttotal: 49.3s\tremaining: 15.1s\n",
      "766:\tlearn: 0.1664182\ttotal: 49.4s\tremaining: 15s\n",
      "767:\tlearn: 0.1663537\ttotal: 49.5s\tremaining: 14.9s\n",
      "768:\tlearn: 0.1662956\ttotal: 49.5s\tremaining: 14.9s\n",
      "769:\tlearn: 0.1662484\ttotal: 49.6s\tremaining: 14.8s\n",
      "770:\tlearn: 0.1661863\ttotal: 49.7s\tremaining: 14.8s\n",
      "771:\tlearn: 0.1661302\ttotal: 49.7s\tremaining: 14.7s\n",
      "772:\tlearn: 0.1660806\ttotal: 49.8s\tremaining: 14.6s\n",
      "773:\tlearn: 0.1660209\ttotal: 49.9s\tremaining: 14.6s\n",
      "774:\tlearn: 0.1659656\ttotal: 49.9s\tremaining: 14.5s\n",
      "775:\tlearn: 0.1659058\ttotal: 50s\tremaining: 14.4s\n",
      "776:\tlearn: 0.1658406\ttotal: 50s\tremaining: 14.4s\n",
      "777:\tlearn: 0.1657872\ttotal: 50.1s\tremaining: 14.3s\n",
      "778:\tlearn: 0.1657307\ttotal: 50.1s\tremaining: 14.2s\n",
      "779:\tlearn: 0.1656681\ttotal: 50.2s\tremaining: 14.2s\n",
      "780:\tlearn: 0.1656135\ttotal: 50.3s\tremaining: 14.1s\n",
      "781:\tlearn: 0.1655542\ttotal: 50.3s\tremaining: 14s\n",
      "782:\tlearn: 0.1655081\ttotal: 50.4s\tremaining: 14s\n",
      "783:\tlearn: 0.1654531\ttotal: 50.5s\tremaining: 13.9s\n",
      "784:\tlearn: 0.1653930\ttotal: 50.5s\tremaining: 13.8s\n",
      "785:\tlearn: 0.1653344\ttotal: 50.6s\tremaining: 13.8s\n",
      "786:\tlearn: 0.1652934\ttotal: 50.6s\tremaining: 13.7s\n",
      "787:\tlearn: 0.1652291\ttotal: 50.7s\tremaining: 13.6s\n",
      "788:\tlearn: 0.1651644\ttotal: 50.8s\tremaining: 13.6s\n",
      "789:\tlearn: 0.1651158\ttotal: 50.8s\tremaining: 13.5s\n",
      "790:\tlearn: 0.1650600\ttotal: 50.9s\tremaining: 13.4s\n",
      "791:\tlearn: 0.1650079\ttotal: 51s\tremaining: 13.4s\n",
      "792:\tlearn: 0.1649448\ttotal: 51s\tremaining: 13.3s\n",
      "793:\tlearn: 0.1648954\ttotal: 51.1s\tremaining: 13.3s\n",
      "794:\tlearn: 0.1648373\ttotal: 51.2s\tremaining: 13.2s\n",
      "795:\tlearn: 0.1647729\ttotal: 51.3s\tremaining: 13.1s\n",
      "796:\tlearn: 0.1647203\ttotal: 51.3s\tremaining: 13.1s\n",
      "797:\tlearn: 0.1646696\ttotal: 51.4s\tremaining: 13s\n",
      "798:\tlearn: 0.1646003\ttotal: 51.5s\tremaining: 12.9s\n",
      "799:\tlearn: 0.1645321\ttotal: 51.5s\tremaining: 12.9s\n",
      "800:\tlearn: 0.1644803\ttotal: 51.6s\tremaining: 12.8s\n",
      "801:\tlearn: 0.1644177\ttotal: 51.7s\tremaining: 12.8s\n",
      "802:\tlearn: 0.1643527\ttotal: 51.8s\tremaining: 12.7s\n",
      "803:\tlearn: 0.1642831\ttotal: 51.8s\tremaining: 12.6s\n",
      "804:\tlearn: 0.1642329\ttotal: 51.9s\tremaining: 12.6s\n",
      "805:\tlearn: 0.1641693\ttotal: 52s\tremaining: 12.5s\n",
      "806:\tlearn: 0.1641071\ttotal: 52.1s\tremaining: 12.5s\n",
      "807:\tlearn: 0.1640494\ttotal: 52.1s\tremaining: 12.4s\n",
      "808:\tlearn: 0.1639911\ttotal: 52.2s\tremaining: 12.3s\n",
      "809:\tlearn: 0.1639392\ttotal: 52.2s\tremaining: 12.3s\n",
      "810:\tlearn: 0.1638830\ttotal: 52.3s\tremaining: 12.2s\n",
      "811:\tlearn: 0.1638098\ttotal: 52.4s\tremaining: 12.1s\n",
      "812:\tlearn: 0.1637534\ttotal: 52.4s\tremaining: 12.1s\n",
      "813:\tlearn: 0.1636893\ttotal: 52.5s\tremaining: 12s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "814:\tlearn: 0.1636271\ttotal: 52.6s\tremaining: 11.9s\n",
      "815:\tlearn: 0.1635660\ttotal: 52.6s\tremaining: 11.9s\n",
      "816:\tlearn: 0.1635126\ttotal: 52.7s\tremaining: 11.8s\n",
      "817:\tlearn: 0.1634645\ttotal: 52.8s\tremaining: 11.7s\n",
      "818:\tlearn: 0.1633992\ttotal: 52.8s\tremaining: 11.7s\n",
      "819:\tlearn: 0.1633491\ttotal: 52.9s\tremaining: 11.6s\n",
      "820:\tlearn: 0.1632866\ttotal: 53s\tremaining: 11.5s\n",
      "821:\tlearn: 0.1632349\ttotal: 53s\tremaining: 11.5s\n",
      "822:\tlearn: 0.1631817\ttotal: 53.1s\tremaining: 11.4s\n",
      "823:\tlearn: 0.1631233\ttotal: 53.2s\tremaining: 11.4s\n",
      "824:\tlearn: 0.1630641\ttotal: 53.3s\tremaining: 11.3s\n",
      "825:\tlearn: 0.1629992\ttotal: 53.4s\tremaining: 11.2s\n",
      "826:\tlearn: 0.1629401\ttotal: 53.4s\tremaining: 11.2s\n",
      "827:\tlearn: 0.1628996\ttotal: 53.5s\tremaining: 11.1s\n",
      "828:\tlearn: 0.1628552\ttotal: 53.6s\tremaining: 11.1s\n",
      "829:\tlearn: 0.1627980\ttotal: 53.7s\tremaining: 11s\n",
      "830:\tlearn: 0.1627477\ttotal: 53.7s\tremaining: 10.9s\n",
      "831:\tlearn: 0.1626955\ttotal: 53.8s\tremaining: 10.9s\n",
      "832:\tlearn: 0.1626403\ttotal: 53.9s\tremaining: 10.8s\n",
      "833:\tlearn: 0.1625847\ttotal: 53.9s\tremaining: 10.7s\n",
      "834:\tlearn: 0.1625256\ttotal: 54s\tremaining: 10.7s\n",
      "835:\tlearn: 0.1624528\ttotal: 54s\tremaining: 10.6s\n",
      "836:\tlearn: 0.1624035\ttotal: 54.1s\tremaining: 10.5s\n",
      "837:\tlearn: 0.1623363\ttotal: 54.2s\tremaining: 10.5s\n",
      "838:\tlearn: 0.1622808\ttotal: 54.2s\tremaining: 10.4s\n",
      "839:\tlearn: 0.1622384\ttotal: 54.3s\tremaining: 10.3s\n",
      "840:\tlearn: 0.1621780\ttotal: 54.3s\tremaining: 10.3s\n",
      "841:\tlearn: 0.1621249\ttotal: 54.4s\tremaining: 10.2s\n",
      "842:\tlearn: 0.1620673\ttotal: 54.5s\tremaining: 10.1s\n",
      "843:\tlearn: 0.1619979\ttotal: 54.5s\tremaining: 10.1s\n",
      "844:\tlearn: 0.1619477\ttotal: 54.6s\tremaining: 10s\n",
      "845:\tlearn: 0.1618844\ttotal: 54.7s\tremaining: 9.95s\n",
      "846:\tlearn: 0.1618301\ttotal: 54.7s\tremaining: 9.89s\n",
      "847:\tlearn: 0.1617584\ttotal: 54.8s\tremaining: 9.83s\n",
      "848:\tlearn: 0.1616975\ttotal: 54.9s\tremaining: 9.76s\n",
      "849:\tlearn: 0.1616341\ttotal: 55s\tremaining: 9.7s\n",
      "850:\tlearn: 0.1615694\ttotal: 55s\tremaining: 9.64s\n",
      "851:\tlearn: 0.1615156\ttotal: 55.1s\tremaining: 9.57s\n",
      "852:\tlearn: 0.1614569\ttotal: 55.2s\tremaining: 9.51s\n",
      "853:\tlearn: 0.1614035\ttotal: 55.2s\tremaining: 9.44s\n",
      "854:\tlearn: 0.1613378\ttotal: 55.3s\tremaining: 9.38s\n",
      "855:\tlearn: 0.1612919\ttotal: 55.4s\tremaining: 9.31s\n",
      "856:\tlearn: 0.1612375\ttotal: 55.4s\tremaining: 9.25s\n",
      "857:\tlearn: 0.1611807\ttotal: 55.5s\tremaining: 9.19s\n",
      "858:\tlearn: 0.1611222\ttotal: 55.6s\tremaining: 9.12s\n",
      "859:\tlearn: 0.1610617\ttotal: 55.6s\tremaining: 9.06s\n",
      "860:\tlearn: 0.1610067\ttotal: 55.7s\tremaining: 8.99s\n",
      "861:\tlearn: 0.1609655\ttotal: 55.8s\tremaining: 8.93s\n",
      "862:\tlearn: 0.1609048\ttotal: 55.9s\tremaining: 8.87s\n",
      "863:\tlearn: 0.1608432\ttotal: 55.9s\tremaining: 8.8s\n",
      "864:\tlearn: 0.1607884\ttotal: 56s\tremaining: 8.74s\n",
      "865:\tlearn: 0.1607314\ttotal: 56.1s\tremaining: 8.67s\n",
      "866:\tlearn: 0.1606859\ttotal: 56.1s\tremaining: 8.61s\n",
      "867:\tlearn: 0.1606327\ttotal: 56.2s\tremaining: 8.54s\n",
      "868:\tlearn: 0.1605727\ttotal: 56.3s\tremaining: 8.48s\n",
      "869:\tlearn: 0.1605141\ttotal: 56.3s\tremaining: 8.41s\n",
      "870:\tlearn: 0.1604637\ttotal: 56.4s\tremaining: 8.35s\n",
      "871:\tlearn: 0.1604117\ttotal: 56.4s\tremaining: 8.28s\n",
      "872:\tlearn: 0.1603496\ttotal: 56.5s\tremaining: 8.22s\n",
      "873:\tlearn: 0.1603021\ttotal: 56.6s\tremaining: 8.15s\n",
      "874:\tlearn: 0.1602627\ttotal: 56.6s\tremaining: 8.09s\n",
      "875:\tlearn: 0.1602062\ttotal: 56.7s\tremaining: 8.03s\n",
      "876:\tlearn: 0.1601619\ttotal: 56.7s\tremaining: 7.96s\n",
      "877:\tlearn: 0.1601069\ttotal: 56.8s\tremaining: 7.89s\n",
      "878:\tlearn: 0.1600570\ttotal: 56.9s\tremaining: 7.83s\n",
      "879:\tlearn: 0.1599935\ttotal: 56.9s\tremaining: 7.76s\n",
      "880:\tlearn: 0.1599287\ttotal: 57s\tremaining: 7.7s\n",
      "881:\tlearn: 0.1598730\ttotal: 57.1s\tremaining: 7.63s\n",
      "882:\tlearn: 0.1598251\ttotal: 57.1s\tremaining: 7.57s\n",
      "883:\tlearn: 0.1597761\ttotal: 57.2s\tremaining: 7.5s\n",
      "884:\tlearn: 0.1597099\ttotal: 57.3s\tremaining: 7.44s\n",
      "885:\tlearn: 0.1596609\ttotal: 57.3s\tremaining: 7.37s\n",
      "886:\tlearn: 0.1595987\ttotal: 57.4s\tremaining: 7.31s\n",
      "887:\tlearn: 0.1595409\ttotal: 57.4s\tremaining: 7.24s\n",
      "888:\tlearn: 0.1594841\ttotal: 57.5s\tremaining: 7.18s\n",
      "889:\tlearn: 0.1594285\ttotal: 57.5s\tremaining: 7.11s\n",
      "890:\tlearn: 0.1593692\ttotal: 57.6s\tremaining: 7.05s\n",
      "891:\tlearn: 0.1593167\ttotal: 57.7s\tremaining: 6.98s\n",
      "892:\tlearn: 0.1592647\ttotal: 57.7s\tremaining: 6.92s\n",
      "893:\tlearn: 0.1592086\ttotal: 57.8s\tremaining: 6.85s\n",
      "894:\tlearn: 0.1591613\ttotal: 57.8s\tremaining: 6.79s\n",
      "895:\tlearn: 0.1591209\ttotal: 57.9s\tremaining: 6.72s\n",
      "896:\tlearn: 0.1590705\ttotal: 58s\tremaining: 6.66s\n",
      "897:\tlearn: 0.1590215\ttotal: 58s\tremaining: 6.59s\n",
      "898:\tlearn: 0.1589645\ttotal: 58.1s\tremaining: 6.53s\n",
      "899:\tlearn: 0.1589146\ttotal: 58.2s\tremaining: 6.46s\n",
      "900:\tlearn: 0.1588516\ttotal: 58.2s\tremaining: 6.4s\n",
      "901:\tlearn: 0.1587926\ttotal: 58.3s\tremaining: 6.33s\n",
      "902:\tlearn: 0.1587570\ttotal: 58.3s\tremaining: 6.26s\n",
      "903:\tlearn: 0.1587053\ttotal: 58.4s\tremaining: 6.2s\n",
      "904:\tlearn: 0.1586555\ttotal: 58.4s\tremaining: 6.13s\n",
      "905:\tlearn: 0.1585994\ttotal: 58.5s\tremaining: 6.07s\n",
      "906:\tlearn: 0.1585333\ttotal: 58.6s\tremaining: 6.01s\n",
      "907:\tlearn: 0.1584675\ttotal: 58.6s\tremaining: 5.94s\n",
      "908:\tlearn: 0.1584172\ttotal: 58.7s\tremaining: 5.88s\n",
      "909:\tlearn: 0.1583636\ttotal: 58.8s\tremaining: 5.81s\n",
      "910:\tlearn: 0.1583115\ttotal: 58.8s\tremaining: 5.75s\n",
      "911:\tlearn: 0.1582616\ttotal: 58.9s\tremaining: 5.68s\n",
      "912:\tlearn: 0.1582081\ttotal: 59s\tremaining: 5.62s\n",
      "913:\tlearn: 0.1581589\ttotal: 59s\tremaining: 5.55s\n",
      "914:\tlearn: 0.1581067\ttotal: 59.1s\tremaining: 5.49s\n",
      "915:\tlearn: 0.1580562\ttotal: 59.2s\tremaining: 5.43s\n",
      "916:\tlearn: 0.1579978\ttotal: 59.2s\tremaining: 5.36s\n",
      "917:\tlearn: 0.1579429\ttotal: 59.3s\tremaining: 5.3s\n",
      "918:\tlearn: 0.1578935\ttotal: 59.4s\tremaining: 5.23s\n",
      "919:\tlearn: 0.1578381\ttotal: 59.4s\tremaining: 5.17s\n",
      "920:\tlearn: 0.1577870\ttotal: 59.5s\tremaining: 5.1s\n",
      "921:\tlearn: 0.1577420\ttotal: 59.6s\tremaining: 5.04s\n",
      "922:\tlearn: 0.1576951\ttotal: 59.6s\tremaining: 4.97s\n",
      "923:\tlearn: 0.1576395\ttotal: 59.7s\tremaining: 4.91s\n",
      "924:\tlearn: 0.1575901\ttotal: 59.8s\tremaining: 4.84s\n",
      "925:\tlearn: 0.1575397\ttotal: 59.8s\tremaining: 4.78s\n",
      "926:\tlearn: 0.1574891\ttotal: 59.9s\tremaining: 4.72s\n",
      "927:\tlearn: 0.1574349\ttotal: 60s\tremaining: 4.65s\n",
      "928:\tlearn: 0.1573755\ttotal: 1m\tremaining: 4.59s\n",
      "929:\tlearn: 0.1573288\ttotal: 1m\tremaining: 4.52s\n",
      "930:\tlearn: 0.1572827\ttotal: 1m\tremaining: 4.46s\n",
      "931:\tlearn: 0.1572341\ttotal: 1m\tremaining: 4.39s\n",
      "932:\tlearn: 0.1571706\ttotal: 1m\tremaining: 4.33s\n",
      "933:\tlearn: 0.1571111\ttotal: 1m\tremaining: 4.26s\n",
      "934:\tlearn: 0.1570509\ttotal: 1m\tremaining: 4.2s\n",
      "935:\tlearn: 0.1570024\ttotal: 1m\tremaining: 4.13s\n",
      "936:\tlearn: 0.1569646\ttotal: 1m\tremaining: 4.07s\n",
      "937:\tlearn: 0.1569127\ttotal: 1m\tremaining: 4s\n",
      "938:\tlearn: 0.1568729\ttotal: 1m\tremaining: 3.94s\n",
      "939:\tlearn: 0.1568113\ttotal: 1m\tremaining: 3.87s\n",
      "940:\tlearn: 0.1567533\ttotal: 1m\tremaining: 3.81s\n",
      "941:\tlearn: 0.1567083\ttotal: 1m\tremaining: 3.74s\n",
      "942:\tlearn: 0.1566632\ttotal: 1m\tremaining: 3.68s\n",
      "943:\tlearn: 0.1566096\ttotal: 1m\tremaining: 3.62s\n",
      "944:\tlearn: 0.1565676\ttotal: 1m\tremaining: 3.55s\n",
      "945:\tlearn: 0.1565259\ttotal: 1m 1s\tremaining: 3.48s\n",
      "946:\tlearn: 0.1564769\ttotal: 1m 1s\tremaining: 3.42s\n",
      "947:\tlearn: 0.1564115\ttotal: 1m 1s\tremaining: 3.36s\n",
      "948:\tlearn: 0.1563758\ttotal: 1m 1s\tremaining: 3.29s\n",
      "949:\tlearn: 0.1563142\ttotal: 1m 1s\tremaining: 3.23s\n",
      "950:\tlearn: 0.1562824\ttotal: 1m 1s\tremaining: 3.16s\n",
      "951:\tlearn: 0.1562318\ttotal: 1m 1s\tremaining: 3.1s\n",
      "952:\tlearn: 0.1561787\ttotal: 1m 1s\tremaining: 3.03s\n",
      "953:\tlearn: 0.1561300\ttotal: 1m 1s\tremaining: 2.97s\n",
      "954:\tlearn: 0.1560764\ttotal: 1m 1s\tremaining: 2.9s\n",
      "955:\tlearn: 0.1560215\ttotal: 1m 1s\tremaining: 2.84s\n",
      "956:\tlearn: 0.1559773\ttotal: 1m 1s\tremaining: 2.77s\n",
      "957:\tlearn: 0.1559246\ttotal: 1m 1s\tremaining: 2.71s\n",
      "958:\tlearn: 0.1558710\ttotal: 1m 1s\tremaining: 2.64s\n",
      "959:\tlearn: 0.1558126\ttotal: 1m 1s\tremaining: 2.58s\n",
      "960:\tlearn: 0.1557529\ttotal: 1m 1s\tremaining: 2.51s\n",
      "961:\tlearn: 0.1556994\ttotal: 1m 2s\tremaining: 2.45s\n",
      "962:\tlearn: 0.1556427\ttotal: 1m 2s\tremaining: 2.38s\n",
      "963:\tlearn: 0.1555915\ttotal: 1m 2s\tremaining: 2.32s\n",
      "964:\tlearn: 0.1555661\ttotal: 1m 2s\tremaining: 2.25s\n",
      "965:\tlearn: 0.1555132\ttotal: 1m 2s\tremaining: 2.19s\n",
      "966:\tlearn: 0.1554610\ttotal: 1m 2s\tremaining: 2.13s\n",
      "967:\tlearn: 0.1554196\ttotal: 1m 2s\tremaining: 2.06s\n",
      "968:\tlearn: 0.1553722\ttotal: 1m 2s\tremaining: 2s\n",
      "969:\tlearn: 0.1553293\ttotal: 1m 2s\tremaining: 1.93s\n",
      "970:\tlearn: 0.1552813\ttotal: 1m 2s\tremaining: 1.87s\n",
      "971:\tlearn: 0.1552355\ttotal: 1m 2s\tremaining: 1.8s\n",
      "972:\tlearn: 0.1551784\ttotal: 1m 2s\tremaining: 1.74s\n",
      "973:\tlearn: 0.1551278\ttotal: 1m 2s\tremaining: 1.68s\n",
      "974:\tlearn: 0.1550713\ttotal: 1m 2s\tremaining: 1.61s\n",
      "975:\tlearn: 0.1550079\ttotal: 1m 2s\tremaining: 1.55s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "976:\tlearn: 0.1549810\ttotal: 1m 2s\tremaining: 1.48s\n",
      "977:\tlearn: 0.1549357\ttotal: 1m 2s\tremaining: 1.42s\n",
      "978:\tlearn: 0.1548865\ttotal: 1m 3s\tremaining: 1.35s\n",
      "979:\tlearn: 0.1548251\ttotal: 1m 3s\tremaining: 1.29s\n",
      "980:\tlearn: 0.1547766\ttotal: 1m 3s\tremaining: 1.22s\n",
      "981:\tlearn: 0.1547181\ttotal: 1m 3s\tremaining: 1.16s\n",
      "982:\tlearn: 0.1546829\ttotal: 1m 3s\tremaining: 1.09s\n",
      "983:\tlearn: 0.1546291\ttotal: 1m 3s\tremaining: 1.03s\n",
      "984:\tlearn: 0.1545723\ttotal: 1m 3s\tremaining: 966ms\n",
      "985:\tlearn: 0.1545153\ttotal: 1m 3s\tremaining: 902ms\n",
      "986:\tlearn: 0.1544633\ttotal: 1m 3s\tremaining: 837ms\n",
      "987:\tlearn: 0.1544081\ttotal: 1m 3s\tremaining: 773ms\n",
      "988:\tlearn: 0.1543522\ttotal: 1m 3s\tremaining: 708ms\n",
      "989:\tlearn: 0.1542989\ttotal: 1m 3s\tremaining: 644ms\n",
      "990:\tlearn: 0.1542636\ttotal: 1m 3s\tremaining: 579ms\n",
      "991:\tlearn: 0.1542063\ttotal: 1m 3s\tremaining: 515ms\n",
      "992:\tlearn: 0.1541537\ttotal: 1m 3s\tremaining: 450ms\n",
      "993:\tlearn: 0.1541034\ttotal: 1m 3s\tremaining: 386ms\n",
      "994:\tlearn: 0.1540558\ttotal: 1m 4s\tremaining: 322ms\n",
      "995:\tlearn: 0.1540127\ttotal: 1m 4s\tremaining: 257ms\n",
      "996:\tlearn: 0.1539674\ttotal: 1m 4s\tremaining: 193ms\n",
      "997:\tlearn: 0.1539179\ttotal: 1m 4s\tremaining: 129ms\n",
      "998:\tlearn: 0.1538627\ttotal: 1m 4s\tremaining: 64.3ms\n",
      "999:\tlearn: 0.1538022\ttotal: 1m 4s\tremaining: 0us\n",
      "Learning rate set to 0.09461\n",
      "0:\tlearn: 0.6142106\ttotal: 66.3ms\tremaining: 1m 6s\n",
      "1:\tlearn: 0.5503593\ttotal: 127ms\tremaining: 1m 3s\n",
      "2:\tlearn: 0.5016414\ttotal: 200ms\tremaining: 1m 6s\n",
      "3:\tlearn: 0.4635983\ttotal: 276ms\tremaining: 1m 8s\n",
      "4:\tlearn: 0.4323521\ttotal: 363ms\tremaining: 1m 12s\n",
      "5:\tlearn: 0.4071579\ttotal: 426ms\tremaining: 1m 10s\n",
      "6:\tlearn: 0.3869257\ttotal: 492ms\tremaining: 1m 9s\n",
      "7:\tlearn: 0.3706220\ttotal: 544ms\tremaining: 1m 7s\n",
      "8:\tlearn: 0.3580557\ttotal: 605ms\tremaining: 1m 6s\n",
      "9:\tlearn: 0.3478936\ttotal: 666ms\tremaining: 1m 5s\n",
      "10:\tlearn: 0.3398044\ttotal: 725ms\tremaining: 1m 5s\n",
      "11:\tlearn: 0.3323240\ttotal: 782ms\tremaining: 1m 4s\n",
      "12:\tlearn: 0.3266413\ttotal: 836ms\tremaining: 1m 3s\n",
      "13:\tlearn: 0.3215702\ttotal: 895ms\tremaining: 1m 3s\n",
      "14:\tlearn: 0.3172699\ttotal: 952ms\tremaining: 1m 2s\n",
      "15:\tlearn: 0.3136854\ttotal: 1s\tremaining: 1m 1s\n",
      "16:\tlearn: 0.3106193\ttotal: 1.06s\tremaining: 1m 1s\n",
      "17:\tlearn: 0.3079194\ttotal: 1.11s\tremaining: 1m\n",
      "18:\tlearn: 0.3055530\ttotal: 1.17s\tremaining: 1m\n",
      "19:\tlearn: 0.3034593\ttotal: 1.22s\tremaining: 59.8s\n",
      "20:\tlearn: 0.3014763\ttotal: 1.27s\tremaining: 59.4s\n",
      "21:\tlearn: 0.2997141\ttotal: 1.33s\tremaining: 59.1s\n",
      "22:\tlearn: 0.2981475\ttotal: 1.38s\tremaining: 58.8s\n",
      "23:\tlearn: 0.2967550\ttotal: 1.44s\tremaining: 58.4s\n",
      "24:\tlearn: 0.2953337\ttotal: 1.49s\tremaining: 58.2s\n",
      "25:\tlearn: 0.2940718\ttotal: 1.55s\tremaining: 58s\n",
      "26:\tlearn: 0.2929748\ttotal: 1.6s\tremaining: 57.7s\n",
      "27:\tlearn: 0.2918610\ttotal: 1.65s\tremaining: 57.4s\n",
      "28:\tlearn: 0.2908203\ttotal: 1.71s\tremaining: 57.2s\n",
      "29:\tlearn: 0.2897875\ttotal: 1.76s\tremaining: 57s\n",
      "30:\tlearn: 0.2887220\ttotal: 1.82s\tremaining: 56.9s\n",
      "31:\tlearn: 0.2878207\ttotal: 1.87s\tremaining: 56.7s\n",
      "32:\tlearn: 0.2869386\ttotal: 1.93s\tremaining: 56.5s\n",
      "33:\tlearn: 0.2860294\ttotal: 1.98s\tremaining: 56.4s\n",
      "34:\tlearn: 0.2851861\ttotal: 2.04s\tremaining: 56.4s\n",
      "35:\tlearn: 0.2843770\ttotal: 2.1s\tremaining: 56.3s\n",
      "36:\tlearn: 0.2835453\ttotal: 2.16s\tremaining: 56.1s\n",
      "37:\tlearn: 0.2827093\ttotal: 2.21s\tremaining: 56.1s\n",
      "38:\tlearn: 0.2819376\ttotal: 2.27s\tremaining: 56s\n",
      "39:\tlearn: 0.2812234\ttotal: 2.33s\tremaining: 55.9s\n",
      "40:\tlearn: 0.2804657\ttotal: 2.39s\tremaining: 55.8s\n",
      "41:\tlearn: 0.2797146\ttotal: 2.44s\tremaining: 55.8s\n",
      "42:\tlearn: 0.2790130\ttotal: 2.5s\tremaining: 55.6s\n",
      "43:\tlearn: 0.2782983\ttotal: 2.55s\tremaining: 55.5s\n",
      "44:\tlearn: 0.2775470\ttotal: 2.61s\tremaining: 55.5s\n",
      "45:\tlearn: 0.2768395\ttotal: 2.68s\tremaining: 55.6s\n",
      "46:\tlearn: 0.2761443\ttotal: 2.74s\tremaining: 55.6s\n",
      "47:\tlearn: 0.2754721\ttotal: 2.81s\tremaining: 55.7s\n",
      "48:\tlearn: 0.2747809\ttotal: 2.88s\tremaining: 55.9s\n",
      "49:\tlearn: 0.2740879\ttotal: 2.95s\tremaining: 56s\n",
      "50:\tlearn: 0.2734506\ttotal: 3s\tremaining: 55.9s\n",
      "51:\tlearn: 0.2728695\ttotal: 3.07s\tremaining: 56s\n",
      "52:\tlearn: 0.2722821\ttotal: 3.15s\tremaining: 56.2s\n",
      "53:\tlearn: 0.2716510\ttotal: 3.22s\tremaining: 56.4s\n",
      "54:\tlearn: 0.2710480\ttotal: 3.29s\tremaining: 56.6s\n",
      "55:\tlearn: 0.2704608\ttotal: 3.36s\tremaining: 56.7s\n",
      "56:\tlearn: 0.2698776\ttotal: 3.43s\tremaining: 56.8s\n",
      "57:\tlearn: 0.2692914\ttotal: 3.5s\tremaining: 56.9s\n",
      "58:\tlearn: 0.2686843\ttotal: 3.57s\tremaining: 57s\n",
      "59:\tlearn: 0.2680956\ttotal: 3.64s\tremaining: 57s\n",
      "60:\tlearn: 0.2674944\ttotal: 3.71s\tremaining: 57s\n",
      "61:\tlearn: 0.2669119\ttotal: 3.77s\tremaining: 57s\n",
      "62:\tlearn: 0.2663836\ttotal: 3.83s\tremaining: 56.9s\n",
      "63:\tlearn: 0.2658664\ttotal: 3.88s\tremaining: 56.8s\n",
      "64:\tlearn: 0.2653414\ttotal: 3.94s\tremaining: 56.7s\n",
      "65:\tlearn: 0.2647667\ttotal: 4s\tremaining: 56.6s\n",
      "66:\tlearn: 0.2642270\ttotal: 4.05s\tremaining: 56.4s\n",
      "67:\tlearn: 0.2637081\ttotal: 4.11s\tremaining: 56.3s\n",
      "68:\tlearn: 0.2631916\ttotal: 4.17s\tremaining: 56.3s\n",
      "69:\tlearn: 0.2626943\ttotal: 4.24s\tremaining: 56.3s\n",
      "70:\tlearn: 0.2622151\ttotal: 4.29s\tremaining: 56.2s\n",
      "71:\tlearn: 0.2617285\ttotal: 4.35s\tremaining: 56s\n",
      "72:\tlearn: 0.2612517\ttotal: 4.41s\tremaining: 56s\n",
      "73:\tlearn: 0.2607844\ttotal: 4.47s\tremaining: 56s\n",
      "74:\tlearn: 0.2603136\ttotal: 4.53s\tremaining: 55.9s\n",
      "75:\tlearn: 0.2598554\ttotal: 4.6s\tremaining: 55.9s\n",
      "76:\tlearn: 0.2594444\ttotal: 4.66s\tremaining: 55.9s\n",
      "77:\tlearn: 0.2589939\ttotal: 4.72s\tremaining: 55.8s\n",
      "78:\tlearn: 0.2585493\ttotal: 4.78s\tremaining: 55.7s\n",
      "79:\tlearn: 0.2580859\ttotal: 4.85s\tremaining: 55.8s\n",
      "80:\tlearn: 0.2576066\ttotal: 4.92s\tremaining: 55.8s\n",
      "81:\tlearn: 0.2571890\ttotal: 4.99s\tremaining: 55.9s\n",
      "82:\tlearn: 0.2567571\ttotal: 5.06s\tremaining: 55.9s\n",
      "83:\tlearn: 0.2563445\ttotal: 5.12s\tremaining: 55.8s\n",
      "84:\tlearn: 0.2559205\ttotal: 5.18s\tremaining: 55.8s\n",
      "85:\tlearn: 0.2555017\ttotal: 5.24s\tremaining: 55.7s\n",
      "86:\tlearn: 0.2550886\ttotal: 5.3s\tremaining: 55.6s\n",
      "87:\tlearn: 0.2546959\ttotal: 5.36s\tremaining: 55.5s\n",
      "88:\tlearn: 0.2542747\ttotal: 5.41s\tremaining: 55.4s\n",
      "89:\tlearn: 0.2538927\ttotal: 5.46s\tremaining: 55.3s\n",
      "90:\tlearn: 0.2535334\ttotal: 5.53s\tremaining: 55.2s\n",
      "91:\tlearn: 0.2531593\ttotal: 5.59s\tremaining: 55.2s\n",
      "92:\tlearn: 0.2527721\ttotal: 5.66s\tremaining: 55.2s\n",
      "93:\tlearn: 0.2523730\ttotal: 5.72s\tremaining: 55.2s\n",
      "94:\tlearn: 0.2520045\ttotal: 5.78s\tremaining: 55.1s\n",
      "95:\tlearn: 0.2515891\ttotal: 5.84s\tremaining: 55s\n",
      "96:\tlearn: 0.2512227\ttotal: 5.9s\tremaining: 54.9s\n",
      "97:\tlearn: 0.2508702\ttotal: 5.96s\tremaining: 54.9s\n",
      "98:\tlearn: 0.2505036\ttotal: 6.02s\tremaining: 54.8s\n",
      "99:\tlearn: 0.2501636\ttotal: 6.07s\tremaining: 54.6s\n",
      "100:\tlearn: 0.2497986\ttotal: 6.13s\tremaining: 54.5s\n",
      "101:\tlearn: 0.2494462\ttotal: 6.18s\tremaining: 54.4s\n",
      "102:\tlearn: 0.2490932\ttotal: 6.24s\tremaining: 54.4s\n",
      "103:\tlearn: 0.2487216\ttotal: 6.31s\tremaining: 54.3s\n",
      "104:\tlearn: 0.2483927\ttotal: 6.36s\tremaining: 54.2s\n",
      "105:\tlearn: 0.2480529\ttotal: 6.44s\tremaining: 54.3s\n",
      "106:\tlearn: 0.2476916\ttotal: 6.5s\tremaining: 54.2s\n",
      "107:\tlearn: 0.2473469\ttotal: 6.57s\tremaining: 54.3s\n",
      "108:\tlearn: 0.2470265\ttotal: 6.64s\tremaining: 54.3s\n",
      "109:\tlearn: 0.2466942\ttotal: 6.7s\tremaining: 54.2s\n",
      "110:\tlearn: 0.2463758\ttotal: 6.75s\tremaining: 54.1s\n",
      "111:\tlearn: 0.2460328\ttotal: 6.81s\tremaining: 54s\n",
      "112:\tlearn: 0.2456753\ttotal: 6.87s\tremaining: 53.9s\n",
      "113:\tlearn: 0.2453424\ttotal: 6.94s\tremaining: 54s\n",
      "114:\tlearn: 0.2450055\ttotal: 7s\tremaining: 53.9s\n",
      "115:\tlearn: 0.2446562\ttotal: 7.08s\tremaining: 53.9s\n",
      "116:\tlearn: 0.2443164\ttotal: 7.15s\tremaining: 54s\n",
      "117:\tlearn: 0.2439945\ttotal: 7.21s\tremaining: 53.9s\n",
      "118:\tlearn: 0.2436873\ttotal: 7.27s\tremaining: 53.8s\n",
      "119:\tlearn: 0.2433919\ttotal: 7.33s\tremaining: 53.7s\n",
      "120:\tlearn: 0.2431054\ttotal: 7.39s\tremaining: 53.7s\n",
      "121:\tlearn: 0.2427833\ttotal: 7.45s\tremaining: 53.6s\n",
      "122:\tlearn: 0.2424691\ttotal: 7.52s\tremaining: 53.6s\n",
      "123:\tlearn: 0.2421726\ttotal: 7.58s\tremaining: 53.6s\n",
      "124:\tlearn: 0.2418940\ttotal: 7.64s\tremaining: 53.5s\n",
      "125:\tlearn: 0.2416031\ttotal: 7.71s\tremaining: 53.5s\n",
      "126:\tlearn: 0.2412822\ttotal: 7.77s\tremaining: 53.4s\n",
      "127:\tlearn: 0.2409748\ttotal: 7.82s\tremaining: 53.3s\n",
      "128:\tlearn: 0.2406653\ttotal: 7.89s\tremaining: 53.3s\n",
      "129:\tlearn: 0.2403727\ttotal: 7.95s\tremaining: 53.2s\n",
      "130:\tlearn: 0.2400924\ttotal: 8s\tremaining: 53.1s\n",
      "131:\tlearn: 0.2398047\ttotal: 8.06s\tremaining: 53s\n",
      "132:\tlearn: 0.2395132\ttotal: 8.12s\tremaining: 52.9s\n",
      "133:\tlearn: 0.2392111\ttotal: 8.19s\tremaining: 52.9s\n",
      "134:\tlearn: 0.2389358\ttotal: 8.24s\tremaining: 52.8s\n",
      "135:\tlearn: 0.2386643\ttotal: 8.29s\tremaining: 52.7s\n",
      "136:\tlearn: 0.2383905\ttotal: 8.34s\tremaining: 52.6s\n",
      "137:\tlearn: 0.2381149\ttotal: 8.4s\tremaining: 52.5s\n",
      "138:\tlearn: 0.2378388\ttotal: 8.46s\tremaining: 52.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139:\tlearn: 0.2375535\ttotal: 8.53s\tremaining: 52.4s\n",
      "140:\tlearn: 0.2372848\ttotal: 8.59s\tremaining: 52.3s\n",
      "141:\tlearn: 0.2369929\ttotal: 8.65s\tremaining: 52.3s\n",
      "142:\tlearn: 0.2367260\ttotal: 8.71s\tremaining: 52.2s\n",
      "143:\tlearn: 0.2364537\ttotal: 8.77s\tremaining: 52.1s\n",
      "144:\tlearn: 0.2361771\ttotal: 8.82s\tremaining: 52s\n",
      "145:\tlearn: 0.2358962\ttotal: 8.88s\tremaining: 52s\n",
      "146:\tlearn: 0.2356184\ttotal: 8.94s\tremaining: 51.9s\n",
      "147:\tlearn: 0.2353631\ttotal: 8.99s\tremaining: 51.8s\n",
      "148:\tlearn: 0.2350748\ttotal: 9.06s\tremaining: 51.7s\n",
      "149:\tlearn: 0.2348225\ttotal: 9.11s\tremaining: 51.7s\n",
      "150:\tlearn: 0.2345214\ttotal: 9.18s\tremaining: 51.6s\n",
      "151:\tlearn: 0.2342466\ttotal: 9.25s\tremaining: 51.6s\n",
      "152:\tlearn: 0.2339902\ttotal: 9.31s\tremaining: 51.5s\n",
      "153:\tlearn: 0.2337291\ttotal: 9.37s\tremaining: 51.5s\n",
      "154:\tlearn: 0.2334484\ttotal: 9.43s\tremaining: 51.4s\n",
      "155:\tlearn: 0.2331990\ttotal: 9.48s\tremaining: 51.3s\n",
      "156:\tlearn: 0.2329555\ttotal: 9.54s\tremaining: 51.2s\n",
      "157:\tlearn: 0.2326889\ttotal: 9.6s\tremaining: 51.1s\n",
      "158:\tlearn: 0.2324456\ttotal: 9.65s\tremaining: 51.1s\n",
      "159:\tlearn: 0.2321926\ttotal: 9.71s\tremaining: 51s\n",
      "160:\tlearn: 0.2319230\ttotal: 9.77s\tremaining: 50.9s\n",
      "161:\tlearn: 0.2316811\ttotal: 9.82s\tremaining: 50.8s\n",
      "162:\tlearn: 0.2314338\ttotal: 9.88s\tremaining: 50.7s\n",
      "163:\tlearn: 0.2311966\ttotal: 9.93s\tremaining: 50.6s\n",
      "164:\tlearn: 0.2309596\ttotal: 9.98s\tremaining: 50.5s\n",
      "165:\tlearn: 0.2307099\ttotal: 10s\tremaining: 50.5s\n",
      "166:\tlearn: 0.2304754\ttotal: 10.1s\tremaining: 50.4s\n",
      "167:\tlearn: 0.2302314\ttotal: 10.2s\tremaining: 50.3s\n",
      "168:\tlearn: 0.2299859\ttotal: 10.2s\tremaining: 50.2s\n",
      "169:\tlearn: 0.2297494\ttotal: 10.3s\tremaining: 50.1s\n",
      "170:\tlearn: 0.2294936\ttotal: 10.3s\tremaining: 50.1s\n",
      "171:\tlearn: 0.2292594\ttotal: 10.4s\tremaining: 50s\n",
      "172:\tlearn: 0.2290329\ttotal: 10.4s\tremaining: 49.9s\n",
      "173:\tlearn: 0.2288144\ttotal: 10.5s\tremaining: 49.8s\n",
      "174:\tlearn: 0.2285910\ttotal: 10.6s\tremaining: 49.8s\n",
      "175:\tlearn: 0.2283538\ttotal: 10.6s\tremaining: 49.7s\n",
      "176:\tlearn: 0.2281221\ttotal: 10.7s\tremaining: 49.7s\n",
      "177:\tlearn: 0.2278851\ttotal: 10.7s\tremaining: 49.6s\n",
      "178:\tlearn: 0.2276547\ttotal: 10.8s\tremaining: 49.6s\n",
      "179:\tlearn: 0.2274212\ttotal: 10.9s\tremaining: 49.5s\n",
      "180:\tlearn: 0.2271989\ttotal: 10.9s\tremaining: 49.4s\n",
      "181:\tlearn: 0.2269795\ttotal: 11s\tremaining: 49.3s\n",
      "182:\tlearn: 0.2267685\ttotal: 11s\tremaining: 49.3s\n",
      "183:\tlearn: 0.2265379\ttotal: 11.1s\tremaining: 49.2s\n",
      "184:\tlearn: 0.2263191\ttotal: 11.2s\tremaining: 49.1s\n",
      "185:\tlearn: 0.2260880\ttotal: 11.2s\tremaining: 49.1s\n",
      "186:\tlearn: 0.2258579\ttotal: 11.3s\tremaining: 49s\n",
      "187:\tlearn: 0.2256407\ttotal: 11.3s\tremaining: 49s\n",
      "188:\tlearn: 0.2254191\ttotal: 11.4s\tremaining: 48.9s\n",
      "189:\tlearn: 0.2252011\ttotal: 11.5s\tremaining: 48.9s\n",
      "190:\tlearn: 0.2249878\ttotal: 11.5s\tremaining: 48.8s\n",
      "191:\tlearn: 0.2247698\ttotal: 11.6s\tremaining: 48.8s\n",
      "192:\tlearn: 0.2245441\ttotal: 11.7s\tremaining: 48.7s\n",
      "193:\tlearn: 0.2243273\ttotal: 11.7s\tremaining: 48.7s\n",
      "194:\tlearn: 0.2241228\ttotal: 11.8s\tremaining: 48.6s\n",
      "195:\tlearn: 0.2239235\ttotal: 11.8s\tremaining: 48.5s\n",
      "196:\tlearn: 0.2237292\ttotal: 11.9s\tremaining: 48.4s\n",
      "197:\tlearn: 0.2235178\ttotal: 11.9s\tremaining: 48.4s\n",
      "198:\tlearn: 0.2233130\ttotal: 12s\tremaining: 48.3s\n",
      "199:\tlearn: 0.2231186\ttotal: 12.1s\tremaining: 48.2s\n",
      "200:\tlearn: 0.2229139\ttotal: 12.1s\tremaining: 48.2s\n",
      "201:\tlearn: 0.2227195\ttotal: 12.2s\tremaining: 48.1s\n",
      "202:\tlearn: 0.2225182\ttotal: 12.2s\tremaining: 48.1s\n",
      "203:\tlearn: 0.2223154\ttotal: 12.3s\tremaining: 48s\n",
      "204:\tlearn: 0.2221296\ttotal: 12.4s\tremaining: 47.9s\n",
      "205:\tlearn: 0.2219345\ttotal: 12.4s\tremaining: 47.8s\n",
      "206:\tlearn: 0.2217493\ttotal: 12.5s\tremaining: 47.8s\n",
      "207:\tlearn: 0.2215591\ttotal: 12.5s\tremaining: 47.7s\n",
      "208:\tlearn: 0.2213674\ttotal: 12.6s\tremaining: 47.6s\n",
      "209:\tlearn: 0.2211757\ttotal: 12.6s\tremaining: 47.5s\n",
      "210:\tlearn: 0.2209786\ttotal: 12.7s\tremaining: 47.5s\n",
      "211:\tlearn: 0.2207884\ttotal: 12.8s\tremaining: 47.4s\n",
      "212:\tlearn: 0.2205881\ttotal: 12.8s\tremaining: 47.4s\n",
      "213:\tlearn: 0.2203921\ttotal: 12.9s\tremaining: 47.3s\n",
      "214:\tlearn: 0.2202040\ttotal: 12.9s\tremaining: 47.3s\n",
      "215:\tlearn: 0.2200219\ttotal: 13s\tremaining: 47.2s\n",
      "216:\tlearn: 0.2198433\ttotal: 13.1s\tremaining: 47.1s\n",
      "217:\tlearn: 0.2196575\ttotal: 13.1s\tremaining: 47.1s\n",
      "218:\tlearn: 0.2194799\ttotal: 13.2s\tremaining: 47s\n",
      "219:\tlearn: 0.2192836\ttotal: 13.2s\tremaining: 46.9s\n",
      "220:\tlearn: 0.2191003\ttotal: 13.3s\tremaining: 46.9s\n",
      "221:\tlearn: 0.2189210\ttotal: 13.4s\tremaining: 46.8s\n",
      "222:\tlearn: 0.2187261\ttotal: 13.4s\tremaining: 46.8s\n",
      "223:\tlearn: 0.2185600\ttotal: 13.5s\tremaining: 46.7s\n",
      "224:\tlearn: 0.2183784\ttotal: 13.5s\tremaining: 46.7s\n",
      "225:\tlearn: 0.2181983\ttotal: 13.6s\tremaining: 46.6s\n",
      "226:\tlearn: 0.2180279\ttotal: 13.7s\tremaining: 46.5s\n",
      "227:\tlearn: 0.2178740\ttotal: 13.7s\tremaining: 46.4s\n",
      "228:\tlearn: 0.2177076\ttotal: 13.8s\tremaining: 46.4s\n",
      "229:\tlearn: 0.2175289\ttotal: 13.8s\tremaining: 46.3s\n",
      "230:\tlearn: 0.2173343\ttotal: 13.9s\tremaining: 46.2s\n",
      "231:\tlearn: 0.2171604\ttotal: 13.9s\tremaining: 46.2s\n",
      "232:\tlearn: 0.2169673\ttotal: 14s\tremaining: 46.1s\n",
      "233:\tlearn: 0.2167904\ttotal: 14.1s\tremaining: 46.1s\n",
      "234:\tlearn: 0.2166191\ttotal: 14.1s\tremaining: 46s\n",
      "235:\tlearn: 0.2164440\ttotal: 14.2s\tremaining: 45.9s\n",
      "236:\tlearn: 0.2162787\ttotal: 14.2s\tremaining: 45.9s\n",
      "237:\tlearn: 0.2161050\ttotal: 14.3s\tremaining: 45.8s\n",
      "238:\tlearn: 0.2159227\ttotal: 14.4s\tremaining: 45.7s\n",
      "239:\tlearn: 0.2157569\ttotal: 14.4s\tremaining: 45.7s\n",
      "240:\tlearn: 0.2155910\ttotal: 14.5s\tremaining: 45.6s\n",
      "241:\tlearn: 0.2154321\ttotal: 14.5s\tremaining: 45.5s\n",
      "242:\tlearn: 0.2152666\ttotal: 14.6s\tremaining: 45.5s\n",
      "243:\tlearn: 0.2151080\ttotal: 14.7s\tremaining: 45.4s\n",
      "244:\tlearn: 0.2149382\ttotal: 14.7s\tremaining: 45.4s\n",
      "245:\tlearn: 0.2147687\ttotal: 14.8s\tremaining: 45.3s\n",
      "246:\tlearn: 0.2146034\ttotal: 14.8s\tremaining: 45.2s\n",
      "247:\tlearn: 0.2144350\ttotal: 14.9s\tremaining: 45.2s\n",
      "248:\tlearn: 0.2142704\ttotal: 15s\tremaining: 45.1s\n",
      "249:\tlearn: 0.2141057\ttotal: 15s\tremaining: 45.1s\n",
      "250:\tlearn: 0.2139314\ttotal: 15.1s\tremaining: 45s\n",
      "251:\tlearn: 0.2137488\ttotal: 15.1s\tremaining: 45s\n",
      "252:\tlearn: 0.2135908\ttotal: 15.2s\tremaining: 44.9s\n",
      "253:\tlearn: 0.2134433\ttotal: 15.3s\tremaining: 44.9s\n",
      "254:\tlearn: 0.2132761\ttotal: 15.3s\tremaining: 44.8s\n",
      "255:\tlearn: 0.2131123\ttotal: 15.4s\tremaining: 44.8s\n",
      "256:\tlearn: 0.2129635\ttotal: 15.5s\tremaining: 44.7s\n",
      "257:\tlearn: 0.2128022\ttotal: 15.5s\tremaining: 44.7s\n",
      "258:\tlearn: 0.2126327\ttotal: 15.6s\tremaining: 44.6s\n",
      "259:\tlearn: 0.2124818\ttotal: 15.6s\tremaining: 44.5s\n",
      "260:\tlearn: 0.2123291\ttotal: 15.7s\tremaining: 44.5s\n",
      "261:\tlearn: 0.2121719\ttotal: 15.8s\tremaining: 44.4s\n",
      "262:\tlearn: 0.2120187\ttotal: 15.8s\tremaining: 44.3s\n",
      "263:\tlearn: 0.2118607\ttotal: 15.9s\tremaining: 44.3s\n",
      "264:\tlearn: 0.2117178\ttotal: 15.9s\tremaining: 44.2s\n",
      "265:\tlearn: 0.2115817\ttotal: 16s\tremaining: 44.1s\n",
      "266:\tlearn: 0.2114270\ttotal: 16.1s\tremaining: 44.1s\n",
      "267:\tlearn: 0.2112667\ttotal: 16.1s\tremaining: 44s\n",
      "268:\tlearn: 0.2111150\ttotal: 16.2s\tremaining: 44s\n",
      "269:\tlearn: 0.2109583\ttotal: 16.2s\tremaining: 43.9s\n",
      "270:\tlearn: 0.2108146\ttotal: 16.3s\tremaining: 43.8s\n",
      "271:\tlearn: 0.2106584\ttotal: 16.4s\tremaining: 43.8s\n",
      "272:\tlearn: 0.2105183\ttotal: 16.4s\tremaining: 43.7s\n",
      "273:\tlearn: 0.2103663\ttotal: 16.5s\tremaining: 43.6s\n",
      "274:\tlearn: 0.2102192\ttotal: 16.5s\tremaining: 43.6s\n",
      "275:\tlearn: 0.2100618\ttotal: 16.6s\tremaining: 43.5s\n",
      "276:\tlearn: 0.2099097\ttotal: 16.6s\tremaining: 43.5s\n",
      "277:\tlearn: 0.2097725\ttotal: 16.7s\tremaining: 43.4s\n",
      "278:\tlearn: 0.2096262\ttotal: 16.8s\tremaining: 43.3s\n",
      "279:\tlearn: 0.2094890\ttotal: 16.8s\tremaining: 43.3s\n",
      "280:\tlearn: 0.2093219\ttotal: 16.9s\tremaining: 43.2s\n",
      "281:\tlearn: 0.2091749\ttotal: 16.9s\tremaining: 43.1s\n",
      "282:\tlearn: 0.2090232\ttotal: 17s\tremaining: 43.1s\n",
      "283:\tlearn: 0.2088810\ttotal: 17.1s\tremaining: 43s\n",
      "284:\tlearn: 0.2087413\ttotal: 17.1s\tremaining: 43s\n",
      "285:\tlearn: 0.2085948\ttotal: 17.2s\tremaining: 42.9s\n",
      "286:\tlearn: 0.2084626\ttotal: 17.3s\tremaining: 42.9s\n",
      "287:\tlearn: 0.2083193\ttotal: 17.3s\tremaining: 42.8s\n",
      "288:\tlearn: 0.2081862\ttotal: 17.4s\tremaining: 42.8s\n",
      "289:\tlearn: 0.2080419\ttotal: 17.5s\tremaining: 42.8s\n",
      "290:\tlearn: 0.2079064\ttotal: 17.5s\tremaining: 42.7s\n",
      "291:\tlearn: 0.2077711\ttotal: 17.6s\tremaining: 42.7s\n",
      "292:\tlearn: 0.2076511\ttotal: 17.7s\tremaining: 42.6s\n",
      "293:\tlearn: 0.2075126\ttotal: 17.7s\tremaining: 42.5s\n",
      "294:\tlearn: 0.2073678\ttotal: 17.8s\tremaining: 42.5s\n",
      "295:\tlearn: 0.2072160\ttotal: 17.9s\tremaining: 42.5s\n",
      "296:\tlearn: 0.2070676\ttotal: 17.9s\tremaining: 42.5s\n",
      "297:\tlearn: 0.2069197\ttotal: 18s\tremaining: 42.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "298:\tlearn: 0.2067861\ttotal: 18.1s\tremaining: 42.4s\n",
      "299:\tlearn: 0.2066545\ttotal: 18.1s\tremaining: 42.3s\n",
      "300:\tlearn: 0.2065078\ttotal: 18.2s\tremaining: 42.3s\n",
      "301:\tlearn: 0.2063707\ttotal: 18.3s\tremaining: 42.3s\n",
      "302:\tlearn: 0.2062386\ttotal: 18.3s\tremaining: 42.2s\n",
      "303:\tlearn: 0.2061079\ttotal: 18.4s\tremaining: 42.1s\n",
      "304:\tlearn: 0.2059715\ttotal: 18.5s\tremaining: 42.1s\n",
      "305:\tlearn: 0.2058265\ttotal: 18.5s\tremaining: 42s\n",
      "306:\tlearn: 0.2057080\ttotal: 18.6s\tremaining: 42s\n",
      "307:\tlearn: 0.2055690\ttotal: 18.7s\tremaining: 41.9s\n",
      "308:\tlearn: 0.2054396\ttotal: 18.7s\tremaining: 41.9s\n",
      "309:\tlearn: 0.2053023\ttotal: 18.8s\tremaining: 41.9s\n",
      "310:\tlearn: 0.2051745\ttotal: 18.9s\tremaining: 41.8s\n",
      "311:\tlearn: 0.2050435\ttotal: 18.9s\tremaining: 41.7s\n",
      "312:\tlearn: 0.2049198\ttotal: 19s\tremaining: 41.7s\n",
      "313:\tlearn: 0.2047926\ttotal: 19s\tremaining: 41.6s\n",
      "314:\tlearn: 0.2046518\ttotal: 19.1s\tremaining: 41.6s\n",
      "315:\tlearn: 0.2045222\ttotal: 19.2s\tremaining: 41.5s\n",
      "316:\tlearn: 0.2043960\ttotal: 19.2s\tremaining: 41.4s\n",
      "317:\tlearn: 0.2042738\ttotal: 19.3s\tremaining: 41.4s\n",
      "318:\tlearn: 0.2041446\ttotal: 19.4s\tremaining: 41.3s\n",
      "319:\tlearn: 0.2040290\ttotal: 19.4s\tremaining: 41.2s\n",
      "320:\tlearn: 0.2039012\ttotal: 19.5s\tremaining: 41.2s\n",
      "321:\tlearn: 0.2037842\ttotal: 19.5s\tremaining: 41.1s\n",
      "322:\tlearn: 0.2036572\ttotal: 19.6s\tremaining: 41.1s\n",
      "323:\tlearn: 0.2035280\ttotal: 19.7s\tremaining: 41s\n",
      "324:\tlearn: 0.2034042\ttotal: 19.7s\tremaining: 41s\n",
      "325:\tlearn: 0.2032856\ttotal: 19.8s\tremaining: 40.9s\n",
      "326:\tlearn: 0.2031641\ttotal: 19.8s\tremaining: 40.9s\n",
      "327:\tlearn: 0.2030306\ttotal: 19.9s\tremaining: 40.8s\n",
      "328:\tlearn: 0.2029100\ttotal: 20s\tremaining: 40.7s\n",
      "329:\tlearn: 0.2027881\ttotal: 20s\tremaining: 40.6s\n",
      "330:\tlearn: 0.2026585\ttotal: 20.1s\tremaining: 40.6s\n",
      "331:\tlearn: 0.2025426\ttotal: 20.1s\tremaining: 40.5s\n",
      "332:\tlearn: 0.2024269\ttotal: 20.2s\tremaining: 40.4s\n",
      "333:\tlearn: 0.2023066\ttotal: 20.2s\tremaining: 40.4s\n",
      "334:\tlearn: 0.2021769\ttotal: 20.3s\tremaining: 40.3s\n",
      "335:\tlearn: 0.2020656\ttotal: 20.4s\tremaining: 40.2s\n",
      "336:\tlearn: 0.2019419\ttotal: 20.4s\tremaining: 40.2s\n",
      "337:\tlearn: 0.2018213\ttotal: 20.5s\tremaining: 40.1s\n",
      "338:\tlearn: 0.2016914\ttotal: 20.5s\tremaining: 40s\n",
      "339:\tlearn: 0.2015715\ttotal: 20.6s\tremaining: 40s\n",
      "340:\tlearn: 0.2014549\ttotal: 20.7s\tremaining: 39.9s\n",
      "341:\tlearn: 0.2013356\ttotal: 20.7s\tremaining: 39.8s\n",
      "342:\tlearn: 0.2012077\ttotal: 20.8s\tremaining: 39.8s\n",
      "343:\tlearn: 0.2010893\ttotal: 20.8s\tremaining: 39.7s\n",
      "344:\tlearn: 0.2009756\ttotal: 20.9s\tremaining: 39.7s\n",
      "345:\tlearn: 0.2008415\ttotal: 21s\tremaining: 39.6s\n",
      "346:\tlearn: 0.2007225\ttotal: 21s\tremaining: 39.6s\n",
      "347:\tlearn: 0.2005950\ttotal: 21.1s\tremaining: 39.5s\n",
      "348:\tlearn: 0.2004749\ttotal: 21.1s\tremaining: 39.4s\n",
      "349:\tlearn: 0.2003549\ttotal: 21.2s\tremaining: 39.4s\n",
      "350:\tlearn: 0.2002390\ttotal: 21.3s\tremaining: 39.3s\n",
      "351:\tlearn: 0.2001133\ttotal: 21.3s\tremaining: 39.3s\n",
      "352:\tlearn: 0.2000020\ttotal: 21.4s\tremaining: 39.2s\n",
      "353:\tlearn: 0.1998951\ttotal: 21.4s\tremaining: 39.1s\n",
      "354:\tlearn: 0.1997829\ttotal: 21.5s\tremaining: 39.1s\n",
      "355:\tlearn: 0.1996707\ttotal: 21.6s\tremaining: 39s\n",
      "356:\tlearn: 0.1995500\ttotal: 21.6s\tremaining: 39s\n",
      "357:\tlearn: 0.1994354\ttotal: 21.7s\tremaining: 38.9s\n",
      "358:\tlearn: 0.1993245\ttotal: 21.8s\tremaining: 38.8s\n",
      "359:\tlearn: 0.1992134\ttotal: 21.8s\tremaining: 38.8s\n",
      "360:\tlearn: 0.1990894\ttotal: 21.9s\tremaining: 38.7s\n",
      "361:\tlearn: 0.1989728\ttotal: 21.9s\tremaining: 38.7s\n",
      "362:\tlearn: 0.1988586\ttotal: 22s\tremaining: 38.6s\n",
      "363:\tlearn: 0.1987424\ttotal: 22s\tremaining: 38.5s\n",
      "364:\tlearn: 0.1986259\ttotal: 22.1s\tremaining: 38.5s\n",
      "365:\tlearn: 0.1985196\ttotal: 22.2s\tremaining: 38.4s\n",
      "366:\tlearn: 0.1984086\ttotal: 22.2s\tremaining: 38.4s\n",
      "367:\tlearn: 0.1982993\ttotal: 22.3s\tremaining: 38.3s\n",
      "368:\tlearn: 0.1981881\ttotal: 22.4s\tremaining: 38.2s\n",
      "369:\tlearn: 0.1980763\ttotal: 22.4s\tremaining: 38.2s\n",
      "370:\tlearn: 0.1979670\ttotal: 22.5s\tremaining: 38.1s\n",
      "371:\tlearn: 0.1978492\ttotal: 22.5s\tremaining: 38s\n",
      "372:\tlearn: 0.1977399\ttotal: 22.6s\tremaining: 38s\n",
      "373:\tlearn: 0.1976271\ttotal: 22.7s\tremaining: 37.9s\n",
      "374:\tlearn: 0.1975097\ttotal: 22.7s\tremaining: 37.9s\n",
      "375:\tlearn: 0.1973934\ttotal: 22.8s\tremaining: 37.8s\n",
      "376:\tlearn: 0.1972850\ttotal: 22.8s\tremaining: 37.8s\n",
      "377:\tlearn: 0.1971677\ttotal: 22.9s\tremaining: 37.7s\n",
      "378:\tlearn: 0.1970520\ttotal: 23s\tremaining: 37.6s\n",
      "379:\tlearn: 0.1969399\ttotal: 23s\tremaining: 37.6s\n",
      "380:\tlearn: 0.1968160\ttotal: 23.1s\tremaining: 37.5s\n",
      "381:\tlearn: 0.1967165\ttotal: 23.2s\tremaining: 37.5s\n",
      "382:\tlearn: 0.1966003\ttotal: 23.3s\tremaining: 37.5s\n",
      "383:\tlearn: 0.1964848\ttotal: 23.3s\tremaining: 37.4s\n",
      "384:\tlearn: 0.1963816\ttotal: 23.4s\tremaining: 37.3s\n",
      "385:\tlearn: 0.1962795\ttotal: 23.4s\tremaining: 37.3s\n",
      "386:\tlearn: 0.1961715\ttotal: 23.5s\tremaining: 37.2s\n",
      "387:\tlearn: 0.1960631\ttotal: 23.6s\tremaining: 37.2s\n",
      "388:\tlearn: 0.1959637\ttotal: 23.6s\tremaining: 37.1s\n",
      "389:\tlearn: 0.1958675\ttotal: 23.7s\tremaining: 37s\n",
      "390:\tlearn: 0.1957530\ttotal: 23.7s\tremaining: 37s\n",
      "391:\tlearn: 0.1956507\ttotal: 23.8s\tremaining: 36.9s\n",
      "392:\tlearn: 0.1955398\ttotal: 23.9s\tremaining: 36.8s\n",
      "393:\tlearn: 0.1954381\ttotal: 23.9s\tremaining: 36.8s\n",
      "394:\tlearn: 0.1953351\ttotal: 24s\tremaining: 36.7s\n",
      "395:\tlearn: 0.1952205\ttotal: 24s\tremaining: 36.7s\n",
      "396:\tlearn: 0.1951198\ttotal: 24.1s\tremaining: 36.6s\n",
      "397:\tlearn: 0.1950218\ttotal: 24.2s\tremaining: 36.5s\n",
      "398:\tlearn: 0.1949199\ttotal: 24.2s\tremaining: 36.5s\n",
      "399:\tlearn: 0.1948198\ttotal: 24.3s\tremaining: 36.4s\n",
      "400:\tlearn: 0.1947227\ttotal: 24.3s\tremaining: 36.3s\n",
      "401:\tlearn: 0.1946157\ttotal: 24.4s\tremaining: 36.3s\n",
      "402:\tlearn: 0.1945187\ttotal: 24.4s\tremaining: 36.2s\n",
      "403:\tlearn: 0.1944150\ttotal: 24.5s\tremaining: 36.2s\n",
      "404:\tlearn: 0.1943188\ttotal: 24.6s\tremaining: 36.1s\n",
      "405:\tlearn: 0.1942047\ttotal: 24.6s\tremaining: 36s\n",
      "406:\tlearn: 0.1941158\ttotal: 24.7s\tremaining: 36s\n",
      "407:\tlearn: 0.1940110\ttotal: 24.8s\tremaining: 35.9s\n",
      "408:\tlearn: 0.1939101\ttotal: 24.8s\tremaining: 35.9s\n",
      "409:\tlearn: 0.1938077\ttotal: 24.9s\tremaining: 35.8s\n",
      "410:\tlearn: 0.1937098\ttotal: 24.9s\tremaining: 35.7s\n",
      "411:\tlearn: 0.1936034\ttotal: 25s\tremaining: 35.7s\n",
      "412:\tlearn: 0.1934889\ttotal: 25.1s\tremaining: 35.6s\n",
      "413:\tlearn: 0.1933921\ttotal: 25.1s\tremaining: 35.6s\n",
      "414:\tlearn: 0.1932924\ttotal: 25.2s\tremaining: 35.5s\n",
      "415:\tlearn: 0.1931851\ttotal: 25.3s\tremaining: 35.5s\n",
      "416:\tlearn: 0.1930951\ttotal: 25.3s\tremaining: 35.4s\n",
      "417:\tlearn: 0.1929926\ttotal: 25.4s\tremaining: 35.3s\n",
      "418:\tlearn: 0.1928992\ttotal: 25.4s\tremaining: 35.3s\n",
      "419:\tlearn: 0.1927885\ttotal: 25.5s\tremaining: 35.2s\n",
      "420:\tlearn: 0.1926811\ttotal: 25.6s\tremaining: 35.2s\n",
      "421:\tlearn: 0.1925927\ttotal: 25.6s\tremaining: 35.1s\n",
      "422:\tlearn: 0.1924864\ttotal: 25.7s\tremaining: 35s\n",
      "423:\tlearn: 0.1923945\ttotal: 25.7s\tremaining: 35s\n",
      "424:\tlearn: 0.1922961\ttotal: 25.8s\tremaining: 34.9s\n",
      "425:\tlearn: 0.1921947\ttotal: 25.9s\tremaining: 34.8s\n",
      "426:\tlearn: 0.1920980\ttotal: 25.9s\tremaining: 34.8s\n",
      "427:\tlearn: 0.1919992\ttotal: 26s\tremaining: 34.7s\n",
      "428:\tlearn: 0.1919026\ttotal: 26s\tremaining: 34.7s\n",
      "429:\tlearn: 0.1918021\ttotal: 26.1s\tremaining: 34.6s\n",
      "430:\tlearn: 0.1917045\ttotal: 26.2s\tremaining: 34.5s\n",
      "431:\tlearn: 0.1916035\ttotal: 26.2s\tremaining: 34.5s\n",
      "432:\tlearn: 0.1915101\ttotal: 26.3s\tremaining: 34.4s\n",
      "433:\tlearn: 0.1914135\ttotal: 26.3s\tremaining: 34.4s\n",
      "434:\tlearn: 0.1913222\ttotal: 26.4s\tremaining: 34.3s\n",
      "435:\tlearn: 0.1912287\ttotal: 26.5s\tremaining: 34.2s\n",
      "436:\tlearn: 0.1911466\ttotal: 26.5s\tremaining: 34.2s\n",
      "437:\tlearn: 0.1910460\ttotal: 26.6s\tremaining: 34.1s\n",
      "438:\tlearn: 0.1909508\ttotal: 26.6s\tremaining: 34.1s\n",
      "439:\tlearn: 0.1908669\ttotal: 26.7s\tremaining: 34s\n",
      "440:\tlearn: 0.1907700\ttotal: 26.8s\tremaining: 34s\n",
      "441:\tlearn: 0.1906773\ttotal: 26.9s\tremaining: 33.9s\n",
      "442:\tlearn: 0.1905980\ttotal: 26.9s\tremaining: 33.8s\n",
      "443:\tlearn: 0.1905100\ttotal: 27s\tremaining: 33.8s\n",
      "444:\tlearn: 0.1904218\ttotal: 27.1s\tremaining: 33.7s\n",
      "445:\tlearn: 0.1903130\ttotal: 27.1s\tremaining: 33.7s\n",
      "446:\tlearn: 0.1902184\ttotal: 27.2s\tremaining: 33.6s\n",
      "447:\tlearn: 0.1901332\ttotal: 27.3s\tremaining: 33.6s\n",
      "448:\tlearn: 0.1900491\ttotal: 27.3s\tremaining: 33.5s\n",
      "449:\tlearn: 0.1899557\ttotal: 27.4s\tremaining: 33.5s\n",
      "450:\tlearn: 0.1898680\ttotal: 27.5s\tremaining: 33.4s\n",
      "451:\tlearn: 0.1897857\ttotal: 27.5s\tremaining: 33.4s\n",
      "452:\tlearn: 0.1896935\ttotal: 27.6s\tremaining: 33.3s\n",
      "453:\tlearn: 0.1896104\ttotal: 27.7s\tremaining: 33.3s\n",
      "454:\tlearn: 0.1895154\ttotal: 27.7s\tremaining: 33.2s\n",
      "455:\tlearn: 0.1894143\ttotal: 27.8s\tremaining: 33.2s\n",
      "456:\tlearn: 0.1893139\ttotal: 27.9s\tremaining: 33.1s\n",
      "457:\tlearn: 0.1892189\ttotal: 27.9s\tremaining: 33.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "458:\tlearn: 0.1891328\ttotal: 28s\tremaining: 33s\n",
      "459:\tlearn: 0.1890379\ttotal: 28.1s\tremaining: 33s\n",
      "460:\tlearn: 0.1889408\ttotal: 28.2s\tremaining: 32.9s\n",
      "461:\tlearn: 0.1888495\ttotal: 28.2s\tremaining: 32.9s\n",
      "462:\tlearn: 0.1887727\ttotal: 28.3s\tremaining: 32.8s\n",
      "463:\tlearn: 0.1886801\ttotal: 28.4s\tremaining: 32.8s\n",
      "464:\tlearn: 0.1885816\ttotal: 28.4s\tremaining: 32.7s\n",
      "465:\tlearn: 0.1884907\ttotal: 28.5s\tremaining: 32.7s\n",
      "466:\tlearn: 0.1884013\ttotal: 28.6s\tremaining: 32.6s\n",
      "467:\tlearn: 0.1883020\ttotal: 28.7s\tremaining: 32.6s\n",
      "468:\tlearn: 0.1882133\ttotal: 28.7s\tremaining: 32.5s\n",
      "469:\tlearn: 0.1881253\ttotal: 28.8s\tremaining: 32.5s\n",
      "470:\tlearn: 0.1880408\ttotal: 28.9s\tremaining: 32.4s\n",
      "471:\tlearn: 0.1879516\ttotal: 28.9s\tremaining: 32.4s\n",
      "472:\tlearn: 0.1878675\ttotal: 29s\tremaining: 32.3s\n",
      "473:\tlearn: 0.1877872\ttotal: 29.1s\tremaining: 32.3s\n",
      "474:\tlearn: 0.1876962\ttotal: 29.2s\tremaining: 32.2s\n",
      "475:\tlearn: 0.1876037\ttotal: 29.2s\tremaining: 32.2s\n",
      "476:\tlearn: 0.1875078\ttotal: 29.3s\tremaining: 32.2s\n",
      "477:\tlearn: 0.1874185\ttotal: 29.4s\tremaining: 32.1s\n",
      "478:\tlearn: 0.1873297\ttotal: 29.5s\tremaining: 32.1s\n",
      "479:\tlearn: 0.1872358\ttotal: 29.6s\tremaining: 32s\n",
      "480:\tlearn: 0.1871560\ttotal: 29.6s\tremaining: 32s\n",
      "481:\tlearn: 0.1870728\ttotal: 29.7s\tremaining: 31.9s\n",
      "482:\tlearn: 0.1869742\ttotal: 29.8s\tremaining: 31.9s\n",
      "483:\tlearn: 0.1868802\ttotal: 29.8s\tremaining: 31.8s\n",
      "484:\tlearn: 0.1867972\ttotal: 29.9s\tremaining: 31.7s\n",
      "485:\tlearn: 0.1866999\ttotal: 30s\tremaining: 31.7s\n",
      "486:\tlearn: 0.1866142\ttotal: 30s\tremaining: 31.6s\n",
      "487:\tlearn: 0.1865386\ttotal: 30.1s\tremaining: 31.6s\n",
      "488:\tlearn: 0.1864553\ttotal: 30.2s\tremaining: 31.5s\n",
      "489:\tlearn: 0.1863634\ttotal: 30.2s\tremaining: 31.5s\n",
      "490:\tlearn: 0.1862863\ttotal: 30.3s\tremaining: 31.4s\n",
      "491:\tlearn: 0.1862030\ttotal: 30.4s\tremaining: 31.4s\n",
      "492:\tlearn: 0.1861082\ttotal: 30.4s\tremaining: 31.3s\n",
      "493:\tlearn: 0.1860073\ttotal: 30.5s\tremaining: 31.3s\n",
      "494:\tlearn: 0.1859206\ttotal: 30.6s\tremaining: 31.2s\n",
      "495:\tlearn: 0.1858235\ttotal: 30.7s\tremaining: 31.2s\n",
      "496:\tlearn: 0.1857312\ttotal: 30.8s\tremaining: 31.1s\n",
      "497:\tlearn: 0.1856433\ttotal: 30.8s\tremaining: 31.1s\n",
      "498:\tlearn: 0.1855565\ttotal: 30.9s\tremaining: 31s\n",
      "499:\tlearn: 0.1854690\ttotal: 31s\tremaining: 31s\n",
      "500:\tlearn: 0.1853867\ttotal: 31.1s\tremaining: 30.9s\n",
      "501:\tlearn: 0.1853128\ttotal: 31.1s\tremaining: 30.9s\n",
      "502:\tlearn: 0.1852452\ttotal: 31.2s\tremaining: 30.8s\n",
      "503:\tlearn: 0.1851624\ttotal: 31.2s\tremaining: 30.7s\n",
      "504:\tlearn: 0.1850689\ttotal: 31.3s\tremaining: 30.7s\n",
      "505:\tlearn: 0.1849890\ttotal: 31.4s\tremaining: 30.6s\n",
      "506:\tlearn: 0.1849105\ttotal: 31.5s\tremaining: 30.6s\n",
      "507:\tlearn: 0.1848193\ttotal: 31.5s\tremaining: 30.5s\n",
      "508:\tlearn: 0.1847431\ttotal: 31.6s\tremaining: 30.5s\n",
      "509:\tlearn: 0.1846532\ttotal: 31.7s\tremaining: 30.4s\n",
      "510:\tlearn: 0.1845649\ttotal: 31.7s\tremaining: 30.4s\n",
      "511:\tlearn: 0.1844788\ttotal: 31.8s\tremaining: 30.3s\n",
      "512:\tlearn: 0.1843900\ttotal: 31.9s\tremaining: 30.3s\n",
      "513:\tlearn: 0.1843153\ttotal: 31.9s\tremaining: 30.2s\n",
      "514:\tlearn: 0.1842279\ttotal: 32s\tremaining: 30.2s\n",
      "515:\tlearn: 0.1841414\ttotal: 32.1s\tremaining: 30.1s\n",
      "516:\tlearn: 0.1840542\ttotal: 32.2s\tremaining: 30s\n",
      "517:\tlearn: 0.1839757\ttotal: 32.2s\tremaining: 30s\n",
      "518:\tlearn: 0.1838965\ttotal: 32.3s\tremaining: 29.9s\n",
      "519:\tlearn: 0.1838112\ttotal: 32.4s\tremaining: 29.9s\n",
      "520:\tlearn: 0.1837286\ttotal: 32.5s\tremaining: 29.8s\n",
      "521:\tlearn: 0.1836516\ttotal: 32.5s\tremaining: 29.8s\n",
      "522:\tlearn: 0.1835587\ttotal: 32.6s\tremaining: 29.7s\n",
      "523:\tlearn: 0.1834794\ttotal: 32.7s\tremaining: 29.7s\n",
      "524:\tlearn: 0.1833991\ttotal: 32.7s\tremaining: 29.6s\n",
      "525:\tlearn: 0.1833137\ttotal: 32.8s\tremaining: 29.6s\n",
      "526:\tlearn: 0.1832328\ttotal: 32.9s\tremaining: 29.5s\n",
      "527:\tlearn: 0.1831605\ttotal: 33s\tremaining: 29.5s\n",
      "528:\tlearn: 0.1830779\ttotal: 33s\tremaining: 29.4s\n",
      "529:\tlearn: 0.1829870\ttotal: 33.1s\tremaining: 29.4s\n",
      "530:\tlearn: 0.1829025\ttotal: 33.2s\tremaining: 29.3s\n",
      "531:\tlearn: 0.1828368\ttotal: 33.2s\tremaining: 29.2s\n",
      "532:\tlearn: 0.1827452\ttotal: 33.3s\tremaining: 29.2s\n",
      "533:\tlearn: 0.1826672\ttotal: 33.4s\tremaining: 29.1s\n",
      "534:\tlearn: 0.1825845\ttotal: 33.5s\tremaining: 29.1s\n",
      "535:\tlearn: 0.1825098\ttotal: 33.5s\tremaining: 29s\n",
      "536:\tlearn: 0.1824307\ttotal: 33.6s\tremaining: 28.9s\n",
      "537:\tlearn: 0.1823408\ttotal: 33.6s\tremaining: 28.9s\n",
      "538:\tlearn: 0.1822635\ttotal: 33.7s\tremaining: 28.8s\n",
      "539:\tlearn: 0.1821890\ttotal: 33.8s\tremaining: 28.8s\n",
      "540:\tlearn: 0.1821059\ttotal: 33.8s\tremaining: 28.7s\n",
      "541:\tlearn: 0.1820244\ttotal: 33.9s\tremaining: 28.7s\n",
      "542:\tlearn: 0.1819462\ttotal: 34s\tremaining: 28.6s\n",
      "543:\tlearn: 0.1818725\ttotal: 34s\tremaining: 28.5s\n",
      "544:\tlearn: 0.1817846\ttotal: 34.1s\tremaining: 28.5s\n",
      "545:\tlearn: 0.1816984\ttotal: 34.2s\tremaining: 28.4s\n",
      "546:\tlearn: 0.1816224\ttotal: 34.2s\tremaining: 28.4s\n",
      "547:\tlearn: 0.1815584\ttotal: 34.3s\tremaining: 28.3s\n",
      "548:\tlearn: 0.1814820\ttotal: 34.4s\tremaining: 28.2s\n",
      "549:\tlearn: 0.1814082\ttotal: 34.4s\tremaining: 28.2s\n",
      "550:\tlearn: 0.1813334\ttotal: 34.5s\tremaining: 28.1s\n",
      "551:\tlearn: 0.1812558\ttotal: 34.6s\tremaining: 28.1s\n",
      "552:\tlearn: 0.1811738\ttotal: 34.7s\tremaining: 28s\n",
      "553:\tlearn: 0.1810995\ttotal: 34.7s\tremaining: 28s\n",
      "554:\tlearn: 0.1810027\ttotal: 34.8s\tremaining: 27.9s\n",
      "555:\tlearn: 0.1809197\ttotal: 34.9s\tremaining: 27.9s\n",
      "556:\tlearn: 0.1808387\ttotal: 35s\tremaining: 27.8s\n",
      "557:\tlearn: 0.1807568\ttotal: 35s\tremaining: 27.7s\n",
      "558:\tlearn: 0.1806845\ttotal: 35.1s\tremaining: 27.7s\n",
      "559:\tlearn: 0.1806083\ttotal: 35.2s\tremaining: 27.6s\n",
      "560:\tlearn: 0.1805310\ttotal: 35.2s\tremaining: 27.6s\n",
      "561:\tlearn: 0.1804533\ttotal: 35.3s\tremaining: 27.5s\n",
      "562:\tlearn: 0.1803742\ttotal: 35.4s\tremaining: 27.5s\n",
      "563:\tlearn: 0.1803001\ttotal: 35.4s\tremaining: 27.4s\n",
      "564:\tlearn: 0.1802262\ttotal: 35.5s\tremaining: 27.3s\n",
      "565:\tlearn: 0.1801467\ttotal: 35.6s\tremaining: 27.3s\n",
      "566:\tlearn: 0.1800726\ttotal: 35.7s\tremaining: 27.2s\n",
      "567:\tlearn: 0.1800005\ttotal: 35.7s\tremaining: 27.2s\n",
      "568:\tlearn: 0.1799193\ttotal: 35.8s\tremaining: 27.1s\n",
      "569:\tlearn: 0.1798450\ttotal: 35.9s\tremaining: 27.1s\n",
      "570:\tlearn: 0.1797654\ttotal: 35.9s\tremaining: 27s\n",
      "571:\tlearn: 0.1796994\ttotal: 36s\tremaining: 26.9s\n",
      "572:\tlearn: 0.1796306\ttotal: 36.1s\tremaining: 26.9s\n",
      "573:\tlearn: 0.1795507\ttotal: 36.1s\tremaining: 26.8s\n",
      "574:\tlearn: 0.1794644\ttotal: 36.2s\tremaining: 26.7s\n",
      "575:\tlearn: 0.1793863\ttotal: 36.2s\tremaining: 26.7s\n",
      "576:\tlearn: 0.1793184\ttotal: 36.3s\tremaining: 26.6s\n",
      "577:\tlearn: 0.1792452\ttotal: 36.4s\tremaining: 26.5s\n",
      "578:\tlearn: 0.1791492\ttotal: 36.4s\tremaining: 26.5s\n",
      "579:\tlearn: 0.1790917\ttotal: 36.5s\tremaining: 26.4s\n",
      "580:\tlearn: 0.1790207\ttotal: 36.5s\tremaining: 26.3s\n",
      "581:\tlearn: 0.1789432\ttotal: 36.6s\tremaining: 26.3s\n",
      "582:\tlearn: 0.1788734\ttotal: 36.6s\tremaining: 26.2s\n",
      "583:\tlearn: 0.1788079\ttotal: 36.7s\tremaining: 26.1s\n",
      "584:\tlearn: 0.1787400\ttotal: 36.8s\tremaining: 26.1s\n",
      "585:\tlearn: 0.1786569\ttotal: 36.8s\tremaining: 26s\n",
      "586:\tlearn: 0.1785765\ttotal: 36.9s\tremaining: 26s\n",
      "587:\tlearn: 0.1784941\ttotal: 37s\tremaining: 25.9s\n",
      "588:\tlearn: 0.1784340\ttotal: 37s\tremaining: 25.8s\n",
      "589:\tlearn: 0.1783581\ttotal: 37.1s\tremaining: 25.8s\n",
      "590:\tlearn: 0.1782896\ttotal: 37.1s\tremaining: 25.7s\n",
      "591:\tlearn: 0.1782068\ttotal: 37.2s\tremaining: 25.6s\n",
      "592:\tlearn: 0.1781332\ttotal: 37.3s\tremaining: 25.6s\n",
      "593:\tlearn: 0.1780526\ttotal: 37.3s\tremaining: 25.5s\n",
      "594:\tlearn: 0.1779792\ttotal: 37.4s\tremaining: 25.5s\n",
      "595:\tlearn: 0.1778851\ttotal: 37.5s\tremaining: 25.4s\n",
      "596:\tlearn: 0.1778127\ttotal: 37.5s\tremaining: 25.3s\n",
      "597:\tlearn: 0.1777423\ttotal: 37.6s\tremaining: 25.3s\n",
      "598:\tlearn: 0.1776796\ttotal: 37.6s\tremaining: 25.2s\n",
      "599:\tlearn: 0.1776059\ttotal: 37.7s\tremaining: 25.1s\n",
      "600:\tlearn: 0.1775302\ttotal: 37.8s\tremaining: 25.1s\n",
      "601:\tlearn: 0.1774566\ttotal: 37.8s\tremaining: 25s\n",
      "602:\tlearn: 0.1773883\ttotal: 37.9s\tremaining: 24.9s\n",
      "603:\tlearn: 0.1773135\ttotal: 37.9s\tremaining: 24.9s\n",
      "604:\tlearn: 0.1772385\ttotal: 38s\tremaining: 24.8s\n",
      "605:\tlearn: 0.1771645\ttotal: 38.1s\tremaining: 24.7s\n",
      "606:\tlearn: 0.1770708\ttotal: 38.1s\tremaining: 24.7s\n",
      "607:\tlearn: 0.1770008\ttotal: 38.2s\tremaining: 24.6s\n",
      "608:\tlearn: 0.1769348\ttotal: 38.3s\tremaining: 24.6s\n",
      "609:\tlearn: 0.1768689\ttotal: 38.3s\tremaining: 24.5s\n",
      "610:\tlearn: 0.1768020\ttotal: 38.4s\tremaining: 24.4s\n",
      "611:\tlearn: 0.1767406\ttotal: 38.4s\tremaining: 24.4s\n",
      "612:\tlearn: 0.1766712\ttotal: 38.5s\tremaining: 24.3s\n",
      "613:\tlearn: 0.1765980\ttotal: 38.6s\tremaining: 24.2s\n",
      "614:\tlearn: 0.1765197\ttotal: 38.6s\tremaining: 24.2s\n",
      "615:\tlearn: 0.1764436\ttotal: 38.7s\tremaining: 24.1s\n",
      "616:\tlearn: 0.1763663\ttotal: 38.8s\tremaining: 24.1s\n",
      "617:\tlearn: 0.1762988\ttotal: 38.9s\tremaining: 24s\n",
      "618:\tlearn: 0.1762175\ttotal: 38.9s\tremaining: 24s\n",
      "619:\tlearn: 0.1761585\ttotal: 39s\tremaining: 23.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "620:\tlearn: 0.1761003\ttotal: 39s\tremaining: 23.8s\n",
      "621:\tlearn: 0.1760318\ttotal: 39.1s\tremaining: 23.8s\n",
      "622:\tlearn: 0.1759594\ttotal: 39.2s\tremaining: 23.7s\n",
      "623:\tlearn: 0.1758869\ttotal: 39.2s\tremaining: 23.6s\n",
      "624:\tlearn: 0.1758200\ttotal: 39.3s\tremaining: 23.6s\n",
      "625:\tlearn: 0.1757525\ttotal: 39.4s\tremaining: 23.5s\n",
      "626:\tlearn: 0.1756801\ttotal: 39.5s\tremaining: 23.5s\n",
      "627:\tlearn: 0.1756058\ttotal: 39.5s\tremaining: 23.4s\n",
      "628:\tlearn: 0.1755455\ttotal: 39.6s\tremaining: 23.4s\n",
      "629:\tlearn: 0.1754772\ttotal: 39.7s\tremaining: 23.3s\n",
      "630:\tlearn: 0.1754035\ttotal: 39.7s\tremaining: 23.2s\n",
      "631:\tlearn: 0.1753397\ttotal: 39.8s\tremaining: 23.2s\n",
      "632:\tlearn: 0.1752822\ttotal: 39.8s\tremaining: 23.1s\n",
      "633:\tlearn: 0.1751976\ttotal: 39.9s\tremaining: 23s\n",
      "634:\tlearn: 0.1751206\ttotal: 40s\tremaining: 23s\n",
      "635:\tlearn: 0.1750435\ttotal: 40s\tremaining: 22.9s\n",
      "636:\tlearn: 0.1749721\ttotal: 40.1s\tremaining: 22.9s\n",
      "637:\tlearn: 0.1749015\ttotal: 40.2s\tremaining: 22.8s\n",
      "638:\tlearn: 0.1748261\ttotal: 40.2s\tremaining: 22.7s\n",
      "639:\tlearn: 0.1747560\ttotal: 40.3s\tremaining: 22.7s\n",
      "640:\tlearn: 0.1746925\ttotal: 40.4s\tremaining: 22.6s\n",
      "641:\tlearn: 0.1746256\ttotal: 40.4s\tremaining: 22.5s\n",
      "642:\tlearn: 0.1745637\ttotal: 40.5s\tremaining: 22.5s\n",
      "643:\tlearn: 0.1744894\ttotal: 40.5s\tremaining: 22.4s\n",
      "644:\tlearn: 0.1744172\ttotal: 40.6s\tremaining: 22.3s\n",
      "645:\tlearn: 0.1743373\ttotal: 40.7s\tremaining: 22.3s\n",
      "646:\tlearn: 0.1742789\ttotal: 40.7s\tremaining: 22.2s\n",
      "647:\tlearn: 0.1742160\ttotal: 40.8s\tremaining: 22.2s\n",
      "648:\tlearn: 0.1741728\ttotal: 40.8s\tremaining: 22.1s\n",
      "649:\tlearn: 0.1741145\ttotal: 40.9s\tremaining: 22s\n",
      "650:\tlearn: 0.1740368\ttotal: 41s\tremaining: 22s\n",
      "651:\tlearn: 0.1739906\ttotal: 41s\tremaining: 21.9s\n",
      "652:\tlearn: 0.1739257\ttotal: 41.1s\tremaining: 21.8s\n",
      "653:\tlearn: 0.1738538\ttotal: 41.2s\tremaining: 21.8s\n",
      "654:\tlearn: 0.1737889\ttotal: 41.2s\tremaining: 21.7s\n",
      "655:\tlearn: 0.1737279\ttotal: 41.3s\tremaining: 21.6s\n",
      "656:\tlearn: 0.1736559\ttotal: 41.3s\tremaining: 21.6s\n",
      "657:\tlearn: 0.1735940\ttotal: 41.4s\tremaining: 21.5s\n",
      "658:\tlearn: 0.1735277\ttotal: 41.5s\tremaining: 21.5s\n",
      "659:\tlearn: 0.1734531\ttotal: 41.5s\tremaining: 21.4s\n",
      "660:\tlearn: 0.1733949\ttotal: 41.6s\tremaining: 21.3s\n",
      "661:\tlearn: 0.1733255\ttotal: 41.6s\tremaining: 21.3s\n",
      "662:\tlearn: 0.1732413\ttotal: 41.7s\tremaining: 21.2s\n",
      "663:\tlearn: 0.1731771\ttotal: 41.8s\tremaining: 21.1s\n",
      "664:\tlearn: 0.1730992\ttotal: 41.8s\tremaining: 21.1s\n",
      "665:\tlearn: 0.1730420\ttotal: 41.9s\tremaining: 21s\n",
      "666:\tlearn: 0.1729816\ttotal: 41.9s\tremaining: 20.9s\n",
      "667:\tlearn: 0.1729240\ttotal: 42s\tremaining: 20.9s\n",
      "668:\tlearn: 0.1728598\ttotal: 42.1s\tremaining: 20.8s\n",
      "669:\tlearn: 0.1728031\ttotal: 42.1s\tremaining: 20.7s\n",
      "670:\tlearn: 0.1727442\ttotal: 42.2s\tremaining: 20.7s\n",
      "671:\tlearn: 0.1726748\ttotal: 42.2s\tremaining: 20.6s\n",
      "672:\tlearn: 0.1726201\ttotal: 42.3s\tremaining: 20.6s\n",
      "673:\tlearn: 0.1725709\ttotal: 42.4s\tremaining: 20.5s\n",
      "674:\tlearn: 0.1725003\ttotal: 42.4s\tremaining: 20.4s\n",
      "675:\tlearn: 0.1724416\ttotal: 42.5s\tremaining: 20.4s\n",
      "676:\tlearn: 0.1723760\ttotal: 42.5s\tremaining: 20.3s\n",
      "677:\tlearn: 0.1723051\ttotal: 42.6s\tremaining: 20.2s\n",
      "678:\tlearn: 0.1722309\ttotal: 42.7s\tremaining: 20.2s\n",
      "679:\tlearn: 0.1721811\ttotal: 42.7s\tremaining: 20.1s\n",
      "680:\tlearn: 0.1721053\ttotal: 42.8s\tremaining: 20.1s\n",
      "681:\tlearn: 0.1720401\ttotal: 42.9s\tremaining: 20s\n",
      "682:\tlearn: 0.1719798\ttotal: 42.9s\tremaining: 19.9s\n",
      "683:\tlearn: 0.1719162\ttotal: 43s\tremaining: 19.9s\n",
      "684:\tlearn: 0.1718460\ttotal: 43.1s\tremaining: 19.8s\n",
      "685:\tlearn: 0.1717806\ttotal: 43.1s\tremaining: 19.7s\n",
      "686:\tlearn: 0.1717232\ttotal: 43.2s\tremaining: 19.7s\n",
      "687:\tlearn: 0.1716564\ttotal: 43.2s\tremaining: 19.6s\n",
      "688:\tlearn: 0.1716056\ttotal: 43.3s\tremaining: 19.5s\n",
      "689:\tlearn: 0.1715304\ttotal: 43.4s\tremaining: 19.5s\n",
      "690:\tlearn: 0.1714644\ttotal: 43.4s\tremaining: 19.4s\n",
      "691:\tlearn: 0.1713921\ttotal: 43.5s\tremaining: 19.4s\n",
      "692:\tlearn: 0.1713245\ttotal: 43.6s\tremaining: 19.3s\n",
      "693:\tlearn: 0.1712529\ttotal: 43.6s\tremaining: 19.2s\n",
      "694:\tlearn: 0.1711847\ttotal: 43.7s\tremaining: 19.2s\n",
      "695:\tlearn: 0.1711255\ttotal: 43.7s\tremaining: 19.1s\n",
      "696:\tlearn: 0.1710530\ttotal: 43.8s\tremaining: 19s\n",
      "697:\tlearn: 0.1709923\ttotal: 43.9s\tremaining: 19s\n",
      "698:\tlearn: 0.1709334\ttotal: 43.9s\tremaining: 18.9s\n",
      "699:\tlearn: 0.1708722\ttotal: 44s\tremaining: 18.8s\n",
      "700:\tlearn: 0.1708260\ttotal: 44s\tremaining: 18.8s\n",
      "701:\tlearn: 0.1707558\ttotal: 44.1s\tremaining: 18.7s\n",
      "702:\tlearn: 0.1706896\ttotal: 44.1s\tremaining: 18.6s\n",
      "703:\tlearn: 0.1706232\ttotal: 44.2s\tremaining: 18.6s\n",
      "704:\tlearn: 0.1705544\ttotal: 44.3s\tremaining: 18.5s\n",
      "705:\tlearn: 0.1704978\ttotal: 44.3s\tremaining: 18.5s\n",
      "706:\tlearn: 0.1704361\ttotal: 44.4s\tremaining: 18.4s\n",
      "707:\tlearn: 0.1703762\ttotal: 44.5s\tremaining: 18.3s\n",
      "708:\tlearn: 0.1703061\ttotal: 44.5s\tremaining: 18.3s\n",
      "709:\tlearn: 0.1702411\ttotal: 44.6s\tremaining: 18.2s\n",
      "710:\tlearn: 0.1701784\ttotal: 44.7s\tremaining: 18.2s\n",
      "711:\tlearn: 0.1701096\ttotal: 44.8s\tremaining: 18.1s\n",
      "712:\tlearn: 0.1700374\ttotal: 44.8s\tremaining: 18.1s\n",
      "713:\tlearn: 0.1699774\ttotal: 44.9s\tremaining: 18s\n",
      "714:\tlearn: 0.1699114\ttotal: 45s\tremaining: 17.9s\n",
      "715:\tlearn: 0.1698465\ttotal: 45.1s\tremaining: 17.9s\n",
      "716:\tlearn: 0.1697813\ttotal: 45.2s\tremaining: 17.8s\n",
      "717:\tlearn: 0.1697270\ttotal: 45.2s\tremaining: 17.8s\n",
      "718:\tlearn: 0.1696564\ttotal: 45.3s\tremaining: 17.7s\n",
      "719:\tlearn: 0.1695936\ttotal: 45.4s\tremaining: 17.6s\n",
      "720:\tlearn: 0.1695210\ttotal: 45.4s\tremaining: 17.6s\n",
      "721:\tlearn: 0.1694405\ttotal: 45.5s\tremaining: 17.5s\n",
      "722:\tlearn: 0.1693697\ttotal: 45.6s\tremaining: 17.5s\n",
      "723:\tlearn: 0.1693125\ttotal: 45.6s\tremaining: 17.4s\n",
      "724:\tlearn: 0.1692473\ttotal: 45.7s\tremaining: 17.3s\n",
      "725:\tlearn: 0.1691823\ttotal: 45.7s\tremaining: 17.3s\n",
      "726:\tlearn: 0.1691133\ttotal: 45.8s\tremaining: 17.2s\n",
      "727:\tlearn: 0.1690492\ttotal: 45.8s\tremaining: 17.1s\n",
      "728:\tlearn: 0.1689830\ttotal: 45.9s\tremaining: 17.1s\n",
      "729:\tlearn: 0.1689283\ttotal: 46s\tremaining: 17s\n",
      "730:\tlearn: 0.1688715\ttotal: 46s\tremaining: 16.9s\n",
      "731:\tlearn: 0.1688138\ttotal: 46.1s\tremaining: 16.9s\n",
      "732:\tlearn: 0.1687509\ttotal: 46.1s\tremaining: 16.8s\n",
      "733:\tlearn: 0.1686865\ttotal: 46.2s\tremaining: 16.8s\n",
      "734:\tlearn: 0.1686247\ttotal: 46.3s\tremaining: 16.7s\n",
      "735:\tlearn: 0.1685635\ttotal: 46.3s\tremaining: 16.6s\n",
      "736:\tlearn: 0.1685011\ttotal: 46.4s\tremaining: 16.6s\n",
      "737:\tlearn: 0.1684493\ttotal: 46.5s\tremaining: 16.5s\n",
      "738:\tlearn: 0.1683776\ttotal: 46.5s\tremaining: 16.4s\n",
      "739:\tlearn: 0.1683398\ttotal: 46.6s\tremaining: 16.4s\n",
      "740:\tlearn: 0.1682856\ttotal: 46.7s\tremaining: 16.3s\n",
      "741:\tlearn: 0.1682336\ttotal: 46.7s\tremaining: 16.2s\n",
      "742:\tlearn: 0.1681631\ttotal: 46.8s\tremaining: 16.2s\n",
      "743:\tlearn: 0.1680921\ttotal: 46.9s\tremaining: 16.1s\n",
      "744:\tlearn: 0.1680443\ttotal: 46.9s\tremaining: 16.1s\n",
      "745:\tlearn: 0.1679831\ttotal: 47s\tremaining: 16s\n",
      "746:\tlearn: 0.1679220\ttotal: 47s\tremaining: 15.9s\n",
      "747:\tlearn: 0.1678722\ttotal: 47.1s\tremaining: 15.9s\n",
      "748:\tlearn: 0.1678178\ttotal: 47.2s\tremaining: 15.8s\n",
      "749:\tlearn: 0.1677525\ttotal: 47.2s\tremaining: 15.7s\n",
      "750:\tlearn: 0.1676983\ttotal: 47.3s\tremaining: 15.7s\n",
      "751:\tlearn: 0.1676317\ttotal: 47.4s\tremaining: 15.6s\n",
      "752:\tlearn: 0.1675727\ttotal: 47.4s\tremaining: 15.6s\n",
      "753:\tlearn: 0.1675188\ttotal: 47.5s\tremaining: 15.5s\n",
      "754:\tlearn: 0.1674540\ttotal: 47.6s\tremaining: 15.4s\n",
      "755:\tlearn: 0.1673873\ttotal: 47.6s\tremaining: 15.4s\n",
      "756:\tlearn: 0.1673194\ttotal: 47.7s\tremaining: 15.3s\n",
      "757:\tlearn: 0.1672460\ttotal: 47.7s\tremaining: 15.2s\n",
      "758:\tlearn: 0.1671884\ttotal: 47.8s\tremaining: 15.2s\n",
      "759:\tlearn: 0.1671146\ttotal: 47.9s\tremaining: 15.1s\n",
      "760:\tlearn: 0.1670700\ttotal: 47.9s\tremaining: 15.1s\n",
      "761:\tlearn: 0.1670144\ttotal: 48s\tremaining: 15s\n",
      "762:\tlearn: 0.1669644\ttotal: 48s\tremaining: 14.9s\n",
      "763:\tlearn: 0.1669142\ttotal: 48.1s\tremaining: 14.9s\n",
      "764:\tlearn: 0.1668557\ttotal: 48.2s\tremaining: 14.8s\n",
      "765:\tlearn: 0.1668073\ttotal: 48.2s\tremaining: 14.7s\n",
      "766:\tlearn: 0.1667515\ttotal: 48.3s\tremaining: 14.7s\n",
      "767:\tlearn: 0.1666861\ttotal: 48.3s\tremaining: 14.6s\n",
      "768:\tlearn: 0.1666238\ttotal: 48.4s\tremaining: 14.5s\n",
      "769:\tlearn: 0.1665631\ttotal: 48.5s\tremaining: 14.5s\n",
      "770:\tlearn: 0.1665085\ttotal: 48.5s\tremaining: 14.4s\n",
      "771:\tlearn: 0.1664522\ttotal: 48.6s\tremaining: 14.3s\n",
      "772:\tlearn: 0.1664055\ttotal: 48.6s\tremaining: 14.3s\n",
      "773:\tlearn: 0.1663577\ttotal: 48.7s\tremaining: 14.2s\n",
      "774:\tlearn: 0.1662993\ttotal: 48.8s\tremaining: 14.2s\n",
      "775:\tlearn: 0.1662328\ttotal: 48.8s\tremaining: 14.1s\n",
      "776:\tlearn: 0.1661794\ttotal: 48.9s\tremaining: 14s\n",
      "777:\tlearn: 0.1661263\ttotal: 48.9s\tremaining: 14s\n",
      "778:\tlearn: 0.1660642\ttotal: 49s\tremaining: 13.9s\n",
      "779:\tlearn: 0.1659988\ttotal: 49.1s\tremaining: 13.8s\n",
      "780:\tlearn: 0.1659517\ttotal: 49.1s\tremaining: 13.8s\n",
      "781:\tlearn: 0.1658988\ttotal: 49.2s\tremaining: 13.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782:\tlearn: 0.1658338\ttotal: 49.3s\tremaining: 13.7s\n",
      "783:\tlearn: 0.1657721\ttotal: 49.3s\tremaining: 13.6s\n",
      "784:\tlearn: 0.1657034\ttotal: 49.4s\tremaining: 13.5s\n",
      "785:\tlearn: 0.1656384\ttotal: 49.5s\tremaining: 13.5s\n",
      "786:\tlearn: 0.1655854\ttotal: 49.5s\tremaining: 13.4s\n",
      "787:\tlearn: 0.1655312\ttotal: 49.6s\tremaining: 13.3s\n",
      "788:\tlearn: 0.1654743\ttotal: 49.6s\tremaining: 13.3s\n",
      "789:\tlearn: 0.1653989\ttotal: 49.7s\tremaining: 13.2s\n",
      "790:\tlearn: 0.1653471\ttotal: 49.8s\tremaining: 13.1s\n",
      "791:\tlearn: 0.1652921\ttotal: 49.8s\tremaining: 13.1s\n",
      "792:\tlearn: 0.1652444\ttotal: 49.9s\tremaining: 13s\n",
      "793:\tlearn: 0.1651948\ttotal: 49.9s\tremaining: 13s\n",
      "794:\tlearn: 0.1651591\ttotal: 50s\tremaining: 12.9s\n",
      "795:\tlearn: 0.1650895\ttotal: 50s\tremaining: 12.8s\n",
      "796:\tlearn: 0.1650380\ttotal: 50.1s\tremaining: 12.8s\n",
      "797:\tlearn: 0.1649699\ttotal: 50.2s\tremaining: 12.7s\n",
      "798:\tlearn: 0.1649061\ttotal: 50.2s\tremaining: 12.6s\n",
      "799:\tlearn: 0.1648439\ttotal: 50.3s\tremaining: 12.6s\n",
      "800:\tlearn: 0.1647855\ttotal: 50.4s\tremaining: 12.5s\n",
      "801:\tlearn: 0.1647266\ttotal: 50.4s\tremaining: 12.4s\n",
      "802:\tlearn: 0.1646595\ttotal: 50.5s\tremaining: 12.4s\n",
      "803:\tlearn: 0.1646079\ttotal: 50.5s\tremaining: 12.3s\n",
      "804:\tlearn: 0.1645509\ttotal: 50.6s\tremaining: 12.3s\n",
      "805:\tlearn: 0.1644875\ttotal: 50.7s\tremaining: 12.2s\n",
      "806:\tlearn: 0.1644320\ttotal: 50.7s\tremaining: 12.1s\n",
      "807:\tlearn: 0.1643762\ttotal: 50.8s\tremaining: 12.1s\n",
      "808:\tlearn: 0.1643158\ttotal: 50.9s\tremaining: 12s\n",
      "809:\tlearn: 0.1642582\ttotal: 50.9s\tremaining: 11.9s\n",
      "810:\tlearn: 0.1642041\ttotal: 51s\tremaining: 11.9s\n",
      "811:\tlearn: 0.1641399\ttotal: 51s\tremaining: 11.8s\n",
      "812:\tlearn: 0.1640875\ttotal: 51.1s\tremaining: 11.8s\n",
      "813:\tlearn: 0.1640369\ttotal: 51.2s\tremaining: 11.7s\n",
      "814:\tlearn: 0.1639971\ttotal: 51.2s\tremaining: 11.6s\n",
      "815:\tlearn: 0.1639455\ttotal: 51.3s\tremaining: 11.6s\n",
      "816:\tlearn: 0.1638918\ttotal: 51.4s\tremaining: 11.5s\n",
      "817:\tlearn: 0.1638361\ttotal: 51.4s\tremaining: 11.4s\n",
      "818:\tlearn: 0.1637739\ttotal: 51.5s\tremaining: 11.4s\n",
      "819:\tlearn: 0.1637148\ttotal: 51.6s\tremaining: 11.3s\n",
      "820:\tlearn: 0.1636586\ttotal: 51.6s\tremaining: 11.3s\n",
      "821:\tlearn: 0.1635901\ttotal: 51.7s\tremaining: 11.2s\n",
      "822:\tlearn: 0.1635367\ttotal: 51.7s\tremaining: 11.1s\n",
      "823:\tlearn: 0.1634795\ttotal: 51.8s\tremaining: 11.1s\n",
      "824:\tlearn: 0.1634140\ttotal: 51.8s\tremaining: 11s\n",
      "825:\tlearn: 0.1633616\ttotal: 51.9s\tremaining: 10.9s\n",
      "826:\tlearn: 0.1633069\ttotal: 52s\tremaining: 10.9s\n",
      "827:\tlearn: 0.1632463\ttotal: 52s\tremaining: 10.8s\n",
      "828:\tlearn: 0.1631807\ttotal: 52.1s\tremaining: 10.7s\n",
      "829:\tlearn: 0.1631136\ttotal: 52.2s\tremaining: 10.7s\n",
      "830:\tlearn: 0.1630541\ttotal: 52.2s\tremaining: 10.6s\n",
      "831:\tlearn: 0.1629895\ttotal: 52.3s\tremaining: 10.6s\n",
      "832:\tlearn: 0.1629407\ttotal: 52.4s\tremaining: 10.5s\n",
      "833:\tlearn: 0.1628821\ttotal: 52.4s\tremaining: 10.4s\n",
      "834:\tlearn: 0.1628342\ttotal: 52.5s\tremaining: 10.4s\n",
      "835:\tlearn: 0.1627798\ttotal: 52.5s\tremaining: 10.3s\n",
      "836:\tlearn: 0.1627214\ttotal: 52.6s\tremaining: 10.2s\n",
      "837:\tlearn: 0.1626550\ttotal: 52.6s\tremaining: 10.2s\n",
      "838:\tlearn: 0.1626012\ttotal: 52.7s\tremaining: 10.1s\n",
      "839:\tlearn: 0.1625418\ttotal: 52.8s\tremaining: 10.1s\n",
      "840:\tlearn: 0.1624843\ttotal: 52.8s\tremaining: 9.99s\n",
      "841:\tlearn: 0.1624201\ttotal: 52.9s\tremaining: 9.93s\n",
      "842:\tlearn: 0.1623703\ttotal: 53s\tremaining: 9.86s\n",
      "843:\tlearn: 0.1623193\ttotal: 53s\tremaining: 9.8s\n",
      "844:\tlearn: 0.1622597\ttotal: 53.1s\tremaining: 9.74s\n",
      "845:\tlearn: 0.1622089\ttotal: 53.2s\tremaining: 9.68s\n",
      "846:\tlearn: 0.1621613\ttotal: 53.2s\tremaining: 9.62s\n",
      "847:\tlearn: 0.1621028\ttotal: 53.3s\tremaining: 9.55s\n",
      "848:\tlearn: 0.1620429\ttotal: 53.4s\tremaining: 9.49s\n",
      "849:\tlearn: 0.1619848\ttotal: 53.4s\tremaining: 9.43s\n",
      "850:\tlearn: 0.1619250\ttotal: 53.5s\tremaining: 9.37s\n",
      "851:\tlearn: 0.1618643\ttotal: 53.6s\tremaining: 9.3s\n",
      "852:\tlearn: 0.1618244\ttotal: 53.6s\tremaining: 9.24s\n",
      "853:\tlearn: 0.1617669\ttotal: 53.7s\tremaining: 9.18s\n",
      "854:\tlearn: 0.1617247\ttotal: 53.8s\tremaining: 9.12s\n",
      "855:\tlearn: 0.1616732\ttotal: 53.8s\tremaining: 9.05s\n",
      "856:\tlearn: 0.1616213\ttotal: 53.9s\tremaining: 8.99s\n",
      "857:\tlearn: 0.1615749\ttotal: 53.9s\tremaining: 8.93s\n",
      "858:\tlearn: 0.1615145\ttotal: 54s\tremaining: 8.86s\n",
      "859:\tlearn: 0.1614681\ttotal: 54.1s\tremaining: 8.8s\n",
      "860:\tlearn: 0.1614207\ttotal: 54.1s\tremaining: 8.74s\n",
      "861:\tlearn: 0.1613711\ttotal: 54.2s\tremaining: 8.68s\n",
      "862:\tlearn: 0.1613068\ttotal: 54.3s\tremaining: 8.61s\n",
      "863:\tlearn: 0.1612468\ttotal: 54.3s\tremaining: 8.55s\n",
      "864:\tlearn: 0.1611954\ttotal: 54.4s\tremaining: 8.49s\n",
      "865:\tlearn: 0.1611460\ttotal: 54.5s\tremaining: 8.43s\n",
      "866:\tlearn: 0.1610932\ttotal: 54.5s\tremaining: 8.36s\n",
      "867:\tlearn: 0.1610425\ttotal: 54.6s\tremaining: 8.3s\n",
      "868:\tlearn: 0.1609856\ttotal: 54.6s\tremaining: 8.23s\n",
      "869:\tlearn: 0.1609353\ttotal: 54.7s\tremaining: 8.17s\n",
      "870:\tlearn: 0.1608858\ttotal: 54.8s\tremaining: 8.11s\n",
      "871:\tlearn: 0.1608244\ttotal: 54.8s\tremaining: 8.05s\n",
      "872:\tlearn: 0.1607803\ttotal: 54.9s\tremaining: 7.99s\n",
      "873:\tlearn: 0.1607225\ttotal: 55s\tremaining: 7.93s\n",
      "874:\tlearn: 0.1606601\ttotal: 55.1s\tremaining: 7.86s\n",
      "875:\tlearn: 0.1605840\ttotal: 55.1s\tremaining: 7.8s\n",
      "876:\tlearn: 0.1605254\ttotal: 55.2s\tremaining: 7.74s\n",
      "877:\tlearn: 0.1604682\ttotal: 55.2s\tremaining: 7.68s\n",
      "878:\tlearn: 0.1604139\ttotal: 55.3s\tremaining: 7.61s\n",
      "879:\tlearn: 0.1603624\ttotal: 55.4s\tremaining: 7.55s\n",
      "880:\tlearn: 0.1603184\ttotal: 55.4s\tremaining: 7.49s\n",
      "881:\tlearn: 0.1602693\ttotal: 55.5s\tremaining: 7.43s\n",
      "882:\tlearn: 0.1602087\ttotal: 55.6s\tremaining: 7.37s\n",
      "883:\tlearn: 0.1601652\ttotal: 55.6s\tremaining: 7.3s\n",
      "884:\tlearn: 0.1601175\ttotal: 55.7s\tremaining: 7.24s\n",
      "885:\tlearn: 0.1600625\ttotal: 55.8s\tremaining: 7.18s\n",
      "886:\tlearn: 0.1599975\ttotal: 55.9s\tremaining: 7.12s\n",
      "887:\tlearn: 0.1599368\ttotal: 55.9s\tremaining: 7.05s\n",
      "888:\tlearn: 0.1598751\ttotal: 56s\tremaining: 6.99s\n",
      "889:\tlearn: 0.1598264\ttotal: 56.1s\tremaining: 6.93s\n",
      "890:\tlearn: 0.1597775\ttotal: 56.1s\tremaining: 6.87s\n",
      "891:\tlearn: 0.1597250\ttotal: 56.2s\tremaining: 6.8s\n",
      "892:\tlearn: 0.1596755\ttotal: 56.2s\tremaining: 6.74s\n",
      "893:\tlearn: 0.1596293\ttotal: 56.3s\tremaining: 6.68s\n",
      "894:\tlearn: 0.1595687\ttotal: 56.4s\tremaining: 6.62s\n",
      "895:\tlearn: 0.1595294\ttotal: 56.5s\tremaining: 6.55s\n",
      "896:\tlearn: 0.1594776\ttotal: 56.5s\tremaining: 6.49s\n",
      "897:\tlearn: 0.1594200\ttotal: 56.6s\tremaining: 6.43s\n",
      "898:\tlearn: 0.1593445\ttotal: 56.7s\tremaining: 6.37s\n",
      "899:\tlearn: 0.1592955\ttotal: 56.8s\tremaining: 6.31s\n",
      "900:\tlearn: 0.1592409\ttotal: 56.9s\tremaining: 6.25s\n",
      "901:\tlearn: 0.1591826\ttotal: 57s\tremaining: 6.19s\n",
      "902:\tlearn: 0.1591352\ttotal: 57.1s\tremaining: 6.13s\n",
      "903:\tlearn: 0.1591057\ttotal: 57.1s\tremaining: 6.07s\n",
      "904:\tlearn: 0.1590496\ttotal: 57.2s\tremaining: 6s\n",
      "905:\tlearn: 0.1589867\ttotal: 57.3s\tremaining: 5.94s\n",
      "906:\tlearn: 0.1589496\ttotal: 57.3s\tremaining: 5.88s\n",
      "907:\tlearn: 0.1588963\ttotal: 57.4s\tremaining: 5.82s\n",
      "908:\tlearn: 0.1588311\ttotal: 57.5s\tremaining: 5.75s\n",
      "909:\tlearn: 0.1587743\ttotal: 57.5s\tremaining: 5.69s\n",
      "910:\tlearn: 0.1587262\ttotal: 57.6s\tremaining: 5.63s\n",
      "911:\tlearn: 0.1586818\ttotal: 57.7s\tremaining: 5.57s\n",
      "912:\tlearn: 0.1586187\ttotal: 57.8s\tremaining: 5.5s\n",
      "913:\tlearn: 0.1585685\ttotal: 57.8s\tremaining: 5.44s\n",
      "914:\tlearn: 0.1585045\ttotal: 57.9s\tremaining: 5.38s\n",
      "915:\tlearn: 0.1584451\ttotal: 58s\tremaining: 5.32s\n",
      "916:\tlearn: 0.1583878\ttotal: 58s\tremaining: 5.25s\n",
      "917:\tlearn: 0.1583364\ttotal: 58.1s\tremaining: 5.19s\n",
      "918:\tlearn: 0.1582993\ttotal: 58.2s\tremaining: 5.13s\n",
      "919:\tlearn: 0.1582583\ttotal: 58.2s\tremaining: 5.07s\n",
      "920:\tlearn: 0.1582064\ttotal: 58.3s\tremaining: 5s\n",
      "921:\tlearn: 0.1581478\ttotal: 58.4s\tremaining: 4.94s\n",
      "922:\tlearn: 0.1581020\ttotal: 58.5s\tremaining: 4.88s\n",
      "923:\tlearn: 0.1580477\ttotal: 58.5s\tremaining: 4.81s\n",
      "924:\tlearn: 0.1579937\ttotal: 58.6s\tremaining: 4.75s\n",
      "925:\tlearn: 0.1579330\ttotal: 58.7s\tremaining: 4.69s\n",
      "926:\tlearn: 0.1578790\ttotal: 58.7s\tremaining: 4.63s\n",
      "927:\tlearn: 0.1578160\ttotal: 58.8s\tremaining: 4.56s\n",
      "928:\tlearn: 0.1577646\ttotal: 58.9s\tremaining: 4.5s\n",
      "929:\tlearn: 0.1577111\ttotal: 59s\tremaining: 4.44s\n",
      "930:\tlearn: 0.1576591\ttotal: 59s\tremaining: 4.38s\n",
      "931:\tlearn: 0.1576037\ttotal: 59.1s\tremaining: 4.31s\n",
      "932:\tlearn: 0.1575446\ttotal: 59.2s\tremaining: 4.25s\n",
      "933:\tlearn: 0.1574828\ttotal: 59.3s\tremaining: 4.19s\n",
      "934:\tlearn: 0.1574185\ttotal: 59.4s\tremaining: 4.13s\n",
      "935:\tlearn: 0.1573673\ttotal: 59.4s\tremaining: 4.06s\n",
      "936:\tlearn: 0.1573224\ttotal: 59.5s\tremaining: 4s\n",
      "937:\tlearn: 0.1572720\ttotal: 59.6s\tremaining: 3.94s\n",
      "938:\tlearn: 0.1572218\ttotal: 59.7s\tremaining: 3.88s\n",
      "939:\tlearn: 0.1571811\ttotal: 59.7s\tremaining: 3.81s\n",
      "940:\tlearn: 0.1571288\ttotal: 59.8s\tremaining: 3.75s\n",
      "941:\tlearn: 0.1570610\ttotal: 59.9s\tremaining: 3.69s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "942:\tlearn: 0.1570058\ttotal: 60s\tremaining: 3.63s\n",
      "943:\tlearn: 0.1569681\ttotal: 1m\tremaining: 3.56s\n",
      "944:\tlearn: 0.1569128\ttotal: 1m\tremaining: 3.5s\n",
      "945:\tlearn: 0.1568601\ttotal: 1m\tremaining: 3.44s\n",
      "946:\tlearn: 0.1568115\ttotal: 1m\tremaining: 3.37s\n",
      "947:\tlearn: 0.1567578\ttotal: 1m\tremaining: 3.31s\n",
      "948:\tlearn: 0.1567061\ttotal: 1m\tremaining: 3.25s\n",
      "949:\tlearn: 0.1566582\ttotal: 1m\tremaining: 3.18s\n",
      "950:\tlearn: 0.1566145\ttotal: 1m\tremaining: 3.12s\n",
      "951:\tlearn: 0.1565547\ttotal: 1m\tremaining: 3.06s\n",
      "952:\tlearn: 0.1565095\ttotal: 1m\tremaining: 2.99s\n",
      "953:\tlearn: 0.1564517\ttotal: 1m\tremaining: 2.93s\n",
      "954:\tlearn: 0.1564068\ttotal: 1m\tremaining: 2.87s\n",
      "955:\tlearn: 0.1563678\ttotal: 1m\tremaining: 2.8s\n",
      "956:\tlearn: 0.1563121\ttotal: 1m\tremaining: 2.74s\n",
      "957:\tlearn: 0.1562427\ttotal: 1m 1s\tremaining: 2.68s\n",
      "958:\tlearn: 0.1561902\ttotal: 1m 1s\tremaining: 2.61s\n",
      "959:\tlearn: 0.1561429\ttotal: 1m 1s\tremaining: 2.55s\n",
      "960:\tlearn: 0.1560831\ttotal: 1m 1s\tremaining: 2.49s\n",
      "961:\tlearn: 0.1560373\ttotal: 1m 1s\tremaining: 2.42s\n",
      "962:\tlearn: 0.1559847\ttotal: 1m 1s\tremaining: 2.36s\n",
      "963:\tlearn: 0.1559337\ttotal: 1m 1s\tremaining: 2.29s\n",
      "964:\tlearn: 0.1558776\ttotal: 1m 1s\tremaining: 2.23s\n",
      "965:\tlearn: 0.1558282\ttotal: 1m 1s\tremaining: 2.17s\n",
      "966:\tlearn: 0.1557831\ttotal: 1m 1s\tremaining: 2.1s\n",
      "967:\tlearn: 0.1557329\ttotal: 1m 1s\tremaining: 2.04s\n",
      "968:\tlearn: 0.1556778\ttotal: 1m 1s\tremaining: 1.98s\n",
      "969:\tlearn: 0.1556404\ttotal: 1m 1s\tremaining: 1.91s\n",
      "970:\tlearn: 0.1555798\ttotal: 1m 1s\tremaining: 1.85s\n",
      "971:\tlearn: 0.1555260\ttotal: 1m 2s\tremaining: 1.79s\n",
      "972:\tlearn: 0.1554674\ttotal: 1m 2s\tremaining: 1.72s\n",
      "973:\tlearn: 0.1554160\ttotal: 1m 2s\tremaining: 1.66s\n",
      "974:\tlearn: 0.1553524\ttotal: 1m 2s\tremaining: 1.59s\n",
      "975:\tlearn: 0.1553114\ttotal: 1m 2s\tremaining: 1.53s\n",
      "976:\tlearn: 0.1552612\ttotal: 1m 2s\tremaining: 1.47s\n",
      "977:\tlearn: 0.1552271\ttotal: 1m 2s\tremaining: 1.4s\n",
      "978:\tlearn: 0.1551730\ttotal: 1m 2s\tremaining: 1.34s\n",
      "979:\tlearn: 0.1551154\ttotal: 1m 2s\tremaining: 1.28s\n",
      "980:\tlearn: 0.1550626\ttotal: 1m 2s\tremaining: 1.21s\n",
      "981:\tlearn: 0.1550118\ttotal: 1m 2s\tremaining: 1.15s\n",
      "982:\tlearn: 0.1549595\ttotal: 1m 2s\tremaining: 1.08s\n",
      "983:\tlearn: 0.1549093\ttotal: 1m 2s\tremaining: 1.02s\n",
      "984:\tlearn: 0.1548655\ttotal: 1m 2s\tremaining: 958ms\n",
      "985:\tlearn: 0.1548192\ttotal: 1m 2s\tremaining: 894ms\n",
      "986:\tlearn: 0.1547652\ttotal: 1m 3s\tremaining: 830ms\n",
      "987:\tlearn: 0.1547234\ttotal: 1m 3s\tremaining: 766ms\n",
      "988:\tlearn: 0.1546842\ttotal: 1m 3s\tremaining: 702ms\n",
      "989:\tlearn: 0.1546303\ttotal: 1m 3s\tremaining: 638ms\n",
      "990:\tlearn: 0.1545626\ttotal: 1m 3s\tremaining: 574ms\n",
      "991:\tlearn: 0.1544922\ttotal: 1m 3s\tremaining: 511ms\n",
      "992:\tlearn: 0.1544258\ttotal: 1m 3s\tremaining: 447ms\n",
      "993:\tlearn: 0.1543811\ttotal: 1m 3s\tremaining: 383ms\n",
      "994:\tlearn: 0.1543327\ttotal: 1m 3s\tremaining: 319ms\n",
      "995:\tlearn: 0.1542852\ttotal: 1m 3s\tremaining: 255ms\n",
      "996:\tlearn: 0.1542424\ttotal: 1m 3s\tremaining: 192ms\n",
      "997:\tlearn: 0.1541843\ttotal: 1m 3s\tremaining: 128ms\n",
      "998:\tlearn: 0.1541273\ttotal: 1m 3s\tremaining: 63.8ms\n",
      "999:\tlearn: 0.1540818\ttotal: 1m 3s\tremaining: 0us\n",
      "Learning rate set to 0.09461\n",
      "0:\tlearn: 0.6142003\ttotal: 68.4ms\tremaining: 1m 8s\n",
      "1:\tlearn: 0.5503187\ttotal: 137ms\tremaining: 1m 8s\n",
      "2:\tlearn: 0.5016186\ttotal: 211ms\tremaining: 1m 10s\n",
      "3:\tlearn: 0.4635842\ttotal: 282ms\tremaining: 1m 10s\n",
      "4:\tlearn: 0.4323198\ttotal: 353ms\tremaining: 1m 10s\n",
      "5:\tlearn: 0.4076154\ttotal: 417ms\tremaining: 1m 9s\n",
      "6:\tlearn: 0.3881284\ttotal: 491ms\tremaining: 1m 9s\n",
      "7:\tlearn: 0.3723465\ttotal: 560ms\tremaining: 1m 9s\n",
      "8:\tlearn: 0.3594818\ttotal: 619ms\tremaining: 1m 8s\n",
      "9:\tlearn: 0.3492471\ttotal: 684ms\tremaining: 1m 7s\n",
      "10:\tlearn: 0.3405367\ttotal: 741ms\tremaining: 1m 6s\n",
      "11:\tlearn: 0.3328931\ttotal: 798ms\tremaining: 1m 5s\n",
      "12:\tlearn: 0.3270113\ttotal: 856ms\tremaining: 1m 5s\n",
      "13:\tlearn: 0.3218490\ttotal: 923ms\tremaining: 1m 4s\n",
      "14:\tlearn: 0.3176815\ttotal: 988ms\tremaining: 1m 4s\n",
      "15:\tlearn: 0.3141138\ttotal: 1.05s\tremaining: 1m 4s\n",
      "16:\tlearn: 0.3109679\ttotal: 1.12s\tremaining: 1m 4s\n",
      "17:\tlearn: 0.3082210\ttotal: 1.19s\tremaining: 1m 4s\n",
      "18:\tlearn: 0.3057762\ttotal: 1.25s\tremaining: 1m 4s\n",
      "19:\tlearn: 0.3035685\ttotal: 1.32s\tremaining: 1m 4s\n",
      "20:\tlearn: 0.3016398\ttotal: 1.37s\tremaining: 1m 4s\n",
      "21:\tlearn: 0.2999565\ttotal: 1.43s\tremaining: 1m 3s\n",
      "22:\tlearn: 0.2984828\ttotal: 1.49s\tremaining: 1m 3s\n",
      "23:\tlearn: 0.2971086\ttotal: 1.54s\tremaining: 1m 2s\n",
      "24:\tlearn: 0.2957584\ttotal: 1.6s\tremaining: 1m 2s\n",
      "25:\tlearn: 0.2944947\ttotal: 1.66s\tremaining: 1m 2s\n",
      "26:\tlearn: 0.2933454\ttotal: 1.73s\tremaining: 1m 2s\n",
      "27:\tlearn: 0.2921450\ttotal: 1.8s\tremaining: 1m 2s\n",
      "28:\tlearn: 0.2910960\ttotal: 1.85s\tremaining: 1m 2s\n",
      "29:\tlearn: 0.2900768\ttotal: 1.9s\tremaining: 1m 1s\n",
      "30:\tlearn: 0.2890227\ttotal: 1.96s\tremaining: 1m 1s\n",
      "31:\tlearn: 0.2880148\ttotal: 2.01s\tremaining: 1m\n",
      "32:\tlearn: 0.2871129\ttotal: 2.07s\tremaining: 1m\n",
      "33:\tlearn: 0.2862540\ttotal: 2.12s\tremaining: 1m\n",
      "34:\tlearn: 0.2854167\ttotal: 2.2s\tremaining: 1m\n",
      "35:\tlearn: 0.2845987\ttotal: 2.27s\tremaining: 1m\n",
      "36:\tlearn: 0.2838101\ttotal: 2.33s\tremaining: 1m\n",
      "37:\tlearn: 0.2829762\ttotal: 2.4s\tremaining: 1m\n",
      "38:\tlearn: 0.2821819\ttotal: 2.47s\tremaining: 1m\n",
      "39:\tlearn: 0.2814068\ttotal: 2.54s\tremaining: 1m\n",
      "40:\tlearn: 0.2806658\ttotal: 2.6s\tremaining: 1m\n",
      "41:\tlearn: 0.2798945\ttotal: 2.66s\tremaining: 1m\n",
      "42:\tlearn: 0.2791457\ttotal: 2.73s\tremaining: 1m\n",
      "43:\tlearn: 0.2783984\ttotal: 2.79s\tremaining: 1m\n",
      "44:\tlearn: 0.2776929\ttotal: 2.86s\tremaining: 1m\n",
      "45:\tlearn: 0.2770031\ttotal: 2.92s\tremaining: 1m\n",
      "46:\tlearn: 0.2763120\ttotal: 2.99s\tremaining: 1m\n",
      "47:\tlearn: 0.2756568\ttotal: 3.06s\tremaining: 1m\n",
      "48:\tlearn: 0.2749841\ttotal: 3.12s\tremaining: 1m\n",
      "49:\tlearn: 0.2742841\ttotal: 3.17s\tremaining: 1m\n",
      "50:\tlearn: 0.2736555\ttotal: 3.22s\tremaining: 60s\n",
      "51:\tlearn: 0.2730078\ttotal: 3.28s\tremaining: 59.9s\n",
      "52:\tlearn: 0.2723743\ttotal: 3.34s\tremaining: 59.8s\n",
      "53:\tlearn: 0.2717620\ttotal: 3.4s\tremaining: 59.6s\n",
      "54:\tlearn: 0.2711122\ttotal: 3.46s\tremaining: 59.5s\n",
      "55:\tlearn: 0.2705438\ttotal: 3.51s\tremaining: 59.2s\n",
      "56:\tlearn: 0.2699483\ttotal: 3.57s\tremaining: 59s\n",
      "57:\tlearn: 0.2693635\ttotal: 3.63s\tremaining: 59s\n",
      "58:\tlearn: 0.2688097\ttotal: 3.69s\tremaining: 58.8s\n",
      "59:\tlearn: 0.2682844\ttotal: 3.75s\tremaining: 58.7s\n",
      "60:\tlearn: 0.2676818\ttotal: 3.81s\tremaining: 58.7s\n",
      "61:\tlearn: 0.2671533\ttotal: 3.87s\tremaining: 58.5s\n",
      "62:\tlearn: 0.2665931\ttotal: 3.94s\tremaining: 58.6s\n",
      "63:\tlearn: 0.2660691\ttotal: 4s\tremaining: 58.5s\n",
      "64:\tlearn: 0.2655353\ttotal: 4.06s\tremaining: 58.4s\n",
      "65:\tlearn: 0.2649942\ttotal: 4.12s\tremaining: 58.3s\n",
      "66:\tlearn: 0.2645083\ttotal: 4.18s\tremaining: 58.2s\n",
      "67:\tlearn: 0.2639811\ttotal: 4.24s\tremaining: 58.1s\n",
      "68:\tlearn: 0.2634738\ttotal: 4.31s\tremaining: 58.2s\n",
      "69:\tlearn: 0.2629611\ttotal: 4.37s\tremaining: 58s\n",
      "70:\tlearn: 0.2624531\ttotal: 4.43s\tremaining: 58s\n",
      "71:\tlearn: 0.2619532\ttotal: 4.5s\tremaining: 58s\n",
      "72:\tlearn: 0.2614686\ttotal: 4.56s\tremaining: 57.9s\n",
      "73:\tlearn: 0.2609845\ttotal: 4.62s\tremaining: 57.8s\n",
      "74:\tlearn: 0.2604967\ttotal: 4.67s\tremaining: 57.7s\n",
      "75:\tlearn: 0.2600224\ttotal: 4.74s\tremaining: 57.6s\n",
      "76:\tlearn: 0.2595238\ttotal: 4.81s\tremaining: 57.6s\n",
      "77:\tlearn: 0.2590719\ttotal: 4.88s\tremaining: 57.6s\n",
      "78:\tlearn: 0.2586071\ttotal: 4.94s\tremaining: 57.6s\n",
      "79:\tlearn: 0.2581604\ttotal: 5s\tremaining: 57.5s\n",
      "80:\tlearn: 0.2576945\ttotal: 5.06s\tremaining: 57.4s\n",
      "81:\tlearn: 0.2572469\ttotal: 5.13s\tremaining: 57.4s\n",
      "82:\tlearn: 0.2567906\ttotal: 5.19s\tremaining: 57.4s\n",
      "83:\tlearn: 0.2563754\ttotal: 5.25s\tremaining: 57.3s\n",
      "84:\tlearn: 0.2559514\ttotal: 5.32s\tremaining: 57.3s\n",
      "85:\tlearn: 0.2555171\ttotal: 5.37s\tremaining: 57.1s\n",
      "86:\tlearn: 0.2551228\ttotal: 5.43s\tremaining: 57s\n",
      "87:\tlearn: 0.2547186\ttotal: 5.49s\tremaining: 56.9s\n",
      "88:\tlearn: 0.2543157\ttotal: 5.55s\tremaining: 56.8s\n",
      "89:\tlearn: 0.2539104\ttotal: 5.61s\tremaining: 56.7s\n",
      "90:\tlearn: 0.2535399\ttotal: 5.67s\tremaining: 56.7s\n",
      "91:\tlearn: 0.2530999\ttotal: 5.74s\tremaining: 56.6s\n",
      "92:\tlearn: 0.2527070\ttotal: 5.8s\tremaining: 56.6s\n",
      "93:\tlearn: 0.2523179\ttotal: 5.86s\tremaining: 56.5s\n",
      "94:\tlearn: 0.2518932\ttotal: 5.93s\tremaining: 56.5s\n",
      "95:\tlearn: 0.2515205\ttotal: 5.99s\tremaining: 56.4s\n",
      "96:\tlearn: 0.2511560\ttotal: 6.05s\tremaining: 56.4s\n",
      "97:\tlearn: 0.2507849\ttotal: 6.12s\tremaining: 56.3s\n",
      "98:\tlearn: 0.2503941\ttotal: 6.19s\tremaining: 56.3s\n",
      "99:\tlearn: 0.2500353\ttotal: 6.25s\tremaining: 56.3s\n",
      "100:\tlearn: 0.2496902\ttotal: 6.32s\tremaining: 56.3s\n",
      "101:\tlearn: 0.2493093\ttotal: 6.38s\tremaining: 56.2s\n",
      "102:\tlearn: 0.2489961\ttotal: 6.44s\tremaining: 56.1s\n",
      "103:\tlearn: 0.2486478\ttotal: 6.5s\tremaining: 56s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104:\tlearn: 0.2482879\ttotal: 6.57s\tremaining: 56s\n",
      "105:\tlearn: 0.2479141\ttotal: 6.63s\tremaining: 55.9s\n",
      "106:\tlearn: 0.2475528\ttotal: 6.69s\tremaining: 55.8s\n",
      "107:\tlearn: 0.2472053\ttotal: 6.75s\tremaining: 55.7s\n",
      "108:\tlearn: 0.2468785\ttotal: 6.8s\tremaining: 55.6s\n",
      "109:\tlearn: 0.2465297\ttotal: 6.87s\tremaining: 55.6s\n",
      "110:\tlearn: 0.2462089\ttotal: 6.93s\tremaining: 55.5s\n",
      "111:\tlearn: 0.2458324\ttotal: 7s\tremaining: 55.5s\n",
      "112:\tlearn: 0.2455036\ttotal: 7.06s\tremaining: 55.4s\n",
      "113:\tlearn: 0.2451603\ttotal: 7.13s\tremaining: 55.4s\n",
      "114:\tlearn: 0.2448446\ttotal: 7.2s\tremaining: 55.4s\n",
      "115:\tlearn: 0.2445427\ttotal: 7.25s\tremaining: 55.3s\n",
      "116:\tlearn: 0.2442481\ttotal: 7.31s\tremaining: 55.1s\n",
      "117:\tlearn: 0.2439385\ttotal: 7.36s\tremaining: 55s\n",
      "118:\tlearn: 0.2436078\ttotal: 7.42s\tremaining: 54.9s\n",
      "119:\tlearn: 0.2433113\ttotal: 7.49s\tremaining: 54.9s\n",
      "120:\tlearn: 0.2429909\ttotal: 7.55s\tremaining: 54.9s\n",
      "121:\tlearn: 0.2426676\ttotal: 7.63s\tremaining: 54.9s\n",
      "122:\tlearn: 0.2423685\ttotal: 7.7s\tremaining: 54.9s\n",
      "123:\tlearn: 0.2420523\ttotal: 7.76s\tremaining: 54.8s\n",
      "124:\tlearn: 0.2417268\ttotal: 7.81s\tremaining: 54.7s\n",
      "125:\tlearn: 0.2414498\ttotal: 7.87s\tremaining: 54.6s\n",
      "126:\tlearn: 0.2411214\ttotal: 7.93s\tremaining: 54.5s\n",
      "127:\tlearn: 0.2408316\ttotal: 8s\tremaining: 54.5s\n",
      "128:\tlearn: 0.2405227\ttotal: 8.07s\tremaining: 54.5s\n",
      "129:\tlearn: 0.2402415\ttotal: 8.13s\tremaining: 54.4s\n",
      "130:\tlearn: 0.2399418\ttotal: 8.21s\tremaining: 54.5s\n",
      "131:\tlearn: 0.2396118\ttotal: 8.3s\tremaining: 54.6s\n",
      "132:\tlearn: 0.2392950\ttotal: 8.37s\tremaining: 54.5s\n",
      "133:\tlearn: 0.2390023\ttotal: 8.43s\tremaining: 54.5s\n",
      "134:\tlearn: 0.2386945\ttotal: 8.49s\tremaining: 54.4s\n",
      "135:\tlearn: 0.2384251\ttotal: 8.54s\tremaining: 54.3s\n",
      "136:\tlearn: 0.2381300\ttotal: 8.61s\tremaining: 54.2s\n",
      "137:\tlearn: 0.2378647\ttotal: 8.66s\tremaining: 54.1s\n",
      "138:\tlearn: 0.2375987\ttotal: 8.73s\tremaining: 54.1s\n",
      "139:\tlearn: 0.2373076\ttotal: 8.79s\tremaining: 54s\n",
      "140:\tlearn: 0.2370427\ttotal: 8.84s\tremaining: 53.9s\n",
      "141:\tlearn: 0.2367536\ttotal: 8.91s\tremaining: 53.9s\n",
      "142:\tlearn: 0.2364627\ttotal: 8.98s\tremaining: 53.8s\n",
      "143:\tlearn: 0.2362059\ttotal: 9.05s\tremaining: 53.8s\n",
      "144:\tlearn: 0.2359333\ttotal: 9.11s\tremaining: 53.7s\n",
      "145:\tlearn: 0.2356425\ttotal: 9.18s\tremaining: 53.7s\n",
      "146:\tlearn: 0.2353651\ttotal: 9.25s\tremaining: 53.7s\n",
      "147:\tlearn: 0.2350904\ttotal: 9.33s\tremaining: 53.7s\n",
      "148:\tlearn: 0.2348402\ttotal: 9.38s\tremaining: 53.6s\n",
      "149:\tlearn: 0.2345860\ttotal: 9.44s\tremaining: 53.5s\n",
      "150:\tlearn: 0.2343149\ttotal: 9.5s\tremaining: 53.4s\n",
      "151:\tlearn: 0.2340579\ttotal: 9.55s\tremaining: 53.3s\n",
      "152:\tlearn: 0.2337992\ttotal: 9.6s\tremaining: 53.2s\n",
      "153:\tlearn: 0.2335391\ttotal: 9.66s\tremaining: 53.1s\n",
      "154:\tlearn: 0.2332747\ttotal: 9.71s\tremaining: 53s\n",
      "155:\tlearn: 0.2330051\ttotal: 9.78s\tremaining: 52.9s\n",
      "156:\tlearn: 0.2327381\ttotal: 9.84s\tremaining: 52.8s\n",
      "157:\tlearn: 0.2324678\ttotal: 9.91s\tremaining: 52.8s\n",
      "158:\tlearn: 0.2322010\ttotal: 9.97s\tremaining: 52.7s\n",
      "159:\tlearn: 0.2319397\ttotal: 10s\tremaining: 52.7s\n",
      "160:\tlearn: 0.2316979\ttotal: 10.1s\tremaining: 52.7s\n",
      "161:\tlearn: 0.2314394\ttotal: 10.2s\tremaining: 52.6s\n",
      "162:\tlearn: 0.2312113\ttotal: 10.2s\tremaining: 52.5s\n",
      "163:\tlearn: 0.2309772\ttotal: 10.3s\tremaining: 52.5s\n",
      "164:\tlearn: 0.2307308\ttotal: 10.4s\tremaining: 52.4s\n",
      "165:\tlearn: 0.2304780\ttotal: 10.4s\tremaining: 52.3s\n",
      "166:\tlearn: 0.2302257\ttotal: 10.5s\tremaining: 52.3s\n",
      "167:\tlearn: 0.2299970\ttotal: 10.5s\tremaining: 52.2s\n",
      "168:\tlearn: 0.2297551\ttotal: 10.6s\tremaining: 52.2s\n",
      "169:\tlearn: 0.2295231\ttotal: 10.7s\tremaining: 52.1s\n",
      "170:\tlearn: 0.2292707\ttotal: 10.7s\tremaining: 52s\n",
      "171:\tlearn: 0.2290314\ttotal: 10.8s\tremaining: 52s\n",
      "172:\tlearn: 0.2287908\ttotal: 10.9s\tremaining: 52s\n",
      "173:\tlearn: 0.2285429\ttotal: 10.9s\tremaining: 51.9s\n",
      "174:\tlearn: 0.2283095\ttotal: 11s\tremaining: 51.7s\n",
      "175:\tlearn: 0.2280817\ttotal: 11s\tremaining: 51.7s\n",
      "176:\tlearn: 0.2278502\ttotal: 11.1s\tremaining: 51.6s\n",
      "177:\tlearn: 0.2276139\ttotal: 11.2s\tremaining: 51.5s\n",
      "178:\tlearn: 0.2273980\ttotal: 11.2s\tremaining: 51.5s\n",
      "179:\tlearn: 0.2271800\ttotal: 11.3s\tremaining: 51.4s\n",
      "180:\tlearn: 0.2269689\ttotal: 11.3s\tremaining: 51.3s\n",
      "181:\tlearn: 0.2267327\ttotal: 11.4s\tremaining: 51.2s\n",
      "182:\tlearn: 0.2265104\ttotal: 11.5s\tremaining: 51.1s\n",
      "183:\tlearn: 0.2262815\ttotal: 11.5s\tremaining: 51.1s\n",
      "184:\tlearn: 0.2260551\ttotal: 11.6s\tremaining: 51s\n",
      "185:\tlearn: 0.2258292\ttotal: 11.6s\tremaining: 51s\n",
      "186:\tlearn: 0.2256066\ttotal: 11.7s\tremaining: 50.9s\n",
      "187:\tlearn: 0.2253732\ttotal: 11.8s\tremaining: 50.8s\n",
      "188:\tlearn: 0.2251502\ttotal: 11.8s\tremaining: 50.8s\n",
      "189:\tlearn: 0.2249395\ttotal: 11.9s\tremaining: 50.8s\n",
      "190:\tlearn: 0.2247276\ttotal: 12s\tremaining: 50.7s\n",
      "191:\tlearn: 0.2245101\ttotal: 12s\tremaining: 50.7s\n",
      "192:\tlearn: 0.2242848\ttotal: 12.1s\tremaining: 50.6s\n",
      "193:\tlearn: 0.2240713\ttotal: 12.2s\tremaining: 50.6s\n",
      "194:\tlearn: 0.2238644\ttotal: 12.2s\tremaining: 50.5s\n",
      "195:\tlearn: 0.2236506\ttotal: 12.3s\tremaining: 50.5s\n",
      "196:\tlearn: 0.2234264\ttotal: 12.4s\tremaining: 50.4s\n",
      "197:\tlearn: 0.2232052\ttotal: 12.4s\tremaining: 50.3s\n",
      "198:\tlearn: 0.2230112\ttotal: 12.5s\tremaining: 50.2s\n",
      "199:\tlearn: 0.2228272\ttotal: 12.5s\tremaining: 50.2s\n",
      "200:\tlearn: 0.2226225\ttotal: 12.6s\tremaining: 50.1s\n",
      "201:\tlearn: 0.2224274\ttotal: 12.7s\tremaining: 50.1s\n",
      "202:\tlearn: 0.2222148\ttotal: 12.7s\tremaining: 50s\n",
      "203:\tlearn: 0.2220197\ttotal: 12.8s\tremaining: 49.9s\n",
      "204:\tlearn: 0.2218216\ttotal: 12.8s\tremaining: 49.8s\n",
      "205:\tlearn: 0.2216328\ttotal: 12.9s\tremaining: 49.8s\n",
      "206:\tlearn: 0.2214400\ttotal: 13s\tremaining: 49.7s\n",
      "207:\tlearn: 0.2212551\ttotal: 13s\tremaining: 49.6s\n",
      "208:\tlearn: 0.2210634\ttotal: 13.1s\tremaining: 49.5s\n",
      "209:\tlearn: 0.2208770\ttotal: 13.1s\tremaining: 49.5s\n",
      "210:\tlearn: 0.2206847\ttotal: 13.2s\tremaining: 49.4s\n",
      "211:\tlearn: 0.2205000\ttotal: 13.3s\tremaining: 49.3s\n",
      "212:\tlearn: 0.2203039\ttotal: 13.3s\tremaining: 49.3s\n",
      "213:\tlearn: 0.2201055\ttotal: 13.4s\tremaining: 49.2s\n",
      "214:\tlearn: 0.2199301\ttotal: 13.5s\tremaining: 49.1s\n",
      "215:\tlearn: 0.2197366\ttotal: 13.5s\tremaining: 49.1s\n",
      "216:\tlearn: 0.2195445\ttotal: 13.6s\tremaining: 49s\n",
      "217:\tlearn: 0.2193652\ttotal: 13.7s\tremaining: 49s\n",
      "218:\tlearn: 0.2191706\ttotal: 13.7s\tremaining: 49s\n",
      "219:\tlearn: 0.2189927\ttotal: 13.8s\tremaining: 48.9s\n",
      "220:\tlearn: 0.2188064\ttotal: 13.8s\tremaining: 48.8s\n",
      "221:\tlearn: 0.2186193\ttotal: 13.9s\tremaining: 48.8s\n",
      "222:\tlearn: 0.2184248\ttotal: 14s\tremaining: 48.7s\n",
      "223:\tlearn: 0.2182256\ttotal: 14.1s\tremaining: 48.7s\n",
      "224:\tlearn: 0.2180611\ttotal: 14.1s\tremaining: 48.7s\n",
      "225:\tlearn: 0.2178864\ttotal: 14.2s\tremaining: 48.7s\n",
      "226:\tlearn: 0.2177205\ttotal: 14.3s\tremaining: 48.7s\n",
      "227:\tlearn: 0.2175542\ttotal: 14.4s\tremaining: 48.6s\n",
      "228:\tlearn: 0.2173912\ttotal: 14.4s\tremaining: 48.6s\n",
      "229:\tlearn: 0.2172217\ttotal: 14.5s\tremaining: 48.5s\n",
      "230:\tlearn: 0.2170472\ttotal: 14.6s\tremaining: 48.5s\n",
      "231:\tlearn: 0.2168618\ttotal: 14.6s\tremaining: 48.5s\n",
      "232:\tlearn: 0.2166951\ttotal: 14.7s\tremaining: 48.4s\n",
      "233:\tlearn: 0.2165234\ttotal: 14.8s\tremaining: 48.4s\n",
      "234:\tlearn: 0.2163515\ttotal: 14.8s\tremaining: 48.3s\n",
      "235:\tlearn: 0.2161627\ttotal: 14.9s\tremaining: 48.2s\n",
      "236:\tlearn: 0.2159806\ttotal: 15s\tremaining: 48.2s\n",
      "237:\tlearn: 0.2158082\ttotal: 15s\tremaining: 48.1s\n",
      "238:\tlearn: 0.2156464\ttotal: 15.1s\tremaining: 48s\n",
      "239:\tlearn: 0.2154849\ttotal: 15.1s\tremaining: 47.9s\n",
      "240:\tlearn: 0.2153254\ttotal: 15.2s\tremaining: 47.9s\n",
      "241:\tlearn: 0.2151450\ttotal: 15.3s\tremaining: 47.8s\n",
      "242:\tlearn: 0.2149821\ttotal: 15.3s\tremaining: 47.7s\n",
      "243:\tlearn: 0.2148279\ttotal: 15.4s\tremaining: 47.7s\n",
      "244:\tlearn: 0.2146446\ttotal: 15.4s\tremaining: 47.6s\n",
      "245:\tlearn: 0.2144803\ttotal: 15.5s\tremaining: 47.5s\n",
      "246:\tlearn: 0.2143154\ttotal: 15.6s\tremaining: 47.5s\n",
      "247:\tlearn: 0.2141506\ttotal: 15.6s\tremaining: 47.4s\n",
      "248:\tlearn: 0.2139840\ttotal: 15.7s\tremaining: 47.3s\n",
      "249:\tlearn: 0.2138226\ttotal: 15.7s\tremaining: 47.2s\n",
      "250:\tlearn: 0.2136480\ttotal: 15.8s\tremaining: 47.2s\n",
      "251:\tlearn: 0.2134975\ttotal: 15.9s\tremaining: 47.1s\n",
      "252:\tlearn: 0.2133431\ttotal: 15.9s\tremaining: 47s\n",
      "253:\tlearn: 0.2131786\ttotal: 16s\tremaining: 47s\n",
      "254:\tlearn: 0.2129992\ttotal: 16.1s\tremaining: 46.9s\n",
      "255:\tlearn: 0.2128312\ttotal: 16.1s\tremaining: 46.9s\n",
      "256:\tlearn: 0.2126723\ttotal: 16.2s\tremaining: 46.8s\n",
      "257:\tlearn: 0.2125128\ttotal: 16.3s\tremaining: 46.8s\n",
      "258:\tlearn: 0.2123573\ttotal: 16.3s\tremaining: 46.7s\n",
      "259:\tlearn: 0.2121989\ttotal: 16.4s\tremaining: 46.6s\n",
      "260:\tlearn: 0.2120532\ttotal: 16.5s\tremaining: 46.6s\n",
      "261:\tlearn: 0.2118964\ttotal: 16.5s\tremaining: 46.6s\n",
      "262:\tlearn: 0.2117350\ttotal: 16.6s\tremaining: 46.6s\n",
      "263:\tlearn: 0.2115861\ttotal: 16.7s\tremaining: 46.5s\n",
      "264:\tlearn: 0.2114233\ttotal: 16.7s\tremaining: 46.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "265:\tlearn: 0.2112810\ttotal: 16.8s\tremaining: 46.4s\n",
      "266:\tlearn: 0.2111288\ttotal: 16.9s\tremaining: 46.3s\n",
      "267:\tlearn: 0.2109796\ttotal: 16.9s\tremaining: 46.2s\n",
      "268:\tlearn: 0.2108272\ttotal: 17s\tremaining: 46.2s\n",
      "269:\tlearn: 0.2106821\ttotal: 17.1s\tremaining: 46.1s\n",
      "270:\tlearn: 0.2105275\ttotal: 17.1s\tremaining: 46s\n",
      "271:\tlearn: 0.2103808\ttotal: 17.2s\tremaining: 46s\n",
      "272:\tlearn: 0.2102294\ttotal: 17.2s\tremaining: 45.9s\n",
      "273:\tlearn: 0.2100928\ttotal: 17.3s\tremaining: 45.8s\n",
      "274:\tlearn: 0.2099464\ttotal: 17.3s\tremaining: 45.7s\n",
      "275:\tlearn: 0.2098030\ttotal: 17.4s\tremaining: 45.7s\n",
      "276:\tlearn: 0.2096559\ttotal: 17.5s\tremaining: 45.6s\n",
      "277:\tlearn: 0.2095078\ttotal: 17.5s\tremaining: 45.6s\n",
      "278:\tlearn: 0.2093524\ttotal: 17.6s\tremaining: 45.5s\n",
      "279:\tlearn: 0.2092113\ttotal: 17.7s\tremaining: 45.5s\n",
      "280:\tlearn: 0.2090582\ttotal: 17.7s\tremaining: 45.4s\n",
      "281:\tlearn: 0.2089255\ttotal: 17.8s\tremaining: 45.3s\n",
      "282:\tlearn: 0.2087644\ttotal: 17.9s\tremaining: 45.3s\n",
      "283:\tlearn: 0.2086153\ttotal: 18s\tremaining: 45.3s\n",
      "284:\tlearn: 0.2084817\ttotal: 18s\tremaining: 45.2s\n",
      "285:\tlearn: 0.2083551\ttotal: 18.1s\tremaining: 45.1s\n",
      "286:\tlearn: 0.2082228\ttotal: 18.1s\tremaining: 45s\n",
      "287:\tlearn: 0.2080793\ttotal: 18.2s\tremaining: 45s\n",
      "288:\tlearn: 0.2079442\ttotal: 18.3s\tremaining: 44.9s\n",
      "289:\tlearn: 0.2078087\ttotal: 18.3s\tremaining: 44.9s\n",
      "290:\tlearn: 0.2076683\ttotal: 18.4s\tremaining: 44.8s\n",
      "291:\tlearn: 0.2075305\ttotal: 18.5s\tremaining: 44.7s\n",
      "292:\tlearn: 0.2073976\ttotal: 18.5s\tremaining: 44.7s\n",
      "293:\tlearn: 0.2072527\ttotal: 18.6s\tremaining: 44.7s\n",
      "294:\tlearn: 0.2071116\ttotal: 18.7s\tremaining: 44.6s\n",
      "295:\tlearn: 0.2069696\ttotal: 18.7s\tremaining: 44.6s\n",
      "296:\tlearn: 0.2068295\ttotal: 18.8s\tremaining: 44.5s\n",
      "297:\tlearn: 0.2066891\ttotal: 18.9s\tremaining: 44.5s\n",
      "298:\tlearn: 0.2065490\ttotal: 19s\tremaining: 44.4s\n",
      "299:\tlearn: 0.2064095\ttotal: 19s\tremaining: 44.4s\n",
      "300:\tlearn: 0.2062693\ttotal: 19.1s\tremaining: 44.4s\n",
      "301:\tlearn: 0.2061311\ttotal: 19.2s\tremaining: 44.3s\n",
      "302:\tlearn: 0.2059845\ttotal: 19.2s\tremaining: 44.3s\n",
      "303:\tlearn: 0.2058592\ttotal: 19.3s\tremaining: 44.2s\n",
      "304:\tlearn: 0.2057364\ttotal: 19.4s\tremaining: 44.1s\n",
      "305:\tlearn: 0.2056071\ttotal: 19.4s\tremaining: 44s\n",
      "306:\tlearn: 0.2054835\ttotal: 19.5s\tremaining: 44s\n",
      "307:\tlearn: 0.2053330\ttotal: 19.5s\tremaining: 43.9s\n",
      "308:\tlearn: 0.2051998\ttotal: 19.6s\tremaining: 43.8s\n",
      "309:\tlearn: 0.2050570\ttotal: 19.7s\tremaining: 43.8s\n",
      "310:\tlearn: 0.2049117\ttotal: 19.7s\tremaining: 43.7s\n",
      "311:\tlearn: 0.2047787\ttotal: 19.8s\tremaining: 43.7s\n",
      "312:\tlearn: 0.2046603\ttotal: 19.9s\tremaining: 43.6s\n",
      "313:\tlearn: 0.2045329\ttotal: 19.9s\tremaining: 43.6s\n",
      "314:\tlearn: 0.2043926\ttotal: 20s\tremaining: 43.5s\n",
      "315:\tlearn: 0.2042510\ttotal: 20.1s\tremaining: 43.4s\n",
      "316:\tlearn: 0.2041244\ttotal: 20.1s\tremaining: 43.4s\n",
      "317:\tlearn: 0.2040035\ttotal: 20.2s\tremaining: 43.4s\n",
      "318:\tlearn: 0.2038563\ttotal: 20.3s\tremaining: 43.3s\n",
      "319:\tlearn: 0.2037279\ttotal: 20.3s\tremaining: 43.2s\n",
      "320:\tlearn: 0.2036050\ttotal: 20.4s\tremaining: 43.2s\n",
      "321:\tlearn: 0.2034781\ttotal: 20.5s\tremaining: 43.1s\n",
      "322:\tlearn: 0.2033437\ttotal: 20.5s\tremaining: 43s\n",
      "323:\tlearn: 0.2032149\ttotal: 20.6s\tremaining: 43s\n",
      "324:\tlearn: 0.2030811\ttotal: 20.7s\tremaining: 42.9s\n",
      "325:\tlearn: 0.2029571\ttotal: 20.7s\tremaining: 42.8s\n",
      "326:\tlearn: 0.2028256\ttotal: 20.8s\tremaining: 42.8s\n",
      "327:\tlearn: 0.2026932\ttotal: 20.9s\tremaining: 42.7s\n",
      "328:\tlearn: 0.2025463\ttotal: 20.9s\tremaining: 42.7s\n",
      "329:\tlearn: 0.2024351\ttotal: 21s\tremaining: 42.6s\n",
      "330:\tlearn: 0.2023140\ttotal: 21.1s\tremaining: 42.6s\n",
      "331:\tlearn: 0.2021887\ttotal: 21.2s\tremaining: 42.6s\n",
      "332:\tlearn: 0.2020607\ttotal: 21.2s\tremaining: 42.5s\n",
      "333:\tlearn: 0.2019497\ttotal: 21.3s\tremaining: 42.5s\n",
      "334:\tlearn: 0.2018377\ttotal: 21.4s\tremaining: 42.4s\n",
      "335:\tlearn: 0.2017202\ttotal: 21.4s\tremaining: 42.4s\n",
      "336:\tlearn: 0.2016007\ttotal: 21.5s\tremaining: 42.3s\n",
      "337:\tlearn: 0.2014783\ttotal: 21.6s\tremaining: 42.3s\n",
      "338:\tlearn: 0.2013568\ttotal: 21.7s\tremaining: 42.2s\n",
      "339:\tlearn: 0.2012418\ttotal: 21.7s\tremaining: 42.2s\n",
      "340:\tlearn: 0.2011173\ttotal: 21.8s\tremaining: 42.1s\n",
      "341:\tlearn: 0.2009989\ttotal: 21.9s\tremaining: 42s\n",
      "342:\tlearn: 0.2008748\ttotal: 21.9s\tremaining: 42s\n",
      "343:\tlearn: 0.2007452\ttotal: 22s\tremaining: 42s\n",
      "344:\tlearn: 0.2006355\ttotal: 22.1s\tremaining: 41.9s\n",
      "345:\tlearn: 0.2005274\ttotal: 22.2s\tremaining: 41.9s\n",
      "346:\tlearn: 0.2004155\ttotal: 22.2s\tremaining: 41.8s\n",
      "347:\tlearn: 0.2002936\ttotal: 22.3s\tremaining: 41.8s\n",
      "348:\tlearn: 0.2001803\ttotal: 22.4s\tremaining: 41.8s\n",
      "349:\tlearn: 0.2000611\ttotal: 22.5s\tremaining: 41.7s\n",
      "350:\tlearn: 0.1999489\ttotal: 22.5s\tremaining: 41.7s\n",
      "351:\tlearn: 0.1998386\ttotal: 22.6s\tremaining: 41.6s\n",
      "352:\tlearn: 0.1997214\ttotal: 22.7s\tremaining: 41.5s\n",
      "353:\tlearn: 0.1995982\ttotal: 22.7s\tremaining: 41.5s\n",
      "354:\tlearn: 0.1994754\ttotal: 22.8s\tremaining: 41.4s\n",
      "355:\tlearn: 0.1993726\ttotal: 22.9s\tremaining: 41.3s\n",
      "356:\tlearn: 0.1992695\ttotal: 22.9s\tremaining: 41.3s\n",
      "357:\tlearn: 0.1991558\ttotal: 23s\tremaining: 41.2s\n",
      "358:\tlearn: 0.1990465\ttotal: 23s\tremaining: 41.1s\n",
      "359:\tlearn: 0.1989489\ttotal: 23.1s\tremaining: 41.1s\n",
      "360:\tlearn: 0.1988375\ttotal: 23.2s\tremaining: 41s\n",
      "361:\tlearn: 0.1987291\ttotal: 23.2s\tremaining: 40.9s\n",
      "362:\tlearn: 0.1986181\ttotal: 23.3s\tremaining: 40.8s\n",
      "363:\tlearn: 0.1985074\ttotal: 23.3s\tremaining: 40.8s\n",
      "364:\tlearn: 0.1983940\ttotal: 23.4s\tremaining: 40.7s\n",
      "365:\tlearn: 0.1982893\ttotal: 23.5s\tremaining: 40.6s\n",
      "366:\tlearn: 0.1981836\ttotal: 23.5s\tremaining: 40.5s\n",
      "367:\tlearn: 0.1980701\ttotal: 23.6s\tremaining: 40.5s\n",
      "368:\tlearn: 0.1979549\ttotal: 23.7s\tremaining: 40.4s\n",
      "369:\tlearn: 0.1978485\ttotal: 23.7s\tremaining: 40.4s\n",
      "370:\tlearn: 0.1977553\ttotal: 23.8s\tremaining: 40.3s\n",
      "371:\tlearn: 0.1976262\ttotal: 23.8s\tremaining: 40.3s\n",
      "372:\tlearn: 0.1975200\ttotal: 23.9s\tremaining: 40.2s\n",
      "373:\tlearn: 0.1974150\ttotal: 24s\tremaining: 40.1s\n",
      "374:\tlearn: 0.1973034\ttotal: 24.1s\tremaining: 40.1s\n",
      "375:\tlearn: 0.1971845\ttotal: 24.1s\tremaining: 40.1s\n",
      "376:\tlearn: 0.1970733\ttotal: 24.2s\tremaining: 40s\n",
      "377:\tlearn: 0.1969754\ttotal: 24.3s\tremaining: 40s\n",
      "378:\tlearn: 0.1968750\ttotal: 24.3s\tremaining: 39.9s\n",
      "379:\tlearn: 0.1967674\ttotal: 24.4s\tremaining: 39.8s\n",
      "380:\tlearn: 0.1966559\ttotal: 24.5s\tremaining: 39.8s\n",
      "381:\tlearn: 0.1965528\ttotal: 24.5s\tremaining: 39.7s\n",
      "382:\tlearn: 0.1964478\ttotal: 24.6s\tremaining: 39.6s\n",
      "383:\tlearn: 0.1963281\ttotal: 24.7s\tremaining: 39.5s\n",
      "384:\tlearn: 0.1962170\ttotal: 24.7s\tremaining: 39.5s\n",
      "385:\tlearn: 0.1960994\ttotal: 24.8s\tremaining: 39.4s\n",
      "386:\tlearn: 0.1959881\ttotal: 24.8s\tremaining: 39.3s\n",
      "387:\tlearn: 0.1958868\ttotal: 24.9s\tremaining: 39.3s\n",
      "388:\tlearn: 0.1957798\ttotal: 25s\tremaining: 39.2s\n",
      "389:\tlearn: 0.1956618\ttotal: 25s\tremaining: 39.1s\n",
      "390:\tlearn: 0.1955573\ttotal: 25.1s\tremaining: 39.1s\n",
      "391:\tlearn: 0.1954356\ttotal: 25.2s\tremaining: 39s\n",
      "392:\tlearn: 0.1953311\ttotal: 25.2s\tremaining: 39s\n",
      "393:\tlearn: 0.1952268\ttotal: 25.3s\tremaining: 38.9s\n",
      "394:\tlearn: 0.1951171\ttotal: 25.4s\tremaining: 38.8s\n",
      "395:\tlearn: 0.1950137\ttotal: 25.4s\tremaining: 38.8s\n",
      "396:\tlearn: 0.1948980\ttotal: 25.5s\tremaining: 38.7s\n",
      "397:\tlearn: 0.1947924\ttotal: 25.6s\tremaining: 38.7s\n",
      "398:\tlearn: 0.1946764\ttotal: 25.6s\tremaining: 38.6s\n",
      "399:\tlearn: 0.1945709\ttotal: 25.7s\tremaining: 38.5s\n",
      "400:\tlearn: 0.1944766\ttotal: 25.8s\tremaining: 38.5s\n",
      "401:\tlearn: 0.1943788\ttotal: 25.8s\tremaining: 38.4s\n",
      "402:\tlearn: 0.1942671\ttotal: 25.9s\tremaining: 38.4s\n",
      "403:\tlearn: 0.1941740\ttotal: 26s\tremaining: 38.3s\n",
      "404:\tlearn: 0.1940777\ttotal: 26s\tremaining: 38.2s\n",
      "405:\tlearn: 0.1939749\ttotal: 26.1s\tremaining: 38.2s\n",
      "406:\tlearn: 0.1938850\ttotal: 26.2s\tremaining: 38.1s\n",
      "407:\tlearn: 0.1937775\ttotal: 26.2s\tremaining: 38.1s\n",
      "408:\tlearn: 0.1936734\ttotal: 26.3s\tremaining: 38s\n",
      "409:\tlearn: 0.1935732\ttotal: 26.4s\tremaining: 38s\n",
      "410:\tlearn: 0.1934800\ttotal: 26.5s\tremaining: 37.9s\n",
      "411:\tlearn: 0.1933788\ttotal: 26.5s\tremaining: 37.9s\n",
      "412:\tlearn: 0.1932722\ttotal: 26.6s\tremaining: 37.8s\n",
      "413:\tlearn: 0.1931753\ttotal: 26.7s\tremaining: 37.8s\n",
      "414:\tlearn: 0.1930649\ttotal: 26.7s\tremaining: 37.7s\n",
      "415:\tlearn: 0.1929692\ttotal: 26.8s\tremaining: 37.6s\n",
      "416:\tlearn: 0.1928774\ttotal: 26.9s\tremaining: 37.5s\n",
      "417:\tlearn: 0.1927686\ttotal: 26.9s\tremaining: 37.5s\n",
      "418:\tlearn: 0.1926759\ttotal: 27s\tremaining: 37.4s\n",
      "419:\tlearn: 0.1925868\ttotal: 27s\tremaining: 37.3s\n",
      "420:\tlearn: 0.1924871\ttotal: 27.1s\tremaining: 37.3s\n",
      "421:\tlearn: 0.1923982\ttotal: 27.1s\tremaining: 37.2s\n",
      "422:\tlearn: 0.1923070\ttotal: 27.2s\tremaining: 37.1s\n",
      "423:\tlearn: 0.1922097\ttotal: 27.3s\tremaining: 37.1s\n",
      "424:\tlearn: 0.1921135\ttotal: 27.4s\tremaining: 37s\n",
      "425:\tlearn: 0.1920065\ttotal: 27.4s\tremaining: 37s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426:\tlearn: 0.1919060\ttotal: 27.5s\tremaining: 36.9s\n",
      "427:\tlearn: 0.1918024\ttotal: 27.6s\tremaining: 36.9s\n",
      "428:\tlearn: 0.1917129\ttotal: 27.7s\tremaining: 36.8s\n",
      "429:\tlearn: 0.1916035\ttotal: 27.7s\tremaining: 36.8s\n",
      "430:\tlearn: 0.1915102\ttotal: 27.8s\tremaining: 36.7s\n",
      "431:\tlearn: 0.1914243\ttotal: 27.9s\tremaining: 36.7s\n",
      "432:\tlearn: 0.1913312\ttotal: 27.9s\tremaining: 36.6s\n",
      "433:\tlearn: 0.1912403\ttotal: 28s\tremaining: 36.5s\n",
      "434:\tlearn: 0.1911382\ttotal: 28.1s\tremaining: 36.5s\n",
      "435:\tlearn: 0.1910481\ttotal: 28.1s\tremaining: 36.4s\n",
      "436:\tlearn: 0.1909490\ttotal: 28.2s\tremaining: 36.3s\n",
      "437:\tlearn: 0.1908678\ttotal: 28.3s\tremaining: 36.3s\n",
      "438:\tlearn: 0.1907567\ttotal: 28.4s\tremaining: 36.2s\n",
      "439:\tlearn: 0.1906713\ttotal: 28.4s\tremaining: 36.2s\n",
      "440:\tlearn: 0.1905834\ttotal: 28.5s\tremaining: 36.1s\n",
      "441:\tlearn: 0.1904901\ttotal: 28.6s\tremaining: 36.1s\n",
      "442:\tlearn: 0.1903894\ttotal: 28.7s\tremaining: 36s\n",
      "443:\tlearn: 0.1903036\ttotal: 28.7s\tremaining: 36s\n",
      "444:\tlearn: 0.1902213\ttotal: 28.8s\tremaining: 35.9s\n",
      "445:\tlearn: 0.1901314\ttotal: 28.9s\tremaining: 35.8s\n",
      "446:\tlearn: 0.1900351\ttotal: 28.9s\tremaining: 35.8s\n",
      "447:\tlearn: 0.1899281\ttotal: 29s\tremaining: 35.7s\n",
      "448:\tlearn: 0.1898367\ttotal: 29s\tremaining: 35.6s\n",
      "449:\tlearn: 0.1897519\ttotal: 29.1s\tremaining: 35.6s\n",
      "450:\tlearn: 0.1896710\ttotal: 29.2s\tremaining: 35.5s\n",
      "451:\tlearn: 0.1895689\ttotal: 29.2s\tremaining: 35.4s\n",
      "452:\tlearn: 0.1894804\ttotal: 29.3s\tremaining: 35.4s\n",
      "453:\tlearn: 0.1894021\ttotal: 29.4s\tremaining: 35.3s\n",
      "454:\tlearn: 0.1893169\ttotal: 29.4s\tremaining: 35.2s\n",
      "455:\tlearn: 0.1892164\ttotal: 29.5s\tremaining: 35.2s\n",
      "456:\tlearn: 0.1891175\ttotal: 29.5s\tremaining: 35.1s\n",
      "457:\tlearn: 0.1890325\ttotal: 29.6s\tremaining: 35s\n",
      "458:\tlearn: 0.1889435\ttotal: 29.7s\tremaining: 35s\n",
      "459:\tlearn: 0.1888538\ttotal: 29.8s\tremaining: 34.9s\n",
      "460:\tlearn: 0.1887634\ttotal: 29.8s\tremaining: 34.9s\n",
      "461:\tlearn: 0.1886594\ttotal: 29.9s\tremaining: 34.8s\n",
      "462:\tlearn: 0.1885688\ttotal: 30s\tremaining: 34.8s\n",
      "463:\tlearn: 0.1884706\ttotal: 30s\tremaining: 34.7s\n",
      "464:\tlearn: 0.1883780\ttotal: 30.1s\tremaining: 34.6s\n",
      "465:\tlearn: 0.1882953\ttotal: 30.2s\tremaining: 34.6s\n",
      "466:\tlearn: 0.1881969\ttotal: 30.2s\tremaining: 34.5s\n",
      "467:\tlearn: 0.1881042\ttotal: 30.3s\tremaining: 34.5s\n",
      "468:\tlearn: 0.1880157\ttotal: 30.4s\tremaining: 34.4s\n",
      "469:\tlearn: 0.1879197\ttotal: 30.5s\tremaining: 34.4s\n",
      "470:\tlearn: 0.1878253\ttotal: 30.6s\tremaining: 34.3s\n",
      "471:\tlearn: 0.1877469\ttotal: 30.6s\tremaining: 34.3s\n",
      "472:\tlearn: 0.1876568\ttotal: 30.7s\tremaining: 34.2s\n",
      "473:\tlearn: 0.1875545\ttotal: 30.8s\tremaining: 34.1s\n",
      "474:\tlearn: 0.1874733\ttotal: 30.8s\tremaining: 34s\n",
      "475:\tlearn: 0.1873925\ttotal: 30.9s\tremaining: 34s\n",
      "476:\tlearn: 0.1873040\ttotal: 30.9s\tremaining: 33.9s\n",
      "477:\tlearn: 0.1872253\ttotal: 31s\tremaining: 33.8s\n",
      "478:\tlearn: 0.1871398\ttotal: 31s\tremaining: 33.8s\n",
      "479:\tlearn: 0.1870436\ttotal: 31.1s\tremaining: 33.7s\n",
      "480:\tlearn: 0.1869560\ttotal: 31.2s\tremaining: 33.6s\n",
      "481:\tlearn: 0.1868562\ttotal: 31.2s\tremaining: 33.6s\n",
      "482:\tlearn: 0.1867797\ttotal: 31.3s\tremaining: 33.5s\n",
      "483:\tlearn: 0.1866826\ttotal: 31.4s\tremaining: 33.4s\n",
      "484:\tlearn: 0.1865962\ttotal: 31.4s\tremaining: 33.4s\n",
      "485:\tlearn: 0.1865067\ttotal: 31.5s\tremaining: 33.3s\n",
      "486:\tlearn: 0.1864114\ttotal: 31.6s\tremaining: 33.3s\n",
      "487:\tlearn: 0.1863238\ttotal: 31.6s\tremaining: 33.2s\n",
      "488:\tlearn: 0.1862347\ttotal: 31.7s\tremaining: 33.2s\n",
      "489:\tlearn: 0.1861515\ttotal: 31.8s\tremaining: 33.1s\n",
      "490:\tlearn: 0.1860514\ttotal: 31.9s\tremaining: 33.1s\n",
      "491:\tlearn: 0.1859640\ttotal: 32s\tremaining: 33s\n",
      "492:\tlearn: 0.1858682\ttotal: 32s\tremaining: 32.9s\n",
      "493:\tlearn: 0.1857737\ttotal: 32.1s\tremaining: 32.9s\n",
      "494:\tlearn: 0.1856917\ttotal: 32.2s\tremaining: 32.8s\n",
      "495:\tlearn: 0.1856093\ttotal: 32.3s\tremaining: 32.8s\n",
      "496:\tlearn: 0.1855308\ttotal: 32.3s\tremaining: 32.7s\n",
      "497:\tlearn: 0.1854583\ttotal: 32.4s\tremaining: 32.7s\n",
      "498:\tlearn: 0.1853784\ttotal: 32.5s\tremaining: 32.6s\n",
      "499:\tlearn: 0.1852979\ttotal: 32.5s\tremaining: 32.5s\n",
      "500:\tlearn: 0.1852125\ttotal: 32.6s\tremaining: 32.5s\n",
      "501:\tlearn: 0.1851317\ttotal: 32.7s\tremaining: 32.4s\n",
      "502:\tlearn: 0.1850438\ttotal: 32.7s\tremaining: 32.4s\n",
      "503:\tlearn: 0.1849553\ttotal: 32.8s\tremaining: 32.3s\n",
      "504:\tlearn: 0.1848787\ttotal: 32.9s\tremaining: 32.2s\n",
      "505:\tlearn: 0.1847926\ttotal: 33s\tremaining: 32.2s\n",
      "506:\tlearn: 0.1847008\ttotal: 33s\tremaining: 32.1s\n",
      "507:\tlearn: 0.1846194\ttotal: 33.1s\tremaining: 32s\n",
      "508:\tlearn: 0.1845312\ttotal: 33.1s\tremaining: 32s\n",
      "509:\tlearn: 0.1844546\ttotal: 33.2s\tremaining: 31.9s\n",
      "510:\tlearn: 0.1843647\ttotal: 33.3s\tremaining: 31.9s\n",
      "511:\tlearn: 0.1842964\ttotal: 33.3s\tremaining: 31.8s\n",
      "512:\tlearn: 0.1842079\ttotal: 33.4s\tremaining: 31.7s\n",
      "513:\tlearn: 0.1841364\ttotal: 33.5s\tremaining: 31.6s\n",
      "514:\tlearn: 0.1840501\ttotal: 33.5s\tremaining: 31.6s\n",
      "515:\tlearn: 0.1839712\ttotal: 33.6s\tremaining: 31.5s\n",
      "516:\tlearn: 0.1838868\ttotal: 33.7s\tremaining: 31.5s\n",
      "517:\tlearn: 0.1838037\ttotal: 33.8s\tremaining: 31.4s\n",
      "518:\tlearn: 0.1837265\ttotal: 33.8s\tremaining: 31.4s\n",
      "519:\tlearn: 0.1836502\ttotal: 33.9s\tremaining: 31.3s\n",
      "520:\tlearn: 0.1835600\ttotal: 34s\tremaining: 31.3s\n",
      "521:\tlearn: 0.1834765\ttotal: 34.1s\tremaining: 31.2s\n",
      "522:\tlearn: 0.1833933\ttotal: 34.2s\tremaining: 31.1s\n",
      "523:\tlearn: 0.1833107\ttotal: 34.2s\tremaining: 31.1s\n",
      "524:\tlearn: 0.1832212\ttotal: 34.3s\tremaining: 31s\n",
      "525:\tlearn: 0.1831354\ttotal: 34.4s\tremaining: 31s\n",
      "526:\tlearn: 0.1830717\ttotal: 34.5s\tremaining: 30.9s\n",
      "527:\tlearn: 0.1829909\ttotal: 34.5s\tremaining: 30.9s\n",
      "528:\tlearn: 0.1829138\ttotal: 34.6s\tremaining: 30.8s\n",
      "529:\tlearn: 0.1828386\ttotal: 34.7s\tremaining: 30.8s\n",
      "530:\tlearn: 0.1827582\ttotal: 34.8s\tremaining: 30.7s\n",
      "531:\tlearn: 0.1826808\ttotal: 34.8s\tremaining: 30.6s\n",
      "532:\tlearn: 0.1825955\ttotal: 34.9s\tremaining: 30.6s\n",
      "533:\tlearn: 0.1825146\ttotal: 35s\tremaining: 30.5s\n",
      "534:\tlearn: 0.1824427\ttotal: 35s\tremaining: 30.4s\n",
      "535:\tlearn: 0.1823608\ttotal: 35.1s\tremaining: 30.4s\n",
      "536:\tlearn: 0.1822792\ttotal: 35.1s\tremaining: 30.3s\n",
      "537:\tlearn: 0.1822080\ttotal: 35.2s\tremaining: 30.2s\n",
      "538:\tlearn: 0.1821256\ttotal: 35.3s\tremaining: 30.2s\n",
      "539:\tlearn: 0.1820399\ttotal: 35.3s\tremaining: 30.1s\n",
      "540:\tlearn: 0.1819506\ttotal: 35.4s\tremaining: 30s\n",
      "541:\tlearn: 0.1818728\ttotal: 35.5s\tremaining: 30s\n",
      "542:\tlearn: 0.1817915\ttotal: 35.5s\tremaining: 29.9s\n",
      "543:\tlearn: 0.1817026\ttotal: 35.6s\tremaining: 29.8s\n",
      "544:\tlearn: 0.1816166\ttotal: 35.7s\tremaining: 29.8s\n",
      "545:\tlearn: 0.1815343\ttotal: 35.7s\tremaining: 29.7s\n",
      "546:\tlearn: 0.1814499\ttotal: 35.8s\tremaining: 29.6s\n",
      "547:\tlearn: 0.1813638\ttotal: 35.9s\tremaining: 29.6s\n",
      "548:\tlearn: 0.1812913\ttotal: 35.9s\tremaining: 29.5s\n",
      "549:\tlearn: 0.1812152\ttotal: 36s\tremaining: 29.4s\n",
      "550:\tlearn: 0.1811293\ttotal: 36.1s\tremaining: 29.4s\n",
      "551:\tlearn: 0.1810505\ttotal: 36.1s\tremaining: 29.3s\n",
      "552:\tlearn: 0.1809805\ttotal: 36.2s\tremaining: 29.2s\n",
      "553:\tlearn: 0.1809117\ttotal: 36.2s\tremaining: 29.2s\n",
      "554:\tlearn: 0.1808316\ttotal: 36.3s\tremaining: 29.1s\n",
      "555:\tlearn: 0.1807536\ttotal: 36.4s\tremaining: 29s\n",
      "556:\tlearn: 0.1806764\ttotal: 36.4s\tremaining: 29s\n",
      "557:\tlearn: 0.1806069\ttotal: 36.5s\tremaining: 28.9s\n",
      "558:\tlearn: 0.1805343\ttotal: 36.6s\tremaining: 28.8s\n",
      "559:\tlearn: 0.1804617\ttotal: 36.6s\tremaining: 28.8s\n",
      "560:\tlearn: 0.1803898\ttotal: 36.7s\tremaining: 28.7s\n",
      "561:\tlearn: 0.1803169\ttotal: 36.7s\tremaining: 28.6s\n",
      "562:\tlearn: 0.1802404\ttotal: 36.8s\tremaining: 28.6s\n",
      "563:\tlearn: 0.1801685\ttotal: 36.9s\tremaining: 28.5s\n",
      "564:\tlearn: 0.1800826\ttotal: 36.9s\tremaining: 28.4s\n",
      "565:\tlearn: 0.1800130\ttotal: 37s\tremaining: 28.4s\n",
      "566:\tlearn: 0.1799254\ttotal: 37s\tremaining: 28.3s\n",
      "567:\tlearn: 0.1798487\ttotal: 37.1s\tremaining: 28.2s\n",
      "568:\tlearn: 0.1797696\ttotal: 37.2s\tremaining: 28.2s\n",
      "569:\tlearn: 0.1796830\ttotal: 37.2s\tremaining: 28.1s\n",
      "570:\tlearn: 0.1796108\ttotal: 37.3s\tremaining: 28s\n",
      "571:\tlearn: 0.1795406\ttotal: 37.3s\tremaining: 27.9s\n",
      "572:\tlearn: 0.1794738\ttotal: 37.4s\tremaining: 27.9s\n",
      "573:\tlearn: 0.1793841\ttotal: 37.5s\tremaining: 27.8s\n",
      "574:\tlearn: 0.1793151\ttotal: 37.5s\tremaining: 27.7s\n",
      "575:\tlearn: 0.1792380\ttotal: 37.6s\tremaining: 27.7s\n",
      "576:\tlearn: 0.1791731\ttotal: 37.6s\tremaining: 27.6s\n",
      "577:\tlearn: 0.1790924\ttotal: 37.7s\tremaining: 27.5s\n",
      "578:\tlearn: 0.1790153\ttotal: 37.8s\tremaining: 27.5s\n",
      "579:\tlearn: 0.1789576\ttotal: 37.8s\tremaining: 27.4s\n",
      "580:\tlearn: 0.1788823\ttotal: 37.9s\tremaining: 27.3s\n",
      "581:\tlearn: 0.1788084\ttotal: 37.9s\tremaining: 27.2s\n",
      "582:\tlearn: 0.1787430\ttotal: 38s\tremaining: 27.2s\n",
      "583:\tlearn: 0.1786651\ttotal: 38.1s\tremaining: 27.1s\n",
      "584:\tlearn: 0.1785820\ttotal: 38.1s\tremaining: 27s\n",
      "585:\tlearn: 0.1785171\ttotal: 38.2s\tremaining: 27s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "586:\tlearn: 0.1784468\ttotal: 38.2s\tremaining: 26.9s\n",
      "587:\tlearn: 0.1783820\ttotal: 38.3s\tremaining: 26.8s\n",
      "588:\tlearn: 0.1783050\ttotal: 38.4s\tremaining: 26.8s\n",
      "589:\tlearn: 0.1782363\ttotal: 38.4s\tremaining: 26.7s\n",
      "590:\tlearn: 0.1781455\ttotal: 38.5s\tremaining: 26.6s\n",
      "591:\tlearn: 0.1780619\ttotal: 38.5s\tremaining: 26.6s\n",
      "592:\tlearn: 0.1779905\ttotal: 38.6s\tremaining: 26.5s\n",
      "593:\tlearn: 0.1779093\ttotal: 38.7s\tremaining: 26.4s\n",
      "594:\tlearn: 0.1778370\ttotal: 38.7s\tremaining: 26.4s\n",
      "595:\tlearn: 0.1777762\ttotal: 38.8s\tremaining: 26.3s\n",
      "596:\tlearn: 0.1777089\ttotal: 38.8s\tremaining: 26.2s\n",
      "597:\tlearn: 0.1776306\ttotal: 38.9s\tremaining: 26.1s\n",
      "598:\tlearn: 0.1775636\ttotal: 38.9s\tremaining: 26.1s\n",
      "599:\tlearn: 0.1775078\ttotal: 39s\tremaining: 26s\n",
      "600:\tlearn: 0.1774289\ttotal: 39.1s\tremaining: 25.9s\n",
      "601:\tlearn: 0.1773586\ttotal: 39.1s\tremaining: 25.9s\n",
      "602:\tlearn: 0.1772856\ttotal: 39.2s\tremaining: 25.8s\n",
      "603:\tlearn: 0.1771996\ttotal: 39.2s\tremaining: 25.7s\n",
      "604:\tlearn: 0.1771308\ttotal: 39.3s\tremaining: 25.7s\n",
      "605:\tlearn: 0.1770571\ttotal: 39.3s\tremaining: 25.6s\n",
      "606:\tlearn: 0.1769967\ttotal: 39.4s\tremaining: 25.5s\n",
      "607:\tlearn: 0.1769196\ttotal: 39.5s\tremaining: 25.4s\n",
      "608:\tlearn: 0.1768592\ttotal: 39.5s\tremaining: 25.4s\n",
      "609:\tlearn: 0.1767998\ttotal: 39.6s\tremaining: 25.3s\n",
      "610:\tlearn: 0.1767291\ttotal: 39.6s\tremaining: 25.2s\n",
      "611:\tlearn: 0.1766525\ttotal: 39.7s\tremaining: 25.2s\n",
      "612:\tlearn: 0.1765779\ttotal: 39.8s\tremaining: 25.1s\n",
      "613:\tlearn: 0.1765136\ttotal: 39.8s\tremaining: 25s\n",
      "614:\tlearn: 0.1764480\ttotal: 39.9s\tremaining: 25s\n",
      "615:\tlearn: 0.1763791\ttotal: 39.9s\tremaining: 24.9s\n",
      "616:\tlearn: 0.1762970\ttotal: 40s\tremaining: 24.8s\n",
      "617:\tlearn: 0.1762301\ttotal: 40.1s\tremaining: 24.8s\n",
      "618:\tlearn: 0.1761590\ttotal: 40.1s\tremaining: 24.7s\n",
      "619:\tlearn: 0.1760859\ttotal: 40.2s\tremaining: 24.6s\n",
      "620:\tlearn: 0.1760212\ttotal: 40.3s\tremaining: 24.6s\n",
      "621:\tlearn: 0.1759555\ttotal: 40.3s\tremaining: 24.5s\n",
      "622:\tlearn: 0.1758843\ttotal: 40.4s\tremaining: 24.4s\n",
      "623:\tlearn: 0.1758084\ttotal: 40.4s\tremaining: 24.4s\n",
      "624:\tlearn: 0.1757363\ttotal: 40.5s\tremaining: 24.3s\n",
      "625:\tlearn: 0.1756727\ttotal: 40.5s\tremaining: 24.2s\n",
      "626:\tlearn: 0.1756104\ttotal: 40.6s\tremaining: 24.2s\n",
      "627:\tlearn: 0.1755369\ttotal: 40.7s\tremaining: 24.1s\n",
      "628:\tlearn: 0.1754630\ttotal: 40.7s\tremaining: 24s\n",
      "629:\tlearn: 0.1753994\ttotal: 40.8s\tremaining: 24s\n",
      "630:\tlearn: 0.1753316\ttotal: 40.9s\tremaining: 23.9s\n",
      "631:\tlearn: 0.1752583\ttotal: 40.9s\tremaining: 23.8s\n",
      "632:\tlearn: 0.1751881\ttotal: 41s\tremaining: 23.8s\n",
      "633:\tlearn: 0.1751144\ttotal: 41s\tremaining: 23.7s\n",
      "634:\tlearn: 0.1750336\ttotal: 41.1s\tremaining: 23.6s\n",
      "635:\tlearn: 0.1749542\ttotal: 41.2s\tremaining: 23.6s\n",
      "636:\tlearn: 0.1748802\ttotal: 41.2s\tremaining: 23.5s\n",
      "637:\tlearn: 0.1748113\ttotal: 41.3s\tremaining: 23.4s\n",
      "638:\tlearn: 0.1747541\ttotal: 41.4s\tremaining: 23.4s\n",
      "639:\tlearn: 0.1746969\ttotal: 41.4s\tremaining: 23.3s\n",
      "640:\tlearn: 0.1746455\ttotal: 41.5s\tremaining: 23.2s\n",
      "641:\tlearn: 0.1745759\ttotal: 41.5s\tremaining: 23.1s\n",
      "642:\tlearn: 0.1745149\ttotal: 41.6s\tremaining: 23.1s\n",
      "643:\tlearn: 0.1744465\ttotal: 41.6s\tremaining: 23s\n",
      "644:\tlearn: 0.1743753\ttotal: 41.7s\tremaining: 22.9s\n",
      "645:\tlearn: 0.1742895\ttotal: 41.8s\tremaining: 22.9s\n",
      "646:\tlearn: 0.1742328\ttotal: 41.8s\tremaining: 22.8s\n",
      "647:\tlearn: 0.1741701\ttotal: 41.9s\tremaining: 22.7s\n",
      "648:\tlearn: 0.1740997\ttotal: 41.9s\tremaining: 22.7s\n",
      "649:\tlearn: 0.1740262\ttotal: 42s\tremaining: 22.6s\n",
      "650:\tlearn: 0.1739703\ttotal: 42.1s\tremaining: 22.5s\n",
      "651:\tlearn: 0.1739039\ttotal: 42.1s\tremaining: 22.5s\n",
      "652:\tlearn: 0.1738390\ttotal: 42.2s\tremaining: 22.4s\n",
      "653:\tlearn: 0.1737694\ttotal: 42.2s\tremaining: 22.3s\n",
      "654:\tlearn: 0.1737007\ttotal: 42.3s\tremaining: 22.3s\n",
      "655:\tlearn: 0.1736215\ttotal: 42.4s\tremaining: 22.2s\n",
      "656:\tlearn: 0.1735661\ttotal: 42.4s\tremaining: 22.1s\n",
      "657:\tlearn: 0.1735055\ttotal: 42.5s\tremaining: 22.1s\n",
      "658:\tlearn: 0.1734464\ttotal: 42.5s\tremaining: 22s\n",
      "659:\tlearn: 0.1733746\ttotal: 42.6s\tremaining: 21.9s\n",
      "660:\tlearn: 0.1733066\ttotal: 42.7s\tremaining: 21.9s\n",
      "661:\tlearn: 0.1732367\ttotal: 42.7s\tremaining: 21.8s\n",
      "662:\tlearn: 0.1731613\ttotal: 42.8s\tremaining: 21.7s\n",
      "663:\tlearn: 0.1730925\ttotal: 42.8s\tremaining: 21.7s\n",
      "664:\tlearn: 0.1730242\ttotal: 42.9s\tremaining: 21.6s\n",
      "665:\tlearn: 0.1729681\ttotal: 43s\tremaining: 21.5s\n",
      "666:\tlearn: 0.1729053\ttotal: 43s\tremaining: 21.5s\n",
      "667:\tlearn: 0.1728267\ttotal: 43.1s\tremaining: 21.4s\n",
      "668:\tlearn: 0.1727625\ttotal: 43.1s\tremaining: 21.3s\n",
      "669:\tlearn: 0.1726868\ttotal: 43.2s\tremaining: 21.3s\n",
      "670:\tlearn: 0.1726276\ttotal: 43.3s\tremaining: 21.2s\n",
      "671:\tlearn: 0.1725490\ttotal: 43.3s\tremaining: 21.1s\n",
      "672:\tlearn: 0.1724834\ttotal: 43.4s\tremaining: 21.1s\n",
      "673:\tlearn: 0.1724221\ttotal: 43.5s\tremaining: 21s\n",
      "674:\tlearn: 0.1723665\ttotal: 43.5s\tremaining: 20.9s\n",
      "675:\tlearn: 0.1723048\ttotal: 43.6s\tremaining: 20.9s\n",
      "676:\tlearn: 0.1722461\ttotal: 43.6s\tremaining: 20.8s\n",
      "677:\tlearn: 0.1721778\ttotal: 43.7s\tremaining: 20.7s\n",
      "678:\tlearn: 0.1721112\ttotal: 43.7s\tremaining: 20.7s\n",
      "679:\tlearn: 0.1720442\ttotal: 43.8s\tremaining: 20.6s\n",
      "680:\tlearn: 0.1719901\ttotal: 43.9s\tremaining: 20.5s\n",
      "681:\tlearn: 0.1719290\ttotal: 43.9s\tremaining: 20.5s\n",
      "682:\tlearn: 0.1718585\ttotal: 44s\tremaining: 20.4s\n",
      "683:\tlearn: 0.1718026\ttotal: 44s\tremaining: 20.3s\n",
      "684:\tlearn: 0.1717343\ttotal: 44.1s\tremaining: 20.3s\n",
      "685:\tlearn: 0.1716593\ttotal: 44.2s\tremaining: 20.2s\n",
      "686:\tlearn: 0.1715763\ttotal: 44.2s\tremaining: 20.2s\n",
      "687:\tlearn: 0.1715140\ttotal: 44.3s\tremaining: 20.1s\n",
      "688:\tlearn: 0.1714491\ttotal: 44.4s\tremaining: 20s\n",
      "689:\tlearn: 0.1713869\ttotal: 44.4s\tremaining: 20s\n",
      "690:\tlearn: 0.1713196\ttotal: 44.5s\tremaining: 19.9s\n",
      "691:\tlearn: 0.1712382\ttotal: 44.6s\tremaining: 19.8s\n",
      "692:\tlearn: 0.1711680\ttotal: 44.6s\tremaining: 19.8s\n",
      "693:\tlearn: 0.1711026\ttotal: 44.7s\tremaining: 19.7s\n",
      "694:\tlearn: 0.1710309\ttotal: 44.7s\tremaining: 19.6s\n",
      "695:\tlearn: 0.1709699\ttotal: 44.8s\tremaining: 19.6s\n",
      "696:\tlearn: 0.1709057\ttotal: 44.8s\tremaining: 19.5s\n",
      "697:\tlearn: 0.1708487\ttotal: 44.9s\tremaining: 19.4s\n",
      "698:\tlearn: 0.1707815\ttotal: 44.9s\tremaining: 19.4s\n",
      "699:\tlearn: 0.1707162\ttotal: 45s\tremaining: 19.3s\n",
      "700:\tlearn: 0.1706523\ttotal: 45.1s\tremaining: 19.2s\n",
      "701:\tlearn: 0.1705990\ttotal: 45.1s\tremaining: 19.2s\n",
      "702:\tlearn: 0.1705319\ttotal: 45.2s\tremaining: 19.1s\n",
      "703:\tlearn: 0.1704649\ttotal: 45.2s\tremaining: 19s\n",
      "704:\tlearn: 0.1703988\ttotal: 45.3s\tremaining: 19s\n",
      "705:\tlearn: 0.1703332\ttotal: 45.4s\tremaining: 18.9s\n",
      "706:\tlearn: 0.1702627\ttotal: 45.4s\tremaining: 18.8s\n",
      "707:\tlearn: 0.1702006\ttotal: 45.5s\tremaining: 18.8s\n",
      "708:\tlearn: 0.1701390\ttotal: 45.5s\tremaining: 18.7s\n",
      "709:\tlearn: 0.1700689\ttotal: 45.6s\tremaining: 18.6s\n",
      "710:\tlearn: 0.1700120\ttotal: 45.7s\tremaining: 18.6s\n",
      "711:\tlearn: 0.1699504\ttotal: 45.7s\tremaining: 18.5s\n",
      "712:\tlearn: 0.1698783\ttotal: 45.8s\tremaining: 18.4s\n",
      "713:\tlearn: 0.1698146\ttotal: 45.9s\tremaining: 18.4s\n",
      "714:\tlearn: 0.1697416\ttotal: 45.9s\tremaining: 18.3s\n",
      "715:\tlearn: 0.1696828\ttotal: 46s\tremaining: 18.2s\n",
      "716:\tlearn: 0.1696214\ttotal: 46s\tremaining: 18.2s\n",
      "717:\tlearn: 0.1695682\ttotal: 46.1s\tremaining: 18.1s\n",
      "718:\tlearn: 0.1695078\ttotal: 46.2s\tremaining: 18s\n",
      "719:\tlearn: 0.1694412\ttotal: 46.2s\tremaining: 18s\n",
      "720:\tlearn: 0.1693691\ttotal: 46.3s\tremaining: 17.9s\n",
      "721:\tlearn: 0.1692938\ttotal: 46.4s\tremaining: 17.9s\n",
      "722:\tlearn: 0.1692271\ttotal: 46.4s\tremaining: 17.8s\n",
      "723:\tlearn: 0.1691672\ttotal: 46.5s\tremaining: 17.7s\n",
      "724:\tlearn: 0.1691046\ttotal: 46.5s\tremaining: 17.7s\n",
      "725:\tlearn: 0.1690445\ttotal: 46.6s\tremaining: 17.6s\n",
      "726:\tlearn: 0.1689914\ttotal: 46.7s\tremaining: 17.5s\n",
      "727:\tlearn: 0.1689436\ttotal: 46.7s\tremaining: 17.5s\n",
      "728:\tlearn: 0.1688784\ttotal: 46.8s\tremaining: 17.4s\n",
      "729:\tlearn: 0.1688231\ttotal: 46.8s\tremaining: 17.3s\n",
      "730:\tlearn: 0.1687757\ttotal: 46.9s\tremaining: 17.3s\n",
      "731:\tlearn: 0.1687203\ttotal: 46.9s\tremaining: 17.2s\n",
      "732:\tlearn: 0.1686459\ttotal: 47s\tremaining: 17.1s\n",
      "733:\tlearn: 0.1685849\ttotal: 47.1s\tremaining: 17.1s\n",
      "734:\tlearn: 0.1685168\ttotal: 47.1s\tremaining: 17s\n",
      "735:\tlearn: 0.1684380\ttotal: 47.2s\tremaining: 16.9s\n",
      "736:\tlearn: 0.1683585\ttotal: 47.3s\tremaining: 16.9s\n",
      "737:\tlearn: 0.1682939\ttotal: 47.3s\tremaining: 16.8s\n",
      "738:\tlearn: 0.1682410\ttotal: 47.4s\tremaining: 16.7s\n",
      "739:\tlearn: 0.1681809\ttotal: 47.4s\tremaining: 16.7s\n",
      "740:\tlearn: 0.1681242\ttotal: 47.5s\tremaining: 16.6s\n",
      "741:\tlearn: 0.1680693\ttotal: 47.6s\tremaining: 16.5s\n",
      "742:\tlearn: 0.1680051\ttotal: 47.6s\tremaining: 16.5s\n",
      "743:\tlearn: 0.1679350\ttotal: 47.7s\tremaining: 16.4s\n",
      "744:\tlearn: 0.1678668\ttotal: 47.7s\tremaining: 16.3s\n",
      "745:\tlearn: 0.1678078\ttotal: 47.8s\tremaining: 16.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "746:\tlearn: 0.1677517\ttotal: 47.9s\tremaining: 16.2s\n",
      "747:\tlearn: 0.1676936\ttotal: 47.9s\tremaining: 16.1s\n",
      "748:\tlearn: 0.1676338\ttotal: 48s\tremaining: 16.1s\n",
      "749:\tlearn: 0.1675672\ttotal: 48s\tremaining: 16s\n",
      "750:\tlearn: 0.1675087\ttotal: 48.1s\tremaining: 15.9s\n",
      "751:\tlearn: 0.1674494\ttotal: 48.2s\tremaining: 15.9s\n",
      "752:\tlearn: 0.1673920\ttotal: 48.2s\tremaining: 15.8s\n",
      "753:\tlearn: 0.1673233\ttotal: 48.3s\tremaining: 15.8s\n",
      "754:\tlearn: 0.1672603\ttotal: 48.3s\tremaining: 15.7s\n",
      "755:\tlearn: 0.1672099\ttotal: 48.4s\tremaining: 15.6s\n",
      "756:\tlearn: 0.1671488\ttotal: 48.5s\tremaining: 15.6s\n",
      "757:\tlearn: 0.1670757\ttotal: 48.5s\tremaining: 15.5s\n",
      "758:\tlearn: 0.1670133\ttotal: 48.6s\tremaining: 15.4s\n",
      "759:\tlearn: 0.1669619\ttotal: 48.7s\tremaining: 15.4s\n",
      "760:\tlearn: 0.1669214\ttotal: 48.7s\tremaining: 15.3s\n",
      "761:\tlearn: 0.1668656\ttotal: 48.8s\tremaining: 15.2s\n",
      "762:\tlearn: 0.1667997\ttotal: 48.8s\tremaining: 15.2s\n",
      "763:\tlearn: 0.1667395\ttotal: 48.9s\tremaining: 15.1s\n",
      "764:\tlearn: 0.1666789\ttotal: 48.9s\tremaining: 15s\n",
      "765:\tlearn: 0.1666233\ttotal: 49s\tremaining: 15s\n",
      "766:\tlearn: 0.1665613\ttotal: 49.1s\tremaining: 14.9s\n",
      "767:\tlearn: 0.1665070\ttotal: 49.1s\tremaining: 14.8s\n",
      "768:\tlearn: 0.1664468\ttotal: 49.2s\tremaining: 14.8s\n",
      "769:\tlearn: 0.1663834\ttotal: 49.3s\tremaining: 14.7s\n",
      "770:\tlearn: 0.1663179\ttotal: 49.3s\tremaining: 14.7s\n",
      "771:\tlearn: 0.1662665\ttotal: 49.4s\tremaining: 14.6s\n",
      "772:\tlearn: 0.1661944\ttotal: 49.4s\tremaining: 14.5s\n",
      "773:\tlearn: 0.1661225\ttotal: 49.5s\tremaining: 14.5s\n",
      "774:\tlearn: 0.1660578\ttotal: 49.6s\tremaining: 14.4s\n",
      "775:\tlearn: 0.1660021\ttotal: 49.6s\tremaining: 14.3s\n",
      "776:\tlearn: 0.1659424\ttotal: 49.7s\tremaining: 14.3s\n",
      "777:\tlearn: 0.1658769\ttotal: 49.8s\tremaining: 14.2s\n",
      "778:\tlearn: 0.1658145\ttotal: 49.8s\tremaining: 14.1s\n",
      "779:\tlearn: 0.1657594\ttotal: 49.9s\tremaining: 14.1s\n",
      "780:\tlearn: 0.1657037\ttotal: 50s\tremaining: 14s\n",
      "781:\tlearn: 0.1656436\ttotal: 50s\tremaining: 13.9s\n",
      "782:\tlearn: 0.1655804\ttotal: 50.1s\tremaining: 13.9s\n",
      "783:\tlearn: 0.1655214\ttotal: 50.1s\tremaining: 13.8s\n",
      "784:\tlearn: 0.1654661\ttotal: 50.2s\tremaining: 13.7s\n",
      "785:\tlearn: 0.1654023\ttotal: 50.2s\tremaining: 13.7s\n",
      "786:\tlearn: 0.1653491\ttotal: 50.3s\tremaining: 13.6s\n",
      "787:\tlearn: 0.1652840\ttotal: 50.4s\tremaining: 13.5s\n",
      "788:\tlearn: 0.1652255\ttotal: 50.4s\tremaining: 13.5s\n",
      "789:\tlearn: 0.1651603\ttotal: 50.5s\tremaining: 13.4s\n",
      "790:\tlearn: 0.1651097\ttotal: 50.5s\tremaining: 13.4s\n",
      "791:\tlearn: 0.1650431\ttotal: 50.6s\tremaining: 13.3s\n",
      "792:\tlearn: 0.1649864\ttotal: 50.6s\tremaining: 13.2s\n",
      "793:\tlearn: 0.1649238\ttotal: 50.7s\tremaining: 13.2s\n",
      "794:\tlearn: 0.1648565\ttotal: 50.8s\tremaining: 13.1s\n",
      "795:\tlearn: 0.1647914\ttotal: 50.8s\tremaining: 13s\n",
      "796:\tlearn: 0.1647433\ttotal: 50.9s\tremaining: 13s\n",
      "797:\tlearn: 0.1646914\ttotal: 51s\tremaining: 12.9s\n",
      "798:\tlearn: 0.1646399\ttotal: 51s\tremaining: 12.8s\n",
      "799:\tlearn: 0.1645800\ttotal: 51.1s\tremaining: 12.8s\n",
      "800:\tlearn: 0.1645306\ttotal: 51.1s\tremaining: 12.7s\n",
      "801:\tlearn: 0.1644776\ttotal: 51.2s\tremaining: 12.6s\n",
      "802:\tlearn: 0.1644339\ttotal: 51.2s\tremaining: 12.6s\n",
      "803:\tlearn: 0.1643787\ttotal: 51.3s\tremaining: 12.5s\n",
      "804:\tlearn: 0.1643250\ttotal: 51.4s\tremaining: 12.4s\n",
      "805:\tlearn: 0.1642665\ttotal: 51.4s\tremaining: 12.4s\n",
      "806:\tlearn: 0.1642160\ttotal: 51.5s\tremaining: 12.3s\n",
      "807:\tlearn: 0.1641615\ttotal: 51.5s\tremaining: 12.2s\n",
      "808:\tlearn: 0.1640966\ttotal: 51.6s\tremaining: 12.2s\n",
      "809:\tlearn: 0.1640409\ttotal: 51.7s\tremaining: 12.1s\n",
      "810:\tlearn: 0.1639899\ttotal: 51.7s\tremaining: 12.1s\n",
      "811:\tlearn: 0.1639469\ttotal: 51.8s\tremaining: 12s\n",
      "812:\tlearn: 0.1638864\ttotal: 51.8s\tremaining: 11.9s\n",
      "813:\tlearn: 0.1638302\ttotal: 51.9s\tremaining: 11.9s\n",
      "814:\tlearn: 0.1637659\ttotal: 52s\tremaining: 11.8s\n",
      "815:\tlearn: 0.1637086\ttotal: 52s\tremaining: 11.7s\n",
      "816:\tlearn: 0.1636474\ttotal: 52.1s\tremaining: 11.7s\n",
      "817:\tlearn: 0.1636061\ttotal: 52.1s\tremaining: 11.6s\n",
      "818:\tlearn: 0.1635458\ttotal: 52.2s\tremaining: 11.5s\n",
      "819:\tlearn: 0.1634855\ttotal: 52.3s\tremaining: 11.5s\n",
      "820:\tlearn: 0.1634179\ttotal: 52.3s\tremaining: 11.4s\n",
      "821:\tlearn: 0.1633634\ttotal: 52.4s\tremaining: 11.3s\n",
      "822:\tlearn: 0.1633148\ttotal: 52.5s\tremaining: 11.3s\n",
      "823:\tlearn: 0.1632529\ttotal: 52.5s\tremaining: 11.2s\n",
      "824:\tlearn: 0.1631911\ttotal: 52.6s\tremaining: 11.2s\n",
      "825:\tlearn: 0.1631314\ttotal: 52.6s\tremaining: 11.1s\n",
      "826:\tlearn: 0.1630830\ttotal: 52.7s\tremaining: 11s\n",
      "827:\tlearn: 0.1630308\ttotal: 52.7s\tremaining: 11s\n",
      "828:\tlearn: 0.1629736\ttotal: 52.8s\tremaining: 10.9s\n",
      "829:\tlearn: 0.1629278\ttotal: 52.8s\tremaining: 10.8s\n",
      "830:\tlearn: 0.1628645\ttotal: 52.9s\tremaining: 10.8s\n",
      "831:\tlearn: 0.1628035\ttotal: 53s\tremaining: 10.7s\n",
      "832:\tlearn: 0.1627546\ttotal: 53s\tremaining: 10.6s\n",
      "833:\tlearn: 0.1626998\ttotal: 53.1s\tremaining: 10.6s\n",
      "834:\tlearn: 0.1626534\ttotal: 53.1s\tremaining: 10.5s\n",
      "835:\tlearn: 0.1626023\ttotal: 53.2s\tremaining: 10.4s\n",
      "836:\tlearn: 0.1625529\ttotal: 53.2s\tremaining: 10.4s\n",
      "837:\tlearn: 0.1624888\ttotal: 53.3s\tremaining: 10.3s\n",
      "838:\tlearn: 0.1624433\ttotal: 53.4s\tremaining: 10.2s\n",
      "839:\tlearn: 0.1623911\ttotal: 53.4s\tremaining: 10.2s\n",
      "840:\tlearn: 0.1623438\ttotal: 53.5s\tremaining: 10.1s\n",
      "841:\tlearn: 0.1622959\ttotal: 53.5s\tremaining: 10s\n",
      "842:\tlearn: 0.1622413\ttotal: 53.6s\tremaining: 9.98s\n",
      "843:\tlearn: 0.1621856\ttotal: 53.6s\tremaining: 9.91s\n",
      "844:\tlearn: 0.1621216\ttotal: 53.7s\tremaining: 9.85s\n",
      "845:\tlearn: 0.1620736\ttotal: 53.7s\tremaining: 9.78s\n",
      "846:\tlearn: 0.1620195\ttotal: 53.8s\tremaining: 9.72s\n",
      "847:\tlearn: 0.1619526\ttotal: 53.9s\tremaining: 9.66s\n",
      "848:\tlearn: 0.1618961\ttotal: 53.9s\tremaining: 9.59s\n",
      "849:\tlearn: 0.1618372\ttotal: 54s\tremaining: 9.53s\n",
      "850:\tlearn: 0.1617632\ttotal: 54.1s\tremaining: 9.47s\n",
      "851:\tlearn: 0.1617134\ttotal: 54.1s\tremaining: 9.4s\n",
      "852:\tlearn: 0.1616642\ttotal: 54.2s\tremaining: 9.34s\n",
      "853:\tlearn: 0.1616110\ttotal: 54.2s\tremaining: 9.27s\n",
      "854:\tlearn: 0.1615651\ttotal: 54.3s\tremaining: 9.21s\n",
      "855:\tlearn: 0.1614989\ttotal: 54.4s\tremaining: 9.15s\n",
      "856:\tlearn: 0.1614350\ttotal: 54.4s\tremaining: 9.08s\n",
      "857:\tlearn: 0.1613859\ttotal: 54.5s\tremaining: 9.02s\n",
      "858:\tlearn: 0.1613317\ttotal: 54.5s\tremaining: 8.95s\n",
      "859:\tlearn: 0.1612721\ttotal: 54.6s\tremaining: 8.89s\n",
      "860:\tlearn: 0.1612227\ttotal: 54.7s\tremaining: 8.82s\n",
      "861:\tlearn: 0.1611725\ttotal: 54.7s\tremaining: 8.76s\n",
      "862:\tlearn: 0.1611225\ttotal: 54.8s\tremaining: 8.7s\n",
      "863:\tlearn: 0.1610617\ttotal: 54.9s\tremaining: 8.63s\n",
      "864:\tlearn: 0.1610179\ttotal: 54.9s\tremaining: 8.57s\n",
      "865:\tlearn: 0.1609641\ttotal: 55s\tremaining: 8.51s\n",
      "866:\tlearn: 0.1609217\ttotal: 55s\tremaining: 8.44s\n",
      "867:\tlearn: 0.1608707\ttotal: 55.1s\tremaining: 8.38s\n",
      "868:\tlearn: 0.1608160\ttotal: 55.1s\tremaining: 8.31s\n",
      "869:\tlearn: 0.1607616\ttotal: 55.2s\tremaining: 8.25s\n",
      "870:\tlearn: 0.1607046\ttotal: 55.3s\tremaining: 8.18s\n",
      "871:\tlearn: 0.1606554\ttotal: 55.3s\tremaining: 8.12s\n",
      "872:\tlearn: 0.1605956\ttotal: 55.4s\tremaining: 8.05s\n",
      "873:\tlearn: 0.1605335\ttotal: 55.4s\tremaining: 7.99s\n",
      "874:\tlearn: 0.1604779\ttotal: 55.5s\tremaining: 7.93s\n",
      "875:\tlearn: 0.1604121\ttotal: 55.6s\tremaining: 7.86s\n",
      "876:\tlearn: 0.1603540\ttotal: 55.6s\tremaining: 7.8s\n",
      "877:\tlearn: 0.1603051\ttotal: 55.7s\tremaining: 7.74s\n",
      "878:\tlearn: 0.1602613\ttotal: 55.7s\tremaining: 7.67s\n",
      "879:\tlearn: 0.1601993\ttotal: 55.8s\tremaining: 7.61s\n",
      "880:\tlearn: 0.1601555\ttotal: 55.8s\tremaining: 7.54s\n",
      "881:\tlearn: 0.1601063\ttotal: 55.9s\tremaining: 7.48s\n",
      "882:\tlearn: 0.1600646\ttotal: 56s\tremaining: 7.42s\n",
      "883:\tlearn: 0.1600231\ttotal: 56s\tremaining: 7.35s\n",
      "884:\tlearn: 0.1599858\ttotal: 56.1s\tremaining: 7.29s\n",
      "885:\tlearn: 0.1599236\ttotal: 56.1s\tremaining: 7.22s\n",
      "886:\tlearn: 0.1598512\ttotal: 56.2s\tremaining: 7.16s\n",
      "887:\tlearn: 0.1597922\ttotal: 56.3s\tremaining: 7.09s\n",
      "888:\tlearn: 0.1597283\ttotal: 56.3s\tremaining: 7.03s\n",
      "889:\tlearn: 0.1596735\ttotal: 56.4s\tremaining: 6.97s\n",
      "890:\tlearn: 0.1596282\ttotal: 56.4s\tremaining: 6.9s\n",
      "891:\tlearn: 0.1595805\ttotal: 56.5s\tremaining: 6.84s\n",
      "892:\tlearn: 0.1595236\ttotal: 56.6s\tremaining: 6.78s\n",
      "893:\tlearn: 0.1594739\ttotal: 56.6s\tremaining: 6.71s\n",
      "894:\tlearn: 0.1594219\ttotal: 56.7s\tremaining: 6.65s\n",
      "895:\tlearn: 0.1593768\ttotal: 56.7s\tremaining: 6.59s\n",
      "896:\tlearn: 0.1593277\ttotal: 56.8s\tremaining: 6.52s\n",
      "897:\tlearn: 0.1592723\ttotal: 56.9s\tremaining: 6.46s\n",
      "898:\tlearn: 0.1592196\ttotal: 56.9s\tremaining: 6.39s\n",
      "899:\tlearn: 0.1591632\ttotal: 57s\tremaining: 6.33s\n",
      "900:\tlearn: 0.1590940\ttotal: 57s\tremaining: 6.27s\n",
      "901:\tlearn: 0.1590376\ttotal: 57.1s\tremaining: 6.2s\n",
      "902:\tlearn: 0.1589741\ttotal: 57.2s\tremaining: 6.14s\n",
      "903:\tlearn: 0.1589304\ttotal: 57.2s\tremaining: 6.08s\n",
      "904:\tlearn: 0.1588723\ttotal: 57.3s\tremaining: 6.01s\n",
      "905:\tlearn: 0.1588186\ttotal: 57.3s\tremaining: 5.95s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "906:\tlearn: 0.1587674\ttotal: 57.4s\tremaining: 5.88s\n",
      "907:\tlearn: 0.1587221\ttotal: 57.4s\tremaining: 5.82s\n",
      "908:\tlearn: 0.1586662\ttotal: 57.5s\tremaining: 5.76s\n",
      "909:\tlearn: 0.1586137\ttotal: 57.6s\tremaining: 5.69s\n",
      "910:\tlearn: 0.1585628\ttotal: 57.6s\tremaining: 5.63s\n",
      "911:\tlearn: 0.1585141\ttotal: 57.7s\tremaining: 5.57s\n",
      "912:\tlearn: 0.1584595\ttotal: 57.8s\tremaining: 5.5s\n",
      "913:\tlearn: 0.1584106\ttotal: 57.8s\tremaining: 5.44s\n",
      "914:\tlearn: 0.1583559\ttotal: 57.9s\tremaining: 5.38s\n",
      "915:\tlearn: 0.1583040\ttotal: 57.9s\tremaining: 5.31s\n",
      "916:\tlearn: 0.1582448\ttotal: 58s\tremaining: 5.25s\n",
      "917:\tlearn: 0.1581804\ttotal: 58s\tremaining: 5.18s\n",
      "918:\tlearn: 0.1581314\ttotal: 58.1s\tremaining: 5.12s\n",
      "919:\tlearn: 0.1580700\ttotal: 58.2s\tremaining: 5.06s\n",
      "920:\tlearn: 0.1580108\ttotal: 58.2s\tremaining: 4.99s\n",
      "921:\tlearn: 0.1579557\ttotal: 58.3s\tremaining: 4.93s\n",
      "922:\tlearn: 0.1579201\ttotal: 58.3s\tremaining: 4.87s\n",
      "923:\tlearn: 0.1578631\ttotal: 58.4s\tremaining: 4.8s\n",
      "924:\tlearn: 0.1578150\ttotal: 58.5s\tremaining: 4.74s\n",
      "925:\tlearn: 0.1577716\ttotal: 58.5s\tremaining: 4.68s\n",
      "926:\tlearn: 0.1577179\ttotal: 58.6s\tremaining: 4.61s\n",
      "927:\tlearn: 0.1576484\ttotal: 58.6s\tremaining: 4.55s\n",
      "928:\tlearn: 0.1576041\ttotal: 58.7s\tremaining: 4.49s\n",
      "929:\tlearn: 0.1575545\ttotal: 58.8s\tremaining: 4.42s\n",
      "930:\tlearn: 0.1574974\ttotal: 58.8s\tremaining: 4.36s\n",
      "931:\tlearn: 0.1574546\ttotal: 58.9s\tremaining: 4.29s\n",
      "932:\tlearn: 0.1574168\ttotal: 58.9s\tremaining: 4.23s\n",
      "933:\tlearn: 0.1573572\ttotal: 59s\tremaining: 4.17s\n",
      "934:\tlearn: 0.1573121\ttotal: 59s\tremaining: 4.1s\n",
      "935:\tlearn: 0.1572550\ttotal: 59.1s\tremaining: 4.04s\n",
      "936:\tlearn: 0.1572020\ttotal: 59.2s\tremaining: 3.98s\n",
      "937:\tlearn: 0.1571469\ttotal: 59.2s\tremaining: 3.91s\n",
      "938:\tlearn: 0.1571165\ttotal: 59.3s\tremaining: 3.85s\n",
      "939:\tlearn: 0.1570565\ttotal: 59.3s\tremaining: 3.79s\n",
      "940:\tlearn: 0.1570008\ttotal: 59.4s\tremaining: 3.72s\n",
      "941:\tlearn: 0.1569530\ttotal: 59.4s\tremaining: 3.66s\n",
      "942:\tlearn: 0.1569003\ttotal: 59.5s\tremaining: 3.6s\n",
      "943:\tlearn: 0.1568460\ttotal: 59.6s\tremaining: 3.53s\n",
      "944:\tlearn: 0.1568035\ttotal: 59.6s\tremaining: 3.47s\n",
      "945:\tlearn: 0.1567451\ttotal: 59.7s\tremaining: 3.41s\n",
      "946:\tlearn: 0.1567091\ttotal: 59.8s\tremaining: 3.34s\n",
      "947:\tlearn: 0.1566580\ttotal: 59.8s\tremaining: 3.28s\n",
      "948:\tlearn: 0.1565983\ttotal: 59.9s\tremaining: 3.22s\n",
      "949:\tlearn: 0.1565440\ttotal: 59.9s\tremaining: 3.15s\n",
      "950:\tlearn: 0.1564996\ttotal: 60s\tremaining: 3.09s\n",
      "951:\tlearn: 0.1564396\ttotal: 1m\tremaining: 3.03s\n",
      "952:\tlearn: 0.1563850\ttotal: 1m\tremaining: 2.96s\n",
      "953:\tlearn: 0.1563236\ttotal: 1m\tremaining: 2.9s\n",
      "954:\tlearn: 0.1562707\ttotal: 1m\tremaining: 2.84s\n",
      "955:\tlearn: 0.1562376\ttotal: 1m\tremaining: 2.77s\n",
      "956:\tlearn: 0.1561838\ttotal: 1m\tremaining: 2.71s\n",
      "957:\tlearn: 0.1561297\ttotal: 1m\tremaining: 2.65s\n",
      "958:\tlearn: 0.1560781\ttotal: 1m\tremaining: 2.58s\n",
      "959:\tlearn: 0.1560308\ttotal: 1m\tremaining: 2.52s\n",
      "960:\tlearn: 0.1559721\ttotal: 1m\tremaining: 2.46s\n",
      "961:\tlearn: 0.1559161\ttotal: 1m\tremaining: 2.4s\n",
      "962:\tlearn: 0.1558727\ttotal: 1m\tremaining: 2.33s\n",
      "963:\tlearn: 0.1558322\ttotal: 1m\tremaining: 2.27s\n",
      "964:\tlearn: 0.1557742\ttotal: 1m\tremaining: 2.21s\n",
      "965:\tlearn: 0.1557392\ttotal: 1m\tremaining: 2.14s\n",
      "966:\tlearn: 0.1556958\ttotal: 1m\tremaining: 2.08s\n",
      "967:\tlearn: 0.1556362\ttotal: 1m\tremaining: 2.02s\n",
      "968:\tlearn: 0.1555810\ttotal: 1m 1s\tremaining: 1.95s\n",
      "969:\tlearn: 0.1555440\ttotal: 1m 1s\tremaining: 1.89s\n",
      "970:\tlearn: 0.1554809\ttotal: 1m 1s\tremaining: 1.83s\n",
      "971:\tlearn: 0.1554151\ttotal: 1m 1s\tremaining: 1.76s\n",
      "972:\tlearn: 0.1553596\ttotal: 1m 1s\tremaining: 1.7s\n",
      "973:\tlearn: 0.1553062\ttotal: 1m 1s\tremaining: 1.64s\n",
      "974:\tlearn: 0.1552619\ttotal: 1m 1s\tremaining: 1.57s\n",
      "975:\tlearn: 0.1552148\ttotal: 1m 1s\tremaining: 1.51s\n",
      "976:\tlearn: 0.1551611\ttotal: 1m 1s\tremaining: 1.45s\n",
      "977:\tlearn: 0.1550994\ttotal: 1m 1s\tremaining: 1.38s\n",
      "978:\tlearn: 0.1550487\ttotal: 1m 1s\tremaining: 1.32s\n",
      "979:\tlearn: 0.1549944\ttotal: 1m 1s\tremaining: 1.26s\n",
      "980:\tlearn: 0.1549364\ttotal: 1m 1s\tremaining: 1.2s\n",
      "981:\tlearn: 0.1548872\ttotal: 1m 1s\tremaining: 1.13s\n",
      "982:\tlearn: 0.1548329\ttotal: 1m 1s\tremaining: 1.07s\n",
      "983:\tlearn: 0.1547914\ttotal: 1m 1s\tremaining: 1.01s\n",
      "984:\tlearn: 0.1547298\ttotal: 1m 2s\tremaining: 944ms\n",
      "985:\tlearn: 0.1546823\ttotal: 1m 2s\tremaining: 881ms\n",
      "986:\tlearn: 0.1546415\ttotal: 1m 2s\tremaining: 818ms\n",
      "987:\tlearn: 0.1545854\ttotal: 1m 2s\tremaining: 755ms\n",
      "988:\tlearn: 0.1545379\ttotal: 1m 2s\tremaining: 692ms\n",
      "989:\tlearn: 0.1544796\ttotal: 1m 2s\tremaining: 629ms\n",
      "990:\tlearn: 0.1544199\ttotal: 1m 2s\tremaining: 566ms\n",
      "991:\tlearn: 0.1543699\ttotal: 1m 2s\tremaining: 503ms\n",
      "992:\tlearn: 0.1543379\ttotal: 1m 2s\tremaining: 440ms\n",
      "993:\tlearn: 0.1542789\ttotal: 1m 2s\tremaining: 377ms\n",
      "994:\tlearn: 0.1542366\ttotal: 1m 2s\tremaining: 314ms\n",
      "995:\tlearn: 0.1541795\ttotal: 1m 2s\tremaining: 251ms\n",
      "996:\tlearn: 0.1541446\ttotal: 1m 2s\tremaining: 189ms\n",
      "997:\tlearn: 0.1541011\ttotal: 1m 2s\tremaining: 126ms\n",
      "998:\tlearn: 0.1540569\ttotal: 1m 2s\tremaining: 62.8ms\n",
      "999:\tlearn: 0.1540113\ttotal: 1m 2s\tremaining: 0us\n",
      "Learning rate set to 0.09461\n",
      "0:\tlearn: 0.6141964\ttotal: 70ms\tremaining: 1m 9s\n",
      "1:\tlearn: 0.5503054\ttotal: 134ms\tremaining: 1m 6s\n",
      "2:\tlearn: 0.5015677\ttotal: 203ms\tremaining: 1m 7s\n",
      "3:\tlearn: 0.4635378\ttotal: 273ms\tremaining: 1m 7s\n",
      "4:\tlearn: 0.4323551\ttotal: 345ms\tremaining: 1m 8s\n",
      "5:\tlearn: 0.4069162\ttotal: 397ms\tremaining: 1m 5s\n",
      "6:\tlearn: 0.3867547\ttotal: 458ms\tremaining: 1m 5s\n",
      "7:\tlearn: 0.3705716\ttotal: 513ms\tremaining: 1m 3s\n",
      "8:\tlearn: 0.3580030\ttotal: 572ms\tremaining: 1m 2s\n",
      "9:\tlearn: 0.3478582\ttotal: 637ms\tremaining: 1m 3s\n",
      "10:\tlearn: 0.3395951\ttotal: 694ms\tremaining: 1m 2s\n",
      "11:\tlearn: 0.3321225\ttotal: 749ms\tremaining: 1m 1s\n",
      "12:\tlearn: 0.3263217\ttotal: 803ms\tremaining: 1m\n",
      "13:\tlearn: 0.3213614\ttotal: 859ms\tremaining: 1m\n",
      "14:\tlearn: 0.3172674\ttotal: 916ms\tremaining: 1m\n",
      "15:\tlearn: 0.3136212\ttotal: 967ms\tremaining: 59.4s\n",
      "16:\tlearn: 0.3104163\ttotal: 1.02s\tremaining: 58.8s\n",
      "17:\tlearn: 0.3078268\ttotal: 1.07s\tremaining: 58.3s\n",
      "18:\tlearn: 0.3054370\ttotal: 1.12s\tremaining: 57.8s\n",
      "19:\tlearn: 0.3032797\ttotal: 1.17s\tremaining: 57.4s\n",
      "20:\tlearn: 0.3013973\ttotal: 1.22s\tremaining: 57.1s\n",
      "21:\tlearn: 0.2997138\ttotal: 1.27s\tremaining: 56.7s\n",
      "22:\tlearn: 0.2981260\ttotal: 1.32s\tremaining: 56.3s\n",
      "23:\tlearn: 0.2967055\ttotal: 1.38s\tremaining: 56.1s\n",
      "24:\tlearn: 0.2953971\ttotal: 1.44s\tremaining: 56.1s\n",
      "25:\tlearn: 0.2941320\ttotal: 1.49s\tremaining: 55.7s\n",
      "26:\tlearn: 0.2929789\ttotal: 1.54s\tremaining: 55.5s\n",
      "27:\tlearn: 0.2918425\ttotal: 1.59s\tremaining: 55.3s\n",
      "28:\tlearn: 0.2907219\ttotal: 1.65s\tremaining: 55.1s\n",
      "29:\tlearn: 0.2897072\ttotal: 1.7s\tremaining: 54.9s\n",
      "30:\tlearn: 0.2887222\ttotal: 1.75s\tremaining: 54.8s\n",
      "31:\tlearn: 0.2877778\ttotal: 1.8s\tremaining: 54.6s\n",
      "32:\tlearn: 0.2868574\ttotal: 1.86s\tremaining: 54.4s\n",
      "33:\tlearn: 0.2860204\ttotal: 1.91s\tremaining: 54.2s\n",
      "34:\tlearn: 0.2852056\ttotal: 1.96s\tremaining: 54.1s\n",
      "35:\tlearn: 0.2843601\ttotal: 2.02s\tremaining: 54s\n",
      "36:\tlearn: 0.2835738\ttotal: 2.07s\tremaining: 53.9s\n",
      "37:\tlearn: 0.2827635\ttotal: 2.12s\tremaining: 53.8s\n",
      "38:\tlearn: 0.2819056\ttotal: 2.19s\tremaining: 53.9s\n",
      "39:\tlearn: 0.2812010\ttotal: 2.24s\tremaining: 53.8s\n",
      "40:\tlearn: 0.2804061\ttotal: 2.3s\tremaining: 53.7s\n",
      "41:\tlearn: 0.2796303\ttotal: 2.36s\tremaining: 53.8s\n",
      "42:\tlearn: 0.2788970\ttotal: 2.42s\tremaining: 53.8s\n",
      "43:\tlearn: 0.2781771\ttotal: 2.47s\tremaining: 53.7s\n",
      "44:\tlearn: 0.2774496\ttotal: 2.53s\tremaining: 53.7s\n",
      "45:\tlearn: 0.2767726\ttotal: 2.59s\tremaining: 53.7s\n",
      "46:\tlearn: 0.2761009\ttotal: 2.64s\tremaining: 53.5s\n",
      "47:\tlearn: 0.2754557\ttotal: 2.7s\tremaining: 53.5s\n",
      "48:\tlearn: 0.2747675\ttotal: 2.75s\tremaining: 53.4s\n",
      "49:\tlearn: 0.2740971\ttotal: 2.8s\tremaining: 53.2s\n",
      "50:\tlearn: 0.2734166\ttotal: 2.86s\tremaining: 53.2s\n",
      "51:\tlearn: 0.2728263\ttotal: 2.91s\tremaining: 53s\n",
      "52:\tlearn: 0.2722578\ttotal: 2.96s\tremaining: 53s\n",
      "53:\tlearn: 0.2716840\ttotal: 3.02s\tremaining: 52.9s\n",
      "54:\tlearn: 0.2710461\ttotal: 3.07s\tremaining: 52.8s\n",
      "55:\tlearn: 0.2704703\ttotal: 3.13s\tremaining: 52.7s\n",
      "56:\tlearn: 0.2698494\ttotal: 3.18s\tremaining: 52.6s\n",
      "57:\tlearn: 0.2692756\ttotal: 3.23s\tremaining: 52.5s\n",
      "58:\tlearn: 0.2687151\ttotal: 3.28s\tremaining: 52.3s\n",
      "59:\tlearn: 0.2681624\ttotal: 3.33s\tremaining: 52.2s\n",
      "60:\tlearn: 0.2675628\ttotal: 3.39s\tremaining: 52.2s\n",
      "61:\tlearn: 0.2670125\ttotal: 3.45s\tremaining: 52.2s\n",
      "62:\tlearn: 0.2664669\ttotal: 3.51s\tremaining: 52.1s\n",
      "63:\tlearn: 0.2659653\ttotal: 3.56s\tremaining: 52s\n",
      "64:\tlearn: 0.2654378\ttotal: 3.61s\tremaining: 51.9s\n",
      "65:\tlearn: 0.2649160\ttotal: 3.66s\tremaining: 51.8s\n",
      "66:\tlearn: 0.2644220\ttotal: 3.71s\tremaining: 51.7s\n",
      "67:\tlearn: 0.2639226\ttotal: 3.77s\tremaining: 51.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68:\tlearn: 0.2633693\ttotal: 3.84s\tremaining: 51.9s\n",
      "69:\tlearn: 0.2629109\ttotal: 3.9s\tremaining: 51.8s\n",
      "70:\tlearn: 0.2624416\ttotal: 3.95s\tremaining: 51.7s\n",
      "71:\tlearn: 0.2619494\ttotal: 4.02s\tremaining: 51.9s\n",
      "72:\tlearn: 0.2614747\ttotal: 4.08s\tremaining: 51.8s\n",
      "73:\tlearn: 0.2609885\ttotal: 4.14s\tremaining: 51.8s\n",
      "74:\tlearn: 0.2605226\ttotal: 4.2s\tremaining: 51.8s\n",
      "75:\tlearn: 0.2600775\ttotal: 4.25s\tremaining: 51.7s\n",
      "76:\tlearn: 0.2596029\ttotal: 4.32s\tremaining: 51.8s\n",
      "77:\tlearn: 0.2591375\ttotal: 4.38s\tremaining: 51.8s\n",
      "78:\tlearn: 0.2587158\ttotal: 4.43s\tremaining: 51.7s\n",
      "79:\tlearn: 0.2582036\ttotal: 4.49s\tremaining: 51.6s\n",
      "80:\tlearn: 0.2577583\ttotal: 4.55s\tremaining: 51.6s\n",
      "81:\tlearn: 0.2573635\ttotal: 4.6s\tremaining: 51.5s\n",
      "82:\tlearn: 0.2569334\ttotal: 4.66s\tremaining: 51.4s\n",
      "83:\tlearn: 0.2564682\ttotal: 4.71s\tremaining: 51.3s\n",
      "84:\tlearn: 0.2560285\ttotal: 4.76s\tremaining: 51.3s\n",
      "85:\tlearn: 0.2556385\ttotal: 4.82s\tremaining: 51.2s\n",
      "86:\tlearn: 0.2552426\ttotal: 4.87s\tremaining: 51.1s\n",
      "87:\tlearn: 0.2547974\ttotal: 4.93s\tremaining: 51.1s\n",
      "88:\tlearn: 0.2544141\ttotal: 4.99s\tremaining: 51.1s\n",
      "89:\tlearn: 0.2540150\ttotal: 5.04s\tremaining: 51s\n",
      "90:\tlearn: 0.2536169\ttotal: 5.09s\tremaining: 50.9s\n",
      "91:\tlearn: 0.2532430\ttotal: 5.15s\tremaining: 50.8s\n",
      "92:\tlearn: 0.2528456\ttotal: 5.21s\tremaining: 50.8s\n",
      "93:\tlearn: 0.2524603\ttotal: 5.26s\tremaining: 50.7s\n",
      "94:\tlearn: 0.2520385\ttotal: 5.32s\tremaining: 50.7s\n",
      "95:\tlearn: 0.2516638\ttotal: 5.37s\tremaining: 50.6s\n",
      "96:\tlearn: 0.2512986\ttotal: 5.42s\tremaining: 50.5s\n",
      "97:\tlearn: 0.2509350\ttotal: 5.48s\tremaining: 50.4s\n",
      "98:\tlearn: 0.2505949\ttotal: 5.54s\tremaining: 50.4s\n",
      "99:\tlearn: 0.2502268\ttotal: 5.59s\tremaining: 50.3s\n",
      "100:\tlearn: 0.2498422\ttotal: 5.65s\tremaining: 50.3s\n",
      "101:\tlearn: 0.2494739\ttotal: 5.71s\tremaining: 50.2s\n",
      "102:\tlearn: 0.2491257\ttotal: 5.76s\tremaining: 50.2s\n",
      "103:\tlearn: 0.2487740\ttotal: 5.82s\tremaining: 50.1s\n",
      "104:\tlearn: 0.2484642\ttotal: 5.88s\tremaining: 50.1s\n",
      "105:\tlearn: 0.2480968\ttotal: 5.94s\tremaining: 50.1s\n",
      "106:\tlearn: 0.2477335\ttotal: 6s\tremaining: 50.1s\n",
      "107:\tlearn: 0.2473896\ttotal: 6.05s\tremaining: 50s\n",
      "108:\tlearn: 0.2470709\ttotal: 6.11s\tremaining: 49.9s\n",
      "109:\tlearn: 0.2467410\ttotal: 6.18s\tremaining: 50s\n",
      "110:\tlearn: 0.2463800\ttotal: 6.24s\tremaining: 50s\n",
      "111:\tlearn: 0.2460345\ttotal: 6.3s\tremaining: 49.9s\n",
      "112:\tlearn: 0.2457271\ttotal: 6.36s\tremaining: 49.9s\n",
      "113:\tlearn: 0.2453664\ttotal: 6.42s\tremaining: 49.9s\n",
      "114:\tlearn: 0.2450496\ttotal: 6.47s\tremaining: 49.8s\n",
      "115:\tlearn: 0.2447354\ttotal: 6.54s\tremaining: 49.8s\n",
      "116:\tlearn: 0.2444090\ttotal: 6.59s\tremaining: 49.7s\n",
      "117:\tlearn: 0.2440756\ttotal: 6.65s\tremaining: 49.7s\n",
      "118:\tlearn: 0.2437124\ttotal: 6.71s\tremaining: 49.7s\n",
      "119:\tlearn: 0.2433889\ttotal: 6.77s\tremaining: 49.6s\n",
      "120:\tlearn: 0.2430541\ttotal: 6.83s\tremaining: 49.7s\n",
      "121:\tlearn: 0.2427664\ttotal: 6.89s\tremaining: 49.6s\n",
      "122:\tlearn: 0.2424593\ttotal: 6.95s\tremaining: 49.6s\n",
      "123:\tlearn: 0.2421351\ttotal: 7.01s\tremaining: 49.5s\n",
      "124:\tlearn: 0.2418180\ttotal: 7.06s\tremaining: 49.4s\n",
      "125:\tlearn: 0.2415050\ttotal: 7.12s\tremaining: 49.4s\n",
      "126:\tlearn: 0.2411783\ttotal: 7.18s\tremaining: 49.4s\n",
      "127:\tlearn: 0.2408811\ttotal: 7.25s\tremaining: 49.4s\n",
      "128:\tlearn: 0.2405812\ttotal: 7.32s\tremaining: 49.4s\n",
      "129:\tlearn: 0.2403082\ttotal: 7.38s\tremaining: 49.4s\n",
      "130:\tlearn: 0.2400105\ttotal: 7.43s\tremaining: 49.3s\n",
      "131:\tlearn: 0.2396898\ttotal: 7.5s\tremaining: 49.3s\n",
      "132:\tlearn: 0.2394237\ttotal: 7.55s\tremaining: 49.2s\n",
      "133:\tlearn: 0.2390986\ttotal: 7.62s\tremaining: 49.2s\n",
      "134:\tlearn: 0.2387997\ttotal: 7.68s\tremaining: 49.2s\n",
      "135:\tlearn: 0.2385060\ttotal: 7.74s\tremaining: 49.2s\n",
      "136:\tlearn: 0.2382263\ttotal: 7.79s\tremaining: 49.1s\n",
      "137:\tlearn: 0.2379392\ttotal: 7.87s\tremaining: 49.1s\n",
      "138:\tlearn: 0.2376621\ttotal: 7.93s\tremaining: 49.1s\n",
      "139:\tlearn: 0.2373830\ttotal: 8s\tremaining: 49.2s\n",
      "140:\tlearn: 0.2370865\ttotal: 8.06s\tremaining: 49.1s\n",
      "141:\tlearn: 0.2368198\ttotal: 8.12s\tremaining: 49s\n",
      "142:\tlearn: 0.2365739\ttotal: 8.17s\tremaining: 49s\n",
      "143:\tlearn: 0.2363203\ttotal: 8.23s\tremaining: 48.9s\n",
      "144:\tlearn: 0.2360250\ttotal: 8.29s\tremaining: 48.9s\n",
      "145:\tlearn: 0.2357328\ttotal: 8.36s\tremaining: 48.9s\n",
      "146:\tlearn: 0.2354491\ttotal: 8.43s\tremaining: 48.9s\n",
      "147:\tlearn: 0.2351911\ttotal: 8.49s\tremaining: 48.9s\n",
      "148:\tlearn: 0.2349331\ttotal: 8.55s\tremaining: 48.8s\n",
      "149:\tlearn: 0.2346628\ttotal: 8.6s\tremaining: 48.7s\n",
      "150:\tlearn: 0.2343947\ttotal: 8.65s\tremaining: 48.6s\n",
      "151:\tlearn: 0.2341503\ttotal: 8.7s\tremaining: 48.6s\n",
      "152:\tlearn: 0.2338827\ttotal: 8.76s\tremaining: 48.5s\n",
      "153:\tlearn: 0.2336340\ttotal: 8.81s\tremaining: 48.4s\n",
      "154:\tlearn: 0.2333417\ttotal: 8.87s\tremaining: 48.4s\n",
      "155:\tlearn: 0.2330899\ttotal: 8.93s\tremaining: 48.3s\n",
      "156:\tlearn: 0.2328496\ttotal: 8.99s\tremaining: 48.3s\n",
      "157:\tlearn: 0.2325979\ttotal: 9.04s\tremaining: 48.2s\n",
      "158:\tlearn: 0.2323448\ttotal: 9.1s\tremaining: 48.1s\n",
      "159:\tlearn: 0.2320852\ttotal: 9.15s\tremaining: 48.1s\n",
      "160:\tlearn: 0.2318470\ttotal: 9.21s\tremaining: 48s\n",
      "161:\tlearn: 0.2316036\ttotal: 9.26s\tremaining: 47.9s\n",
      "162:\tlearn: 0.2313424\ttotal: 9.32s\tremaining: 47.9s\n",
      "163:\tlearn: 0.2311055\ttotal: 9.37s\tremaining: 47.8s\n",
      "164:\tlearn: 0.2308691\ttotal: 9.43s\tremaining: 47.7s\n",
      "165:\tlearn: 0.2306276\ttotal: 9.49s\tremaining: 47.7s\n",
      "166:\tlearn: 0.2303865\ttotal: 9.55s\tremaining: 47.6s\n",
      "167:\tlearn: 0.2301559\ttotal: 9.61s\tremaining: 47.6s\n",
      "168:\tlearn: 0.2299127\ttotal: 9.68s\tremaining: 47.6s\n",
      "169:\tlearn: 0.2296629\ttotal: 9.75s\tremaining: 47.6s\n",
      "170:\tlearn: 0.2294223\ttotal: 9.83s\tremaining: 47.7s\n",
      "171:\tlearn: 0.2291749\ttotal: 9.89s\tremaining: 47.6s\n",
      "172:\tlearn: 0.2289213\ttotal: 9.96s\tremaining: 47.6s\n",
      "173:\tlearn: 0.2286942\ttotal: 10s\tremaining: 47.6s\n",
      "174:\tlearn: 0.2284340\ttotal: 10.1s\tremaining: 47.6s\n",
      "175:\tlearn: 0.2282033\ttotal: 10.1s\tremaining: 47.5s\n",
      "176:\tlearn: 0.2279699\ttotal: 10.2s\tremaining: 47.5s\n",
      "177:\tlearn: 0.2277532\ttotal: 10.3s\tremaining: 47.4s\n",
      "178:\tlearn: 0.2275199\ttotal: 10.3s\tremaining: 47.4s\n",
      "179:\tlearn: 0.2272948\ttotal: 10.4s\tremaining: 47.4s\n",
      "180:\tlearn: 0.2270575\ttotal: 10.5s\tremaining: 47.3s\n",
      "181:\tlearn: 0.2268385\ttotal: 10.5s\tremaining: 47.3s\n",
      "182:\tlearn: 0.2266207\ttotal: 10.6s\tremaining: 47.3s\n",
      "183:\tlearn: 0.2264007\ttotal: 10.6s\tremaining: 47.2s\n",
      "184:\tlearn: 0.2261967\ttotal: 10.7s\tremaining: 47.1s\n",
      "185:\tlearn: 0.2259583\ttotal: 10.8s\tremaining: 47.1s\n",
      "186:\tlearn: 0.2257243\ttotal: 10.8s\tremaining: 47.1s\n",
      "187:\tlearn: 0.2254887\ttotal: 10.9s\tremaining: 47.1s\n",
      "188:\tlearn: 0.2252701\ttotal: 11s\tremaining: 47s\n",
      "189:\tlearn: 0.2250616\ttotal: 11s\tremaining: 47s\n",
      "190:\tlearn: 0.2248559\ttotal: 11.1s\tremaining: 46.9s\n",
      "191:\tlearn: 0.2246467\ttotal: 11.1s\tremaining: 46.8s\n",
      "192:\tlearn: 0.2244245\ttotal: 11.2s\tremaining: 46.8s\n",
      "193:\tlearn: 0.2242272\ttotal: 11.2s\tremaining: 46.7s\n",
      "194:\tlearn: 0.2240336\ttotal: 11.3s\tremaining: 46.6s\n",
      "195:\tlearn: 0.2237928\ttotal: 11.4s\tremaining: 46.6s\n",
      "196:\tlearn: 0.2235888\ttotal: 11.4s\tremaining: 46.5s\n",
      "197:\tlearn: 0.2233864\ttotal: 11.5s\tremaining: 46.5s\n",
      "198:\tlearn: 0.2231798\ttotal: 11.5s\tremaining: 46.4s\n",
      "199:\tlearn: 0.2229765\ttotal: 11.6s\tremaining: 46.3s\n",
      "200:\tlearn: 0.2227776\ttotal: 11.6s\tremaining: 46.3s\n",
      "201:\tlearn: 0.2225837\ttotal: 11.7s\tremaining: 46.2s\n",
      "202:\tlearn: 0.2223853\ttotal: 11.8s\tremaining: 46.2s\n",
      "203:\tlearn: 0.2221983\ttotal: 11.8s\tremaining: 46.1s\n",
      "204:\tlearn: 0.2219955\ttotal: 11.9s\tremaining: 46.1s\n",
      "205:\tlearn: 0.2218121\ttotal: 11.9s\tremaining: 46s\n",
      "206:\tlearn: 0.2216213\ttotal: 12s\tremaining: 45.9s\n",
      "207:\tlearn: 0.2214308\ttotal: 12s\tremaining: 45.9s\n",
      "208:\tlearn: 0.2212222\ttotal: 12.1s\tremaining: 45.9s\n",
      "209:\tlearn: 0.2210233\ttotal: 12.2s\tremaining: 45.8s\n",
      "210:\tlearn: 0.2208358\ttotal: 12.2s\tremaining: 45.8s\n",
      "211:\tlearn: 0.2206578\ttotal: 12.3s\tremaining: 45.7s\n",
      "212:\tlearn: 0.2204575\ttotal: 12.4s\tremaining: 45.6s\n",
      "213:\tlearn: 0.2202546\ttotal: 12.4s\tremaining: 45.6s\n",
      "214:\tlearn: 0.2200675\ttotal: 12.5s\tremaining: 45.6s\n",
      "215:\tlearn: 0.2198817\ttotal: 12.5s\tremaining: 45.5s\n",
      "216:\tlearn: 0.2196810\ttotal: 12.6s\tremaining: 45.5s\n",
      "217:\tlearn: 0.2194894\ttotal: 12.7s\tremaining: 45.4s\n",
      "218:\tlearn: 0.2193074\ttotal: 12.7s\tremaining: 45.4s\n",
      "219:\tlearn: 0.2191104\ttotal: 12.8s\tremaining: 45.3s\n",
      "220:\tlearn: 0.2189240\ttotal: 12.8s\tremaining: 45.3s\n",
      "221:\tlearn: 0.2187383\ttotal: 12.9s\tremaining: 45.2s\n",
      "222:\tlearn: 0.2185531\ttotal: 13s\tremaining: 45.1s\n",
      "223:\tlearn: 0.2183880\ttotal: 13s\tremaining: 45.1s\n",
      "224:\tlearn: 0.2182124\ttotal: 13.1s\tremaining: 45s\n",
      "225:\tlearn: 0.2180392\ttotal: 13.1s\tremaining: 44.9s\n",
      "226:\tlearn: 0.2178640\ttotal: 13.2s\tremaining: 44.9s\n",
      "227:\tlearn: 0.2176940\ttotal: 13.2s\tremaining: 44.8s\n",
      "228:\tlearn: 0.2175094\ttotal: 13.3s\tremaining: 44.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "229:\tlearn: 0.2173328\ttotal: 13.3s\tremaining: 44.7s\n",
      "230:\tlearn: 0.2171400\ttotal: 13.4s\tremaining: 44.6s\n",
      "231:\tlearn: 0.2169669\ttotal: 13.5s\tremaining: 44.6s\n",
      "232:\tlearn: 0.2167991\ttotal: 13.5s\tremaining: 44.5s\n",
      "233:\tlearn: 0.2166335\ttotal: 13.6s\tremaining: 44.4s\n",
      "234:\tlearn: 0.2164665\ttotal: 13.6s\tremaining: 44.4s\n",
      "235:\tlearn: 0.2162990\ttotal: 13.7s\tremaining: 44.3s\n",
      "236:\tlearn: 0.2161346\ttotal: 13.7s\tremaining: 44.3s\n",
      "237:\tlearn: 0.2159659\ttotal: 13.8s\tremaining: 44.2s\n",
      "238:\tlearn: 0.2158041\ttotal: 13.9s\tremaining: 44.2s\n",
      "239:\tlearn: 0.2156367\ttotal: 13.9s\tremaining: 44.1s\n",
      "240:\tlearn: 0.2154600\ttotal: 14s\tremaining: 44.1s\n",
      "241:\tlearn: 0.2152867\ttotal: 14.1s\tremaining: 44s\n",
      "242:\tlearn: 0.2151075\ttotal: 14.1s\tremaining: 44s\n",
      "243:\tlearn: 0.2149373\ttotal: 14.2s\tremaining: 43.9s\n",
      "244:\tlearn: 0.2147625\ttotal: 14.2s\tremaining: 43.9s\n",
      "245:\tlearn: 0.2145982\ttotal: 14.3s\tremaining: 43.8s\n",
      "246:\tlearn: 0.2144328\ttotal: 14.4s\tremaining: 43.8s\n",
      "247:\tlearn: 0.2142589\ttotal: 14.4s\tremaining: 43.7s\n",
      "248:\tlearn: 0.2140949\ttotal: 14.5s\tremaining: 43.6s\n",
      "249:\tlearn: 0.2139339\ttotal: 14.5s\tremaining: 43.6s\n",
      "250:\tlearn: 0.2137897\ttotal: 14.6s\tremaining: 43.5s\n",
      "251:\tlearn: 0.2136307\ttotal: 14.6s\tremaining: 43.4s\n",
      "252:\tlearn: 0.2134770\ttotal: 14.7s\tremaining: 43.4s\n",
      "253:\tlearn: 0.2133313\ttotal: 14.7s\tremaining: 43.3s\n",
      "254:\tlearn: 0.2131684\ttotal: 14.8s\tremaining: 43.3s\n",
      "255:\tlearn: 0.2130059\ttotal: 14.9s\tremaining: 43.2s\n",
      "256:\tlearn: 0.2128475\ttotal: 14.9s\tremaining: 43.1s\n",
      "257:\tlearn: 0.2126835\ttotal: 15s\tremaining: 43.1s\n",
      "258:\tlearn: 0.2125341\ttotal: 15s\tremaining: 43s\n",
      "259:\tlearn: 0.2123599\ttotal: 15.1s\tremaining: 43s\n",
      "260:\tlearn: 0.2122008\ttotal: 15.2s\tremaining: 42.9s\n",
      "261:\tlearn: 0.2120473\ttotal: 15.2s\tremaining: 42.9s\n",
      "262:\tlearn: 0.2118956\ttotal: 15.3s\tremaining: 42.8s\n",
      "263:\tlearn: 0.2117346\ttotal: 15.3s\tremaining: 42.7s\n",
      "264:\tlearn: 0.2115761\ttotal: 15.4s\tremaining: 42.7s\n",
      "265:\tlearn: 0.2114136\ttotal: 15.4s\tremaining: 42.6s\n",
      "266:\tlearn: 0.2112629\ttotal: 15.5s\tremaining: 42.5s\n",
      "267:\tlearn: 0.2111096\ttotal: 15.6s\tremaining: 42.5s\n",
      "268:\tlearn: 0.2109685\ttotal: 15.6s\tremaining: 42.4s\n",
      "269:\tlearn: 0.2108242\ttotal: 15.7s\tremaining: 42.4s\n",
      "270:\tlearn: 0.2106722\ttotal: 15.7s\tremaining: 42.3s\n",
      "271:\tlearn: 0.2105459\ttotal: 15.8s\tremaining: 42.3s\n",
      "272:\tlearn: 0.2103893\ttotal: 15.8s\tremaining: 42.2s\n",
      "273:\tlearn: 0.2102380\ttotal: 15.9s\tremaining: 42.2s\n",
      "274:\tlearn: 0.2100693\ttotal: 16s\tremaining: 42.1s\n",
      "275:\tlearn: 0.2099113\ttotal: 16s\tremaining: 42.1s\n",
      "276:\tlearn: 0.2097633\ttotal: 16.1s\tremaining: 42s\n",
      "277:\tlearn: 0.2096198\ttotal: 16.2s\tremaining: 42s\n",
      "278:\tlearn: 0.2094697\ttotal: 16.2s\tremaining: 42s\n",
      "279:\tlearn: 0.2093218\ttotal: 16.3s\tremaining: 41.9s\n",
      "280:\tlearn: 0.2091858\ttotal: 16.3s\tremaining: 41.8s\n",
      "281:\tlearn: 0.2090277\ttotal: 16.4s\tremaining: 41.8s\n",
      "282:\tlearn: 0.2088713\ttotal: 16.5s\tremaining: 41.8s\n",
      "283:\tlearn: 0.2087144\ttotal: 16.6s\tremaining: 41.7s\n",
      "284:\tlearn: 0.2085699\ttotal: 16.6s\tremaining: 41.7s\n",
      "285:\tlearn: 0.2084198\ttotal: 16.7s\tremaining: 41.6s\n",
      "286:\tlearn: 0.2082755\ttotal: 16.7s\tremaining: 41.6s\n",
      "287:\tlearn: 0.2081203\ttotal: 16.8s\tremaining: 41.5s\n",
      "288:\tlearn: 0.2079793\ttotal: 16.9s\tremaining: 41.5s\n",
      "289:\tlearn: 0.2078561\ttotal: 16.9s\tremaining: 41.4s\n",
      "290:\tlearn: 0.2077246\ttotal: 17s\tremaining: 41.3s\n",
      "291:\tlearn: 0.2075901\ttotal: 17s\tremaining: 41.3s\n",
      "292:\tlearn: 0.2074553\ttotal: 17.1s\tremaining: 41.2s\n",
      "293:\tlearn: 0.2073153\ttotal: 17.1s\tremaining: 41.2s\n",
      "294:\tlearn: 0.2071793\ttotal: 17.2s\tremaining: 41.1s\n",
      "295:\tlearn: 0.2070390\ttotal: 17.3s\tremaining: 41s\n",
      "296:\tlearn: 0.2068964\ttotal: 17.3s\tremaining: 41s\n",
      "297:\tlearn: 0.2067512\ttotal: 17.4s\tremaining: 40.9s\n",
      "298:\tlearn: 0.2066128\ttotal: 17.4s\tremaining: 40.9s\n",
      "299:\tlearn: 0.2064765\ttotal: 17.5s\tremaining: 40.8s\n",
      "300:\tlearn: 0.2063404\ttotal: 17.6s\tremaining: 40.8s\n",
      "301:\tlearn: 0.2062027\ttotal: 17.6s\tremaining: 40.7s\n",
      "302:\tlearn: 0.2060529\ttotal: 17.7s\tremaining: 40.7s\n",
      "303:\tlearn: 0.2059169\ttotal: 17.8s\tremaining: 40.7s\n",
      "304:\tlearn: 0.2057760\ttotal: 17.8s\tremaining: 40.6s\n",
      "305:\tlearn: 0.2056422\ttotal: 17.9s\tremaining: 40.6s\n",
      "306:\tlearn: 0.2055122\ttotal: 17.9s\tremaining: 40.5s\n",
      "307:\tlearn: 0.2053879\ttotal: 18s\tremaining: 40.5s\n",
      "308:\tlearn: 0.2052689\ttotal: 18.1s\tremaining: 40.4s\n",
      "309:\tlearn: 0.2051456\ttotal: 18.1s\tremaining: 40.3s\n",
      "310:\tlearn: 0.2050042\ttotal: 18.2s\tremaining: 40.3s\n",
      "311:\tlearn: 0.2048677\ttotal: 18.2s\tremaining: 40.2s\n",
      "312:\tlearn: 0.2047057\ttotal: 18.3s\tremaining: 40.2s\n",
      "313:\tlearn: 0.2045804\ttotal: 18.4s\tremaining: 40.1s\n",
      "314:\tlearn: 0.2044587\ttotal: 18.4s\tremaining: 40.1s\n",
      "315:\tlearn: 0.2043444\ttotal: 18.5s\tremaining: 40s\n",
      "316:\tlearn: 0.2042190\ttotal: 18.5s\tremaining: 40s\n",
      "317:\tlearn: 0.2040857\ttotal: 18.6s\tremaining: 39.9s\n",
      "318:\tlearn: 0.2039520\ttotal: 18.7s\tremaining: 39.8s\n",
      "319:\tlearn: 0.2038394\ttotal: 18.7s\tremaining: 39.8s\n",
      "320:\tlearn: 0.2037191\ttotal: 18.8s\tremaining: 39.7s\n",
      "321:\tlearn: 0.2035872\ttotal: 18.8s\tremaining: 39.6s\n",
      "322:\tlearn: 0.2034650\ttotal: 18.9s\tremaining: 39.6s\n",
      "323:\tlearn: 0.2033464\ttotal: 18.9s\tremaining: 39.5s\n",
      "324:\tlearn: 0.2032344\ttotal: 19s\tremaining: 39.4s\n",
      "325:\tlearn: 0.2031100\ttotal: 19.1s\tremaining: 39.4s\n",
      "326:\tlearn: 0.2029792\ttotal: 19.1s\tremaining: 39.3s\n",
      "327:\tlearn: 0.2028468\ttotal: 19.2s\tremaining: 39.3s\n",
      "328:\tlearn: 0.2027244\ttotal: 19.2s\tremaining: 39.2s\n",
      "329:\tlearn: 0.2026069\ttotal: 19.3s\tremaining: 39.2s\n",
      "330:\tlearn: 0.2024745\ttotal: 19.4s\tremaining: 39.1s\n",
      "331:\tlearn: 0.2023416\ttotal: 19.4s\tremaining: 39.1s\n",
      "332:\tlearn: 0.2022273\ttotal: 19.5s\tremaining: 39s\n",
      "333:\tlearn: 0.2021118\ttotal: 19.5s\tremaining: 39s\n",
      "334:\tlearn: 0.2019878\ttotal: 19.6s\tremaining: 38.9s\n",
      "335:\tlearn: 0.2018663\ttotal: 19.7s\tremaining: 38.8s\n",
      "336:\tlearn: 0.2017320\ttotal: 19.7s\tremaining: 38.8s\n",
      "337:\tlearn: 0.2016071\ttotal: 19.8s\tremaining: 38.8s\n",
      "338:\tlearn: 0.2014927\ttotal: 19.9s\tremaining: 38.7s\n",
      "339:\tlearn: 0.2013746\ttotal: 19.9s\tremaining: 38.7s\n",
      "340:\tlearn: 0.2012656\ttotal: 20s\tremaining: 38.6s\n",
      "341:\tlearn: 0.2011611\ttotal: 20s\tremaining: 38.6s\n",
      "342:\tlearn: 0.2010367\ttotal: 20.1s\tremaining: 38.5s\n",
      "343:\tlearn: 0.2009105\ttotal: 20.2s\tremaining: 38.5s\n",
      "344:\tlearn: 0.2008015\ttotal: 20.2s\tremaining: 38.4s\n",
      "345:\tlearn: 0.2006707\ttotal: 20.3s\tremaining: 38.4s\n",
      "346:\tlearn: 0.2005493\ttotal: 20.4s\tremaining: 38.4s\n",
      "347:\tlearn: 0.2004292\ttotal: 20.4s\tremaining: 38.3s\n",
      "348:\tlearn: 0.2003171\ttotal: 20.5s\tremaining: 38.3s\n",
      "349:\tlearn: 0.2002042\ttotal: 20.6s\tremaining: 38.2s\n",
      "350:\tlearn: 0.2000863\ttotal: 20.6s\tremaining: 38.1s\n",
      "351:\tlearn: 0.1999656\ttotal: 20.7s\tremaining: 38.1s\n",
      "352:\tlearn: 0.1998440\ttotal: 20.7s\tremaining: 38s\n",
      "353:\tlearn: 0.1997330\ttotal: 20.8s\tremaining: 37.9s\n",
      "354:\tlearn: 0.1996261\ttotal: 20.8s\tremaining: 37.9s\n",
      "355:\tlearn: 0.1995137\ttotal: 20.9s\tremaining: 37.8s\n",
      "356:\tlearn: 0.1994125\ttotal: 21s\tremaining: 37.7s\n",
      "357:\tlearn: 0.1992960\ttotal: 21s\tremaining: 37.7s\n",
      "358:\tlearn: 0.1991712\ttotal: 21.1s\tremaining: 37.6s\n",
      "359:\tlearn: 0.1990702\ttotal: 21.1s\tremaining: 37.6s\n",
      "360:\tlearn: 0.1989483\ttotal: 21.2s\tremaining: 37.5s\n",
      "361:\tlearn: 0.1988269\ttotal: 21.3s\tremaining: 37.5s\n",
      "362:\tlearn: 0.1987171\ttotal: 21.3s\tremaining: 37.4s\n",
      "363:\tlearn: 0.1986080\ttotal: 21.4s\tremaining: 37.3s\n",
      "364:\tlearn: 0.1984991\ttotal: 21.4s\tremaining: 37.3s\n",
      "365:\tlearn: 0.1983881\ttotal: 21.5s\tremaining: 37.2s\n",
      "366:\tlearn: 0.1982749\ttotal: 21.6s\tremaining: 37.2s\n",
      "367:\tlearn: 0.1981611\ttotal: 21.6s\tremaining: 37.1s\n",
      "368:\tlearn: 0.1980490\ttotal: 21.7s\tremaining: 37.1s\n",
      "369:\tlearn: 0.1979326\ttotal: 21.7s\tremaining: 37s\n",
      "370:\tlearn: 0.1978152\ttotal: 21.8s\tremaining: 37s\n",
      "371:\tlearn: 0.1976980\ttotal: 21.9s\tremaining: 36.9s\n",
      "372:\tlearn: 0.1975875\ttotal: 21.9s\tremaining: 36.9s\n",
      "373:\tlearn: 0.1974802\ttotal: 22s\tremaining: 36.8s\n",
      "374:\tlearn: 0.1973652\ttotal: 22s\tremaining: 36.7s\n",
      "375:\tlearn: 0.1972401\ttotal: 22.1s\tremaining: 36.7s\n",
      "376:\tlearn: 0.1971291\ttotal: 22.2s\tremaining: 36.7s\n",
      "377:\tlearn: 0.1970146\ttotal: 22.3s\tremaining: 36.6s\n",
      "378:\tlearn: 0.1969116\ttotal: 22.3s\tremaining: 36.6s\n",
      "379:\tlearn: 0.1968110\ttotal: 22.4s\tremaining: 36.5s\n",
      "380:\tlearn: 0.1967133\ttotal: 22.4s\tremaining: 36.5s\n",
      "381:\tlearn: 0.1966003\ttotal: 22.5s\tremaining: 36.4s\n",
      "382:\tlearn: 0.1965084\ttotal: 22.6s\tremaining: 36.3s\n",
      "383:\tlearn: 0.1964062\ttotal: 22.6s\tremaining: 36.3s\n",
      "384:\tlearn: 0.1962858\ttotal: 22.7s\tremaining: 36.2s\n",
      "385:\tlearn: 0.1961766\ttotal: 22.7s\tremaining: 36.2s\n",
      "386:\tlearn: 0.1960757\ttotal: 22.8s\tremaining: 36.1s\n",
      "387:\tlearn: 0.1959708\ttotal: 22.9s\tremaining: 36s\n",
      "388:\tlearn: 0.1958687\ttotal: 22.9s\tremaining: 36s\n",
      "389:\tlearn: 0.1957542\ttotal: 23s\tremaining: 35.9s\n",
      "390:\tlearn: 0.1956386\ttotal: 23s\tremaining: 35.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391:\tlearn: 0.1955262\ttotal: 23.1s\tremaining: 35.8s\n",
      "392:\tlearn: 0.1954277\ttotal: 23.2s\tremaining: 35.8s\n",
      "393:\tlearn: 0.1953310\ttotal: 23.2s\tremaining: 35.7s\n",
      "394:\tlearn: 0.1952267\ttotal: 23.3s\tremaining: 35.6s\n",
      "395:\tlearn: 0.1951341\ttotal: 23.3s\tremaining: 35.6s\n",
      "396:\tlearn: 0.1950315\ttotal: 23.4s\tremaining: 35.5s\n",
      "397:\tlearn: 0.1949436\ttotal: 23.4s\tremaining: 35.4s\n",
      "398:\tlearn: 0.1948496\ttotal: 23.5s\tremaining: 35.4s\n",
      "399:\tlearn: 0.1947412\ttotal: 23.5s\tremaining: 35.3s\n",
      "400:\tlearn: 0.1946356\ttotal: 23.6s\tremaining: 35.3s\n",
      "401:\tlearn: 0.1945330\ttotal: 23.7s\tremaining: 35.2s\n",
      "402:\tlearn: 0.1944286\ttotal: 23.7s\tremaining: 35.1s\n",
      "403:\tlearn: 0.1943300\ttotal: 23.8s\tremaining: 35.1s\n",
      "404:\tlearn: 0.1942203\ttotal: 23.9s\tremaining: 35s\n",
      "405:\tlearn: 0.1941118\ttotal: 23.9s\tremaining: 35s\n",
      "406:\tlearn: 0.1940038\ttotal: 24s\tremaining: 34.9s\n",
      "407:\tlearn: 0.1938850\ttotal: 24.1s\tremaining: 34.9s\n",
      "408:\tlearn: 0.1937811\ttotal: 24.1s\tremaining: 34.9s\n",
      "409:\tlearn: 0.1936831\ttotal: 24.2s\tremaining: 34.8s\n",
      "410:\tlearn: 0.1935767\ttotal: 24.3s\tremaining: 34.8s\n",
      "411:\tlearn: 0.1934662\ttotal: 24.3s\tremaining: 34.7s\n",
      "412:\tlearn: 0.1933626\ttotal: 24.4s\tremaining: 34.7s\n",
      "413:\tlearn: 0.1932621\ttotal: 24.4s\tremaining: 34.6s\n",
      "414:\tlearn: 0.1931636\ttotal: 24.5s\tremaining: 34.6s\n",
      "415:\tlearn: 0.1930688\ttotal: 24.6s\tremaining: 34.5s\n",
      "416:\tlearn: 0.1929731\ttotal: 24.6s\tremaining: 34.4s\n",
      "417:\tlearn: 0.1928783\ttotal: 24.7s\tremaining: 34.4s\n",
      "418:\tlearn: 0.1927875\ttotal: 24.7s\tremaining: 34.3s\n",
      "419:\tlearn: 0.1926902\ttotal: 24.8s\tremaining: 34.2s\n",
      "420:\tlearn: 0.1925910\ttotal: 24.8s\tremaining: 34.2s\n",
      "421:\tlearn: 0.1924893\ttotal: 24.9s\tremaining: 34.1s\n",
      "422:\tlearn: 0.1923761\ttotal: 25s\tremaining: 34.1s\n",
      "423:\tlearn: 0.1922807\ttotal: 25s\tremaining: 34s\n",
      "424:\tlearn: 0.1921801\ttotal: 25.1s\tremaining: 33.9s\n",
      "425:\tlearn: 0.1920788\ttotal: 25.1s\tremaining: 33.9s\n",
      "426:\tlearn: 0.1919795\ttotal: 25.2s\tremaining: 33.8s\n",
      "427:\tlearn: 0.1918827\ttotal: 25.3s\tremaining: 33.8s\n",
      "428:\tlearn: 0.1917900\ttotal: 25.3s\tremaining: 33.7s\n",
      "429:\tlearn: 0.1916967\ttotal: 25.4s\tremaining: 33.6s\n",
      "430:\tlearn: 0.1915991\ttotal: 25.4s\tremaining: 33.6s\n",
      "431:\tlearn: 0.1914964\ttotal: 25.5s\tremaining: 33.5s\n",
      "432:\tlearn: 0.1913996\ttotal: 25.6s\tremaining: 33.5s\n",
      "433:\tlearn: 0.1913075\ttotal: 25.6s\tremaining: 33.4s\n",
      "434:\tlearn: 0.1912127\ttotal: 25.7s\tremaining: 33.3s\n",
      "435:\tlearn: 0.1911137\ttotal: 25.7s\tremaining: 33.3s\n",
      "436:\tlearn: 0.1910164\ttotal: 25.8s\tremaining: 33.2s\n",
      "437:\tlearn: 0.1909115\ttotal: 25.9s\tremaining: 33.2s\n",
      "438:\tlearn: 0.1908176\ttotal: 25.9s\tremaining: 33.1s\n",
      "439:\tlearn: 0.1907199\ttotal: 26s\tremaining: 33.1s\n",
      "440:\tlearn: 0.1906191\ttotal: 26.1s\tremaining: 33s\n",
      "441:\tlearn: 0.1905364\ttotal: 26.1s\tremaining: 33s\n",
      "442:\tlearn: 0.1904490\ttotal: 26.2s\tremaining: 32.9s\n",
      "443:\tlearn: 0.1903549\ttotal: 26.2s\tremaining: 32.9s\n",
      "444:\tlearn: 0.1902578\ttotal: 26.3s\tremaining: 32.8s\n",
      "445:\tlearn: 0.1901447\ttotal: 26.4s\tremaining: 32.8s\n",
      "446:\tlearn: 0.1900480\ttotal: 26.4s\tremaining: 32.7s\n",
      "447:\tlearn: 0.1899482\ttotal: 26.5s\tremaining: 32.7s\n",
      "448:\tlearn: 0.1898564\ttotal: 26.6s\tremaining: 32.6s\n",
      "449:\tlearn: 0.1897696\ttotal: 26.6s\tremaining: 32.5s\n",
      "450:\tlearn: 0.1896761\ttotal: 26.7s\tremaining: 32.5s\n",
      "451:\tlearn: 0.1895896\ttotal: 26.7s\tremaining: 32.4s\n",
      "452:\tlearn: 0.1894972\ttotal: 26.8s\tremaining: 32.4s\n",
      "453:\tlearn: 0.1894006\ttotal: 26.9s\tremaining: 32.3s\n",
      "454:\tlearn: 0.1893025\ttotal: 26.9s\tremaining: 32.2s\n",
      "455:\tlearn: 0.1891987\ttotal: 27s\tremaining: 32.2s\n",
      "456:\tlearn: 0.1891086\ttotal: 27s\tremaining: 32.1s\n",
      "457:\tlearn: 0.1890293\ttotal: 27.1s\tremaining: 32.1s\n",
      "458:\tlearn: 0.1889391\ttotal: 27.2s\tremaining: 32s\n",
      "459:\tlearn: 0.1888544\ttotal: 27.2s\tremaining: 31.9s\n",
      "460:\tlearn: 0.1887674\ttotal: 27.3s\tremaining: 31.9s\n",
      "461:\tlearn: 0.1886837\ttotal: 27.3s\tremaining: 31.8s\n",
      "462:\tlearn: 0.1885907\ttotal: 27.4s\tremaining: 31.8s\n",
      "463:\tlearn: 0.1884942\ttotal: 27.5s\tremaining: 31.7s\n",
      "464:\tlearn: 0.1883919\ttotal: 27.5s\tremaining: 31.7s\n",
      "465:\tlearn: 0.1882901\ttotal: 27.6s\tremaining: 31.6s\n",
      "466:\tlearn: 0.1881943\ttotal: 27.7s\tremaining: 31.6s\n",
      "467:\tlearn: 0.1881117\ttotal: 27.7s\tremaining: 31.5s\n",
      "468:\tlearn: 0.1880239\ttotal: 27.8s\tremaining: 31.5s\n",
      "469:\tlearn: 0.1879450\ttotal: 27.9s\tremaining: 31.4s\n",
      "470:\tlearn: 0.1878731\ttotal: 27.9s\tremaining: 31.3s\n",
      "471:\tlearn: 0.1877843\ttotal: 28s\tremaining: 31.3s\n",
      "472:\tlearn: 0.1876905\ttotal: 28s\tremaining: 31.2s\n",
      "473:\tlearn: 0.1875948\ttotal: 28.1s\tremaining: 31.2s\n",
      "474:\tlearn: 0.1875094\ttotal: 28.2s\tremaining: 31.1s\n",
      "475:\tlearn: 0.1874248\ttotal: 28.2s\tremaining: 31.1s\n",
      "476:\tlearn: 0.1873242\ttotal: 28.3s\tremaining: 31s\n",
      "477:\tlearn: 0.1872360\ttotal: 28.3s\tremaining: 30.9s\n",
      "478:\tlearn: 0.1871562\ttotal: 28.4s\tremaining: 30.9s\n",
      "479:\tlearn: 0.1870668\ttotal: 28.5s\tremaining: 30.8s\n",
      "480:\tlearn: 0.1869902\ttotal: 28.5s\tremaining: 30.8s\n",
      "481:\tlearn: 0.1869033\ttotal: 28.6s\tremaining: 30.7s\n",
      "482:\tlearn: 0.1868175\ttotal: 28.6s\tremaining: 30.6s\n",
      "483:\tlearn: 0.1867314\ttotal: 28.7s\tremaining: 30.6s\n",
      "484:\tlearn: 0.1866471\ttotal: 28.7s\tremaining: 30.5s\n",
      "485:\tlearn: 0.1865687\ttotal: 28.8s\tremaining: 30.5s\n",
      "486:\tlearn: 0.1864911\ttotal: 28.8s\tremaining: 30.4s\n",
      "487:\tlearn: 0.1864136\ttotal: 28.9s\tremaining: 30.3s\n",
      "488:\tlearn: 0.1863306\ttotal: 29s\tremaining: 30.3s\n",
      "489:\tlearn: 0.1862553\ttotal: 29s\tremaining: 30.2s\n",
      "490:\tlearn: 0.1861620\ttotal: 29.1s\tremaining: 30.1s\n",
      "491:\tlearn: 0.1860770\ttotal: 29.1s\tremaining: 30.1s\n",
      "492:\tlearn: 0.1859951\ttotal: 29.2s\tremaining: 30s\n",
      "493:\tlearn: 0.1859095\ttotal: 29.3s\tremaining: 30s\n",
      "494:\tlearn: 0.1858198\ttotal: 29.3s\tremaining: 29.9s\n",
      "495:\tlearn: 0.1857356\ttotal: 29.4s\tremaining: 29.9s\n",
      "496:\tlearn: 0.1856449\ttotal: 29.4s\tremaining: 29.8s\n",
      "497:\tlearn: 0.1855625\ttotal: 29.5s\tremaining: 29.7s\n",
      "498:\tlearn: 0.1854900\ttotal: 29.6s\tremaining: 29.7s\n",
      "499:\tlearn: 0.1854039\ttotal: 29.6s\tremaining: 29.6s\n",
      "500:\tlearn: 0.1853220\ttotal: 29.7s\tremaining: 29.6s\n",
      "501:\tlearn: 0.1852330\ttotal: 29.8s\tremaining: 29.5s\n",
      "502:\tlearn: 0.1851428\ttotal: 29.8s\tremaining: 29.5s\n",
      "503:\tlearn: 0.1850516\ttotal: 29.9s\tremaining: 29.4s\n",
      "504:\tlearn: 0.1849707\ttotal: 29.9s\tremaining: 29.4s\n",
      "505:\tlearn: 0.1848819\ttotal: 30s\tremaining: 29.3s\n",
      "506:\tlearn: 0.1847968\ttotal: 30.1s\tremaining: 29.2s\n",
      "507:\tlearn: 0.1847141\ttotal: 30.1s\tremaining: 29.2s\n",
      "508:\tlearn: 0.1846084\ttotal: 30.2s\tremaining: 29.1s\n",
      "509:\tlearn: 0.1845266\ttotal: 30.2s\tremaining: 29.1s\n",
      "510:\tlearn: 0.1844417\ttotal: 30.3s\tremaining: 29s\n",
      "511:\tlearn: 0.1843588\ttotal: 30.4s\tremaining: 29s\n",
      "512:\tlearn: 0.1842785\ttotal: 30.5s\tremaining: 28.9s\n",
      "513:\tlearn: 0.1841978\ttotal: 30.5s\tremaining: 28.9s\n",
      "514:\tlearn: 0.1841165\ttotal: 30.6s\tremaining: 28.8s\n",
      "515:\tlearn: 0.1840333\ttotal: 30.6s\tremaining: 28.7s\n",
      "516:\tlearn: 0.1839455\ttotal: 30.7s\tremaining: 28.7s\n",
      "517:\tlearn: 0.1838642\ttotal: 30.8s\tremaining: 28.6s\n",
      "518:\tlearn: 0.1837873\ttotal: 30.8s\tremaining: 28.6s\n",
      "519:\tlearn: 0.1837148\ttotal: 30.9s\tremaining: 28.5s\n",
      "520:\tlearn: 0.1836305\ttotal: 30.9s\tremaining: 28.4s\n",
      "521:\tlearn: 0.1835429\ttotal: 31s\tremaining: 28.4s\n",
      "522:\tlearn: 0.1834695\ttotal: 31.1s\tremaining: 28.3s\n",
      "523:\tlearn: 0.1833954\ttotal: 31.1s\tremaining: 28.3s\n",
      "524:\tlearn: 0.1833194\ttotal: 31.2s\tremaining: 28.2s\n",
      "525:\tlearn: 0.1832344\ttotal: 31.2s\tremaining: 28.1s\n",
      "526:\tlearn: 0.1831597\ttotal: 31.3s\tremaining: 28.1s\n",
      "527:\tlearn: 0.1830650\ttotal: 31.3s\tremaining: 28s\n",
      "528:\tlearn: 0.1829857\ttotal: 31.4s\tremaining: 28s\n",
      "529:\tlearn: 0.1828972\ttotal: 31.5s\tremaining: 27.9s\n",
      "530:\tlearn: 0.1828142\ttotal: 31.5s\tremaining: 27.8s\n",
      "531:\tlearn: 0.1827357\ttotal: 31.6s\tremaining: 27.8s\n",
      "532:\tlearn: 0.1826575\ttotal: 31.6s\tremaining: 27.7s\n",
      "533:\tlearn: 0.1825843\ttotal: 31.7s\tremaining: 27.7s\n",
      "534:\tlearn: 0.1825022\ttotal: 31.8s\tremaining: 27.6s\n",
      "535:\tlearn: 0.1824231\ttotal: 31.8s\tremaining: 27.6s\n",
      "536:\tlearn: 0.1823448\ttotal: 31.9s\tremaining: 27.5s\n",
      "537:\tlearn: 0.1822701\ttotal: 31.9s\tremaining: 27.4s\n",
      "538:\tlearn: 0.1821937\ttotal: 32s\tremaining: 27.4s\n",
      "539:\tlearn: 0.1821136\ttotal: 32.1s\tremaining: 27.3s\n",
      "540:\tlearn: 0.1820411\ttotal: 32.1s\tremaining: 27.3s\n",
      "541:\tlearn: 0.1819706\ttotal: 32.2s\tremaining: 27.2s\n",
      "542:\tlearn: 0.1818770\ttotal: 32.3s\tremaining: 27.2s\n",
      "543:\tlearn: 0.1818023\ttotal: 32.3s\tremaining: 27.1s\n",
      "544:\tlearn: 0.1817233\ttotal: 32.4s\tremaining: 27s\n",
      "545:\tlearn: 0.1816400\ttotal: 32.5s\tremaining: 27s\n",
      "546:\tlearn: 0.1815615\ttotal: 32.5s\tremaining: 26.9s\n",
      "547:\tlearn: 0.1814843\ttotal: 32.6s\tremaining: 26.9s\n",
      "548:\tlearn: 0.1814101\ttotal: 32.6s\tremaining: 26.8s\n",
      "549:\tlearn: 0.1813202\ttotal: 32.7s\tremaining: 26.7s\n",
      "550:\tlearn: 0.1812593\ttotal: 32.7s\tremaining: 26.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "551:\tlearn: 0.1811898\ttotal: 32.8s\tremaining: 26.6s\n",
      "552:\tlearn: 0.1811075\ttotal: 32.9s\tremaining: 26.6s\n",
      "553:\tlearn: 0.1810200\ttotal: 32.9s\tremaining: 26.5s\n",
      "554:\tlearn: 0.1809382\ttotal: 33s\tremaining: 26.5s\n",
      "555:\tlearn: 0.1808682\ttotal: 33.1s\tremaining: 26.4s\n",
      "556:\tlearn: 0.1807907\ttotal: 33.1s\tremaining: 26.3s\n",
      "557:\tlearn: 0.1807181\ttotal: 33.2s\tremaining: 26.3s\n",
      "558:\tlearn: 0.1806439\ttotal: 33.3s\tremaining: 26.2s\n",
      "559:\tlearn: 0.1805652\ttotal: 33.3s\tremaining: 26.2s\n",
      "560:\tlearn: 0.1804852\ttotal: 33.4s\tremaining: 26.1s\n",
      "561:\tlearn: 0.1804101\ttotal: 33.5s\tremaining: 26.1s\n",
      "562:\tlearn: 0.1803315\ttotal: 33.5s\tremaining: 26s\n",
      "563:\tlearn: 0.1802553\ttotal: 33.6s\tremaining: 26s\n",
      "564:\tlearn: 0.1801780\ttotal: 33.6s\tremaining: 25.9s\n",
      "565:\tlearn: 0.1801078\ttotal: 33.7s\tremaining: 25.8s\n",
      "566:\tlearn: 0.1800324\ttotal: 33.8s\tremaining: 25.8s\n",
      "567:\tlearn: 0.1799388\ttotal: 33.8s\tremaining: 25.7s\n",
      "568:\tlearn: 0.1798793\ttotal: 33.9s\tremaining: 25.7s\n",
      "569:\tlearn: 0.1797889\ttotal: 34s\tremaining: 25.6s\n",
      "570:\tlearn: 0.1797287\ttotal: 34s\tremaining: 25.6s\n",
      "571:\tlearn: 0.1796508\ttotal: 34.1s\tremaining: 25.5s\n",
      "572:\tlearn: 0.1795676\ttotal: 34.2s\tremaining: 25.5s\n",
      "573:\tlearn: 0.1795038\ttotal: 34.2s\tremaining: 25.4s\n",
      "574:\tlearn: 0.1794200\ttotal: 34.3s\tremaining: 25.3s\n",
      "575:\tlearn: 0.1793367\ttotal: 34.4s\tremaining: 25.3s\n",
      "576:\tlearn: 0.1792663\ttotal: 34.4s\tremaining: 25.2s\n",
      "577:\tlearn: 0.1791767\ttotal: 34.5s\tremaining: 25.2s\n",
      "578:\tlearn: 0.1791020\ttotal: 34.6s\tremaining: 25.1s\n",
      "579:\tlearn: 0.1790253\ttotal: 34.6s\tremaining: 25.1s\n",
      "580:\tlearn: 0.1789585\ttotal: 34.7s\tremaining: 25s\n",
      "581:\tlearn: 0.1788719\ttotal: 34.8s\tremaining: 25s\n",
      "582:\tlearn: 0.1787886\ttotal: 34.8s\tremaining: 24.9s\n",
      "583:\tlearn: 0.1787056\ttotal: 34.9s\tremaining: 24.9s\n",
      "584:\tlearn: 0.1786306\ttotal: 35s\tremaining: 24.8s\n",
      "585:\tlearn: 0.1785553\ttotal: 35.1s\tremaining: 24.8s\n",
      "586:\tlearn: 0.1784805\ttotal: 35.1s\tremaining: 24.7s\n",
      "587:\tlearn: 0.1784039\ttotal: 35.2s\tremaining: 24.7s\n",
      "588:\tlearn: 0.1783186\ttotal: 35.3s\tremaining: 24.6s\n",
      "589:\tlearn: 0.1782347\ttotal: 35.3s\tremaining: 24.6s\n",
      "590:\tlearn: 0.1781509\ttotal: 35.4s\tremaining: 24.5s\n",
      "591:\tlearn: 0.1780901\ttotal: 35.5s\tremaining: 24.5s\n",
      "592:\tlearn: 0.1780089\ttotal: 35.6s\tremaining: 24.4s\n",
      "593:\tlearn: 0.1779253\ttotal: 35.6s\tremaining: 24.4s\n",
      "594:\tlearn: 0.1778673\ttotal: 35.7s\tremaining: 24.3s\n",
      "595:\tlearn: 0.1777871\ttotal: 35.8s\tremaining: 24.3s\n",
      "596:\tlearn: 0.1777198\ttotal: 35.9s\tremaining: 24.2s\n",
      "597:\tlearn: 0.1776459\ttotal: 35.9s\tremaining: 24.1s\n",
      "598:\tlearn: 0.1775830\ttotal: 36s\tremaining: 24.1s\n",
      "599:\tlearn: 0.1775076\ttotal: 36s\tremaining: 24s\n",
      "600:\tlearn: 0.1774359\ttotal: 36.1s\tremaining: 24s\n",
      "601:\tlearn: 0.1773708\ttotal: 36.2s\tremaining: 23.9s\n",
      "602:\tlearn: 0.1772977\ttotal: 36.2s\tremaining: 23.8s\n",
      "603:\tlearn: 0.1772451\ttotal: 36.3s\tremaining: 23.8s\n",
      "604:\tlearn: 0.1771693\ttotal: 36.4s\tremaining: 23.7s\n",
      "605:\tlearn: 0.1770889\ttotal: 36.4s\tremaining: 23.7s\n",
      "606:\tlearn: 0.1770336\ttotal: 36.5s\tremaining: 23.6s\n",
      "607:\tlearn: 0.1769762\ttotal: 36.6s\tremaining: 23.6s\n",
      "608:\tlearn: 0.1769082\ttotal: 36.6s\tremaining: 23.5s\n",
      "609:\tlearn: 0.1768369\ttotal: 36.7s\tremaining: 23.5s\n",
      "610:\tlearn: 0.1767691\ttotal: 36.8s\tremaining: 23.4s\n",
      "611:\tlearn: 0.1766986\ttotal: 36.8s\tremaining: 23.4s\n",
      "612:\tlearn: 0.1766261\ttotal: 36.9s\tremaining: 23.3s\n",
      "613:\tlearn: 0.1765507\ttotal: 37s\tremaining: 23.3s\n",
      "614:\tlearn: 0.1764723\ttotal: 37.1s\tremaining: 23.2s\n",
      "615:\tlearn: 0.1764003\ttotal: 37.1s\tremaining: 23.2s\n",
      "616:\tlearn: 0.1763152\ttotal: 37.2s\tremaining: 23.1s\n",
      "617:\tlearn: 0.1762486\ttotal: 37.3s\tremaining: 23.1s\n",
      "618:\tlearn: 0.1761757\ttotal: 37.4s\tremaining: 23s\n",
      "619:\tlearn: 0.1761123\ttotal: 37.4s\tremaining: 22.9s\n",
      "620:\tlearn: 0.1760382\ttotal: 37.5s\tremaining: 22.9s\n",
      "621:\tlearn: 0.1759668\ttotal: 37.6s\tremaining: 22.8s\n",
      "622:\tlearn: 0.1759057\ttotal: 37.6s\tremaining: 22.8s\n",
      "623:\tlearn: 0.1758453\ttotal: 37.7s\tremaining: 22.7s\n",
      "624:\tlearn: 0.1757631\ttotal: 37.8s\tremaining: 22.7s\n",
      "625:\tlearn: 0.1757006\ttotal: 37.8s\tremaining: 22.6s\n",
      "626:\tlearn: 0.1756339\ttotal: 37.9s\tremaining: 22.5s\n",
      "627:\tlearn: 0.1755628\ttotal: 38s\tremaining: 22.5s\n",
      "628:\tlearn: 0.1754916\ttotal: 38s\tremaining: 22.4s\n",
      "629:\tlearn: 0.1754112\ttotal: 38.1s\tremaining: 22.4s\n",
      "630:\tlearn: 0.1753393\ttotal: 38.2s\tremaining: 22.3s\n",
      "631:\tlearn: 0.1752704\ttotal: 38.2s\tremaining: 22.3s\n",
      "632:\tlearn: 0.1752041\ttotal: 38.3s\tremaining: 22.2s\n",
      "633:\tlearn: 0.1751287\ttotal: 38.3s\tremaining: 22.1s\n",
      "634:\tlearn: 0.1750536\ttotal: 38.4s\tremaining: 22.1s\n",
      "635:\tlearn: 0.1749917\ttotal: 38.5s\tremaining: 22s\n",
      "636:\tlearn: 0.1749179\ttotal: 38.5s\tremaining: 22s\n",
      "637:\tlearn: 0.1748580\ttotal: 38.6s\tremaining: 21.9s\n",
      "638:\tlearn: 0.1747959\ttotal: 38.6s\tremaining: 21.8s\n",
      "639:\tlearn: 0.1747237\ttotal: 38.7s\tremaining: 21.8s\n",
      "640:\tlearn: 0.1746720\ttotal: 38.8s\tremaining: 21.7s\n",
      "641:\tlearn: 0.1745990\ttotal: 38.8s\tremaining: 21.6s\n",
      "642:\tlearn: 0.1745384\ttotal: 38.9s\tremaining: 21.6s\n",
      "643:\tlearn: 0.1744657\ttotal: 38.9s\tremaining: 21.5s\n",
      "644:\tlearn: 0.1743931\ttotal: 39s\tremaining: 21.5s\n",
      "645:\tlearn: 0.1743295\ttotal: 39.1s\tremaining: 21.4s\n",
      "646:\tlearn: 0.1742679\ttotal: 39.1s\tremaining: 21.3s\n",
      "647:\tlearn: 0.1741897\ttotal: 39.2s\tremaining: 21.3s\n",
      "648:\tlearn: 0.1741219\ttotal: 39.2s\tremaining: 21.2s\n",
      "649:\tlearn: 0.1740616\ttotal: 39.3s\tremaining: 21.2s\n",
      "650:\tlearn: 0.1739992\ttotal: 39.3s\tremaining: 21.1s\n",
      "651:\tlearn: 0.1739370\ttotal: 39.4s\tremaining: 21s\n",
      "652:\tlearn: 0.1738643\ttotal: 39.5s\tremaining: 21s\n",
      "653:\tlearn: 0.1738007\ttotal: 39.5s\tremaining: 20.9s\n",
      "654:\tlearn: 0.1737409\ttotal: 39.6s\tremaining: 20.9s\n",
      "655:\tlearn: 0.1736806\ttotal: 39.7s\tremaining: 20.8s\n",
      "656:\tlearn: 0.1736199\ttotal: 39.7s\tremaining: 20.7s\n",
      "657:\tlearn: 0.1735478\ttotal: 39.8s\tremaining: 20.7s\n",
      "658:\tlearn: 0.1734863\ttotal: 39.9s\tremaining: 20.6s\n",
      "659:\tlearn: 0.1734066\ttotal: 39.9s\tremaining: 20.6s\n",
      "660:\tlearn: 0.1733361\ttotal: 40s\tremaining: 20.5s\n",
      "661:\tlearn: 0.1732742\ttotal: 40s\tremaining: 20.4s\n",
      "662:\tlearn: 0.1732094\ttotal: 40.1s\tremaining: 20.4s\n",
      "663:\tlearn: 0.1731258\ttotal: 40.2s\tremaining: 20.3s\n",
      "664:\tlearn: 0.1730553\ttotal: 40.2s\tremaining: 20.3s\n",
      "665:\tlearn: 0.1729889\ttotal: 40.3s\tremaining: 20.2s\n",
      "666:\tlearn: 0.1729113\ttotal: 40.4s\tremaining: 20.2s\n",
      "667:\tlearn: 0.1728391\ttotal: 40.5s\tremaining: 20.1s\n",
      "668:\tlearn: 0.1727707\ttotal: 40.5s\tremaining: 20.1s\n",
      "669:\tlearn: 0.1727120\ttotal: 40.6s\tremaining: 20s\n",
      "670:\tlearn: 0.1726487\ttotal: 40.6s\tremaining: 19.9s\n",
      "671:\tlearn: 0.1725845\ttotal: 40.7s\tremaining: 19.9s\n",
      "672:\tlearn: 0.1725081\ttotal: 40.8s\tremaining: 19.8s\n",
      "673:\tlearn: 0.1724496\ttotal: 40.8s\tremaining: 19.8s\n",
      "674:\tlearn: 0.1723755\ttotal: 40.9s\tremaining: 19.7s\n",
      "675:\tlearn: 0.1723127\ttotal: 41s\tremaining: 19.6s\n",
      "676:\tlearn: 0.1722457\ttotal: 41s\tremaining: 19.6s\n",
      "677:\tlearn: 0.1721773\ttotal: 41.1s\tremaining: 19.5s\n",
      "678:\tlearn: 0.1721192\ttotal: 41.2s\tremaining: 19.5s\n",
      "679:\tlearn: 0.1720570\ttotal: 41.2s\tremaining: 19.4s\n",
      "680:\tlearn: 0.1719823\ttotal: 41.3s\tremaining: 19.3s\n",
      "681:\tlearn: 0.1719189\ttotal: 41.3s\tremaining: 19.3s\n",
      "682:\tlearn: 0.1718476\ttotal: 41.4s\tremaining: 19.2s\n",
      "683:\tlearn: 0.1717836\ttotal: 41.5s\tremaining: 19.2s\n",
      "684:\tlearn: 0.1717197\ttotal: 41.5s\tremaining: 19.1s\n",
      "685:\tlearn: 0.1716414\ttotal: 41.6s\tremaining: 19s\n",
      "686:\tlearn: 0.1715741\ttotal: 41.7s\tremaining: 19s\n",
      "687:\tlearn: 0.1715098\ttotal: 41.7s\tremaining: 18.9s\n",
      "688:\tlearn: 0.1714415\ttotal: 41.8s\tremaining: 18.9s\n",
      "689:\tlearn: 0.1713784\ttotal: 41.9s\tremaining: 18.8s\n",
      "690:\tlearn: 0.1713066\ttotal: 42s\tremaining: 18.8s\n",
      "691:\tlearn: 0.1712463\ttotal: 42s\tremaining: 18.7s\n",
      "692:\tlearn: 0.1711871\ttotal: 42.1s\tremaining: 18.7s\n",
      "693:\tlearn: 0.1711230\ttotal: 42.2s\tremaining: 18.6s\n",
      "694:\tlearn: 0.1710478\ttotal: 42.3s\tremaining: 18.6s\n",
      "695:\tlearn: 0.1709867\ttotal: 42.3s\tremaining: 18.5s\n",
      "696:\tlearn: 0.1709159\ttotal: 42.4s\tremaining: 18.4s\n",
      "697:\tlearn: 0.1708422\ttotal: 42.5s\tremaining: 18.4s\n",
      "698:\tlearn: 0.1707805\ttotal: 42.6s\tremaining: 18.3s\n",
      "699:\tlearn: 0.1707151\ttotal: 42.6s\tremaining: 18.3s\n",
      "700:\tlearn: 0.1706449\ttotal: 42.7s\tremaining: 18.2s\n",
      "701:\tlearn: 0.1705808\ttotal: 42.8s\tremaining: 18.2s\n",
      "702:\tlearn: 0.1705156\ttotal: 42.8s\tremaining: 18.1s\n",
      "703:\tlearn: 0.1704514\ttotal: 42.9s\tremaining: 18s\n",
      "704:\tlearn: 0.1703942\ttotal: 43s\tremaining: 18s\n",
      "705:\tlearn: 0.1703202\ttotal: 43s\tremaining: 17.9s\n",
      "706:\tlearn: 0.1702560\ttotal: 43.1s\tremaining: 17.9s\n",
      "707:\tlearn: 0.1701929\ttotal: 43.1s\tremaining: 17.8s\n",
      "708:\tlearn: 0.1701239\ttotal: 43.2s\tremaining: 17.7s\n",
      "709:\tlearn: 0.1700661\ttotal: 43.3s\tremaining: 17.7s\n",
      "710:\tlearn: 0.1700052\ttotal: 43.3s\tremaining: 17.6s\n",
      "711:\tlearn: 0.1699414\ttotal: 43.4s\tremaining: 17.6s\n",
      "712:\tlearn: 0.1698693\ttotal: 43.5s\tremaining: 17.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "713:\tlearn: 0.1698067\ttotal: 43.5s\tremaining: 17.4s\n",
      "714:\tlearn: 0.1697404\ttotal: 43.6s\tremaining: 17.4s\n",
      "715:\tlearn: 0.1696726\ttotal: 43.7s\tremaining: 17.3s\n",
      "716:\tlearn: 0.1696119\ttotal: 43.7s\tremaining: 17.3s\n",
      "717:\tlearn: 0.1695632\ttotal: 43.8s\tremaining: 17.2s\n",
      "718:\tlearn: 0.1695033\ttotal: 43.8s\tremaining: 17.1s\n",
      "719:\tlearn: 0.1694387\ttotal: 43.9s\tremaining: 17.1s\n",
      "720:\tlearn: 0.1693729\ttotal: 44s\tremaining: 17s\n",
      "721:\tlearn: 0.1693032\ttotal: 44s\tremaining: 17s\n",
      "722:\tlearn: 0.1692453\ttotal: 44.1s\tremaining: 16.9s\n",
      "723:\tlearn: 0.1691817\ttotal: 44.2s\tremaining: 16.8s\n",
      "724:\tlearn: 0.1691126\ttotal: 44.2s\tremaining: 16.8s\n",
      "725:\tlearn: 0.1690513\ttotal: 44.3s\tremaining: 16.7s\n",
      "726:\tlearn: 0.1689814\ttotal: 44.4s\tremaining: 16.7s\n",
      "727:\tlearn: 0.1689210\ttotal: 44.4s\tremaining: 16.6s\n",
      "728:\tlearn: 0.1688551\ttotal: 44.5s\tremaining: 16.5s\n",
      "729:\tlearn: 0.1687983\ttotal: 44.6s\tremaining: 16.5s\n",
      "730:\tlearn: 0.1687328\ttotal: 44.6s\tremaining: 16.4s\n",
      "731:\tlearn: 0.1686800\ttotal: 44.7s\tremaining: 16.4s\n",
      "732:\tlearn: 0.1686155\ttotal: 44.8s\tremaining: 16.3s\n",
      "733:\tlearn: 0.1685604\ttotal: 44.8s\tremaining: 16.2s\n",
      "734:\tlearn: 0.1685051\ttotal: 44.9s\tremaining: 16.2s\n",
      "735:\tlearn: 0.1684399\ttotal: 45s\tremaining: 16.1s\n",
      "736:\tlearn: 0.1683708\ttotal: 45s\tremaining: 16.1s\n",
      "737:\tlearn: 0.1683060\ttotal: 45.1s\tremaining: 16s\n",
      "738:\tlearn: 0.1682345\ttotal: 45.2s\tremaining: 16s\n",
      "739:\tlearn: 0.1681667\ttotal: 45.2s\tremaining: 15.9s\n",
      "740:\tlearn: 0.1681025\ttotal: 45.3s\tremaining: 15.8s\n",
      "741:\tlearn: 0.1680419\ttotal: 45.4s\tremaining: 15.8s\n",
      "742:\tlearn: 0.1679759\ttotal: 45.5s\tremaining: 15.7s\n",
      "743:\tlearn: 0.1679200\ttotal: 45.5s\tremaining: 15.7s\n",
      "744:\tlearn: 0.1678600\ttotal: 45.6s\tremaining: 15.6s\n",
      "745:\tlearn: 0.1678098\ttotal: 45.7s\tremaining: 15.6s\n",
      "746:\tlearn: 0.1677553\ttotal: 45.8s\tremaining: 15.5s\n",
      "747:\tlearn: 0.1676959\ttotal: 45.8s\tremaining: 15.4s\n",
      "748:\tlearn: 0.1676318\ttotal: 45.9s\tremaining: 15.4s\n",
      "749:\tlearn: 0.1675647\ttotal: 46s\tremaining: 15.3s\n",
      "750:\tlearn: 0.1675122\ttotal: 46.1s\tremaining: 15.3s\n",
      "751:\tlearn: 0.1674540\ttotal: 46.1s\tremaining: 15.2s\n",
      "752:\tlearn: 0.1673845\ttotal: 46.2s\tremaining: 15.2s\n",
      "753:\tlearn: 0.1673197\ttotal: 46.3s\tremaining: 15.1s\n",
      "754:\tlearn: 0.1672706\ttotal: 46.4s\tremaining: 15.1s\n",
      "755:\tlearn: 0.1672142\ttotal: 46.5s\tremaining: 15s\n",
      "756:\tlearn: 0.1671599\ttotal: 46.5s\tremaining: 14.9s\n",
      "757:\tlearn: 0.1670969\ttotal: 46.6s\tremaining: 14.9s\n",
      "758:\tlearn: 0.1670422\ttotal: 46.7s\tremaining: 14.8s\n",
      "759:\tlearn: 0.1669702\ttotal: 46.7s\tremaining: 14.8s\n",
      "760:\tlearn: 0.1669073\ttotal: 46.8s\tremaining: 14.7s\n",
      "761:\tlearn: 0.1668414\ttotal: 46.9s\tremaining: 14.6s\n",
      "762:\tlearn: 0.1667681\ttotal: 47s\tremaining: 14.6s\n",
      "763:\tlearn: 0.1667153\ttotal: 47s\tremaining: 14.5s\n",
      "764:\tlearn: 0.1666659\ttotal: 47.1s\tremaining: 14.5s\n",
      "765:\tlearn: 0.1666043\ttotal: 47.2s\tremaining: 14.4s\n",
      "766:\tlearn: 0.1665539\ttotal: 47.2s\tremaining: 14.3s\n",
      "767:\tlearn: 0.1664916\ttotal: 47.3s\tremaining: 14.3s\n",
      "768:\tlearn: 0.1664301\ttotal: 47.4s\tremaining: 14.2s\n",
      "769:\tlearn: 0.1663614\ttotal: 47.4s\tremaining: 14.2s\n",
      "770:\tlearn: 0.1662839\ttotal: 47.5s\tremaining: 14.1s\n",
      "771:\tlearn: 0.1662207\ttotal: 47.6s\tremaining: 14.1s\n",
      "772:\tlearn: 0.1661537\ttotal: 47.6s\tremaining: 14s\n",
      "773:\tlearn: 0.1660913\ttotal: 47.7s\tremaining: 13.9s\n",
      "774:\tlearn: 0.1660369\ttotal: 47.8s\tremaining: 13.9s\n",
      "775:\tlearn: 0.1659736\ttotal: 47.8s\tremaining: 13.8s\n",
      "776:\tlearn: 0.1659046\ttotal: 47.9s\tremaining: 13.7s\n",
      "777:\tlearn: 0.1658530\ttotal: 48s\tremaining: 13.7s\n",
      "778:\tlearn: 0.1657948\ttotal: 48s\tremaining: 13.6s\n",
      "779:\tlearn: 0.1657351\ttotal: 48.1s\tremaining: 13.6s\n",
      "780:\tlearn: 0.1656815\ttotal: 48.2s\tremaining: 13.5s\n",
      "781:\tlearn: 0.1656217\ttotal: 48.2s\tremaining: 13.4s\n",
      "782:\tlearn: 0.1655707\ttotal: 48.3s\tremaining: 13.4s\n",
      "783:\tlearn: 0.1655116\ttotal: 48.4s\tremaining: 13.3s\n",
      "784:\tlearn: 0.1654608\ttotal: 48.5s\tremaining: 13.3s\n",
      "785:\tlearn: 0.1654027\ttotal: 48.5s\tremaining: 13.2s\n",
      "786:\tlearn: 0.1653403\ttotal: 48.6s\tremaining: 13.2s\n",
      "787:\tlearn: 0.1652814\ttotal: 48.7s\tremaining: 13.1s\n",
      "788:\tlearn: 0.1652308\ttotal: 48.7s\tremaining: 13s\n",
      "789:\tlearn: 0.1651718\ttotal: 48.8s\tremaining: 13s\n",
      "790:\tlearn: 0.1651185\ttotal: 48.9s\tremaining: 12.9s\n",
      "791:\tlearn: 0.1650650\ttotal: 48.9s\tremaining: 12.8s\n",
      "792:\tlearn: 0.1649930\ttotal: 49s\tremaining: 12.8s\n",
      "793:\tlearn: 0.1649332\ttotal: 49.1s\tremaining: 12.7s\n",
      "794:\tlearn: 0.1648795\ttotal: 49.1s\tremaining: 12.7s\n",
      "795:\tlearn: 0.1648226\ttotal: 49.2s\tremaining: 12.6s\n",
      "796:\tlearn: 0.1647692\ttotal: 49.3s\tremaining: 12.6s\n",
      "797:\tlearn: 0.1647115\ttotal: 49.3s\tremaining: 12.5s\n",
      "798:\tlearn: 0.1646467\ttotal: 49.4s\tremaining: 12.4s\n",
      "799:\tlearn: 0.1645939\ttotal: 49.5s\tremaining: 12.4s\n",
      "800:\tlearn: 0.1645614\ttotal: 49.6s\tremaining: 12.3s\n",
      "801:\tlearn: 0.1645159\ttotal: 49.7s\tremaining: 12.3s\n",
      "802:\tlearn: 0.1644653\ttotal: 49.7s\tremaining: 12.2s\n",
      "803:\tlearn: 0.1644052\ttotal: 49.8s\tremaining: 12.1s\n",
      "804:\tlearn: 0.1643502\ttotal: 49.9s\tremaining: 12.1s\n",
      "805:\tlearn: 0.1642950\ttotal: 49.9s\tremaining: 12s\n",
      "806:\tlearn: 0.1642397\ttotal: 50s\tremaining: 12s\n",
      "807:\tlearn: 0.1641891\ttotal: 50.1s\tremaining: 11.9s\n",
      "808:\tlearn: 0.1641258\ttotal: 50.2s\tremaining: 11.8s\n",
      "809:\tlearn: 0.1640711\ttotal: 50.3s\tremaining: 11.8s\n",
      "810:\tlearn: 0.1640220\ttotal: 50.3s\tremaining: 11.7s\n",
      "811:\tlearn: 0.1639657\ttotal: 50.4s\tremaining: 11.7s\n",
      "812:\tlearn: 0.1639186\ttotal: 50.5s\tremaining: 11.6s\n",
      "813:\tlearn: 0.1638542\ttotal: 50.6s\tremaining: 11.6s\n",
      "814:\tlearn: 0.1637943\ttotal: 50.7s\tremaining: 11.5s\n",
      "815:\tlearn: 0.1637426\ttotal: 50.7s\tremaining: 11.4s\n",
      "816:\tlearn: 0.1636833\ttotal: 50.8s\tremaining: 11.4s\n",
      "817:\tlearn: 0.1636140\ttotal: 50.9s\tremaining: 11.3s\n",
      "818:\tlearn: 0.1635653\ttotal: 51s\tremaining: 11.3s\n",
      "819:\tlearn: 0.1635159\ttotal: 51s\tremaining: 11.2s\n",
      "820:\tlearn: 0.1634518\ttotal: 51.1s\tremaining: 11.1s\n",
      "821:\tlearn: 0.1634034\ttotal: 51.2s\tremaining: 11.1s\n",
      "822:\tlearn: 0.1633467\ttotal: 51.3s\tremaining: 11s\n",
      "823:\tlearn: 0.1632769\ttotal: 51.4s\tremaining: 11s\n",
      "824:\tlearn: 0.1632320\ttotal: 51.5s\tremaining: 10.9s\n",
      "825:\tlearn: 0.1631788\ttotal: 51.5s\tremaining: 10.9s\n",
      "826:\tlearn: 0.1631151\ttotal: 51.6s\tremaining: 10.8s\n",
      "827:\tlearn: 0.1630634\ttotal: 51.7s\tremaining: 10.7s\n",
      "828:\tlearn: 0.1629989\ttotal: 51.8s\tremaining: 10.7s\n",
      "829:\tlearn: 0.1629405\ttotal: 51.8s\tremaining: 10.6s\n",
      "830:\tlearn: 0.1628832\ttotal: 51.9s\tremaining: 10.6s\n",
      "831:\tlearn: 0.1628296\ttotal: 52s\tremaining: 10.5s\n",
      "832:\tlearn: 0.1627748\ttotal: 52s\tremaining: 10.4s\n",
      "833:\tlearn: 0.1627232\ttotal: 52.1s\tremaining: 10.4s\n",
      "834:\tlearn: 0.1626620\ttotal: 52.2s\tremaining: 10.3s\n",
      "835:\tlearn: 0.1625980\ttotal: 52.2s\tremaining: 10.2s\n",
      "836:\tlearn: 0.1625385\ttotal: 52.3s\tremaining: 10.2s\n",
      "837:\tlearn: 0.1624793\ttotal: 52.4s\tremaining: 10.1s\n",
      "838:\tlearn: 0.1624233\ttotal: 52.4s\tremaining: 10.1s\n",
      "839:\tlearn: 0.1623642\ttotal: 52.5s\tremaining: 10s\n",
      "840:\tlearn: 0.1623204\ttotal: 52.6s\tremaining: 9.94s\n",
      "841:\tlearn: 0.1622762\ttotal: 52.6s\tremaining: 9.88s\n",
      "842:\tlearn: 0.1622182\ttotal: 52.7s\tremaining: 9.81s\n",
      "843:\tlearn: 0.1621674\ttotal: 52.8s\tremaining: 9.75s\n",
      "844:\tlearn: 0.1621106\ttotal: 52.8s\tremaining: 9.69s\n",
      "845:\tlearn: 0.1620624\ttotal: 52.9s\tremaining: 9.63s\n",
      "846:\tlearn: 0.1620025\ttotal: 52.9s\tremaining: 9.56s\n",
      "847:\tlearn: 0.1619501\ttotal: 53s\tremaining: 9.5s\n",
      "848:\tlearn: 0.1618858\ttotal: 53.1s\tremaining: 9.44s\n",
      "849:\tlearn: 0.1618337\ttotal: 53.1s\tremaining: 9.38s\n",
      "850:\tlearn: 0.1617756\ttotal: 53.2s\tremaining: 9.31s\n",
      "851:\tlearn: 0.1617119\ttotal: 53.3s\tremaining: 9.25s\n",
      "852:\tlearn: 0.1616554\ttotal: 53.3s\tremaining: 9.19s\n",
      "853:\tlearn: 0.1616036\ttotal: 53.4s\tremaining: 9.13s\n",
      "854:\tlearn: 0.1615650\ttotal: 53.5s\tremaining: 9.07s\n",
      "855:\tlearn: 0.1615097\ttotal: 53.5s\tremaining: 9.01s\n",
      "856:\tlearn: 0.1614591\ttotal: 53.6s\tremaining: 8.94s\n",
      "857:\tlearn: 0.1614122\ttotal: 53.7s\tremaining: 8.88s\n",
      "858:\tlearn: 0.1613610\ttotal: 53.7s\tremaining: 8.82s\n",
      "859:\tlearn: 0.1613161\ttotal: 53.8s\tremaining: 8.76s\n",
      "860:\tlearn: 0.1612701\ttotal: 53.9s\tremaining: 8.7s\n",
      "861:\tlearn: 0.1612160\ttotal: 53.9s\tremaining: 8.63s\n",
      "862:\tlearn: 0.1611693\ttotal: 54s\tremaining: 8.57s\n",
      "863:\tlearn: 0.1611080\ttotal: 54s\tremaining: 8.51s\n",
      "864:\tlearn: 0.1610534\ttotal: 54.1s\tremaining: 8.45s\n",
      "865:\tlearn: 0.1609949\ttotal: 54.2s\tremaining: 8.38s\n",
      "866:\tlearn: 0.1609358\ttotal: 54.3s\tremaining: 8.32s\n",
      "867:\tlearn: 0.1608746\ttotal: 54.3s\tremaining: 8.26s\n",
      "868:\tlearn: 0.1608123\ttotal: 54.4s\tremaining: 8.2s\n",
      "869:\tlearn: 0.1607732\ttotal: 54.4s\tremaining: 8.14s\n",
      "870:\tlearn: 0.1607173\ttotal: 54.5s\tremaining: 8.07s\n",
      "871:\tlearn: 0.1606570\ttotal: 54.6s\tremaining: 8.01s\n",
      "872:\tlearn: 0.1606028\ttotal: 54.6s\tremaining: 7.95s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "873:\tlearn: 0.1605464\ttotal: 54.7s\tremaining: 7.89s\n",
      "874:\tlearn: 0.1604866\ttotal: 54.8s\tremaining: 7.83s\n",
      "875:\tlearn: 0.1604427\ttotal: 54.8s\tremaining: 7.76s\n",
      "876:\tlearn: 0.1603945\ttotal: 54.9s\tremaining: 7.7s\n",
      "877:\tlearn: 0.1603392\ttotal: 55s\tremaining: 7.64s\n",
      "878:\tlearn: 0.1602804\ttotal: 55s\tremaining: 7.58s\n",
      "879:\tlearn: 0.1602266\ttotal: 55.1s\tremaining: 7.51s\n",
      "880:\tlearn: 0.1601803\ttotal: 55.2s\tremaining: 7.45s\n",
      "881:\tlearn: 0.1601222\ttotal: 55.2s\tremaining: 7.39s\n",
      "882:\tlearn: 0.1600662\ttotal: 55.3s\tremaining: 7.33s\n",
      "883:\tlearn: 0.1600103\ttotal: 55.4s\tremaining: 7.27s\n",
      "884:\tlearn: 0.1599556\ttotal: 55.4s\tremaining: 7.2s\n",
      "885:\tlearn: 0.1599031\ttotal: 55.5s\tremaining: 7.14s\n",
      "886:\tlearn: 0.1598607\ttotal: 55.6s\tremaining: 7.08s\n",
      "887:\tlearn: 0.1598149\ttotal: 55.6s\tremaining: 7.01s\n",
      "888:\tlearn: 0.1597651\ttotal: 55.7s\tremaining: 6.95s\n",
      "889:\tlearn: 0.1597275\ttotal: 55.8s\tremaining: 6.89s\n",
      "890:\tlearn: 0.1596646\ttotal: 55.8s\tremaining: 6.83s\n",
      "891:\tlearn: 0.1596081\ttotal: 55.9s\tremaining: 6.76s\n",
      "892:\tlearn: 0.1595532\ttotal: 55.9s\tremaining: 6.7s\n",
      "893:\tlearn: 0.1595087\ttotal: 56s\tremaining: 6.64s\n",
      "894:\tlearn: 0.1594564\ttotal: 56.1s\tremaining: 6.58s\n",
      "895:\tlearn: 0.1594085\ttotal: 56.1s\tremaining: 6.51s\n",
      "896:\tlearn: 0.1593483\ttotal: 56.2s\tremaining: 6.45s\n",
      "897:\tlearn: 0.1592971\ttotal: 56.2s\tremaining: 6.39s\n",
      "898:\tlearn: 0.1592462\ttotal: 56.3s\tremaining: 6.32s\n",
      "899:\tlearn: 0.1591812\ttotal: 56.4s\tremaining: 6.26s\n",
      "900:\tlearn: 0.1591280\ttotal: 56.4s\tremaining: 6.2s\n",
      "901:\tlearn: 0.1590796\ttotal: 56.5s\tremaining: 6.13s\n",
      "902:\tlearn: 0.1590242\ttotal: 56.5s\tremaining: 6.07s\n",
      "903:\tlearn: 0.1589744\ttotal: 56.6s\tremaining: 6.01s\n",
      "904:\tlearn: 0.1589244\ttotal: 56.6s\tremaining: 5.95s\n",
      "905:\tlearn: 0.1588719\ttotal: 56.7s\tremaining: 5.88s\n",
      "906:\tlearn: 0.1588182\ttotal: 56.8s\tremaining: 5.82s\n",
      "907:\tlearn: 0.1587545\ttotal: 56.8s\tremaining: 5.76s\n",
      "908:\tlearn: 0.1587123\ttotal: 56.9s\tremaining: 5.69s\n",
      "909:\tlearn: 0.1586640\ttotal: 56.9s\tremaining: 5.63s\n",
      "910:\tlearn: 0.1586072\ttotal: 57s\tremaining: 5.57s\n",
      "911:\tlearn: 0.1585627\ttotal: 57s\tremaining: 5.5s\n",
      "912:\tlearn: 0.1585041\ttotal: 57.1s\tremaining: 5.44s\n",
      "913:\tlearn: 0.1584703\ttotal: 57.2s\tremaining: 5.38s\n",
      "914:\tlearn: 0.1584081\ttotal: 57.2s\tremaining: 5.32s\n",
      "915:\tlearn: 0.1583532\ttotal: 57.3s\tremaining: 5.25s\n",
      "916:\tlearn: 0.1582924\ttotal: 57.3s\tremaining: 5.19s\n",
      "917:\tlearn: 0.1582440\ttotal: 57.4s\tremaining: 5.13s\n",
      "918:\tlearn: 0.1582024\ttotal: 57.4s\tremaining: 5.06s\n",
      "919:\tlearn: 0.1581514\ttotal: 57.5s\tremaining: 5s\n",
      "920:\tlearn: 0.1581043\ttotal: 57.6s\tremaining: 4.94s\n",
      "921:\tlearn: 0.1580538\ttotal: 57.6s\tremaining: 4.87s\n",
      "922:\tlearn: 0.1579850\ttotal: 57.7s\tremaining: 4.81s\n",
      "923:\tlearn: 0.1579320\ttotal: 57.7s\tremaining: 4.75s\n",
      "924:\tlearn: 0.1578767\ttotal: 57.8s\tremaining: 4.69s\n",
      "925:\tlearn: 0.1578186\ttotal: 57.9s\tremaining: 4.62s\n",
      "926:\tlearn: 0.1577602\ttotal: 57.9s\tremaining: 4.56s\n",
      "927:\tlearn: 0.1577154\ttotal: 58s\tremaining: 4.5s\n",
      "928:\tlearn: 0.1576637\ttotal: 58s\tremaining: 4.44s\n",
      "929:\tlearn: 0.1576021\ttotal: 58.1s\tremaining: 4.37s\n",
      "930:\tlearn: 0.1575571\ttotal: 58.2s\tremaining: 4.31s\n",
      "931:\tlearn: 0.1574926\ttotal: 58.2s\tremaining: 4.25s\n",
      "932:\tlearn: 0.1574494\ttotal: 58.3s\tremaining: 4.19s\n",
      "933:\tlearn: 0.1573983\ttotal: 58.4s\tremaining: 4.12s\n",
      "934:\tlearn: 0.1573409\ttotal: 58.4s\tremaining: 4.06s\n",
      "935:\tlearn: 0.1572891\ttotal: 58.5s\tremaining: 4s\n",
      "936:\tlearn: 0.1572313\ttotal: 58.5s\tremaining: 3.94s\n",
      "937:\tlearn: 0.1571791\ttotal: 58.6s\tremaining: 3.87s\n",
      "938:\tlearn: 0.1571374\ttotal: 58.7s\tremaining: 3.81s\n",
      "939:\tlearn: 0.1570870\ttotal: 58.7s\tremaining: 3.75s\n",
      "940:\tlearn: 0.1570244\ttotal: 58.8s\tremaining: 3.69s\n",
      "941:\tlearn: 0.1569787\ttotal: 58.8s\tremaining: 3.62s\n",
      "942:\tlearn: 0.1569231\ttotal: 58.9s\tremaining: 3.56s\n",
      "943:\tlearn: 0.1568679\ttotal: 59s\tremaining: 3.5s\n",
      "944:\tlearn: 0.1568211\ttotal: 59s\tremaining: 3.44s\n",
      "945:\tlearn: 0.1567616\ttotal: 59.1s\tremaining: 3.37s\n",
      "946:\tlearn: 0.1567078\ttotal: 59.2s\tremaining: 3.31s\n",
      "947:\tlearn: 0.1566700\ttotal: 59.2s\tremaining: 3.25s\n",
      "948:\tlearn: 0.1566194\ttotal: 59.3s\tremaining: 3.19s\n",
      "949:\tlearn: 0.1565708\ttotal: 59.4s\tremaining: 3.12s\n",
      "950:\tlearn: 0.1565169\ttotal: 59.4s\tremaining: 3.06s\n",
      "951:\tlearn: 0.1564812\ttotal: 59.5s\tremaining: 3s\n",
      "952:\tlearn: 0.1564379\ttotal: 59.6s\tremaining: 2.94s\n",
      "953:\tlearn: 0.1563935\ttotal: 59.6s\tremaining: 2.87s\n",
      "954:\tlearn: 0.1563407\ttotal: 59.7s\tremaining: 2.81s\n",
      "955:\tlearn: 0.1562888\ttotal: 59.7s\tremaining: 2.75s\n",
      "956:\tlearn: 0.1562259\ttotal: 59.8s\tremaining: 2.69s\n",
      "957:\tlearn: 0.1561609\ttotal: 59.9s\tremaining: 2.63s\n",
      "958:\tlearn: 0.1561043\ttotal: 59.9s\tremaining: 2.56s\n",
      "959:\tlearn: 0.1560441\ttotal: 60s\tremaining: 2.5s\n",
      "960:\tlearn: 0.1560090\ttotal: 1m\tremaining: 2.44s\n",
      "961:\tlearn: 0.1559552\ttotal: 1m\tremaining: 2.38s\n",
      "962:\tlearn: 0.1559113\ttotal: 1m\tremaining: 2.31s\n",
      "963:\tlearn: 0.1558645\ttotal: 1m\tremaining: 2.25s\n",
      "964:\tlearn: 0.1558184\ttotal: 1m\tremaining: 2.19s\n",
      "965:\tlearn: 0.1557592\ttotal: 1m\tremaining: 2.13s\n",
      "966:\tlearn: 0.1557058\ttotal: 1m\tremaining: 2.06s\n",
      "967:\tlearn: 0.1556639\ttotal: 1m\tremaining: 2s\n",
      "968:\tlearn: 0.1555976\ttotal: 1m\tremaining: 1.94s\n",
      "969:\tlearn: 0.1555463\ttotal: 1m\tremaining: 1.88s\n",
      "970:\tlearn: 0.1554865\ttotal: 1m\tremaining: 1.81s\n",
      "971:\tlearn: 0.1554372\ttotal: 1m\tremaining: 1.75s\n",
      "972:\tlearn: 0.1553833\ttotal: 1m\tremaining: 1.69s\n",
      "973:\tlearn: 0.1553363\ttotal: 1m\tremaining: 1.63s\n",
      "974:\tlearn: 0.1552806\ttotal: 1m\tremaining: 1.56s\n",
      "975:\tlearn: 0.1552262\ttotal: 1m 1s\tremaining: 1.5s\n",
      "976:\tlearn: 0.1551786\ttotal: 1m 1s\tremaining: 1.44s\n",
      "977:\tlearn: 0.1551323\ttotal: 1m 1s\tremaining: 1.38s\n",
      "978:\tlearn: 0.1550884\ttotal: 1m 1s\tremaining: 1.31s\n",
      "979:\tlearn: 0.1550324\ttotal: 1m 1s\tremaining: 1.25s\n",
      "980:\tlearn: 0.1549824\ttotal: 1m 1s\tremaining: 1.19s\n",
      "981:\tlearn: 0.1549255\ttotal: 1m 1s\tremaining: 1.12s\n",
      "982:\tlearn: 0.1548689\ttotal: 1m 1s\tremaining: 1.06s\n",
      "983:\tlearn: 0.1548015\ttotal: 1m 1s\tremaining: 1000ms\n",
      "984:\tlearn: 0.1547622\ttotal: 1m 1s\tremaining: 937ms\n",
      "985:\tlearn: 0.1547193\ttotal: 1m 1s\tremaining: 875ms\n",
      "986:\tlearn: 0.1546663\ttotal: 1m 1s\tremaining: 812ms\n",
      "987:\tlearn: 0.1546154\ttotal: 1m 1s\tremaining: 750ms\n",
      "988:\tlearn: 0.1545701\ttotal: 1m 1s\tremaining: 687ms\n",
      "989:\tlearn: 0.1545275\ttotal: 1m 1s\tremaining: 624ms\n",
      "990:\tlearn: 0.1544717\ttotal: 1m 1s\tremaining: 562ms\n",
      "991:\tlearn: 0.1544074\ttotal: 1m 1s\tremaining: 500ms\n",
      "992:\tlearn: 0.1543625\ttotal: 1m 2s\tremaining: 437ms\n",
      "993:\tlearn: 0.1543199\ttotal: 1m 2s\tremaining: 375ms\n",
      "994:\tlearn: 0.1542680\ttotal: 1m 2s\tremaining: 312ms\n",
      "995:\tlearn: 0.1542171\ttotal: 1m 2s\tremaining: 250ms\n",
      "996:\tlearn: 0.1541612\ttotal: 1m 2s\tremaining: 187ms\n",
      "997:\tlearn: 0.1541032\ttotal: 1m 2s\tremaining: 125ms\n",
      "998:\tlearn: 0.1540630\ttotal: 1m 2s\tremaining: 62.4ms\n",
      "999:\tlearn: 0.1540103\ttotal: 1m 2s\tremaining: 0us\n",
      "Learning rate set to 0.09461\n",
      "0:\tlearn: 0.6142352\ttotal: 66.4ms\tremaining: 1m 6s\n",
      "1:\tlearn: 0.5504070\ttotal: 135ms\tremaining: 1m 7s\n",
      "2:\tlearn: 0.5016566\ttotal: 208ms\tremaining: 1m 9s\n",
      "3:\tlearn: 0.4636088\ttotal: 283ms\tremaining: 1m 10s\n",
      "4:\tlearn: 0.4326917\ttotal: 353ms\tremaining: 1m 10s\n",
      "5:\tlearn: 0.4072704\ttotal: 409ms\tremaining: 1m 7s\n",
      "6:\tlearn: 0.3870516\ttotal: 475ms\tremaining: 1m 7s\n",
      "7:\tlearn: 0.3710727\ttotal: 538ms\tremaining: 1m 6s\n",
      "8:\tlearn: 0.3585395\ttotal: 613ms\tremaining: 1m 7s\n",
      "9:\tlearn: 0.3484156\ttotal: 682ms\tremaining: 1m 7s\n",
      "10:\tlearn: 0.3401433\ttotal: 752ms\tremaining: 1m 7s\n",
      "11:\tlearn: 0.3327260\ttotal: 817ms\tremaining: 1m 7s\n",
      "12:\tlearn: 0.3267519\ttotal: 886ms\tremaining: 1m 7s\n",
      "13:\tlearn: 0.3215477\ttotal: 957ms\tremaining: 1m 7s\n",
      "14:\tlearn: 0.3174452\ttotal: 1.03s\tremaining: 1m 7s\n",
      "15:\tlearn: 0.3138985\ttotal: 1.09s\tremaining: 1m 6s\n",
      "16:\tlearn: 0.3107838\ttotal: 1.14s\tremaining: 1m 5s\n",
      "17:\tlearn: 0.3081251\ttotal: 1.19s\tremaining: 1m 5s\n",
      "18:\tlearn: 0.3057092\ttotal: 1.25s\tremaining: 1m 4s\n",
      "19:\tlearn: 0.3036424\ttotal: 1.31s\tremaining: 1m 4s\n",
      "20:\tlearn: 0.3017430\ttotal: 1.38s\tremaining: 1m 4s\n",
      "21:\tlearn: 0.3000141\ttotal: 1.44s\tremaining: 1m 3s\n",
      "22:\tlearn: 0.2984713\ttotal: 1.5s\tremaining: 1m 3s\n",
      "23:\tlearn: 0.2970467\ttotal: 1.56s\tremaining: 1m 3s\n",
      "24:\tlearn: 0.2957661\ttotal: 1.63s\tremaining: 1m 3s\n",
      "25:\tlearn: 0.2945384\ttotal: 1.7s\tremaining: 1m 3s\n",
      "26:\tlearn: 0.2933859\ttotal: 1.75s\tremaining: 1m 3s\n",
      "27:\tlearn: 0.2922083\ttotal: 1.82s\tremaining: 1m 3s\n",
      "28:\tlearn: 0.2910994\ttotal: 1.88s\tremaining: 1m 2s\n",
      "29:\tlearn: 0.2901053\ttotal: 1.94s\tremaining: 1m 2s\n",
      "30:\tlearn: 0.2891687\ttotal: 2s\tremaining: 1m 2s\n",
      "31:\tlearn: 0.2881861\ttotal: 2.06s\tremaining: 1m 2s\n",
      "32:\tlearn: 0.2872806\ttotal: 2.12s\tremaining: 1m 2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33:\tlearn: 0.2864495\ttotal: 2.17s\tremaining: 1m 1s\n",
      "34:\tlearn: 0.2855669\ttotal: 2.24s\tremaining: 1m 1s\n",
      "35:\tlearn: 0.2847209\ttotal: 2.31s\tremaining: 1m 1s\n",
      "36:\tlearn: 0.2838976\ttotal: 2.38s\tremaining: 1m 1s\n",
      "37:\tlearn: 0.2830253\ttotal: 2.45s\tremaining: 1m 1s\n",
      "38:\tlearn: 0.2822380\ttotal: 2.51s\tremaining: 1m 1s\n",
      "39:\tlearn: 0.2814689\ttotal: 2.58s\tremaining: 1m 1s\n",
      "40:\tlearn: 0.2806763\ttotal: 2.64s\tremaining: 1m 1s\n",
      "41:\tlearn: 0.2799860\ttotal: 2.69s\tremaining: 1m 1s\n",
      "42:\tlearn: 0.2792357\ttotal: 2.75s\tremaining: 1m 1s\n",
      "43:\tlearn: 0.2785319\ttotal: 2.81s\tremaining: 1m 1s\n",
      "44:\tlearn: 0.2777634\ttotal: 2.87s\tremaining: 1m\n",
      "45:\tlearn: 0.2771000\ttotal: 2.92s\tremaining: 1m\n",
      "46:\tlearn: 0.2763916\ttotal: 2.98s\tremaining: 1m\n",
      "47:\tlearn: 0.2757263\ttotal: 3.04s\tremaining: 1m\n",
      "48:\tlearn: 0.2750679\ttotal: 3.09s\tremaining: 59.9s\n",
      "49:\tlearn: 0.2743636\ttotal: 3.16s\tremaining: 60s\n",
      "50:\tlearn: 0.2736906\ttotal: 3.21s\tremaining: 59.7s\n",
      "51:\tlearn: 0.2729915\ttotal: 3.28s\tremaining: 59.8s\n",
      "52:\tlearn: 0.2723991\ttotal: 3.34s\tremaining: 59.7s\n",
      "53:\tlearn: 0.2718014\ttotal: 3.41s\tremaining: 59.7s\n",
      "54:\tlearn: 0.2711155\ttotal: 3.48s\tremaining: 59.8s\n",
      "55:\tlearn: 0.2705095\ttotal: 3.54s\tremaining: 59.7s\n",
      "56:\tlearn: 0.2699281\ttotal: 3.6s\tremaining: 59.6s\n",
      "57:\tlearn: 0.2692868\ttotal: 3.68s\tremaining: 59.8s\n",
      "58:\tlearn: 0.2686917\ttotal: 3.74s\tremaining: 59.7s\n",
      "59:\tlearn: 0.2681102\ttotal: 3.79s\tremaining: 59.4s\n",
      "60:\tlearn: 0.2675049\ttotal: 3.85s\tremaining: 59.3s\n",
      "61:\tlearn: 0.2669064\ttotal: 3.91s\tremaining: 59.2s\n",
      "62:\tlearn: 0.2663443\ttotal: 3.98s\tremaining: 59.2s\n",
      "63:\tlearn: 0.2658661\ttotal: 4.04s\tremaining: 59.2s\n",
      "64:\tlearn: 0.2653301\ttotal: 4.11s\tremaining: 59.2s\n",
      "65:\tlearn: 0.2648330\ttotal: 4.18s\tremaining: 59.1s\n",
      "66:\tlearn: 0.2642894\ttotal: 4.25s\tremaining: 59.2s\n",
      "67:\tlearn: 0.2637885\ttotal: 4.32s\tremaining: 59.2s\n",
      "68:\tlearn: 0.2633289\ttotal: 4.4s\tremaining: 59.3s\n",
      "69:\tlearn: 0.2628334\ttotal: 4.46s\tremaining: 59.3s\n",
      "70:\tlearn: 0.2623506\ttotal: 4.53s\tremaining: 59.3s\n",
      "71:\tlearn: 0.2618437\ttotal: 4.6s\tremaining: 59.3s\n",
      "72:\tlearn: 0.2613547\ttotal: 4.66s\tremaining: 59.2s\n",
      "73:\tlearn: 0.2608817\ttotal: 4.72s\tremaining: 59.1s\n",
      "74:\tlearn: 0.2604267\ttotal: 4.79s\tremaining: 59s\n",
      "75:\tlearn: 0.2599587\ttotal: 4.84s\tremaining: 58.8s\n",
      "76:\tlearn: 0.2595190\ttotal: 4.89s\tremaining: 58.7s\n",
      "77:\tlearn: 0.2590409\ttotal: 4.95s\tremaining: 58.5s\n",
      "78:\tlearn: 0.2585902\ttotal: 5.01s\tremaining: 58.4s\n",
      "79:\tlearn: 0.2580978\ttotal: 5.09s\tremaining: 58.5s\n",
      "80:\tlearn: 0.2576501\ttotal: 5.15s\tremaining: 58.4s\n",
      "81:\tlearn: 0.2571780\ttotal: 5.21s\tremaining: 58.3s\n",
      "82:\tlearn: 0.2567513\ttotal: 5.26s\tremaining: 58.1s\n",
      "83:\tlearn: 0.2563174\ttotal: 5.32s\tremaining: 58s\n",
      "84:\tlearn: 0.2559146\ttotal: 5.38s\tremaining: 57.9s\n",
      "85:\tlearn: 0.2554761\ttotal: 5.44s\tremaining: 57.8s\n",
      "86:\tlearn: 0.2550773\ttotal: 5.49s\tremaining: 57.6s\n",
      "87:\tlearn: 0.2546625\ttotal: 5.55s\tremaining: 57.5s\n",
      "88:\tlearn: 0.2542351\ttotal: 5.61s\tremaining: 57.4s\n",
      "89:\tlearn: 0.2538915\ttotal: 5.66s\tremaining: 57.3s\n",
      "90:\tlearn: 0.2534774\ttotal: 5.73s\tremaining: 57.2s\n",
      "91:\tlearn: 0.2530572\ttotal: 5.79s\tremaining: 57.1s\n",
      "92:\tlearn: 0.2526140\ttotal: 5.85s\tremaining: 57s\n",
      "93:\tlearn: 0.2522248\ttotal: 5.91s\tremaining: 56.9s\n",
      "94:\tlearn: 0.2518024\ttotal: 5.96s\tremaining: 56.8s\n",
      "95:\tlearn: 0.2514325\ttotal: 6.02s\tremaining: 56.7s\n",
      "96:\tlearn: 0.2510650\ttotal: 6.08s\tremaining: 56.6s\n",
      "97:\tlearn: 0.2507185\ttotal: 6.14s\tremaining: 56.5s\n",
      "98:\tlearn: 0.2503408\ttotal: 6.2s\tremaining: 56.4s\n",
      "99:\tlearn: 0.2499960\ttotal: 6.25s\tremaining: 56.3s\n",
      "100:\tlearn: 0.2496599\ttotal: 6.32s\tremaining: 56.3s\n",
      "101:\tlearn: 0.2493233\ttotal: 6.43s\tremaining: 56.6s\n",
      "102:\tlearn: 0.2489183\ttotal: 6.52s\tremaining: 56.8s\n",
      "103:\tlearn: 0.2485762\ttotal: 6.58s\tremaining: 56.7s\n",
      "104:\tlearn: 0.2482427\ttotal: 6.65s\tremaining: 56.7s\n",
      "105:\tlearn: 0.2478559\ttotal: 6.72s\tremaining: 56.7s\n",
      "106:\tlearn: 0.2475260\ttotal: 6.79s\tremaining: 56.7s\n",
      "107:\tlearn: 0.2471967\ttotal: 6.86s\tremaining: 56.7s\n",
      "108:\tlearn: 0.2468480\ttotal: 6.93s\tremaining: 56.6s\n",
      "109:\tlearn: 0.2464525\ttotal: 7s\tremaining: 56.6s\n",
      "110:\tlearn: 0.2461267\ttotal: 7.05s\tremaining: 56.5s\n",
      "111:\tlearn: 0.2457360\ttotal: 7.13s\tremaining: 56.5s\n",
      "112:\tlearn: 0.2454180\ttotal: 7.19s\tremaining: 56.5s\n",
      "113:\tlearn: 0.2450612\ttotal: 7.26s\tremaining: 56.4s\n",
      "114:\tlearn: 0.2447395\ttotal: 7.32s\tremaining: 56.3s\n",
      "115:\tlearn: 0.2444336\ttotal: 7.38s\tremaining: 56.3s\n",
      "116:\tlearn: 0.2441248\ttotal: 7.45s\tremaining: 56.2s\n",
      "117:\tlearn: 0.2438098\ttotal: 7.51s\tremaining: 56.1s\n",
      "118:\tlearn: 0.2434875\ttotal: 7.57s\tremaining: 56.1s\n",
      "119:\tlearn: 0.2431586\ttotal: 7.64s\tremaining: 56s\n",
      "120:\tlearn: 0.2428282\ttotal: 7.7s\tremaining: 56s\n",
      "121:\tlearn: 0.2425454\ttotal: 7.76s\tremaining: 55.8s\n",
      "122:\tlearn: 0.2422326\ttotal: 7.83s\tremaining: 55.8s\n",
      "123:\tlearn: 0.2419130\ttotal: 7.89s\tremaining: 55.8s\n",
      "124:\tlearn: 0.2416537\ttotal: 7.96s\tremaining: 55.7s\n",
      "125:\tlearn: 0.2413550\ttotal: 8.03s\tremaining: 55.7s\n",
      "126:\tlearn: 0.2410285\ttotal: 8.1s\tremaining: 55.7s\n",
      "127:\tlearn: 0.2407225\ttotal: 8.16s\tremaining: 55.6s\n",
      "128:\tlearn: 0.2404207\ttotal: 8.22s\tremaining: 55.5s\n",
      "129:\tlearn: 0.2401100\ttotal: 8.29s\tremaining: 55.5s\n",
      "130:\tlearn: 0.2398356\ttotal: 8.36s\tremaining: 55.5s\n",
      "131:\tlearn: 0.2395382\ttotal: 8.42s\tremaining: 55.4s\n",
      "132:\tlearn: 0.2392538\ttotal: 8.48s\tremaining: 55.3s\n",
      "133:\tlearn: 0.2389570\ttotal: 8.54s\tremaining: 55.2s\n",
      "134:\tlearn: 0.2386584\ttotal: 8.61s\tremaining: 55.2s\n",
      "135:\tlearn: 0.2383916\ttotal: 8.67s\tremaining: 55.1s\n",
      "136:\tlearn: 0.2380975\ttotal: 8.73s\tremaining: 55s\n",
      "137:\tlearn: 0.2378488\ttotal: 8.78s\tremaining: 54.9s\n",
      "138:\tlearn: 0.2375521\ttotal: 8.86s\tremaining: 54.9s\n",
      "139:\tlearn: 0.2372646\ttotal: 8.93s\tremaining: 54.9s\n",
      "140:\tlearn: 0.2369723\ttotal: 8.99s\tremaining: 54.8s\n",
      "141:\tlearn: 0.2367053\ttotal: 9.04s\tremaining: 54.6s\n",
      "142:\tlearn: 0.2364414\ttotal: 9.1s\tremaining: 54.5s\n",
      "143:\tlearn: 0.2361780\ttotal: 9.15s\tremaining: 54.4s\n",
      "144:\tlearn: 0.2359347\ttotal: 9.21s\tremaining: 54.3s\n",
      "145:\tlearn: 0.2356709\ttotal: 9.26s\tremaining: 54.2s\n",
      "146:\tlearn: 0.2353960\ttotal: 9.33s\tremaining: 54.1s\n",
      "147:\tlearn: 0.2351298\ttotal: 9.4s\tremaining: 54.1s\n",
      "148:\tlearn: 0.2348624\ttotal: 9.46s\tremaining: 54s\n",
      "149:\tlearn: 0.2345892\ttotal: 9.52s\tremaining: 53.9s\n",
      "150:\tlearn: 0.2343405\ttotal: 9.57s\tremaining: 53.8s\n",
      "151:\tlearn: 0.2340806\ttotal: 9.64s\tremaining: 53.8s\n",
      "152:\tlearn: 0.2338322\ttotal: 9.71s\tremaining: 53.8s\n",
      "153:\tlearn: 0.2335951\ttotal: 9.79s\tremaining: 53.8s\n",
      "154:\tlearn: 0.2333288\ttotal: 9.85s\tremaining: 53.7s\n",
      "155:\tlearn: 0.2330804\ttotal: 9.91s\tremaining: 53.6s\n",
      "156:\tlearn: 0.2327956\ttotal: 9.99s\tremaining: 53.6s\n",
      "157:\tlearn: 0.2325366\ttotal: 10.1s\tremaining: 53.7s\n",
      "158:\tlearn: 0.2322780\ttotal: 10.2s\tremaining: 53.7s\n",
      "159:\tlearn: 0.2320211\ttotal: 10.2s\tremaining: 53.8s\n",
      "160:\tlearn: 0.2317804\ttotal: 10.3s\tremaining: 53.7s\n",
      "161:\tlearn: 0.2315317\ttotal: 10.4s\tremaining: 53.7s\n",
      "162:\tlearn: 0.2312952\ttotal: 10.5s\tremaining: 53.8s\n",
      "163:\tlearn: 0.2310819\ttotal: 10.5s\tremaining: 53.8s\n",
      "164:\tlearn: 0.2308467\ttotal: 10.6s\tremaining: 53.8s\n",
      "165:\tlearn: 0.2306009\ttotal: 10.7s\tremaining: 53.8s\n",
      "166:\tlearn: 0.2303852\ttotal: 10.8s\tremaining: 53.8s\n",
      "167:\tlearn: 0.2301453\ttotal: 10.9s\tremaining: 53.8s\n",
      "168:\tlearn: 0.2298950\ttotal: 10.9s\tremaining: 53.8s\n",
      "169:\tlearn: 0.2296493\ttotal: 11s\tremaining: 53.8s\n",
      "170:\tlearn: 0.2294249\ttotal: 11.1s\tremaining: 53.8s\n",
      "171:\tlearn: 0.2291897\ttotal: 11.2s\tremaining: 53.8s\n",
      "172:\tlearn: 0.2289467\ttotal: 11.3s\tremaining: 53.9s\n",
      "173:\tlearn: 0.2287206\ttotal: 11.3s\tremaining: 53.8s\n",
      "174:\tlearn: 0.2284780\ttotal: 11.4s\tremaining: 53.8s\n",
      "175:\tlearn: 0.2282527\ttotal: 11.5s\tremaining: 53.7s\n",
      "176:\tlearn: 0.2280198\ttotal: 11.5s\tremaining: 53.6s\n",
      "177:\tlearn: 0.2278005\ttotal: 11.6s\tremaining: 53.5s\n",
      "178:\tlearn: 0.2275907\ttotal: 11.6s\tremaining: 53.4s\n",
      "179:\tlearn: 0.2273672\ttotal: 11.7s\tremaining: 53.3s\n",
      "180:\tlearn: 0.2271441\ttotal: 11.8s\tremaining: 53.2s\n",
      "181:\tlearn: 0.2269204\ttotal: 11.8s\tremaining: 53.2s\n",
      "182:\tlearn: 0.2266908\ttotal: 11.9s\tremaining: 53.1s\n",
      "183:\tlearn: 0.2264687\ttotal: 12s\tremaining: 53.1s\n",
      "184:\tlearn: 0.2262313\ttotal: 12s\tremaining: 53s\n",
      "185:\tlearn: 0.2260058\ttotal: 12.1s\tremaining: 53s\n",
      "186:\tlearn: 0.2257971\ttotal: 12.2s\tremaining: 52.9s\n",
      "187:\tlearn: 0.2255895\ttotal: 12.2s\tremaining: 52.8s\n",
      "188:\tlearn: 0.2253651\ttotal: 12.3s\tremaining: 52.7s\n",
      "189:\tlearn: 0.2251460\ttotal: 12.4s\tremaining: 52.7s\n",
      "190:\tlearn: 0.2249231\ttotal: 12.4s\tremaining: 52.6s\n",
      "191:\tlearn: 0.2247302\ttotal: 12.5s\tremaining: 52.5s\n",
      "192:\tlearn: 0.2245113\ttotal: 12.5s\tremaining: 52.4s\n",
      "193:\tlearn: 0.2242975\ttotal: 12.6s\tremaining: 52.3s\n",
      "194:\tlearn: 0.2240728\ttotal: 12.7s\tremaining: 52.3s\n",
      "195:\tlearn: 0.2238787\ttotal: 12.7s\tremaining: 52.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196:\tlearn: 0.2236659\ttotal: 12.8s\tremaining: 52.1s\n",
      "197:\tlearn: 0.2234882\ttotal: 12.8s\tremaining: 52s\n",
      "198:\tlearn: 0.2232816\ttotal: 12.9s\tremaining: 52s\n",
      "199:\tlearn: 0.2230578\ttotal: 13s\tremaining: 51.9s\n",
      "200:\tlearn: 0.2228556\ttotal: 13s\tremaining: 51.9s\n",
      "201:\tlearn: 0.2226519\ttotal: 13.1s\tremaining: 51.8s\n",
      "202:\tlearn: 0.2224466\ttotal: 13.2s\tremaining: 51.7s\n",
      "203:\tlearn: 0.2222628\ttotal: 13.2s\tremaining: 51.6s\n",
      "204:\tlearn: 0.2220558\ttotal: 13.3s\tremaining: 51.5s\n",
      "205:\tlearn: 0.2218425\ttotal: 13.3s\tremaining: 51.5s\n",
      "206:\tlearn: 0.2216316\ttotal: 13.4s\tremaining: 51.4s\n",
      "207:\tlearn: 0.2214508\ttotal: 13.5s\tremaining: 51.3s\n",
      "208:\tlearn: 0.2212559\ttotal: 13.6s\tremaining: 51.3s\n",
      "209:\tlearn: 0.2210576\ttotal: 13.6s\tremaining: 51.2s\n",
      "210:\tlearn: 0.2208539\ttotal: 13.7s\tremaining: 51.2s\n",
      "211:\tlearn: 0.2206676\ttotal: 13.7s\tremaining: 51.1s\n",
      "212:\tlearn: 0.2204789\ttotal: 13.8s\tremaining: 51s\n",
      "213:\tlearn: 0.2202883\ttotal: 13.9s\tremaining: 50.9s\n",
      "214:\tlearn: 0.2200922\ttotal: 13.9s\tremaining: 50.9s\n",
      "215:\tlearn: 0.2199192\ttotal: 14s\tremaining: 50.8s\n",
      "216:\tlearn: 0.2197263\ttotal: 14.1s\tremaining: 50.7s\n",
      "217:\tlearn: 0.2195297\ttotal: 14.1s\tremaining: 50.7s\n",
      "218:\tlearn: 0.2193344\ttotal: 14.2s\tremaining: 50.6s\n",
      "219:\tlearn: 0.2191481\ttotal: 14.3s\tremaining: 50.6s\n",
      "220:\tlearn: 0.2189615\ttotal: 14.3s\tremaining: 50.5s\n",
      "221:\tlearn: 0.2187839\ttotal: 14.4s\tremaining: 50.5s\n",
      "222:\tlearn: 0.2186217\ttotal: 14.5s\tremaining: 50.4s\n",
      "223:\tlearn: 0.2184487\ttotal: 14.5s\tremaining: 50.3s\n",
      "224:\tlearn: 0.2182507\ttotal: 14.6s\tremaining: 50.2s\n",
      "225:\tlearn: 0.2180678\ttotal: 14.7s\tremaining: 50.3s\n",
      "226:\tlearn: 0.2178964\ttotal: 14.7s\tremaining: 50.2s\n",
      "227:\tlearn: 0.2177281\ttotal: 14.8s\tremaining: 50.1s\n",
      "228:\tlearn: 0.2175604\ttotal: 14.9s\tremaining: 50s\n",
      "229:\tlearn: 0.2173742\ttotal: 14.9s\tremaining: 50s\n",
      "230:\tlearn: 0.2172104\ttotal: 15s\tremaining: 49.9s\n",
      "231:\tlearn: 0.2170265\ttotal: 15s\tremaining: 49.8s\n",
      "232:\tlearn: 0.2168646\ttotal: 15.1s\tremaining: 49.7s\n",
      "233:\tlearn: 0.2167021\ttotal: 15.2s\tremaining: 49.6s\n",
      "234:\tlearn: 0.2165094\ttotal: 15.2s\tremaining: 49.5s\n",
      "235:\tlearn: 0.2163281\ttotal: 15.3s\tremaining: 49.5s\n",
      "236:\tlearn: 0.2161626\ttotal: 15.4s\tremaining: 49.5s\n",
      "237:\tlearn: 0.2159848\ttotal: 15.4s\tremaining: 49.4s\n",
      "238:\tlearn: 0.2158093\ttotal: 15.5s\tremaining: 49.3s\n",
      "239:\tlearn: 0.2156443\ttotal: 15.6s\tremaining: 49.2s\n",
      "240:\tlearn: 0.2154749\ttotal: 15.6s\tremaining: 49.2s\n",
      "241:\tlearn: 0.2153144\ttotal: 15.7s\tremaining: 49.1s\n",
      "242:\tlearn: 0.2151444\ttotal: 15.7s\tremaining: 49s\n",
      "243:\tlearn: 0.2149671\ttotal: 15.8s\tremaining: 49s\n",
      "244:\tlearn: 0.2147734\ttotal: 15.9s\tremaining: 48.9s\n",
      "245:\tlearn: 0.2146085\ttotal: 15.9s\tremaining: 48.8s\n",
      "246:\tlearn: 0.2144316\ttotal: 16s\tremaining: 48.8s\n",
      "247:\tlearn: 0.2142664\ttotal: 16.1s\tremaining: 48.7s\n",
      "248:\tlearn: 0.2141016\ttotal: 16.1s\tremaining: 48.6s\n",
      "249:\tlearn: 0.2139252\ttotal: 16.2s\tremaining: 48.5s\n",
      "250:\tlearn: 0.2137598\ttotal: 16.3s\tremaining: 48.5s\n",
      "251:\tlearn: 0.2136109\ttotal: 16.3s\tremaining: 48.5s\n",
      "252:\tlearn: 0.2134570\ttotal: 16.4s\tremaining: 48.4s\n",
      "253:\tlearn: 0.2133078\ttotal: 16.5s\tremaining: 48.3s\n",
      "254:\tlearn: 0.2131476\ttotal: 16.5s\tremaining: 48.3s\n",
      "255:\tlearn: 0.2129703\ttotal: 16.6s\tremaining: 48.3s\n",
      "256:\tlearn: 0.2128169\ttotal: 16.7s\tremaining: 48.3s\n",
      "257:\tlearn: 0.2126526\ttotal: 16.8s\tremaining: 48.2s\n",
      "258:\tlearn: 0.2124944\ttotal: 16.8s\tremaining: 48.1s\n",
      "259:\tlearn: 0.2123333\ttotal: 16.9s\tremaining: 48.1s\n",
      "260:\tlearn: 0.2121794\ttotal: 17s\tremaining: 48s\n",
      "261:\tlearn: 0.2120189\ttotal: 17s\tremaining: 48s\n",
      "262:\tlearn: 0.2118619\ttotal: 17.1s\tremaining: 47.9s\n",
      "263:\tlearn: 0.2117087\ttotal: 17.1s\tremaining: 47.8s\n",
      "264:\tlearn: 0.2115464\ttotal: 17.2s\tremaining: 47.7s\n",
      "265:\tlearn: 0.2114055\ttotal: 17.3s\tremaining: 47.6s\n",
      "266:\tlearn: 0.2112617\ttotal: 17.3s\tremaining: 47.6s\n",
      "267:\tlearn: 0.2111159\ttotal: 17.4s\tremaining: 47.5s\n",
      "268:\tlearn: 0.2109702\ttotal: 17.5s\tremaining: 47.4s\n",
      "269:\tlearn: 0.2108330\ttotal: 17.5s\tremaining: 47.3s\n",
      "270:\tlearn: 0.2106658\ttotal: 17.6s\tremaining: 47.3s\n",
      "271:\tlearn: 0.2105209\ttotal: 17.6s\tremaining: 47.2s\n",
      "272:\tlearn: 0.2103749\ttotal: 17.7s\tremaining: 47.1s\n",
      "273:\tlearn: 0.2102307\ttotal: 17.7s\tremaining: 47s\n",
      "274:\tlearn: 0.2100807\ttotal: 17.8s\tremaining: 47s\n",
      "275:\tlearn: 0.2099395\ttotal: 17.9s\tremaining: 46.9s\n",
      "276:\tlearn: 0.2098004\ttotal: 17.9s\tremaining: 46.8s\n",
      "277:\tlearn: 0.2096472\ttotal: 18s\tremaining: 46.8s\n",
      "278:\tlearn: 0.2095002\ttotal: 18.1s\tremaining: 46.7s\n",
      "279:\tlearn: 0.2093391\ttotal: 18.1s\tremaining: 46.6s\n",
      "280:\tlearn: 0.2091985\ttotal: 18.2s\tremaining: 46.6s\n",
      "281:\tlearn: 0.2090488\ttotal: 18.3s\tremaining: 46.5s\n",
      "282:\tlearn: 0.2089062\ttotal: 18.3s\tremaining: 46.4s\n",
      "283:\tlearn: 0.2087636\ttotal: 18.4s\tremaining: 46.4s\n",
      "284:\tlearn: 0.2086105\ttotal: 18.5s\tremaining: 46.3s\n",
      "285:\tlearn: 0.2084897\ttotal: 18.5s\tremaining: 46.2s\n",
      "286:\tlearn: 0.2083468\ttotal: 18.6s\tremaining: 46.2s\n",
      "287:\tlearn: 0.2082116\ttotal: 18.6s\tremaining: 46.1s\n",
      "288:\tlearn: 0.2080776\ttotal: 18.7s\tremaining: 46s\n",
      "289:\tlearn: 0.2079377\ttotal: 18.8s\tremaining: 45.9s\n",
      "290:\tlearn: 0.2078007\ttotal: 18.8s\tremaining: 45.9s\n",
      "291:\tlearn: 0.2076677\ttotal: 18.9s\tremaining: 45.8s\n",
      "292:\tlearn: 0.2075382\ttotal: 19s\tremaining: 45.7s\n",
      "293:\tlearn: 0.2074074\ttotal: 19s\tremaining: 45.7s\n",
      "294:\tlearn: 0.2072772\ttotal: 19.1s\tremaining: 45.6s\n",
      "295:\tlearn: 0.2071299\ttotal: 19.1s\tremaining: 45.5s\n",
      "296:\tlearn: 0.2069906\ttotal: 19.2s\tremaining: 45.5s\n",
      "297:\tlearn: 0.2068556\ttotal: 19.3s\tremaining: 45.4s\n",
      "298:\tlearn: 0.2067083\ttotal: 19.3s\tremaining: 45.3s\n",
      "299:\tlearn: 0.2065725\ttotal: 19.4s\tremaining: 45.3s\n",
      "300:\tlearn: 0.2064251\ttotal: 19.5s\tremaining: 45.2s\n",
      "301:\tlearn: 0.2062951\ttotal: 19.5s\tremaining: 45.1s\n",
      "302:\tlearn: 0.2061586\ttotal: 19.6s\tremaining: 45s\n",
      "303:\tlearn: 0.2060239\ttotal: 19.6s\tremaining: 45s\n",
      "304:\tlearn: 0.2058964\ttotal: 19.7s\tremaining: 44.9s\n",
      "305:\tlearn: 0.2057642\ttotal: 19.8s\tremaining: 44.9s\n",
      "306:\tlearn: 0.2056245\ttotal: 19.9s\tremaining: 44.8s\n",
      "307:\tlearn: 0.2054872\ttotal: 19.9s\tremaining: 44.7s\n",
      "308:\tlearn: 0.2053447\ttotal: 20s\tremaining: 44.7s\n",
      "309:\tlearn: 0.2051964\ttotal: 20.1s\tremaining: 44.6s\n",
      "310:\tlearn: 0.2050635\ttotal: 20.1s\tremaining: 44.5s\n",
      "311:\tlearn: 0.2049293\ttotal: 20.2s\tremaining: 44.5s\n",
      "312:\tlearn: 0.2048021\ttotal: 20.2s\tremaining: 44.4s\n",
      "313:\tlearn: 0.2046552\ttotal: 20.3s\tremaining: 44.3s\n",
      "314:\tlearn: 0.2045294\ttotal: 20.4s\tremaining: 44.3s\n",
      "315:\tlearn: 0.2043973\ttotal: 20.4s\tremaining: 44.2s\n",
      "316:\tlearn: 0.2042770\ttotal: 20.5s\tremaining: 44.2s\n",
      "317:\tlearn: 0.2041512\ttotal: 20.6s\tremaining: 44.1s\n",
      "318:\tlearn: 0.2040340\ttotal: 20.6s\tremaining: 44s\n",
      "319:\tlearn: 0.2039037\ttotal: 20.7s\tremaining: 44s\n",
      "320:\tlearn: 0.2037848\ttotal: 20.7s\tremaining: 43.9s\n",
      "321:\tlearn: 0.2036622\ttotal: 20.8s\tremaining: 43.8s\n",
      "322:\tlearn: 0.2035342\ttotal: 20.9s\tremaining: 43.8s\n",
      "323:\tlearn: 0.2034077\ttotal: 20.9s\tremaining: 43.7s\n",
      "324:\tlearn: 0.2032801\ttotal: 21s\tremaining: 43.7s\n",
      "325:\tlearn: 0.2031581\ttotal: 21.1s\tremaining: 43.6s\n",
      "326:\tlearn: 0.2030382\ttotal: 21.1s\tremaining: 43.5s\n",
      "327:\tlearn: 0.2029040\ttotal: 21.2s\tremaining: 43.4s\n",
      "328:\tlearn: 0.2027872\ttotal: 21.2s\tremaining: 43.3s\n",
      "329:\tlearn: 0.2026746\ttotal: 21.3s\tremaining: 43.3s\n",
      "330:\tlearn: 0.2025426\ttotal: 21.4s\tremaining: 43.2s\n",
      "331:\tlearn: 0.2024166\ttotal: 21.4s\tremaining: 43.1s\n",
      "332:\tlearn: 0.2022904\ttotal: 21.5s\tremaining: 43s\n",
      "333:\tlearn: 0.2021747\ttotal: 21.5s\tremaining: 43s\n",
      "334:\tlearn: 0.2020638\ttotal: 21.6s\tremaining: 42.9s\n",
      "335:\tlearn: 0.2019532\ttotal: 21.7s\tremaining: 42.8s\n",
      "336:\tlearn: 0.2018221\ttotal: 21.7s\tremaining: 42.7s\n",
      "337:\tlearn: 0.2016951\ttotal: 21.8s\tremaining: 42.7s\n",
      "338:\tlearn: 0.2015652\ttotal: 21.9s\tremaining: 42.6s\n",
      "339:\tlearn: 0.2014389\ttotal: 21.9s\tremaining: 42.5s\n",
      "340:\tlearn: 0.2013091\ttotal: 22s\tremaining: 42.5s\n",
      "341:\tlearn: 0.2011895\ttotal: 22s\tremaining: 42.4s\n",
      "342:\tlearn: 0.2010731\ttotal: 22.1s\tremaining: 42.4s\n",
      "343:\tlearn: 0.2009518\ttotal: 22.2s\tremaining: 42.3s\n",
      "344:\tlearn: 0.2008343\ttotal: 22.2s\tremaining: 42.2s\n",
      "345:\tlearn: 0.2006906\ttotal: 22.3s\tremaining: 42.2s\n",
      "346:\tlearn: 0.2005556\ttotal: 22.4s\tremaining: 42.1s\n",
      "347:\tlearn: 0.2004499\ttotal: 22.4s\tremaining: 42s\n",
      "348:\tlearn: 0.2003290\ttotal: 22.5s\tremaining: 42s\n",
      "349:\tlearn: 0.2002217\ttotal: 22.6s\tremaining: 41.9s\n",
      "350:\tlearn: 0.2001063\ttotal: 22.6s\tremaining: 41.8s\n",
      "351:\tlearn: 0.1999861\ttotal: 22.7s\tremaining: 41.8s\n",
      "352:\tlearn: 0.1998838\ttotal: 22.7s\tremaining: 41.7s\n",
      "353:\tlearn: 0.1997701\ttotal: 22.8s\tremaining: 41.6s\n",
      "354:\tlearn: 0.1996476\ttotal: 22.9s\tremaining: 41.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "355:\tlearn: 0.1995429\ttotal: 22.9s\tremaining: 41.5s\n",
      "356:\tlearn: 0.1994182\ttotal: 23s\tremaining: 41.4s\n",
      "357:\tlearn: 0.1993108\ttotal: 23.1s\tremaining: 41.4s\n",
      "358:\tlearn: 0.1992014\ttotal: 23.1s\tremaining: 41.3s\n",
      "359:\tlearn: 0.1990963\ttotal: 23.2s\tremaining: 41.2s\n",
      "360:\tlearn: 0.1989840\ttotal: 23.3s\tremaining: 41.2s\n",
      "361:\tlearn: 0.1988705\ttotal: 23.3s\tremaining: 41.1s\n",
      "362:\tlearn: 0.1987544\ttotal: 23.4s\tremaining: 41s\n",
      "363:\tlearn: 0.1986347\ttotal: 23.5s\tremaining: 41s\n",
      "364:\tlearn: 0.1985195\ttotal: 23.5s\tremaining: 40.9s\n",
      "365:\tlearn: 0.1984062\ttotal: 23.6s\tremaining: 40.9s\n",
      "366:\tlearn: 0.1983103\ttotal: 23.6s\tremaining: 40.8s\n",
      "367:\tlearn: 0.1982034\ttotal: 23.7s\tremaining: 40.7s\n",
      "368:\tlearn: 0.1980955\ttotal: 23.8s\tremaining: 40.6s\n",
      "369:\tlearn: 0.1979970\ttotal: 23.8s\tremaining: 40.6s\n",
      "370:\tlearn: 0.1978755\ttotal: 23.9s\tremaining: 40.5s\n",
      "371:\tlearn: 0.1977541\ttotal: 23.9s\tremaining: 40.4s\n",
      "372:\tlearn: 0.1976511\ttotal: 24s\tremaining: 40.3s\n",
      "373:\tlearn: 0.1975419\ttotal: 24.1s\tremaining: 40.3s\n",
      "374:\tlearn: 0.1974342\ttotal: 24.1s\tremaining: 40.2s\n",
      "375:\tlearn: 0.1973130\ttotal: 24.2s\tremaining: 40.2s\n",
      "376:\tlearn: 0.1972054\ttotal: 24.3s\tremaining: 40.1s\n",
      "377:\tlearn: 0.1970963\ttotal: 24.3s\tremaining: 40s\n",
      "378:\tlearn: 0.1969811\ttotal: 24.4s\tremaining: 40s\n",
      "379:\tlearn: 0.1968758\ttotal: 24.5s\tremaining: 39.9s\n",
      "380:\tlearn: 0.1967768\ttotal: 24.5s\tremaining: 39.8s\n",
      "381:\tlearn: 0.1966730\ttotal: 24.6s\tremaining: 39.8s\n",
      "382:\tlearn: 0.1965803\ttotal: 24.6s\tremaining: 39.7s\n",
      "383:\tlearn: 0.1964765\ttotal: 24.7s\tremaining: 39.6s\n",
      "384:\tlearn: 0.1963627\ttotal: 24.8s\tremaining: 39.6s\n",
      "385:\tlearn: 0.1962522\ttotal: 24.8s\tremaining: 39.5s\n",
      "386:\tlearn: 0.1961593\ttotal: 24.9s\tremaining: 39.4s\n",
      "387:\tlearn: 0.1960495\ttotal: 25s\tremaining: 39.4s\n",
      "388:\tlearn: 0.1959428\ttotal: 25s\tremaining: 39.3s\n",
      "389:\tlearn: 0.1958399\ttotal: 25.1s\tremaining: 39.2s\n",
      "390:\tlearn: 0.1957245\ttotal: 25.1s\tremaining: 39.2s\n",
      "391:\tlearn: 0.1956241\ttotal: 25.2s\tremaining: 39.1s\n",
      "392:\tlearn: 0.1955238\ttotal: 25.3s\tremaining: 39s\n",
      "393:\tlearn: 0.1954078\ttotal: 25.3s\tremaining: 39s\n",
      "394:\tlearn: 0.1952971\ttotal: 25.4s\tremaining: 38.9s\n",
      "395:\tlearn: 0.1951903\ttotal: 25.4s\tremaining: 38.8s\n",
      "396:\tlearn: 0.1950979\ttotal: 25.5s\tremaining: 38.7s\n",
      "397:\tlearn: 0.1949951\ttotal: 25.6s\tremaining: 38.7s\n",
      "398:\tlearn: 0.1948877\ttotal: 25.6s\tremaining: 38.6s\n",
      "399:\tlearn: 0.1947832\ttotal: 25.7s\tremaining: 38.5s\n",
      "400:\tlearn: 0.1946746\ttotal: 25.8s\tremaining: 38.5s\n",
      "401:\tlearn: 0.1945705\ttotal: 25.8s\tremaining: 38.4s\n",
      "402:\tlearn: 0.1944650\ttotal: 25.9s\tremaining: 38.3s\n",
      "403:\tlearn: 0.1943645\ttotal: 25.9s\tremaining: 38.3s\n",
      "404:\tlearn: 0.1942619\ttotal: 26s\tremaining: 38.2s\n",
      "405:\tlearn: 0.1941590\ttotal: 26.1s\tremaining: 38.2s\n",
      "406:\tlearn: 0.1940554\ttotal: 26.2s\tremaining: 38.1s\n",
      "407:\tlearn: 0.1939461\ttotal: 26.3s\tremaining: 38.1s\n",
      "408:\tlearn: 0.1938403\ttotal: 26.3s\tremaining: 38.1s\n",
      "409:\tlearn: 0.1937317\ttotal: 26.4s\tremaining: 38s\n",
      "410:\tlearn: 0.1936257\ttotal: 26.5s\tremaining: 37.9s\n",
      "411:\tlearn: 0.1935159\ttotal: 26.5s\tremaining: 37.9s\n",
      "412:\tlearn: 0.1934057\ttotal: 26.6s\tremaining: 37.8s\n",
      "413:\tlearn: 0.1933044\ttotal: 26.6s\tremaining: 37.7s\n",
      "414:\tlearn: 0.1931927\ttotal: 26.7s\tremaining: 37.7s\n",
      "415:\tlearn: 0.1930940\ttotal: 26.8s\tremaining: 37.6s\n",
      "416:\tlearn: 0.1929976\ttotal: 26.9s\tremaining: 37.6s\n",
      "417:\tlearn: 0.1929027\ttotal: 26.9s\tremaining: 37.5s\n",
      "418:\tlearn: 0.1927957\ttotal: 27s\tremaining: 37.4s\n",
      "419:\tlearn: 0.1926927\ttotal: 27.1s\tremaining: 37.4s\n",
      "420:\tlearn: 0.1926186\ttotal: 27.1s\tremaining: 37.3s\n",
      "421:\tlearn: 0.1925300\ttotal: 27.2s\tremaining: 37.2s\n",
      "422:\tlearn: 0.1924433\ttotal: 27.2s\tremaining: 37.1s\n",
      "423:\tlearn: 0.1923607\ttotal: 27.3s\tremaining: 37.1s\n",
      "424:\tlearn: 0.1922619\ttotal: 27.3s\tremaining: 37s\n",
      "425:\tlearn: 0.1921555\ttotal: 27.4s\tremaining: 36.9s\n",
      "426:\tlearn: 0.1920532\ttotal: 27.5s\tremaining: 36.9s\n",
      "427:\tlearn: 0.1919579\ttotal: 27.5s\tremaining: 36.8s\n",
      "428:\tlearn: 0.1918590\ttotal: 27.6s\tremaining: 36.7s\n",
      "429:\tlearn: 0.1917605\ttotal: 27.7s\tremaining: 36.7s\n",
      "430:\tlearn: 0.1916569\ttotal: 27.7s\tremaining: 36.6s\n",
      "431:\tlearn: 0.1915680\ttotal: 27.8s\tremaining: 36.5s\n",
      "432:\tlearn: 0.1914811\ttotal: 27.8s\tremaining: 36.5s\n",
      "433:\tlearn: 0.1913784\ttotal: 27.9s\tremaining: 36.4s\n",
      "434:\tlearn: 0.1912816\ttotal: 28s\tremaining: 36.4s\n",
      "435:\tlearn: 0.1911756\ttotal: 28.1s\tremaining: 36.3s\n",
      "436:\tlearn: 0.1910909\ttotal: 28.2s\tremaining: 36.3s\n",
      "437:\tlearn: 0.1909888\ttotal: 28.2s\tremaining: 36.2s\n",
      "438:\tlearn: 0.1909073\ttotal: 28.3s\tremaining: 36.1s\n",
      "439:\tlearn: 0.1908131\ttotal: 28.4s\tremaining: 36.1s\n",
      "440:\tlearn: 0.1907226\ttotal: 28.4s\tremaining: 36s\n",
      "441:\tlearn: 0.1906228\ttotal: 28.5s\tremaining: 35.9s\n",
      "442:\tlearn: 0.1905291\ttotal: 28.5s\tremaining: 35.9s\n",
      "443:\tlearn: 0.1904368\ttotal: 28.6s\tremaining: 35.8s\n",
      "444:\tlearn: 0.1903408\ttotal: 28.7s\tremaining: 35.8s\n",
      "445:\tlearn: 0.1902563\ttotal: 28.7s\tremaining: 35.7s\n",
      "446:\tlearn: 0.1901613\ttotal: 28.8s\tremaining: 35.6s\n",
      "447:\tlearn: 0.1900859\ttotal: 28.9s\tremaining: 35.5s\n",
      "448:\tlearn: 0.1899871\ttotal: 28.9s\tremaining: 35.5s\n",
      "449:\tlearn: 0.1898865\ttotal: 29s\tremaining: 35.4s\n",
      "450:\tlearn: 0.1897966\ttotal: 29s\tremaining: 35.3s\n",
      "451:\tlearn: 0.1896929\ttotal: 29.1s\tremaining: 35.3s\n",
      "452:\tlearn: 0.1895887\ttotal: 29.2s\tremaining: 35.2s\n",
      "453:\tlearn: 0.1895003\ttotal: 29.2s\tremaining: 35.1s\n",
      "454:\tlearn: 0.1894166\ttotal: 29.3s\tremaining: 35.1s\n",
      "455:\tlearn: 0.1893255\ttotal: 29.3s\tremaining: 35s\n",
      "456:\tlearn: 0.1892263\ttotal: 29.4s\tremaining: 34.9s\n",
      "457:\tlearn: 0.1891211\ttotal: 29.5s\tremaining: 34.9s\n",
      "458:\tlearn: 0.1890334\ttotal: 29.5s\tremaining: 34.8s\n",
      "459:\tlearn: 0.1889473\ttotal: 29.6s\tremaining: 34.7s\n",
      "460:\tlearn: 0.1888569\ttotal: 29.7s\tremaining: 34.7s\n",
      "461:\tlearn: 0.1887737\ttotal: 29.7s\tremaining: 34.6s\n",
      "462:\tlearn: 0.1886791\ttotal: 29.8s\tremaining: 34.6s\n",
      "463:\tlearn: 0.1885892\ttotal: 29.9s\tremaining: 34.5s\n",
      "464:\tlearn: 0.1885026\ttotal: 29.9s\tremaining: 34.4s\n",
      "465:\tlearn: 0.1884079\ttotal: 30s\tremaining: 34.4s\n",
      "466:\tlearn: 0.1883245\ttotal: 30s\tremaining: 34.3s\n",
      "467:\tlearn: 0.1882221\ttotal: 30.1s\tremaining: 34.2s\n",
      "468:\tlearn: 0.1881336\ttotal: 30.2s\tremaining: 34.2s\n",
      "469:\tlearn: 0.1880509\ttotal: 30.2s\tremaining: 34.1s\n",
      "470:\tlearn: 0.1879603\ttotal: 30.3s\tremaining: 34s\n",
      "471:\tlearn: 0.1878722\ttotal: 30.3s\tremaining: 33.9s\n",
      "472:\tlearn: 0.1877854\ttotal: 30.4s\tremaining: 33.9s\n",
      "473:\tlearn: 0.1877155\ttotal: 30.5s\tremaining: 33.8s\n",
      "474:\tlearn: 0.1876194\ttotal: 30.5s\tremaining: 33.8s\n",
      "475:\tlearn: 0.1875296\ttotal: 30.6s\tremaining: 33.7s\n",
      "476:\tlearn: 0.1874493\ttotal: 30.7s\tremaining: 33.6s\n",
      "477:\tlearn: 0.1873744\ttotal: 30.7s\tremaining: 33.5s\n",
      "478:\tlearn: 0.1872936\ttotal: 30.8s\tremaining: 33.5s\n",
      "479:\tlearn: 0.1872111\ttotal: 30.8s\tremaining: 33.4s\n",
      "480:\tlearn: 0.1871304\ttotal: 30.9s\tremaining: 33.3s\n",
      "481:\tlearn: 0.1870514\ttotal: 30.9s\tremaining: 33.3s\n",
      "482:\tlearn: 0.1869668\ttotal: 31s\tremaining: 33.2s\n",
      "483:\tlearn: 0.1868777\ttotal: 31.1s\tremaining: 33.1s\n",
      "484:\tlearn: 0.1867907\ttotal: 31.1s\tremaining: 33s\n",
      "485:\tlearn: 0.1867040\ttotal: 31.2s\tremaining: 33s\n",
      "486:\tlearn: 0.1866351\ttotal: 31.2s\tremaining: 32.9s\n",
      "487:\tlearn: 0.1865508\ttotal: 31.3s\tremaining: 32.8s\n",
      "488:\tlearn: 0.1864587\ttotal: 31.4s\tremaining: 32.8s\n",
      "489:\tlearn: 0.1863770\ttotal: 31.4s\tremaining: 32.7s\n",
      "490:\tlearn: 0.1862909\ttotal: 31.5s\tremaining: 32.6s\n",
      "491:\tlearn: 0.1862087\ttotal: 31.5s\tremaining: 32.6s\n",
      "492:\tlearn: 0.1861206\ttotal: 31.6s\tremaining: 32.5s\n",
      "493:\tlearn: 0.1860375\ttotal: 31.7s\tremaining: 32.4s\n",
      "494:\tlearn: 0.1859519\ttotal: 31.7s\tremaining: 32.4s\n",
      "495:\tlearn: 0.1858542\ttotal: 31.8s\tremaining: 32.3s\n",
      "496:\tlearn: 0.1857742\ttotal: 31.9s\tremaining: 32.3s\n",
      "497:\tlearn: 0.1857048\ttotal: 31.9s\tremaining: 32.2s\n",
      "498:\tlearn: 0.1856244\ttotal: 32s\tremaining: 32.1s\n",
      "499:\tlearn: 0.1855354\ttotal: 32.1s\tremaining: 32.1s\n",
      "500:\tlearn: 0.1854315\ttotal: 32.1s\tremaining: 32s\n",
      "501:\tlearn: 0.1853547\ttotal: 32.2s\tremaining: 32s\n",
      "502:\tlearn: 0.1852836\ttotal: 32.3s\tremaining: 31.9s\n",
      "503:\tlearn: 0.1851957\ttotal: 32.3s\tremaining: 31.8s\n",
      "504:\tlearn: 0.1851097\ttotal: 32.4s\tremaining: 31.8s\n",
      "505:\tlearn: 0.1850310\ttotal: 32.5s\tremaining: 31.7s\n",
      "506:\tlearn: 0.1849377\ttotal: 32.6s\tremaining: 31.7s\n",
      "507:\tlearn: 0.1848576\ttotal: 32.6s\tremaining: 31.6s\n",
      "508:\tlearn: 0.1847765\ttotal: 32.7s\tremaining: 31.5s\n",
      "509:\tlearn: 0.1847042\ttotal: 32.8s\tremaining: 31.5s\n",
      "510:\tlearn: 0.1846123\ttotal: 32.8s\tremaining: 31.4s\n",
      "511:\tlearn: 0.1845299\ttotal: 32.9s\tremaining: 31.3s\n",
      "512:\tlearn: 0.1844461\ttotal: 32.9s\tremaining: 31.3s\n",
      "513:\tlearn: 0.1843646\ttotal: 33s\tremaining: 31.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "514:\tlearn: 0.1842757\ttotal: 33.1s\tremaining: 31.1s\n",
      "515:\tlearn: 0.1842025\ttotal: 33.1s\tremaining: 31.1s\n",
      "516:\tlearn: 0.1841231\ttotal: 33.2s\tremaining: 31s\n",
      "517:\tlearn: 0.1840412\ttotal: 33.3s\tremaining: 30.9s\n",
      "518:\tlearn: 0.1839516\ttotal: 33.3s\tremaining: 30.9s\n",
      "519:\tlearn: 0.1838697\ttotal: 33.4s\tremaining: 30.8s\n",
      "520:\tlearn: 0.1837839\ttotal: 33.4s\tremaining: 30.7s\n",
      "521:\tlearn: 0.1837062\ttotal: 33.5s\tremaining: 30.7s\n",
      "522:\tlearn: 0.1836280\ttotal: 33.6s\tremaining: 30.6s\n",
      "523:\tlearn: 0.1835316\ttotal: 33.6s\tremaining: 30.6s\n",
      "524:\tlearn: 0.1834440\ttotal: 33.7s\tremaining: 30.5s\n",
      "525:\tlearn: 0.1833491\ttotal: 33.8s\tremaining: 30.4s\n",
      "526:\tlearn: 0.1832663\ttotal: 33.8s\tremaining: 30.4s\n",
      "527:\tlearn: 0.1831774\ttotal: 33.9s\tremaining: 30.3s\n",
      "528:\tlearn: 0.1830828\ttotal: 34s\tremaining: 30.2s\n",
      "529:\tlearn: 0.1830216\ttotal: 34s\tremaining: 30.2s\n",
      "530:\tlearn: 0.1829394\ttotal: 34.1s\tremaining: 30.1s\n",
      "531:\tlearn: 0.1828613\ttotal: 34.2s\tremaining: 30s\n",
      "532:\tlearn: 0.1827864\ttotal: 34.2s\tremaining: 30s\n",
      "533:\tlearn: 0.1827125\ttotal: 34.3s\tremaining: 29.9s\n",
      "534:\tlearn: 0.1826313\ttotal: 34.4s\tremaining: 29.9s\n",
      "535:\tlearn: 0.1825706\ttotal: 34.4s\tremaining: 29.8s\n",
      "536:\tlearn: 0.1824779\ttotal: 34.5s\tremaining: 29.7s\n",
      "537:\tlearn: 0.1824111\ttotal: 34.5s\tremaining: 29.7s\n",
      "538:\tlearn: 0.1823329\ttotal: 34.6s\tremaining: 29.6s\n",
      "539:\tlearn: 0.1822525\ttotal: 34.7s\tremaining: 29.5s\n",
      "540:\tlearn: 0.1821801\ttotal: 34.8s\tremaining: 29.5s\n",
      "541:\tlearn: 0.1821093\ttotal: 34.8s\tremaining: 29.4s\n",
      "542:\tlearn: 0.1820348\ttotal: 34.9s\tremaining: 29.4s\n",
      "543:\tlearn: 0.1819506\ttotal: 35s\tremaining: 29.3s\n",
      "544:\tlearn: 0.1818588\ttotal: 35s\tremaining: 29.2s\n",
      "545:\tlearn: 0.1817879\ttotal: 35.1s\tremaining: 29.2s\n",
      "546:\tlearn: 0.1817045\ttotal: 35.2s\tremaining: 29.1s\n",
      "547:\tlearn: 0.1816282\ttotal: 35.2s\tremaining: 29.1s\n",
      "548:\tlearn: 0.1815472\ttotal: 35.3s\tremaining: 29s\n",
      "549:\tlearn: 0.1814643\ttotal: 35.4s\tremaining: 28.9s\n",
      "550:\tlearn: 0.1813902\ttotal: 35.4s\tremaining: 28.9s\n",
      "551:\tlearn: 0.1813169\ttotal: 35.5s\tremaining: 28.8s\n",
      "552:\tlearn: 0.1812353\ttotal: 35.5s\tremaining: 28.7s\n",
      "553:\tlearn: 0.1811597\ttotal: 35.6s\tremaining: 28.7s\n",
      "554:\tlearn: 0.1810851\ttotal: 35.6s\tremaining: 28.6s\n",
      "555:\tlearn: 0.1810098\ttotal: 35.7s\tremaining: 28.5s\n",
      "556:\tlearn: 0.1809377\ttotal: 35.8s\tremaining: 28.5s\n",
      "557:\tlearn: 0.1808617\ttotal: 35.8s\tremaining: 28.4s\n",
      "558:\tlearn: 0.1807920\ttotal: 35.9s\tremaining: 28.3s\n",
      "559:\tlearn: 0.1807226\ttotal: 36s\tremaining: 28.3s\n",
      "560:\tlearn: 0.1806412\ttotal: 36s\tremaining: 28.2s\n",
      "561:\tlearn: 0.1805681\ttotal: 36.1s\tremaining: 28.1s\n",
      "562:\tlearn: 0.1805020\ttotal: 36.1s\tremaining: 28s\n",
      "563:\tlearn: 0.1804303\ttotal: 36.2s\tremaining: 28s\n",
      "564:\tlearn: 0.1803587\ttotal: 36.3s\tremaining: 27.9s\n",
      "565:\tlearn: 0.1802898\ttotal: 36.3s\tremaining: 27.8s\n",
      "566:\tlearn: 0.1802004\ttotal: 36.4s\tremaining: 27.8s\n",
      "567:\tlearn: 0.1801272\ttotal: 36.4s\tremaining: 27.7s\n",
      "568:\tlearn: 0.1800596\ttotal: 36.5s\tremaining: 27.7s\n",
      "569:\tlearn: 0.1799755\ttotal: 36.6s\tremaining: 27.6s\n",
      "570:\tlearn: 0.1798949\ttotal: 36.6s\tremaining: 27.5s\n",
      "571:\tlearn: 0.1798180\ttotal: 36.7s\tremaining: 27.5s\n",
      "572:\tlearn: 0.1797585\ttotal: 36.8s\tremaining: 27.4s\n",
      "573:\tlearn: 0.1796908\ttotal: 36.8s\tremaining: 27.3s\n",
      "574:\tlearn: 0.1796412\ttotal: 36.9s\tremaining: 27.3s\n",
      "575:\tlearn: 0.1795736\ttotal: 36.9s\tremaining: 27.2s\n",
      "576:\tlearn: 0.1795118\ttotal: 37s\tremaining: 27.1s\n",
      "577:\tlearn: 0.1794310\ttotal: 37.1s\tremaining: 27.1s\n",
      "578:\tlearn: 0.1793550\ttotal: 37.1s\tremaining: 27s\n",
      "579:\tlearn: 0.1792901\ttotal: 37.2s\tremaining: 26.9s\n",
      "580:\tlearn: 0.1792136\ttotal: 37.2s\tremaining: 26.9s\n",
      "581:\tlearn: 0.1791362\ttotal: 37.3s\tremaining: 26.8s\n",
      "582:\tlearn: 0.1790636\ttotal: 37.4s\tremaining: 26.7s\n",
      "583:\tlearn: 0.1789799\ttotal: 37.4s\tremaining: 26.6s\n",
      "584:\tlearn: 0.1789013\ttotal: 37.5s\tremaining: 26.6s\n",
      "585:\tlearn: 0.1788229\ttotal: 37.5s\tremaining: 26.5s\n",
      "586:\tlearn: 0.1787416\ttotal: 37.6s\tremaining: 26.5s\n",
      "587:\tlearn: 0.1786662\ttotal: 37.7s\tremaining: 26.4s\n",
      "588:\tlearn: 0.1785869\ttotal: 37.7s\tremaining: 26.3s\n",
      "589:\tlearn: 0.1785069\ttotal: 37.8s\tremaining: 26.3s\n",
      "590:\tlearn: 0.1784353\ttotal: 37.8s\tremaining: 26.2s\n",
      "591:\tlearn: 0.1783718\ttotal: 37.9s\tremaining: 26.1s\n",
      "592:\tlearn: 0.1782909\ttotal: 38s\tremaining: 26.1s\n",
      "593:\tlearn: 0.1782187\ttotal: 38s\tremaining: 26s\n",
      "594:\tlearn: 0.1781599\ttotal: 38.1s\tremaining: 25.9s\n",
      "595:\tlearn: 0.1780819\ttotal: 38.1s\tremaining: 25.9s\n",
      "596:\tlearn: 0.1780124\ttotal: 38.2s\tremaining: 25.8s\n",
      "597:\tlearn: 0.1779330\ttotal: 38.3s\tremaining: 25.7s\n",
      "598:\tlearn: 0.1778673\ttotal: 38.3s\tremaining: 25.7s\n",
      "599:\tlearn: 0.1777985\ttotal: 38.4s\tremaining: 25.6s\n",
      "600:\tlearn: 0.1777146\ttotal: 38.5s\tremaining: 25.5s\n",
      "601:\tlearn: 0.1776397\ttotal: 38.5s\tremaining: 25.5s\n",
      "602:\tlearn: 0.1775619\ttotal: 38.6s\tremaining: 25.4s\n",
      "603:\tlearn: 0.1774863\ttotal: 38.6s\tremaining: 25.3s\n",
      "604:\tlearn: 0.1774143\ttotal: 38.7s\tremaining: 25.3s\n",
      "605:\tlearn: 0.1773369\ttotal: 38.8s\tremaining: 25.2s\n",
      "606:\tlearn: 0.1772671\ttotal: 38.9s\tremaining: 25.2s\n",
      "607:\tlearn: 0.1771979\ttotal: 38.9s\tremaining: 25.1s\n",
      "608:\tlearn: 0.1771388\ttotal: 39s\tremaining: 25s\n",
      "609:\tlearn: 0.1770601\ttotal: 39s\tremaining: 25s\n",
      "610:\tlearn: 0.1769924\ttotal: 39.1s\tremaining: 24.9s\n",
      "611:\tlearn: 0.1769195\ttotal: 39.2s\tremaining: 24.8s\n",
      "612:\tlearn: 0.1768504\ttotal: 39.2s\tremaining: 24.8s\n",
      "613:\tlearn: 0.1767787\ttotal: 39.3s\tremaining: 24.7s\n",
      "614:\tlearn: 0.1767242\ttotal: 39.4s\tremaining: 24.6s\n",
      "615:\tlearn: 0.1766432\ttotal: 39.4s\tremaining: 24.6s\n",
      "616:\tlearn: 0.1765841\ttotal: 39.5s\tremaining: 24.5s\n",
      "617:\tlearn: 0.1765236\ttotal: 39.5s\tremaining: 24.4s\n",
      "618:\tlearn: 0.1764417\ttotal: 39.6s\tremaining: 24.4s\n",
      "619:\tlearn: 0.1763612\ttotal: 39.7s\tremaining: 24.3s\n",
      "620:\tlearn: 0.1762977\ttotal: 39.7s\tremaining: 24.3s\n",
      "621:\tlearn: 0.1762183\ttotal: 39.8s\tremaining: 24.2s\n",
      "622:\tlearn: 0.1761580\ttotal: 39.9s\tremaining: 24.1s\n",
      "623:\tlearn: 0.1760950\ttotal: 39.9s\tremaining: 24.1s\n",
      "624:\tlearn: 0.1760236\ttotal: 40s\tremaining: 24s\n",
      "625:\tlearn: 0.1759616\ttotal: 40.1s\tremaining: 23.9s\n",
      "626:\tlearn: 0.1758923\ttotal: 40.1s\tremaining: 23.9s\n",
      "627:\tlearn: 0.1758210\ttotal: 40.2s\tremaining: 23.8s\n",
      "628:\tlearn: 0.1757525\ttotal: 40.3s\tremaining: 23.7s\n",
      "629:\tlearn: 0.1757015\ttotal: 40.3s\tremaining: 23.7s\n",
      "630:\tlearn: 0.1756331\ttotal: 40.4s\tremaining: 23.6s\n",
      "631:\tlearn: 0.1755731\ttotal: 40.4s\tremaining: 23.5s\n",
      "632:\tlearn: 0.1754916\ttotal: 40.5s\tremaining: 23.5s\n",
      "633:\tlearn: 0.1754237\ttotal: 40.6s\tremaining: 23.4s\n",
      "634:\tlearn: 0.1753562\ttotal: 40.6s\tremaining: 23.4s\n",
      "635:\tlearn: 0.1752830\ttotal: 40.7s\tremaining: 23.3s\n",
      "636:\tlearn: 0.1752196\ttotal: 40.8s\tremaining: 23.2s\n",
      "637:\tlearn: 0.1751417\ttotal: 40.8s\tremaining: 23.2s\n",
      "638:\tlearn: 0.1750793\ttotal: 40.9s\tremaining: 23.1s\n",
      "639:\tlearn: 0.1750018\ttotal: 41s\tremaining: 23s\n",
      "640:\tlearn: 0.1749295\ttotal: 41s\tremaining: 23s\n",
      "641:\tlearn: 0.1748593\ttotal: 41.1s\tremaining: 22.9s\n",
      "642:\tlearn: 0.1747942\ttotal: 41.2s\tremaining: 22.9s\n",
      "643:\tlearn: 0.1747500\ttotal: 41.2s\tremaining: 22.8s\n",
      "644:\tlearn: 0.1746767\ttotal: 41.3s\tremaining: 22.7s\n",
      "645:\tlearn: 0.1746287\ttotal: 41.3s\tremaining: 22.6s\n",
      "646:\tlearn: 0.1745547\ttotal: 41.4s\tremaining: 22.6s\n",
      "647:\tlearn: 0.1744931\ttotal: 41.5s\tremaining: 22.5s\n",
      "648:\tlearn: 0.1744230\ttotal: 41.5s\tremaining: 22.5s\n",
      "649:\tlearn: 0.1743382\ttotal: 41.6s\tremaining: 22.4s\n",
      "650:\tlearn: 0.1742817\ttotal: 41.6s\tremaining: 22.3s\n",
      "651:\tlearn: 0.1742111\ttotal: 41.7s\tremaining: 22.3s\n",
      "652:\tlearn: 0.1741497\ttotal: 41.8s\tremaining: 22.2s\n",
      "653:\tlearn: 0.1740861\ttotal: 41.8s\tremaining: 22.1s\n",
      "654:\tlearn: 0.1740213\ttotal: 41.9s\tremaining: 22.1s\n",
      "655:\tlearn: 0.1739520\ttotal: 42s\tremaining: 22s\n",
      "656:\tlearn: 0.1738844\ttotal: 42s\tremaining: 21.9s\n",
      "657:\tlearn: 0.1738186\ttotal: 42.1s\tremaining: 21.9s\n",
      "658:\tlearn: 0.1737500\ttotal: 42.1s\tremaining: 21.8s\n",
      "659:\tlearn: 0.1736823\ttotal: 42.2s\tremaining: 21.7s\n",
      "660:\tlearn: 0.1736262\ttotal: 42.3s\tremaining: 21.7s\n",
      "661:\tlearn: 0.1735629\ttotal: 42.3s\tremaining: 21.6s\n",
      "662:\tlearn: 0.1735006\ttotal: 42.4s\tremaining: 21.6s\n",
      "663:\tlearn: 0.1734350\ttotal: 42.5s\tremaining: 21.5s\n",
      "664:\tlearn: 0.1733664\ttotal: 42.5s\tremaining: 21.4s\n",
      "665:\tlearn: 0.1733021\ttotal: 42.6s\tremaining: 21.4s\n",
      "666:\tlearn: 0.1732445\ttotal: 42.6s\tremaining: 21.3s\n",
      "667:\tlearn: 0.1731842\ttotal: 42.7s\tremaining: 21.2s\n",
      "668:\tlearn: 0.1731243\ttotal: 42.8s\tremaining: 21.2s\n",
      "669:\tlearn: 0.1730572\ttotal: 42.8s\tremaining: 21.1s\n",
      "670:\tlearn: 0.1730012\ttotal: 42.9s\tremaining: 21s\n",
      "671:\tlearn: 0.1729513\ttotal: 42.9s\tremaining: 21s\n",
      "672:\tlearn: 0.1728840\ttotal: 43s\tremaining: 20.9s\n",
      "673:\tlearn: 0.1728115\ttotal: 43.1s\tremaining: 20.8s\n",
      "674:\tlearn: 0.1727397\ttotal: 43.1s\tremaining: 20.8s\n",
      "675:\tlearn: 0.1726698\ttotal: 43.2s\tremaining: 20.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "676:\tlearn: 0.1725963\ttotal: 43.3s\tremaining: 20.6s\n",
      "677:\tlearn: 0.1725336\ttotal: 43.3s\tremaining: 20.6s\n",
      "678:\tlearn: 0.1724708\ttotal: 43.4s\tremaining: 20.5s\n",
      "679:\tlearn: 0.1723974\ttotal: 43.4s\tremaining: 20.4s\n",
      "680:\tlearn: 0.1723399\ttotal: 43.5s\tremaining: 20.4s\n",
      "681:\tlearn: 0.1722824\ttotal: 43.6s\tremaining: 20.3s\n",
      "682:\tlearn: 0.1722116\ttotal: 43.6s\tremaining: 20.2s\n",
      "683:\tlearn: 0.1721497\ttotal: 43.7s\tremaining: 20.2s\n",
      "684:\tlearn: 0.1720890\ttotal: 43.7s\tremaining: 20.1s\n",
      "685:\tlearn: 0.1720275\ttotal: 43.8s\tremaining: 20s\n",
      "686:\tlearn: 0.1719625\ttotal: 43.9s\tremaining: 20s\n",
      "687:\tlearn: 0.1718939\ttotal: 43.9s\tremaining: 19.9s\n",
      "688:\tlearn: 0.1718046\ttotal: 44s\tremaining: 19.9s\n",
      "689:\tlearn: 0.1717274\ttotal: 44.1s\tremaining: 19.8s\n",
      "690:\tlearn: 0.1716633\ttotal: 44.1s\tremaining: 19.7s\n",
      "691:\tlearn: 0.1716114\ttotal: 44.2s\tremaining: 19.7s\n",
      "692:\tlearn: 0.1715576\ttotal: 44.2s\tremaining: 19.6s\n",
      "693:\tlearn: 0.1714926\ttotal: 44.3s\tremaining: 19.5s\n",
      "694:\tlearn: 0.1714236\ttotal: 44.4s\tremaining: 19.5s\n",
      "695:\tlearn: 0.1713638\ttotal: 44.5s\tremaining: 19.4s\n",
      "696:\tlearn: 0.1712991\ttotal: 44.5s\tremaining: 19.4s\n",
      "697:\tlearn: 0.1712351\ttotal: 44.6s\tremaining: 19.3s\n",
      "698:\tlearn: 0.1711606\ttotal: 44.7s\tremaining: 19.2s\n",
      "699:\tlearn: 0.1711071\ttotal: 44.7s\tremaining: 19.2s\n",
      "700:\tlearn: 0.1710370\ttotal: 44.8s\tremaining: 19.1s\n",
      "701:\tlearn: 0.1709743\ttotal: 44.8s\tremaining: 19s\n",
      "702:\tlearn: 0.1709179\ttotal: 44.9s\tremaining: 19s\n",
      "703:\tlearn: 0.1708631\ttotal: 45s\tremaining: 18.9s\n",
      "704:\tlearn: 0.1707991\ttotal: 45s\tremaining: 18.8s\n",
      "705:\tlearn: 0.1707346\ttotal: 45.1s\tremaining: 18.8s\n",
      "706:\tlearn: 0.1706800\ttotal: 45.1s\tremaining: 18.7s\n",
      "707:\tlearn: 0.1706092\ttotal: 45.2s\tremaining: 18.6s\n",
      "708:\tlearn: 0.1705490\ttotal: 45.3s\tremaining: 18.6s\n",
      "709:\tlearn: 0.1704893\ttotal: 45.3s\tremaining: 18.5s\n",
      "710:\tlearn: 0.1704272\ttotal: 45.4s\tremaining: 18.4s\n",
      "711:\tlearn: 0.1703630\ttotal: 45.5s\tremaining: 18.4s\n",
      "712:\tlearn: 0.1702962\ttotal: 45.5s\tremaining: 18.3s\n",
      "713:\tlearn: 0.1702250\ttotal: 45.6s\tremaining: 18.3s\n",
      "714:\tlearn: 0.1701551\ttotal: 45.6s\tremaining: 18.2s\n",
      "715:\tlearn: 0.1701071\ttotal: 45.7s\tremaining: 18.1s\n",
      "716:\tlearn: 0.1700404\ttotal: 45.8s\tremaining: 18.1s\n",
      "717:\tlearn: 0.1699807\ttotal: 45.8s\tremaining: 18s\n",
      "718:\tlearn: 0.1699103\ttotal: 45.9s\tremaining: 17.9s\n",
      "719:\tlearn: 0.1698464\ttotal: 46s\tremaining: 17.9s\n",
      "720:\tlearn: 0.1697736\ttotal: 46s\tremaining: 17.8s\n",
      "721:\tlearn: 0.1697053\ttotal: 46.1s\tremaining: 17.7s\n",
      "722:\tlearn: 0.1696429\ttotal: 46.2s\tremaining: 17.7s\n",
      "723:\tlearn: 0.1695725\ttotal: 46.2s\tremaining: 17.6s\n",
      "724:\tlearn: 0.1695084\ttotal: 46.3s\tremaining: 17.6s\n",
      "725:\tlearn: 0.1694413\ttotal: 46.3s\tremaining: 17.5s\n",
      "726:\tlearn: 0.1693768\ttotal: 46.4s\tremaining: 17.4s\n",
      "727:\tlearn: 0.1693168\ttotal: 46.5s\tremaining: 17.4s\n",
      "728:\tlearn: 0.1692587\ttotal: 46.5s\tremaining: 17.3s\n",
      "729:\tlearn: 0.1692022\ttotal: 46.6s\tremaining: 17.2s\n",
      "730:\tlearn: 0.1691378\ttotal: 46.7s\tremaining: 17.2s\n",
      "731:\tlearn: 0.1690731\ttotal: 46.7s\tremaining: 17.1s\n",
      "732:\tlearn: 0.1690145\ttotal: 46.8s\tremaining: 17s\n",
      "733:\tlearn: 0.1689591\ttotal: 46.9s\tremaining: 17s\n",
      "734:\tlearn: 0.1689107\ttotal: 46.9s\tremaining: 16.9s\n",
      "735:\tlearn: 0.1688506\ttotal: 47s\tremaining: 16.8s\n",
      "736:\tlearn: 0.1687853\ttotal: 47s\tremaining: 16.8s\n",
      "737:\tlearn: 0.1687279\ttotal: 47.1s\tremaining: 16.7s\n",
      "738:\tlearn: 0.1686591\ttotal: 47.1s\tremaining: 16.7s\n",
      "739:\tlearn: 0.1686007\ttotal: 47.2s\tremaining: 16.6s\n",
      "740:\tlearn: 0.1685532\ttotal: 47.3s\tremaining: 16.5s\n",
      "741:\tlearn: 0.1684931\ttotal: 47.3s\tremaining: 16.4s\n",
      "742:\tlearn: 0.1684426\ttotal: 47.4s\tremaining: 16.4s\n",
      "743:\tlearn: 0.1683732\ttotal: 47.4s\tremaining: 16.3s\n",
      "744:\tlearn: 0.1683087\ttotal: 47.5s\tremaining: 16.3s\n",
      "745:\tlearn: 0.1682515\ttotal: 47.6s\tremaining: 16.2s\n",
      "746:\tlearn: 0.1681820\ttotal: 47.6s\tremaining: 16.1s\n",
      "747:\tlearn: 0.1681156\ttotal: 47.7s\tremaining: 16.1s\n",
      "748:\tlearn: 0.1680578\ttotal: 47.7s\tremaining: 16s\n",
      "749:\tlearn: 0.1679910\ttotal: 47.8s\tremaining: 15.9s\n",
      "750:\tlearn: 0.1679318\ttotal: 47.9s\tremaining: 15.9s\n",
      "751:\tlearn: 0.1678695\ttotal: 47.9s\tremaining: 15.8s\n",
      "752:\tlearn: 0.1678107\ttotal: 48s\tremaining: 15.7s\n",
      "753:\tlearn: 0.1677525\ttotal: 48s\tremaining: 15.7s\n",
      "754:\tlearn: 0.1676918\ttotal: 48.1s\tremaining: 15.6s\n",
      "755:\tlearn: 0.1676431\ttotal: 48.2s\tremaining: 15.5s\n",
      "756:\tlearn: 0.1675717\ttotal: 48.2s\tremaining: 15.5s\n",
      "757:\tlearn: 0.1675054\ttotal: 48.3s\tremaining: 15.4s\n",
      "758:\tlearn: 0.1674604\ttotal: 48.3s\tremaining: 15.4s\n",
      "759:\tlearn: 0.1674012\ttotal: 48.4s\tremaining: 15.3s\n",
      "760:\tlearn: 0.1673291\ttotal: 48.5s\tremaining: 15.2s\n",
      "761:\tlearn: 0.1672718\ttotal: 48.5s\tremaining: 15.2s\n",
      "762:\tlearn: 0.1672059\ttotal: 48.6s\tremaining: 15.1s\n",
      "763:\tlearn: 0.1671405\ttotal: 48.7s\tremaining: 15s\n",
      "764:\tlearn: 0.1670757\ttotal: 48.7s\tremaining: 15s\n",
      "765:\tlearn: 0.1670040\ttotal: 48.8s\tremaining: 14.9s\n",
      "766:\tlearn: 0.1669474\ttotal: 48.9s\tremaining: 14.8s\n",
      "767:\tlearn: 0.1668819\ttotal: 48.9s\tremaining: 14.8s\n",
      "768:\tlearn: 0.1668256\ttotal: 49s\tremaining: 14.7s\n",
      "769:\tlearn: 0.1667564\ttotal: 49.1s\tremaining: 14.7s\n",
      "770:\tlearn: 0.1666964\ttotal: 49.1s\tremaining: 14.6s\n",
      "771:\tlearn: 0.1666405\ttotal: 49.2s\tremaining: 14.5s\n",
      "772:\tlearn: 0.1665747\ttotal: 49.2s\tremaining: 14.5s\n",
      "773:\tlearn: 0.1665124\ttotal: 49.3s\tremaining: 14.4s\n",
      "774:\tlearn: 0.1664579\ttotal: 49.4s\tremaining: 14.3s\n",
      "775:\tlearn: 0.1663946\ttotal: 49.4s\tremaining: 14.3s\n",
      "776:\tlearn: 0.1663369\ttotal: 49.5s\tremaining: 14.2s\n",
      "777:\tlearn: 0.1662702\ttotal: 49.5s\tremaining: 14.1s\n",
      "778:\tlearn: 0.1662201\ttotal: 49.6s\tremaining: 14.1s\n",
      "779:\tlearn: 0.1661637\ttotal: 49.7s\tremaining: 14s\n",
      "780:\tlearn: 0.1661034\ttotal: 49.7s\tremaining: 13.9s\n",
      "781:\tlearn: 0.1660430\ttotal: 49.8s\tremaining: 13.9s\n",
      "782:\tlearn: 0.1659858\ttotal: 49.8s\tremaining: 13.8s\n",
      "783:\tlearn: 0.1659201\ttotal: 49.9s\tremaining: 13.8s\n",
      "784:\tlearn: 0.1658488\ttotal: 50s\tremaining: 13.7s\n",
      "785:\tlearn: 0.1657833\ttotal: 50s\tremaining: 13.6s\n",
      "786:\tlearn: 0.1657282\ttotal: 50.1s\tremaining: 13.6s\n",
      "787:\tlearn: 0.1656674\ttotal: 50.2s\tremaining: 13.5s\n",
      "788:\tlearn: 0.1655976\ttotal: 50.2s\tremaining: 13.4s\n",
      "789:\tlearn: 0.1655507\ttotal: 50.3s\tremaining: 13.4s\n",
      "790:\tlearn: 0.1654835\ttotal: 50.3s\tremaining: 13.3s\n",
      "791:\tlearn: 0.1654104\ttotal: 50.4s\tremaining: 13.2s\n",
      "792:\tlearn: 0.1653748\ttotal: 50.5s\tremaining: 13.2s\n",
      "793:\tlearn: 0.1653317\ttotal: 50.5s\tremaining: 13.1s\n",
      "794:\tlearn: 0.1652864\ttotal: 50.6s\tremaining: 13s\n",
      "795:\tlearn: 0.1652352\ttotal: 50.7s\tremaining: 13s\n",
      "796:\tlearn: 0.1651863\ttotal: 50.7s\tremaining: 12.9s\n",
      "797:\tlearn: 0.1651186\ttotal: 50.8s\tremaining: 12.9s\n",
      "798:\tlearn: 0.1650566\ttotal: 50.8s\tremaining: 12.8s\n",
      "799:\tlearn: 0.1650009\ttotal: 50.9s\tremaining: 12.7s\n",
      "800:\tlearn: 0.1649441\ttotal: 51s\tremaining: 12.7s\n",
      "801:\tlearn: 0.1648758\ttotal: 51s\tremaining: 12.6s\n",
      "802:\tlearn: 0.1648195\ttotal: 51.1s\tremaining: 12.5s\n",
      "803:\tlearn: 0.1647567\ttotal: 51.1s\tremaining: 12.5s\n",
      "804:\tlearn: 0.1647061\ttotal: 51.2s\tremaining: 12.4s\n",
      "805:\tlearn: 0.1646511\ttotal: 51.2s\tremaining: 12.3s\n",
      "806:\tlearn: 0.1645890\ttotal: 51.3s\tremaining: 12.3s\n",
      "807:\tlearn: 0.1645322\ttotal: 51.4s\tremaining: 12.2s\n",
      "808:\tlearn: 0.1644988\ttotal: 51.4s\tremaining: 12.1s\n",
      "809:\tlearn: 0.1644294\ttotal: 51.5s\tremaining: 12.1s\n",
      "810:\tlearn: 0.1643779\ttotal: 51.6s\tremaining: 12s\n",
      "811:\tlearn: 0.1643123\ttotal: 51.6s\tremaining: 12s\n",
      "812:\tlearn: 0.1642524\ttotal: 51.7s\tremaining: 11.9s\n",
      "813:\tlearn: 0.1641892\ttotal: 51.7s\tremaining: 11.8s\n",
      "814:\tlearn: 0.1641334\ttotal: 51.8s\tremaining: 11.8s\n",
      "815:\tlearn: 0.1640819\ttotal: 51.9s\tremaining: 11.7s\n",
      "816:\tlearn: 0.1640251\ttotal: 51.9s\tremaining: 11.6s\n",
      "817:\tlearn: 0.1639739\ttotal: 52s\tremaining: 11.6s\n",
      "818:\tlearn: 0.1639162\ttotal: 52s\tremaining: 11.5s\n",
      "819:\tlearn: 0.1638694\ttotal: 52.1s\tremaining: 11.4s\n",
      "820:\tlearn: 0.1638133\ttotal: 52.2s\tremaining: 11.4s\n",
      "821:\tlearn: 0.1637616\ttotal: 52.2s\tremaining: 11.3s\n",
      "822:\tlearn: 0.1637111\ttotal: 52.3s\tremaining: 11.2s\n",
      "823:\tlearn: 0.1636561\ttotal: 52.3s\tremaining: 11.2s\n",
      "824:\tlearn: 0.1635825\ttotal: 52.4s\tremaining: 11.1s\n",
      "825:\tlearn: 0.1635229\ttotal: 52.5s\tremaining: 11.1s\n",
      "826:\tlearn: 0.1634724\ttotal: 52.5s\tremaining: 11s\n",
      "827:\tlearn: 0.1634268\ttotal: 52.6s\tremaining: 10.9s\n",
      "828:\tlearn: 0.1633687\ttotal: 52.6s\tremaining: 10.9s\n",
      "829:\tlearn: 0.1633094\ttotal: 52.7s\tremaining: 10.8s\n",
      "830:\tlearn: 0.1632495\ttotal: 52.8s\tremaining: 10.7s\n",
      "831:\tlearn: 0.1631837\ttotal: 52.8s\tremaining: 10.7s\n",
      "832:\tlearn: 0.1631157\ttotal: 52.9s\tremaining: 10.6s\n",
      "833:\tlearn: 0.1630780\ttotal: 52.9s\tremaining: 10.5s\n",
      "834:\tlearn: 0.1630235\ttotal: 53s\tremaining: 10.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "835:\tlearn: 0.1629539\ttotal: 53.1s\tremaining: 10.4s\n",
      "836:\tlearn: 0.1629001\ttotal: 53.2s\tremaining: 10.4s\n",
      "837:\tlearn: 0.1628451\ttotal: 53.2s\tremaining: 10.3s\n",
      "838:\tlearn: 0.1627894\ttotal: 53.3s\tremaining: 10.2s\n",
      "839:\tlearn: 0.1627256\ttotal: 53.4s\tremaining: 10.2s\n",
      "840:\tlearn: 0.1626932\ttotal: 53.4s\tremaining: 10.1s\n",
      "841:\tlearn: 0.1626447\ttotal: 53.5s\tremaining: 10s\n",
      "842:\tlearn: 0.1625932\ttotal: 53.6s\tremaining: 9.97s\n",
      "843:\tlearn: 0.1625455\ttotal: 53.6s\tremaining: 9.91s\n",
      "844:\tlearn: 0.1624968\ttotal: 53.7s\tremaining: 9.84s\n",
      "845:\tlearn: 0.1624411\ttotal: 53.7s\tremaining: 9.78s\n",
      "846:\tlearn: 0.1623731\ttotal: 53.8s\tremaining: 9.72s\n",
      "847:\tlearn: 0.1623177\ttotal: 53.9s\tremaining: 9.65s\n",
      "848:\tlearn: 0.1622713\ttotal: 53.9s\tremaining: 9.59s\n",
      "849:\tlearn: 0.1622130\ttotal: 54s\tremaining: 9.53s\n",
      "850:\tlearn: 0.1621477\ttotal: 54s\tremaining: 9.46s\n",
      "851:\tlearn: 0.1620975\ttotal: 54.1s\tremaining: 9.4s\n",
      "852:\tlearn: 0.1620534\ttotal: 54.2s\tremaining: 9.33s\n",
      "853:\tlearn: 0.1619897\ttotal: 54.2s\tremaining: 9.27s\n",
      "854:\tlearn: 0.1619338\ttotal: 54.3s\tremaining: 9.21s\n",
      "855:\tlearn: 0.1618720\ttotal: 54.4s\tremaining: 9.14s\n",
      "856:\tlearn: 0.1618290\ttotal: 54.4s\tremaining: 9.08s\n",
      "857:\tlearn: 0.1617690\ttotal: 54.5s\tremaining: 9.01s\n",
      "858:\tlearn: 0.1617186\ttotal: 54.5s\tremaining: 8.95s\n",
      "859:\tlearn: 0.1616775\ttotal: 54.6s\tremaining: 8.88s\n",
      "860:\tlearn: 0.1616150\ttotal: 54.7s\tremaining: 8.82s\n",
      "861:\tlearn: 0.1615489\ttotal: 54.7s\tremaining: 8.76s\n",
      "862:\tlearn: 0.1615002\ttotal: 54.8s\tremaining: 8.7s\n",
      "863:\tlearn: 0.1614638\ttotal: 54.8s\tremaining: 8.63s\n",
      "864:\tlearn: 0.1614149\ttotal: 54.9s\tremaining: 8.57s\n",
      "865:\tlearn: 0.1613566\ttotal: 55s\tremaining: 8.5s\n",
      "866:\tlearn: 0.1613011\ttotal: 55s\tremaining: 8.44s\n",
      "867:\tlearn: 0.1612524\ttotal: 55.1s\tremaining: 8.38s\n",
      "868:\tlearn: 0.1611950\ttotal: 55.1s\tremaining: 8.31s\n",
      "869:\tlearn: 0.1611427\ttotal: 55.2s\tremaining: 8.25s\n",
      "870:\tlearn: 0.1610888\ttotal: 55.3s\tremaining: 8.19s\n",
      "871:\tlearn: 0.1610337\ttotal: 55.3s\tremaining: 8.12s\n",
      "872:\tlearn: 0.1609786\ttotal: 55.4s\tremaining: 8.06s\n",
      "873:\tlearn: 0.1609260\ttotal: 55.4s\tremaining: 7.99s\n",
      "874:\tlearn: 0.1608753\ttotal: 55.5s\tremaining: 7.93s\n",
      "875:\tlearn: 0.1608189\ttotal: 55.6s\tremaining: 7.87s\n",
      "876:\tlearn: 0.1607635\ttotal: 55.6s\tremaining: 7.8s\n",
      "877:\tlearn: 0.1606915\ttotal: 55.7s\tremaining: 7.74s\n",
      "878:\tlearn: 0.1606311\ttotal: 55.8s\tremaining: 7.68s\n",
      "879:\tlearn: 0.1605619\ttotal: 55.9s\tremaining: 7.62s\n",
      "880:\tlearn: 0.1605066\ttotal: 55.9s\tremaining: 7.55s\n",
      "881:\tlearn: 0.1604534\ttotal: 56s\tremaining: 7.49s\n",
      "882:\tlearn: 0.1603962\ttotal: 56s\tremaining: 7.43s\n",
      "883:\tlearn: 0.1603345\ttotal: 56.1s\tremaining: 7.36s\n",
      "884:\tlearn: 0.1602766\ttotal: 56.2s\tremaining: 7.3s\n",
      "885:\tlearn: 0.1602219\ttotal: 56.2s\tremaining: 7.24s\n",
      "886:\tlearn: 0.1601548\ttotal: 56.3s\tremaining: 7.17s\n",
      "887:\tlearn: 0.1601056\ttotal: 56.4s\tremaining: 7.11s\n",
      "888:\tlearn: 0.1600491\ttotal: 56.4s\tremaining: 7.04s\n",
      "889:\tlearn: 0.1599816\ttotal: 56.5s\tremaining: 6.98s\n",
      "890:\tlearn: 0.1599421\ttotal: 56.6s\tremaining: 6.92s\n",
      "891:\tlearn: 0.1598859\ttotal: 56.6s\tremaining: 6.85s\n",
      "892:\tlearn: 0.1598436\ttotal: 56.7s\tremaining: 6.79s\n",
      "893:\tlearn: 0.1597937\ttotal: 56.7s\tremaining: 6.72s\n",
      "894:\tlearn: 0.1597373\ttotal: 56.8s\tremaining: 6.66s\n",
      "895:\tlearn: 0.1596872\ttotal: 56.8s\tremaining: 6.6s\n",
      "896:\tlearn: 0.1596361\ttotal: 56.9s\tremaining: 6.54s\n",
      "897:\tlearn: 0.1595719\ttotal: 57s\tremaining: 6.47s\n",
      "898:\tlearn: 0.1595241\ttotal: 57s\tremaining: 6.41s\n",
      "899:\tlearn: 0.1594769\ttotal: 57.1s\tremaining: 6.34s\n",
      "900:\tlearn: 0.1594319\ttotal: 57.2s\tremaining: 6.28s\n",
      "901:\tlearn: 0.1593771\ttotal: 57.2s\tremaining: 6.22s\n",
      "902:\tlearn: 0.1593190\ttotal: 57.3s\tremaining: 6.15s\n",
      "903:\tlearn: 0.1592631\ttotal: 57.3s\tremaining: 6.09s\n",
      "904:\tlearn: 0.1592071\ttotal: 57.4s\tremaining: 6.02s\n",
      "905:\tlearn: 0.1591493\ttotal: 57.5s\tremaining: 5.96s\n",
      "906:\tlearn: 0.1590946\ttotal: 57.5s\tremaining: 5.9s\n",
      "907:\tlearn: 0.1590513\ttotal: 57.6s\tremaining: 5.83s\n",
      "908:\tlearn: 0.1589897\ttotal: 57.6s\tremaining: 5.77s\n",
      "909:\tlearn: 0.1589278\ttotal: 57.7s\tremaining: 5.71s\n",
      "910:\tlearn: 0.1588779\ttotal: 57.8s\tremaining: 5.64s\n",
      "911:\tlearn: 0.1588268\ttotal: 57.8s\tremaining: 5.58s\n",
      "912:\tlearn: 0.1587831\ttotal: 57.9s\tremaining: 5.52s\n",
      "913:\tlearn: 0.1587304\ttotal: 58s\tremaining: 5.45s\n",
      "914:\tlearn: 0.1586810\ttotal: 58s\tremaining: 5.39s\n",
      "915:\tlearn: 0.1586329\ttotal: 58.1s\tremaining: 5.33s\n",
      "916:\tlearn: 0.1585936\ttotal: 58.2s\tremaining: 5.26s\n",
      "917:\tlearn: 0.1585376\ttotal: 58.2s\tremaining: 5.2s\n",
      "918:\tlearn: 0.1584934\ttotal: 58.3s\tremaining: 5.13s\n",
      "919:\tlearn: 0.1584334\ttotal: 58.3s\tremaining: 5.07s\n",
      "920:\tlearn: 0.1583759\ttotal: 58.4s\tremaining: 5.01s\n",
      "921:\tlearn: 0.1583296\ttotal: 58.5s\tremaining: 4.95s\n",
      "922:\tlearn: 0.1582756\ttotal: 58.5s\tremaining: 4.88s\n",
      "923:\tlearn: 0.1582217\ttotal: 58.6s\tremaining: 4.82s\n",
      "924:\tlearn: 0.1581790\ttotal: 58.7s\tremaining: 4.76s\n",
      "925:\tlearn: 0.1581335\ttotal: 58.7s\tremaining: 4.69s\n",
      "926:\tlearn: 0.1580848\ttotal: 58.8s\tremaining: 4.63s\n",
      "927:\tlearn: 0.1580353\ttotal: 58.8s\tremaining: 4.57s\n",
      "928:\tlearn: 0.1579818\ttotal: 58.9s\tremaining: 4.5s\n",
      "929:\tlearn: 0.1579363\ttotal: 59s\tremaining: 4.44s\n",
      "930:\tlearn: 0.1578782\ttotal: 59s\tremaining: 4.37s\n",
      "931:\tlearn: 0.1578258\ttotal: 59.1s\tremaining: 4.31s\n",
      "932:\tlearn: 0.1577814\ttotal: 59.1s\tremaining: 4.25s\n",
      "933:\tlearn: 0.1577236\ttotal: 59.2s\tremaining: 4.18s\n",
      "934:\tlearn: 0.1576730\ttotal: 59.3s\tremaining: 4.12s\n",
      "935:\tlearn: 0.1576077\ttotal: 59.3s\tremaining: 4.06s\n",
      "936:\tlearn: 0.1575693\ttotal: 59.4s\tremaining: 3.99s\n",
      "937:\tlearn: 0.1575098\ttotal: 59.4s\tremaining: 3.93s\n",
      "938:\tlearn: 0.1574447\ttotal: 59.5s\tremaining: 3.87s\n",
      "939:\tlearn: 0.1573914\ttotal: 59.6s\tremaining: 3.8s\n",
      "940:\tlearn: 0.1573433\ttotal: 59.6s\tremaining: 3.74s\n",
      "941:\tlearn: 0.1572814\ttotal: 59.7s\tremaining: 3.67s\n",
      "942:\tlearn: 0.1572282\ttotal: 59.7s\tremaining: 3.61s\n",
      "943:\tlearn: 0.1571708\ttotal: 59.8s\tremaining: 3.55s\n",
      "944:\tlearn: 0.1571193\ttotal: 59.9s\tremaining: 3.48s\n",
      "945:\tlearn: 0.1570766\ttotal: 59.9s\tremaining: 3.42s\n",
      "946:\tlearn: 0.1570254\ttotal: 60s\tremaining: 3.36s\n",
      "947:\tlearn: 0.1569795\ttotal: 1m\tremaining: 3.29s\n",
      "948:\tlearn: 0.1569318\ttotal: 1m\tremaining: 3.23s\n",
      "949:\tlearn: 0.1568775\ttotal: 1m\tremaining: 3.17s\n",
      "950:\tlearn: 0.1568409\ttotal: 1m\tremaining: 3.1s\n",
      "951:\tlearn: 0.1567781\ttotal: 1m\tremaining: 3.04s\n",
      "952:\tlearn: 0.1567348\ttotal: 1m\tremaining: 2.98s\n",
      "953:\tlearn: 0.1566866\ttotal: 1m\tremaining: 2.91s\n",
      "954:\tlearn: 0.1566408\ttotal: 1m\tremaining: 2.85s\n",
      "955:\tlearn: 0.1565884\ttotal: 1m\tremaining: 2.79s\n",
      "956:\tlearn: 0.1565333\ttotal: 1m\tremaining: 2.72s\n",
      "957:\tlearn: 0.1564675\ttotal: 1m\tremaining: 2.66s\n",
      "958:\tlearn: 0.1564195\ttotal: 1m\tremaining: 2.6s\n",
      "959:\tlearn: 0.1563801\ttotal: 1m\tremaining: 2.53s\n",
      "960:\tlearn: 0.1563317\ttotal: 1m\tremaining: 2.47s\n",
      "961:\tlearn: 0.1562724\ttotal: 1m\tremaining: 2.4s\n",
      "962:\tlearn: 0.1562111\ttotal: 1m\tremaining: 2.34s\n",
      "963:\tlearn: 0.1561601\ttotal: 1m 1s\tremaining: 2.28s\n",
      "964:\tlearn: 0.1561107\ttotal: 1m 1s\tremaining: 2.21s\n",
      "965:\tlearn: 0.1560627\ttotal: 1m 1s\tremaining: 2.15s\n",
      "966:\tlearn: 0.1560014\ttotal: 1m 1s\tremaining: 2.09s\n",
      "967:\tlearn: 0.1559522\ttotal: 1m 1s\tremaining: 2.02s\n",
      "968:\tlearn: 0.1558993\ttotal: 1m 1s\tremaining: 1.96s\n",
      "969:\tlearn: 0.1558449\ttotal: 1m 1s\tremaining: 1.9s\n",
      "970:\tlearn: 0.1557910\ttotal: 1m 1s\tremaining: 1.83s\n",
      "971:\tlearn: 0.1557363\ttotal: 1m 1s\tremaining: 1.77s\n",
      "972:\tlearn: 0.1556877\ttotal: 1m 1s\tremaining: 1.71s\n",
      "973:\tlearn: 0.1556373\ttotal: 1m 1s\tremaining: 1.64s\n",
      "974:\tlearn: 0.1555908\ttotal: 1m 1s\tremaining: 1.58s\n",
      "975:\tlearn: 0.1555446\ttotal: 1m 1s\tremaining: 1.52s\n",
      "976:\tlearn: 0.1554832\ttotal: 1m 1s\tremaining: 1.45s\n",
      "977:\tlearn: 0.1554222\ttotal: 1m 1s\tremaining: 1.39s\n",
      "978:\tlearn: 0.1553686\ttotal: 1m 1s\tremaining: 1.33s\n",
      "979:\tlearn: 0.1553233\ttotal: 1m 2s\tremaining: 1.26s\n",
      "980:\tlearn: 0.1552725\ttotal: 1m 2s\tremaining: 1.2s\n",
      "981:\tlearn: 0.1552247\ttotal: 1m 2s\tremaining: 1.14s\n",
      "982:\tlearn: 0.1551762\ttotal: 1m 2s\tremaining: 1.07s\n",
      "983:\tlearn: 0.1551265\ttotal: 1m 2s\tremaining: 1.01s\n",
      "984:\tlearn: 0.1550734\ttotal: 1m 2s\tremaining: 949ms\n",
      "985:\tlearn: 0.1550363\ttotal: 1m 2s\tremaining: 886ms\n",
      "986:\tlearn: 0.1549945\ttotal: 1m 2s\tremaining: 823ms\n",
      "987:\tlearn: 0.1549413\ttotal: 1m 2s\tremaining: 759ms\n",
      "988:\tlearn: 0.1548987\ttotal: 1m 2s\tremaining: 696ms\n",
      "989:\tlearn: 0.1548512\ttotal: 1m 2s\tremaining: 633ms\n",
      "990:\tlearn: 0.1547953\ttotal: 1m 2s\tremaining: 569ms\n",
      "991:\tlearn: 0.1547475\ttotal: 1m 2s\tremaining: 506ms\n",
      "992:\tlearn: 0.1547085\ttotal: 1m 2s\tremaining: 443ms\n",
      "993:\tlearn: 0.1546575\ttotal: 1m 2s\tremaining: 379ms\n",
      "994:\tlearn: 0.1546171\ttotal: 1m 2s\tremaining: 316ms\n",
      "995:\tlearn: 0.1545855\ttotal: 1m 2s\tremaining: 253ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "996:\tlearn: 0.1545381\ttotal: 1m 3s\tremaining: 190ms\n",
      "997:\tlearn: 0.1544984\ttotal: 1m 3s\tremaining: 126ms\n",
      "998:\tlearn: 0.1544508\ttotal: 1m 3s\tremaining: 63.2ms\n",
      "999:\tlearn: 0.1544039\ttotal: 1m 3s\tremaining: 0us\n",
      "Learning rate set to 0.09461\n",
      "0:\tlearn: 0.6142270\ttotal: 61.2ms\tremaining: 1m 1s\n",
      "1:\tlearn: 0.5503685\ttotal: 124ms\tremaining: 1m 2s\n",
      "2:\tlearn: 0.5015765\ttotal: 195ms\tremaining: 1m 4s\n",
      "3:\tlearn: 0.4635413\ttotal: 264ms\tremaining: 1m 5s\n",
      "4:\tlearn: 0.4323132\ttotal: 337ms\tremaining: 1m 7s\n",
      "5:\tlearn: 0.4076304\ttotal: 401ms\tremaining: 1m 6s\n",
      "6:\tlearn: 0.3881252\ttotal: 465ms\tremaining: 1m 5s\n",
      "7:\tlearn: 0.3722464\ttotal: 527ms\tremaining: 1m 5s\n",
      "8:\tlearn: 0.3595895\ttotal: 587ms\tremaining: 1m 4s\n",
      "9:\tlearn: 0.3493894\ttotal: 655ms\tremaining: 1m 4s\n",
      "10:\tlearn: 0.3409157\ttotal: 711ms\tremaining: 1m 3s\n",
      "11:\tlearn: 0.3332492\ttotal: 766ms\tremaining: 1m 3s\n",
      "12:\tlearn: 0.3272286\ttotal: 822ms\tremaining: 1m 2s\n",
      "13:\tlearn: 0.3220699\ttotal: 877ms\tremaining: 1m 1s\n",
      "14:\tlearn: 0.3180676\ttotal: 932ms\tremaining: 1m 1s\n",
      "15:\tlearn: 0.3142903\ttotal: 985ms\tremaining: 1m\n",
      "16:\tlearn: 0.3112043\ttotal: 1.04s\tremaining: 1m\n",
      "17:\tlearn: 0.3086264\ttotal: 1.09s\tremaining: 59.6s\n",
      "18:\tlearn: 0.3061876\ttotal: 1.15s\tremaining: 59.2s\n",
      "19:\tlearn: 0.3040612\ttotal: 1.2s\tremaining: 58.9s\n",
      "20:\tlearn: 0.3020824\ttotal: 1.25s\tremaining: 58.5s\n",
      "21:\tlearn: 0.3004388\ttotal: 1.3s\tremaining: 58s\n",
      "22:\tlearn: 0.2987991\ttotal: 1.36s\tremaining: 57.7s\n",
      "23:\tlearn: 0.2974288\ttotal: 1.41s\tremaining: 57.4s\n",
      "24:\tlearn: 0.2961146\ttotal: 1.47s\tremaining: 57.2s\n",
      "25:\tlearn: 0.2948562\ttotal: 1.52s\tremaining: 57s\n",
      "26:\tlearn: 0.2937425\ttotal: 1.57s\tremaining: 56.7s\n",
      "27:\tlearn: 0.2925972\ttotal: 1.63s\tremaining: 56.7s\n",
      "28:\tlearn: 0.2915281\ttotal: 1.69s\tremaining: 56.5s\n",
      "29:\tlearn: 0.2904608\ttotal: 1.74s\tremaining: 56.3s\n",
      "30:\tlearn: 0.2894164\ttotal: 1.79s\tremaining: 56s\n",
      "31:\tlearn: 0.2885346\ttotal: 1.84s\tremaining: 55.7s\n",
      "32:\tlearn: 0.2876482\ttotal: 1.9s\tremaining: 55.6s\n",
      "33:\tlearn: 0.2868067\ttotal: 1.95s\tremaining: 55.4s\n",
      "34:\tlearn: 0.2860148\ttotal: 2.01s\tremaining: 55.5s\n",
      "35:\tlearn: 0.2851422\ttotal: 2.06s\tremaining: 55.3s\n",
      "36:\tlearn: 0.2842725\ttotal: 2.13s\tremaining: 55.4s\n",
      "37:\tlearn: 0.2834329\ttotal: 2.19s\tremaining: 55.4s\n",
      "38:\tlearn: 0.2826500\ttotal: 2.25s\tremaining: 55.4s\n",
      "39:\tlearn: 0.2819294\ttotal: 2.31s\tremaining: 55.4s\n",
      "40:\tlearn: 0.2811075\ttotal: 2.36s\tremaining: 55.3s\n",
      "41:\tlearn: 0.2802703\ttotal: 2.44s\tremaining: 55.6s\n",
      "42:\tlearn: 0.2795889\ttotal: 2.49s\tremaining: 55.4s\n",
      "43:\tlearn: 0.2788381\ttotal: 2.55s\tremaining: 55.4s\n",
      "44:\tlearn: 0.2780569\ttotal: 2.61s\tremaining: 55.4s\n",
      "45:\tlearn: 0.2773897\ttotal: 2.67s\tremaining: 55.3s\n",
      "46:\tlearn: 0.2767443\ttotal: 2.72s\tremaining: 55.1s\n",
      "47:\tlearn: 0.2761025\ttotal: 2.78s\tremaining: 55.1s\n",
      "48:\tlearn: 0.2753802\ttotal: 2.84s\tremaining: 55.1s\n",
      "49:\tlearn: 0.2747192\ttotal: 2.89s\tremaining: 55s\n",
      "50:\tlearn: 0.2740903\ttotal: 2.95s\tremaining: 54.9s\n",
      "51:\tlearn: 0.2734615\ttotal: 3s\tremaining: 54.8s\n",
      "52:\tlearn: 0.2728105\ttotal: 3.07s\tremaining: 54.8s\n",
      "53:\tlearn: 0.2722382\ttotal: 3.12s\tremaining: 54.6s\n",
      "54:\tlearn: 0.2716047\ttotal: 3.17s\tremaining: 54.6s\n",
      "55:\tlearn: 0.2710409\ttotal: 3.23s\tremaining: 54.5s\n",
      "56:\tlearn: 0.2704469\ttotal: 3.29s\tremaining: 54.4s\n",
      "57:\tlearn: 0.2698061\ttotal: 3.36s\tremaining: 54.5s\n",
      "58:\tlearn: 0.2692406\ttotal: 3.41s\tremaining: 54.4s\n",
      "59:\tlearn: 0.2687209\ttotal: 3.46s\tremaining: 54.3s\n",
      "60:\tlearn: 0.2681354\ttotal: 3.52s\tremaining: 54.2s\n",
      "61:\tlearn: 0.2675716\ttotal: 3.59s\tremaining: 54.3s\n",
      "62:\tlearn: 0.2669771\ttotal: 3.65s\tremaining: 54.3s\n",
      "63:\tlearn: 0.2664757\ttotal: 3.72s\tremaining: 54.4s\n",
      "64:\tlearn: 0.2659163\ttotal: 3.78s\tremaining: 54.4s\n",
      "65:\tlearn: 0.2654053\ttotal: 3.84s\tremaining: 54.4s\n",
      "66:\tlearn: 0.2648785\ttotal: 3.9s\tremaining: 54.3s\n",
      "67:\tlearn: 0.2643387\ttotal: 3.97s\tremaining: 54.4s\n",
      "68:\tlearn: 0.2637843\ttotal: 4.03s\tremaining: 54.4s\n",
      "69:\tlearn: 0.2633013\ttotal: 4.09s\tremaining: 54.3s\n",
      "70:\tlearn: 0.2628219\ttotal: 4.14s\tremaining: 54.2s\n",
      "71:\tlearn: 0.2623222\ttotal: 4.2s\tremaining: 54.1s\n",
      "72:\tlearn: 0.2618385\ttotal: 4.26s\tremaining: 54.1s\n",
      "73:\tlearn: 0.2613780\ttotal: 4.31s\tremaining: 54s\n",
      "74:\tlearn: 0.2609098\ttotal: 4.37s\tremaining: 53.9s\n",
      "75:\tlearn: 0.2604247\ttotal: 4.43s\tremaining: 53.9s\n",
      "76:\tlearn: 0.2599497\ttotal: 4.49s\tremaining: 53.8s\n",
      "77:\tlearn: 0.2595200\ttotal: 4.55s\tremaining: 53.8s\n",
      "78:\tlearn: 0.2590622\ttotal: 4.61s\tremaining: 53.7s\n",
      "79:\tlearn: 0.2586124\ttotal: 4.68s\tremaining: 53.8s\n",
      "80:\tlearn: 0.2581977\ttotal: 4.74s\tremaining: 53.8s\n",
      "81:\tlearn: 0.2577665\ttotal: 4.8s\tremaining: 53.7s\n",
      "82:\tlearn: 0.2573505\ttotal: 4.86s\tremaining: 53.7s\n",
      "83:\tlearn: 0.2569352\ttotal: 4.92s\tremaining: 53.7s\n",
      "84:\tlearn: 0.2564770\ttotal: 4.99s\tremaining: 53.7s\n",
      "85:\tlearn: 0.2560382\ttotal: 5.05s\tremaining: 53.7s\n",
      "86:\tlearn: 0.2555946\ttotal: 5.12s\tremaining: 53.7s\n",
      "87:\tlearn: 0.2551943\ttotal: 5.18s\tremaining: 53.7s\n",
      "88:\tlearn: 0.2547973\ttotal: 5.25s\tremaining: 53.7s\n",
      "89:\tlearn: 0.2543945\ttotal: 5.3s\tremaining: 53.6s\n",
      "90:\tlearn: 0.2540010\ttotal: 5.36s\tremaining: 53.5s\n",
      "91:\tlearn: 0.2535958\ttotal: 5.42s\tremaining: 53.5s\n",
      "92:\tlearn: 0.2531548\ttotal: 5.48s\tremaining: 53.4s\n",
      "93:\tlearn: 0.2527691\ttotal: 5.54s\tremaining: 53.4s\n",
      "94:\tlearn: 0.2523813\ttotal: 5.59s\tremaining: 53.3s\n",
      "95:\tlearn: 0.2520004\ttotal: 5.65s\tremaining: 53.2s\n",
      "96:\tlearn: 0.2516104\ttotal: 5.71s\tremaining: 53.2s\n",
      "97:\tlearn: 0.2512512\ttotal: 5.77s\tremaining: 53.1s\n",
      "98:\tlearn: 0.2508829\ttotal: 5.82s\tremaining: 53s\n",
      "99:\tlearn: 0.2505294\ttotal: 5.88s\tremaining: 52.9s\n",
      "100:\tlearn: 0.2501476\ttotal: 5.93s\tremaining: 52.8s\n",
      "101:\tlearn: 0.2498192\ttotal: 5.99s\tremaining: 52.7s\n",
      "102:\tlearn: 0.2494541\ttotal: 6.05s\tremaining: 52.7s\n",
      "103:\tlearn: 0.2491271\ttotal: 6.11s\tremaining: 52.7s\n",
      "104:\tlearn: 0.2487633\ttotal: 6.17s\tremaining: 52.6s\n",
      "105:\tlearn: 0.2483912\ttotal: 6.24s\tremaining: 52.6s\n",
      "106:\tlearn: 0.2480081\ttotal: 6.31s\tremaining: 52.7s\n",
      "107:\tlearn: 0.2476615\ttotal: 6.37s\tremaining: 52.6s\n",
      "108:\tlearn: 0.2473291\ttotal: 6.43s\tremaining: 52.5s\n",
      "109:\tlearn: 0.2469645\ttotal: 6.49s\tremaining: 52.5s\n",
      "110:\tlearn: 0.2466267\ttotal: 6.55s\tremaining: 52.4s\n",
      "111:\tlearn: 0.2462879\ttotal: 6.6s\tremaining: 52.3s\n",
      "112:\tlearn: 0.2459661\ttotal: 6.65s\tremaining: 52.2s\n",
      "113:\tlearn: 0.2456567\ttotal: 6.71s\tremaining: 52.1s\n",
      "114:\tlearn: 0.2453314\ttotal: 6.76s\tremaining: 52s\n",
      "115:\tlearn: 0.2450190\ttotal: 6.83s\tremaining: 52s\n",
      "116:\tlearn: 0.2446804\ttotal: 6.88s\tremaining: 52s\n",
      "117:\tlearn: 0.2443532\ttotal: 6.94s\tremaining: 51.9s\n",
      "118:\tlearn: 0.2440341\ttotal: 7s\tremaining: 51.8s\n",
      "119:\tlearn: 0.2437435\ttotal: 7.05s\tremaining: 51.7s\n",
      "120:\tlearn: 0.2434410\ttotal: 7.1s\tremaining: 51.6s\n",
      "121:\tlearn: 0.2431396\ttotal: 7.16s\tremaining: 51.5s\n",
      "122:\tlearn: 0.2428220\ttotal: 7.22s\tremaining: 51.5s\n",
      "123:\tlearn: 0.2425121\ttotal: 7.28s\tremaining: 51.4s\n",
      "124:\tlearn: 0.2421936\ttotal: 7.34s\tremaining: 51.4s\n",
      "125:\tlearn: 0.2419008\ttotal: 7.4s\tremaining: 51.3s\n",
      "126:\tlearn: 0.2416116\ttotal: 7.46s\tremaining: 51.3s\n",
      "127:\tlearn: 0.2413218\ttotal: 7.52s\tremaining: 51.2s\n",
      "128:\tlearn: 0.2410380\ttotal: 7.57s\tremaining: 51.1s\n",
      "129:\tlearn: 0.2407448\ttotal: 7.63s\tremaining: 51.1s\n",
      "130:\tlearn: 0.2404532\ttotal: 7.69s\tremaining: 51s\n",
      "131:\tlearn: 0.2401600\ttotal: 7.75s\tremaining: 51s\n",
      "132:\tlearn: 0.2398848\ttotal: 7.81s\tremaining: 50.9s\n",
      "133:\tlearn: 0.2395828\ttotal: 7.87s\tremaining: 50.8s\n",
      "134:\tlearn: 0.2393008\ttotal: 7.92s\tremaining: 50.8s\n",
      "135:\tlearn: 0.2390012\ttotal: 7.99s\tremaining: 50.8s\n",
      "136:\tlearn: 0.2387355\ttotal: 8.05s\tremaining: 50.7s\n",
      "137:\tlearn: 0.2384775\ttotal: 8.11s\tremaining: 50.6s\n",
      "138:\tlearn: 0.2382116\ttotal: 8.17s\tremaining: 50.6s\n",
      "139:\tlearn: 0.2379235\ttotal: 8.23s\tremaining: 50.6s\n",
      "140:\tlearn: 0.2376360\ttotal: 8.29s\tremaining: 50.5s\n",
      "141:\tlearn: 0.2373492\ttotal: 8.36s\tremaining: 50.5s\n",
      "142:\tlearn: 0.2370652\ttotal: 8.42s\tremaining: 50.4s\n",
      "143:\tlearn: 0.2368000\ttotal: 8.47s\tremaining: 50.4s\n",
      "144:\tlearn: 0.2365402\ttotal: 8.53s\tremaining: 50.3s\n",
      "145:\tlearn: 0.2362861\ttotal: 8.59s\tremaining: 50.2s\n",
      "146:\tlearn: 0.2359974\ttotal: 8.67s\tremaining: 50.3s\n",
      "147:\tlearn: 0.2357413\ttotal: 8.73s\tremaining: 50.2s\n",
      "148:\tlearn: 0.2354771\ttotal: 8.79s\tremaining: 50.2s\n",
      "149:\tlearn: 0.2351971\ttotal: 8.85s\tremaining: 50.1s\n",
      "150:\tlearn: 0.2349409\ttotal: 8.91s\tremaining: 50.1s\n",
      "151:\tlearn: 0.2346727\ttotal: 8.98s\tremaining: 50.1s\n",
      "152:\tlearn: 0.2343903\ttotal: 9.04s\tremaining: 50s\n",
      "153:\tlearn: 0.2341369\ttotal: 9.1s\tremaining: 50s\n",
      "154:\tlearn: 0.2338809\ttotal: 9.15s\tremaining: 49.9s\n",
      "155:\tlearn: 0.2336220\ttotal: 9.23s\tremaining: 49.9s\n",
      "156:\tlearn: 0.2333642\ttotal: 9.3s\tremaining: 49.9s\n",
      "157:\tlearn: 0.2331075\ttotal: 9.36s\tremaining: 49.9s\n",
      "158:\tlearn: 0.2328461\ttotal: 9.43s\tremaining: 49.9s\n",
      "159:\tlearn: 0.2325915\ttotal: 9.48s\tremaining: 49.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160:\tlearn: 0.2323342\ttotal: 9.54s\tremaining: 49.7s\n",
      "161:\tlearn: 0.2320985\ttotal: 9.6s\tremaining: 49.7s\n",
      "162:\tlearn: 0.2318582\ttotal: 9.65s\tremaining: 49.6s\n",
      "163:\tlearn: 0.2316249\ttotal: 9.72s\tremaining: 49.5s\n",
      "164:\tlearn: 0.2313805\ttotal: 9.78s\tremaining: 49.5s\n",
      "165:\tlearn: 0.2311388\ttotal: 9.84s\tremaining: 49.4s\n",
      "166:\tlearn: 0.2308918\ttotal: 9.9s\tremaining: 49.4s\n",
      "167:\tlearn: 0.2306647\ttotal: 9.96s\tremaining: 49.3s\n",
      "168:\tlearn: 0.2304085\ttotal: 10s\tremaining: 49.3s\n",
      "169:\tlearn: 0.2301889\ttotal: 10.1s\tremaining: 49.2s\n",
      "170:\tlearn: 0.2299427\ttotal: 10.1s\tremaining: 49.2s\n",
      "171:\tlearn: 0.2297141\ttotal: 10.2s\tremaining: 49.2s\n",
      "172:\tlearn: 0.2294869\ttotal: 10.3s\tremaining: 49.2s\n",
      "173:\tlearn: 0.2292470\ttotal: 10.4s\tremaining: 49.1s\n",
      "174:\tlearn: 0.2290218\ttotal: 10.4s\tremaining: 49.1s\n",
      "175:\tlearn: 0.2287908\ttotal: 10.5s\tremaining: 49.1s\n",
      "176:\tlearn: 0.2285581\ttotal: 10.5s\tremaining: 49s\n",
      "177:\tlearn: 0.2283200\ttotal: 10.6s\tremaining: 49s\n",
      "178:\tlearn: 0.2280885\ttotal: 10.7s\tremaining: 49s\n",
      "179:\tlearn: 0.2278667\ttotal: 10.7s\tremaining: 48.9s\n",
      "180:\tlearn: 0.2276505\ttotal: 10.8s\tremaining: 48.9s\n",
      "181:\tlearn: 0.2274164\ttotal: 10.9s\tremaining: 48.8s\n",
      "182:\tlearn: 0.2271647\ttotal: 10.9s\tremaining: 48.8s\n",
      "183:\tlearn: 0.2269466\ttotal: 11s\tremaining: 48.8s\n",
      "184:\tlearn: 0.2267322\ttotal: 11s\tremaining: 48.7s\n",
      "185:\tlearn: 0.2265255\ttotal: 11.1s\tremaining: 48.6s\n",
      "186:\tlearn: 0.2263239\ttotal: 11.2s\tremaining: 48.6s\n",
      "187:\tlearn: 0.2260932\ttotal: 11.3s\tremaining: 48.6s\n",
      "188:\tlearn: 0.2258761\ttotal: 11.3s\tremaining: 48.6s\n",
      "189:\tlearn: 0.2256579\ttotal: 11.4s\tremaining: 48.5s\n",
      "190:\tlearn: 0.2254352\ttotal: 11.4s\tremaining: 48.5s\n",
      "191:\tlearn: 0.2252288\ttotal: 11.5s\tremaining: 48.4s\n",
      "192:\tlearn: 0.2250247\ttotal: 11.6s\tremaining: 48.3s\n",
      "193:\tlearn: 0.2248220\ttotal: 11.6s\tremaining: 48.2s\n",
      "194:\tlearn: 0.2246133\ttotal: 11.7s\tremaining: 48.2s\n",
      "195:\tlearn: 0.2243977\ttotal: 11.7s\tremaining: 48.1s\n",
      "196:\tlearn: 0.2241991\ttotal: 11.8s\tremaining: 48.1s\n",
      "197:\tlearn: 0.2239895\ttotal: 11.9s\tremaining: 48s\n",
      "198:\tlearn: 0.2237869\ttotal: 11.9s\tremaining: 48s\n",
      "199:\tlearn: 0.2235920\ttotal: 12s\tremaining: 48s\n",
      "200:\tlearn: 0.2233929\ttotal: 12.1s\tremaining: 48s\n",
      "201:\tlearn: 0.2231721\ttotal: 12.2s\tremaining: 48s\n",
      "202:\tlearn: 0.2229736\ttotal: 12.2s\tremaining: 48s\n",
      "203:\tlearn: 0.2227803\ttotal: 12.3s\tremaining: 48s\n",
      "204:\tlearn: 0.2225874\ttotal: 12.3s\tremaining: 47.9s\n",
      "205:\tlearn: 0.2223966\ttotal: 12.4s\tremaining: 47.8s\n",
      "206:\tlearn: 0.2222065\ttotal: 12.5s\tremaining: 47.8s\n",
      "207:\tlearn: 0.2220035\ttotal: 12.5s\tremaining: 47.7s\n",
      "208:\tlearn: 0.2218083\ttotal: 12.6s\tremaining: 47.6s\n",
      "209:\tlearn: 0.2216116\ttotal: 12.7s\tremaining: 47.6s\n",
      "210:\tlearn: 0.2214056\ttotal: 12.7s\tremaining: 47.6s\n",
      "211:\tlearn: 0.2212090\ttotal: 12.8s\tremaining: 47.5s\n",
      "212:\tlearn: 0.2210330\ttotal: 12.8s\tremaining: 47.4s\n",
      "213:\tlearn: 0.2208340\ttotal: 12.9s\tremaining: 47.4s\n",
      "214:\tlearn: 0.2206450\ttotal: 13s\tremaining: 47.3s\n",
      "215:\tlearn: 0.2204586\ttotal: 13s\tremaining: 47.3s\n",
      "216:\tlearn: 0.2202574\ttotal: 13.1s\tremaining: 47.3s\n",
      "217:\tlearn: 0.2200741\ttotal: 13.2s\tremaining: 47.3s\n",
      "218:\tlearn: 0.2198793\ttotal: 13.2s\tremaining: 47.2s\n",
      "219:\tlearn: 0.2197042\ttotal: 13.3s\tremaining: 47.2s\n",
      "220:\tlearn: 0.2195250\ttotal: 13.4s\tremaining: 47.1s\n",
      "221:\tlearn: 0.2193367\ttotal: 13.4s\tremaining: 47s\n",
      "222:\tlearn: 0.2191380\ttotal: 13.5s\tremaining: 47s\n",
      "223:\tlearn: 0.2189586\ttotal: 13.5s\tremaining: 46.9s\n",
      "224:\tlearn: 0.2187713\ttotal: 13.6s\tremaining: 46.9s\n",
      "225:\tlearn: 0.2185892\ttotal: 13.7s\tremaining: 46.8s\n",
      "226:\tlearn: 0.2184101\ttotal: 13.7s\tremaining: 46.8s\n",
      "227:\tlearn: 0.2182381\ttotal: 13.8s\tremaining: 46.7s\n",
      "228:\tlearn: 0.2180663\ttotal: 13.9s\tremaining: 46.6s\n",
      "229:\tlearn: 0.2178911\ttotal: 13.9s\tremaining: 46.6s\n",
      "230:\tlearn: 0.2177230\ttotal: 14s\tremaining: 46.5s\n",
      "231:\tlearn: 0.2175448\ttotal: 14s\tremaining: 46.5s\n",
      "232:\tlearn: 0.2173626\ttotal: 14.1s\tremaining: 46.4s\n",
      "233:\tlearn: 0.2171857\ttotal: 14.2s\tremaining: 46.4s\n",
      "234:\tlearn: 0.2170210\ttotal: 14.2s\tremaining: 46.4s\n",
      "235:\tlearn: 0.2168517\ttotal: 14.3s\tremaining: 46.4s\n",
      "236:\tlearn: 0.2166753\ttotal: 14.4s\tremaining: 46.3s\n",
      "237:\tlearn: 0.2165119\ttotal: 14.5s\tremaining: 46.3s\n",
      "238:\tlearn: 0.2163426\ttotal: 14.5s\tremaining: 46.2s\n",
      "239:\tlearn: 0.2161875\ttotal: 14.6s\tremaining: 46.1s\n",
      "240:\tlearn: 0.2160314\ttotal: 14.6s\tremaining: 46.1s\n",
      "241:\tlearn: 0.2158626\ttotal: 14.7s\tremaining: 46s\n",
      "242:\tlearn: 0.2156923\ttotal: 14.7s\tremaining: 45.9s\n",
      "243:\tlearn: 0.2155260\ttotal: 14.8s\tremaining: 45.8s\n",
      "244:\tlearn: 0.2153641\ttotal: 14.8s\tremaining: 45.8s\n",
      "245:\tlearn: 0.2152101\ttotal: 14.9s\tremaining: 45.7s\n",
      "246:\tlearn: 0.2150469\ttotal: 15s\tremaining: 45.6s\n",
      "247:\tlearn: 0.2148851\ttotal: 15s\tremaining: 45.6s\n",
      "248:\tlearn: 0.2147057\ttotal: 15.1s\tremaining: 45.5s\n",
      "249:\tlearn: 0.2145373\ttotal: 15.2s\tremaining: 45.5s\n",
      "250:\tlearn: 0.2143690\ttotal: 15.2s\tremaining: 45.4s\n",
      "251:\tlearn: 0.2141970\ttotal: 15.3s\tremaining: 45.4s\n",
      "252:\tlearn: 0.2140265\ttotal: 15.3s\tremaining: 45.3s\n",
      "253:\tlearn: 0.2138803\ttotal: 15.4s\tremaining: 45.3s\n",
      "254:\tlearn: 0.2137152\ttotal: 15.5s\tremaining: 45.2s\n",
      "255:\tlearn: 0.2135498\ttotal: 15.5s\tremaining: 45.2s\n",
      "256:\tlearn: 0.2133880\ttotal: 15.6s\tremaining: 45.1s\n",
      "257:\tlearn: 0.2132314\ttotal: 15.7s\tremaining: 45s\n",
      "258:\tlearn: 0.2130779\ttotal: 15.7s\tremaining: 45s\n",
      "259:\tlearn: 0.2129159\ttotal: 15.8s\tremaining: 44.9s\n",
      "260:\tlearn: 0.2127724\ttotal: 15.8s\tremaining: 44.9s\n",
      "261:\tlearn: 0.2126063\ttotal: 15.9s\tremaining: 44.8s\n",
      "262:\tlearn: 0.2124545\ttotal: 16s\tremaining: 44.7s\n",
      "263:\tlearn: 0.2123076\ttotal: 16s\tremaining: 44.7s\n",
      "264:\tlearn: 0.2121634\ttotal: 16.1s\tremaining: 44.6s\n",
      "265:\tlearn: 0.2120091\ttotal: 16.1s\tremaining: 44.5s\n",
      "266:\tlearn: 0.2118591\ttotal: 16.2s\tremaining: 44.5s\n",
      "267:\tlearn: 0.2117019\ttotal: 16.3s\tremaining: 44.4s\n",
      "268:\tlearn: 0.2115607\ttotal: 16.3s\tremaining: 44.3s\n",
      "269:\tlearn: 0.2114085\ttotal: 16.4s\tremaining: 44.3s\n",
      "270:\tlearn: 0.2112677\ttotal: 16.4s\tremaining: 44.2s\n",
      "271:\tlearn: 0.2111046\ttotal: 16.5s\tremaining: 44.2s\n",
      "272:\tlearn: 0.2109514\ttotal: 16.6s\tremaining: 44.1s\n",
      "273:\tlearn: 0.2108157\ttotal: 16.6s\tremaining: 44.1s\n",
      "274:\tlearn: 0.2106735\ttotal: 16.7s\tremaining: 44s\n",
      "275:\tlearn: 0.2105264\ttotal: 16.8s\tremaining: 44s\n",
      "276:\tlearn: 0.2103793\ttotal: 16.8s\tremaining: 43.9s\n",
      "277:\tlearn: 0.2102302\ttotal: 16.9s\tremaining: 43.8s\n",
      "278:\tlearn: 0.2100763\ttotal: 16.9s\tremaining: 43.8s\n",
      "279:\tlearn: 0.2099421\ttotal: 17s\tremaining: 43.7s\n",
      "280:\tlearn: 0.2097998\ttotal: 17.1s\tremaining: 43.6s\n",
      "281:\tlearn: 0.2096566\ttotal: 17.1s\tremaining: 43.6s\n",
      "282:\tlearn: 0.2095050\ttotal: 17.2s\tremaining: 43.6s\n",
      "283:\tlearn: 0.2093576\ttotal: 17.3s\tremaining: 43.5s\n",
      "284:\tlearn: 0.2092061\ttotal: 17.3s\tremaining: 43.4s\n",
      "285:\tlearn: 0.2090638\ttotal: 17.4s\tremaining: 43.4s\n",
      "286:\tlearn: 0.2089289\ttotal: 17.4s\tremaining: 43.3s\n",
      "287:\tlearn: 0.2087940\ttotal: 17.5s\tremaining: 43.3s\n",
      "288:\tlearn: 0.2086556\ttotal: 17.6s\tremaining: 43.2s\n",
      "289:\tlearn: 0.2085140\ttotal: 17.6s\tremaining: 43.1s\n",
      "290:\tlearn: 0.2083725\ttotal: 17.7s\tremaining: 43.1s\n",
      "291:\tlearn: 0.2082255\ttotal: 17.7s\tremaining: 43s\n",
      "292:\tlearn: 0.2080870\ttotal: 17.8s\tremaining: 43s\n",
      "293:\tlearn: 0.2079431\ttotal: 17.9s\tremaining: 42.9s\n",
      "294:\tlearn: 0.2078032\ttotal: 17.9s\tremaining: 42.9s\n",
      "295:\tlearn: 0.2076737\ttotal: 18s\tremaining: 42.8s\n",
      "296:\tlearn: 0.2075390\ttotal: 18.1s\tremaining: 42.8s\n",
      "297:\tlearn: 0.2074083\ttotal: 18.1s\tremaining: 42.7s\n",
      "298:\tlearn: 0.2072852\ttotal: 18.2s\tremaining: 42.7s\n",
      "299:\tlearn: 0.2071464\ttotal: 18.3s\tremaining: 42.6s\n",
      "300:\tlearn: 0.2070040\ttotal: 18.3s\tremaining: 42.6s\n",
      "301:\tlearn: 0.2068769\ttotal: 18.4s\tremaining: 42.5s\n",
      "302:\tlearn: 0.2067331\ttotal: 18.5s\tremaining: 42.5s\n",
      "303:\tlearn: 0.2066071\ttotal: 18.5s\tremaining: 42.4s\n",
      "304:\tlearn: 0.2064788\ttotal: 18.6s\tremaining: 42.3s\n",
      "305:\tlearn: 0.2063408\ttotal: 18.6s\tremaining: 42.2s\n",
      "306:\tlearn: 0.2062085\ttotal: 18.7s\tremaining: 42.2s\n",
      "307:\tlearn: 0.2060645\ttotal: 18.8s\tremaining: 42.1s\n",
      "308:\tlearn: 0.2059342\ttotal: 18.8s\tremaining: 42.1s\n",
      "309:\tlearn: 0.2058024\ttotal: 18.9s\tremaining: 42s\n",
      "310:\tlearn: 0.2056556\ttotal: 18.9s\tremaining: 42s\n",
      "311:\tlearn: 0.2055222\ttotal: 19s\tremaining: 41.9s\n",
      "312:\tlearn: 0.2053844\ttotal: 19.1s\tremaining: 41.9s\n",
      "313:\tlearn: 0.2052593\ttotal: 19.1s\tremaining: 41.8s\n",
      "314:\tlearn: 0.2051224\ttotal: 19.2s\tremaining: 41.7s\n",
      "315:\tlearn: 0.2049726\ttotal: 19.2s\tremaining: 41.7s\n",
      "316:\tlearn: 0.2048333\ttotal: 19.3s\tremaining: 41.6s\n",
      "317:\tlearn: 0.2046851\ttotal: 19.4s\tremaining: 41.6s\n",
      "318:\tlearn: 0.2045490\ttotal: 19.5s\tremaining: 41.5s\n",
      "319:\tlearn: 0.2044237\ttotal: 19.5s\tremaining: 41.5s\n",
      "320:\tlearn: 0.2042973\ttotal: 19.6s\tremaining: 41.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "321:\tlearn: 0.2041696\ttotal: 19.6s\tremaining: 41.4s\n",
      "322:\tlearn: 0.2040477\ttotal: 19.7s\tremaining: 41.3s\n",
      "323:\tlearn: 0.2039136\ttotal: 19.8s\tremaining: 41.3s\n",
      "324:\tlearn: 0.2037735\ttotal: 19.8s\tremaining: 41.2s\n",
      "325:\tlearn: 0.2036585\ttotal: 19.9s\tremaining: 41.1s\n",
      "326:\tlearn: 0.2035228\ttotal: 20s\tremaining: 41.1s\n",
      "327:\tlearn: 0.2033907\ttotal: 20s\tremaining: 41.1s\n",
      "328:\tlearn: 0.2032725\ttotal: 20.1s\tremaining: 41s\n",
      "329:\tlearn: 0.2031472\ttotal: 20.2s\tremaining: 41s\n",
      "330:\tlearn: 0.2030342\ttotal: 20.2s\tremaining: 40.9s\n",
      "331:\tlearn: 0.2029083\ttotal: 20.3s\tremaining: 40.8s\n",
      "332:\tlearn: 0.2027872\ttotal: 20.4s\tremaining: 40.8s\n",
      "333:\tlearn: 0.2026673\ttotal: 20.4s\tremaining: 40.7s\n",
      "334:\tlearn: 0.2025326\ttotal: 20.5s\tremaining: 40.7s\n",
      "335:\tlearn: 0.2024089\ttotal: 20.5s\tremaining: 40.6s\n",
      "336:\tlearn: 0.2022854\ttotal: 20.6s\tremaining: 40.5s\n",
      "337:\tlearn: 0.2021719\ttotal: 20.7s\tremaining: 40.5s\n",
      "338:\tlearn: 0.2020577\ttotal: 20.7s\tremaining: 40.4s\n",
      "339:\tlearn: 0.2019266\ttotal: 20.8s\tremaining: 40.4s\n",
      "340:\tlearn: 0.2018070\ttotal: 20.8s\tremaining: 40.3s\n",
      "341:\tlearn: 0.2016820\ttotal: 20.9s\tremaining: 40.2s\n",
      "342:\tlearn: 0.2015471\ttotal: 21s\tremaining: 40.2s\n",
      "343:\tlearn: 0.2014337\ttotal: 21s\tremaining: 40.1s\n",
      "344:\tlearn: 0.2013141\ttotal: 21.1s\tremaining: 40.1s\n",
      "345:\tlearn: 0.2011945\ttotal: 21.2s\tremaining: 40s\n",
      "346:\tlearn: 0.2010741\ttotal: 21.2s\tremaining: 39.9s\n",
      "347:\tlearn: 0.2009579\ttotal: 21.3s\tremaining: 39.9s\n",
      "348:\tlearn: 0.2008400\ttotal: 21.3s\tremaining: 39.8s\n",
      "349:\tlearn: 0.2007154\ttotal: 21.4s\tremaining: 39.8s\n",
      "350:\tlearn: 0.2006071\ttotal: 21.5s\tremaining: 39.7s\n",
      "351:\tlearn: 0.2004964\ttotal: 21.5s\tremaining: 39.6s\n",
      "352:\tlearn: 0.2003863\ttotal: 21.6s\tremaining: 39.6s\n",
      "353:\tlearn: 0.2002783\ttotal: 21.6s\tremaining: 39.5s\n",
      "354:\tlearn: 0.2001446\ttotal: 21.7s\tremaining: 39.4s\n",
      "355:\tlearn: 0.2000370\ttotal: 21.8s\tremaining: 39.4s\n",
      "356:\tlearn: 0.1999205\ttotal: 21.8s\tremaining: 39.4s\n",
      "357:\tlearn: 0.1998073\ttotal: 21.9s\tremaining: 39.3s\n",
      "358:\tlearn: 0.1996966\ttotal: 22s\tremaining: 39.3s\n",
      "359:\tlearn: 0.1995886\ttotal: 22s\tremaining: 39.2s\n",
      "360:\tlearn: 0.1994808\ttotal: 22.1s\tremaining: 39.1s\n",
      "361:\tlearn: 0.1993721\ttotal: 22.2s\tremaining: 39.1s\n",
      "362:\tlearn: 0.1992583\ttotal: 22.2s\tremaining: 39s\n",
      "363:\tlearn: 0.1991417\ttotal: 22.3s\tremaining: 39s\n",
      "364:\tlearn: 0.1990271\ttotal: 22.4s\tremaining: 38.9s\n",
      "365:\tlearn: 0.1989025\ttotal: 22.5s\tremaining: 38.9s\n",
      "366:\tlearn: 0.1987771\ttotal: 22.5s\tremaining: 38.8s\n",
      "367:\tlearn: 0.1986631\ttotal: 22.6s\tremaining: 38.8s\n",
      "368:\tlearn: 0.1985437\ttotal: 22.7s\tremaining: 38.8s\n",
      "369:\tlearn: 0.1984396\ttotal: 22.7s\tremaining: 38.7s\n",
      "370:\tlearn: 0.1983237\ttotal: 22.8s\tremaining: 38.6s\n",
      "371:\tlearn: 0.1982169\ttotal: 22.9s\tremaining: 38.6s\n",
      "372:\tlearn: 0.1981053\ttotal: 22.9s\tremaining: 38.5s\n",
      "373:\tlearn: 0.1980026\ttotal: 23s\tremaining: 38.5s\n",
      "374:\tlearn: 0.1978889\ttotal: 23.1s\tremaining: 38.5s\n",
      "375:\tlearn: 0.1977810\ttotal: 23.2s\tremaining: 38.4s\n",
      "376:\tlearn: 0.1976725\ttotal: 23.2s\tremaining: 38.4s\n",
      "377:\tlearn: 0.1975656\ttotal: 23.3s\tremaining: 38.3s\n",
      "378:\tlearn: 0.1974676\ttotal: 23.4s\tremaining: 38.3s\n",
      "379:\tlearn: 0.1973645\ttotal: 23.4s\tremaining: 38.3s\n",
      "380:\tlearn: 0.1972727\ttotal: 23.5s\tremaining: 38.2s\n",
      "381:\tlearn: 0.1971676\ttotal: 23.6s\tremaining: 38.2s\n",
      "382:\tlearn: 0.1970521\ttotal: 23.7s\tremaining: 38.1s\n",
      "383:\tlearn: 0.1969554\ttotal: 23.8s\tremaining: 38.1s\n",
      "384:\tlearn: 0.1968539\ttotal: 23.8s\tremaining: 38.1s\n",
      "385:\tlearn: 0.1967547\ttotal: 23.9s\tremaining: 38s\n",
      "386:\tlearn: 0.1966576\ttotal: 24s\tremaining: 38s\n",
      "387:\tlearn: 0.1965595\ttotal: 24s\tremaining: 37.9s\n",
      "388:\tlearn: 0.1964607\ttotal: 24.1s\tremaining: 37.9s\n",
      "389:\tlearn: 0.1963651\ttotal: 24.2s\tremaining: 37.8s\n",
      "390:\tlearn: 0.1962546\ttotal: 24.3s\tremaining: 37.8s\n",
      "391:\tlearn: 0.1961316\ttotal: 24.3s\tremaining: 37.8s\n",
      "392:\tlearn: 0.1960321\ttotal: 24.4s\tremaining: 37.7s\n",
      "393:\tlearn: 0.1959244\ttotal: 24.5s\tremaining: 37.7s\n",
      "394:\tlearn: 0.1958207\ttotal: 24.6s\tremaining: 37.6s\n",
      "395:\tlearn: 0.1957175\ttotal: 24.6s\tremaining: 37.6s\n",
      "396:\tlearn: 0.1956064\ttotal: 24.7s\tremaining: 37.5s\n",
      "397:\tlearn: 0.1955002\ttotal: 24.8s\tremaining: 37.5s\n",
      "398:\tlearn: 0.1953987\ttotal: 24.8s\tremaining: 37.4s\n",
      "399:\tlearn: 0.1953032\ttotal: 24.9s\tremaining: 37.4s\n",
      "400:\tlearn: 0.1951969\ttotal: 25s\tremaining: 37.3s\n",
      "401:\tlearn: 0.1950998\ttotal: 25s\tremaining: 37.2s\n",
      "402:\tlearn: 0.1949899\ttotal: 25.1s\tremaining: 37.2s\n",
      "403:\tlearn: 0.1948898\ttotal: 25.2s\tremaining: 37.2s\n",
      "404:\tlearn: 0.1947855\ttotal: 25.3s\tremaining: 37.1s\n",
      "405:\tlearn: 0.1946803\ttotal: 25.3s\tremaining: 37s\n",
      "406:\tlearn: 0.1945791\ttotal: 25.4s\tremaining: 37s\n",
      "407:\tlearn: 0.1944708\ttotal: 25.4s\tremaining: 36.9s\n",
      "408:\tlearn: 0.1943781\ttotal: 25.5s\tremaining: 36.9s\n",
      "409:\tlearn: 0.1942675\ttotal: 25.6s\tremaining: 36.8s\n",
      "410:\tlearn: 0.1941666\ttotal: 25.6s\tremaining: 36.7s\n",
      "411:\tlearn: 0.1940564\ttotal: 25.7s\tremaining: 36.7s\n",
      "412:\tlearn: 0.1939603\ttotal: 25.8s\tremaining: 36.6s\n",
      "413:\tlearn: 0.1938625\ttotal: 25.8s\tremaining: 36.6s\n",
      "414:\tlearn: 0.1937658\ttotal: 25.9s\tremaining: 36.5s\n",
      "415:\tlearn: 0.1936679\ttotal: 26s\tremaining: 36.4s\n",
      "416:\tlearn: 0.1935802\ttotal: 26s\tremaining: 36.4s\n",
      "417:\tlearn: 0.1934778\ttotal: 26.1s\tremaining: 36.3s\n",
      "418:\tlearn: 0.1933801\ttotal: 26.1s\tremaining: 36.3s\n",
      "419:\tlearn: 0.1932836\ttotal: 26.2s\tremaining: 36.2s\n",
      "420:\tlearn: 0.1931719\ttotal: 26.3s\tremaining: 36.1s\n",
      "421:\tlearn: 0.1930941\ttotal: 26.3s\tremaining: 36.1s\n",
      "422:\tlearn: 0.1929856\ttotal: 26.4s\tremaining: 36s\n",
      "423:\tlearn: 0.1928798\ttotal: 26.5s\tremaining: 36s\n",
      "424:\tlearn: 0.1927834\ttotal: 26.5s\tremaining: 35.9s\n",
      "425:\tlearn: 0.1926898\ttotal: 26.6s\tremaining: 35.8s\n",
      "426:\tlearn: 0.1925870\ttotal: 26.7s\tremaining: 35.8s\n",
      "427:\tlearn: 0.1924864\ttotal: 26.7s\tremaining: 35.7s\n",
      "428:\tlearn: 0.1923768\ttotal: 26.8s\tremaining: 35.7s\n",
      "429:\tlearn: 0.1922885\ttotal: 26.9s\tremaining: 35.6s\n",
      "430:\tlearn: 0.1921907\ttotal: 26.9s\tremaining: 35.5s\n",
      "431:\tlearn: 0.1920873\ttotal: 27s\tremaining: 35.5s\n",
      "432:\tlearn: 0.1920016\ttotal: 27s\tremaining: 35.4s\n",
      "433:\tlearn: 0.1918993\ttotal: 27.1s\tremaining: 35.3s\n",
      "434:\tlearn: 0.1918073\ttotal: 27.2s\tremaining: 35.3s\n",
      "435:\tlearn: 0.1917108\ttotal: 27.2s\tremaining: 35.2s\n",
      "436:\tlearn: 0.1916171\ttotal: 27.3s\tremaining: 35.2s\n",
      "437:\tlearn: 0.1915243\ttotal: 27.3s\tremaining: 35.1s\n",
      "438:\tlearn: 0.1914304\ttotal: 27.4s\tremaining: 35s\n",
      "439:\tlearn: 0.1913212\ttotal: 27.5s\tremaining: 35s\n",
      "440:\tlearn: 0.1912287\ttotal: 27.5s\tremaining: 34.9s\n",
      "441:\tlearn: 0.1911360\ttotal: 27.6s\tremaining: 34.9s\n",
      "442:\tlearn: 0.1910488\ttotal: 27.7s\tremaining: 34.8s\n",
      "443:\tlearn: 0.1909481\ttotal: 27.7s\tremaining: 34.7s\n",
      "444:\tlearn: 0.1908439\ttotal: 27.8s\tremaining: 34.7s\n",
      "445:\tlearn: 0.1907523\ttotal: 27.9s\tremaining: 34.6s\n",
      "446:\tlearn: 0.1906528\ttotal: 27.9s\tremaining: 34.5s\n",
      "447:\tlearn: 0.1905650\ttotal: 28s\tremaining: 34.5s\n",
      "448:\tlearn: 0.1904848\ttotal: 28s\tremaining: 34.4s\n",
      "449:\tlearn: 0.1903999\ttotal: 28.1s\tremaining: 34.3s\n",
      "450:\tlearn: 0.1903209\ttotal: 28.2s\tremaining: 34.3s\n",
      "451:\tlearn: 0.1902249\ttotal: 28.2s\tremaining: 34.2s\n",
      "452:\tlearn: 0.1901184\ttotal: 28.3s\tremaining: 34.1s\n",
      "453:\tlearn: 0.1900313\ttotal: 28.4s\tremaining: 34.1s\n",
      "454:\tlearn: 0.1899369\ttotal: 28.4s\tremaining: 34s\n",
      "455:\tlearn: 0.1898464\ttotal: 28.5s\tremaining: 34s\n",
      "456:\tlearn: 0.1897545\ttotal: 28.5s\tremaining: 33.9s\n",
      "457:\tlearn: 0.1896676\ttotal: 28.6s\tremaining: 33.8s\n",
      "458:\tlearn: 0.1895860\ttotal: 28.7s\tremaining: 33.8s\n",
      "459:\tlearn: 0.1894798\ttotal: 28.7s\tremaining: 33.7s\n",
      "460:\tlearn: 0.1893999\ttotal: 28.8s\tremaining: 33.6s\n",
      "461:\tlearn: 0.1893153\ttotal: 28.8s\tremaining: 33.6s\n",
      "462:\tlearn: 0.1892195\ttotal: 28.9s\tremaining: 33.5s\n",
      "463:\tlearn: 0.1891255\ttotal: 29s\tremaining: 33.4s\n",
      "464:\tlearn: 0.1890407\ttotal: 29s\tremaining: 33.4s\n",
      "465:\tlearn: 0.1889528\ttotal: 29.1s\tremaining: 33.3s\n",
      "466:\tlearn: 0.1888659\ttotal: 29.1s\tremaining: 33.3s\n",
      "467:\tlearn: 0.1887894\ttotal: 29.2s\tremaining: 33.2s\n",
      "468:\tlearn: 0.1887051\ttotal: 29.2s\tremaining: 33.1s\n",
      "469:\tlearn: 0.1886042\ttotal: 29.3s\tremaining: 33.1s\n",
      "470:\tlearn: 0.1885059\ttotal: 29.4s\tremaining: 33s\n",
      "471:\tlearn: 0.1884143\ttotal: 29.5s\tremaining: 32.9s\n",
      "472:\tlearn: 0.1883032\ttotal: 29.5s\tremaining: 32.9s\n",
      "473:\tlearn: 0.1882136\ttotal: 29.6s\tremaining: 32.8s\n",
      "474:\tlearn: 0.1881214\ttotal: 29.7s\tremaining: 32.8s\n",
      "475:\tlearn: 0.1880313\ttotal: 29.7s\tremaining: 32.7s\n",
      "476:\tlearn: 0.1879478\ttotal: 29.8s\tremaining: 32.6s\n",
      "477:\tlearn: 0.1878667\ttotal: 29.8s\tremaining: 32.6s\n",
      "478:\tlearn: 0.1877735\ttotal: 29.9s\tremaining: 32.5s\n",
      "479:\tlearn: 0.1876851\ttotal: 30s\tremaining: 32.5s\n",
      "480:\tlearn: 0.1875945\ttotal: 30s\tremaining: 32.4s\n",
      "481:\tlearn: 0.1875009\ttotal: 30.1s\tremaining: 32.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "482:\tlearn: 0.1874126\ttotal: 30.2s\tremaining: 32.3s\n",
      "483:\tlearn: 0.1873317\ttotal: 30.2s\tremaining: 32.2s\n",
      "484:\tlearn: 0.1872475\ttotal: 30.3s\tremaining: 32.2s\n",
      "485:\tlearn: 0.1871490\ttotal: 30.3s\tremaining: 32.1s\n",
      "486:\tlearn: 0.1870635\ttotal: 30.4s\tremaining: 32s\n",
      "487:\tlearn: 0.1869781\ttotal: 30.5s\tremaining: 32s\n",
      "488:\tlearn: 0.1868883\ttotal: 30.5s\tremaining: 31.9s\n",
      "489:\tlearn: 0.1868214\ttotal: 30.6s\tremaining: 31.8s\n",
      "490:\tlearn: 0.1867354\ttotal: 30.6s\tremaining: 31.8s\n",
      "491:\tlearn: 0.1866490\ttotal: 30.7s\tremaining: 31.7s\n",
      "492:\tlearn: 0.1865692\ttotal: 30.8s\tremaining: 31.6s\n",
      "493:\tlearn: 0.1864915\ttotal: 30.8s\tremaining: 31.6s\n",
      "494:\tlearn: 0.1863973\ttotal: 30.9s\tremaining: 31.5s\n",
      "495:\tlearn: 0.1863064\ttotal: 31s\tremaining: 31.4s\n",
      "496:\tlearn: 0.1862298\ttotal: 31s\tremaining: 31.4s\n",
      "497:\tlearn: 0.1861574\ttotal: 31.1s\tremaining: 31.3s\n",
      "498:\tlearn: 0.1860753\ttotal: 31.1s\tremaining: 31.3s\n",
      "499:\tlearn: 0.1859875\ttotal: 31.2s\tremaining: 31.2s\n",
      "500:\tlearn: 0.1859050\ttotal: 31.3s\tremaining: 31.1s\n",
      "501:\tlearn: 0.1858245\ttotal: 31.3s\tremaining: 31.1s\n",
      "502:\tlearn: 0.1857441\ttotal: 31.4s\tremaining: 31s\n",
      "503:\tlearn: 0.1856669\ttotal: 31.4s\tremaining: 30.9s\n",
      "504:\tlearn: 0.1855772\ttotal: 31.5s\tremaining: 30.9s\n",
      "505:\tlearn: 0.1854942\ttotal: 31.6s\tremaining: 30.8s\n",
      "506:\tlearn: 0.1854091\ttotal: 31.6s\tremaining: 30.8s\n",
      "507:\tlearn: 0.1853332\ttotal: 31.7s\tremaining: 30.7s\n",
      "508:\tlearn: 0.1852459\ttotal: 31.8s\tremaining: 30.6s\n",
      "509:\tlearn: 0.1851448\ttotal: 31.8s\tremaining: 30.6s\n",
      "510:\tlearn: 0.1850607\ttotal: 31.9s\tremaining: 30.5s\n",
      "511:\tlearn: 0.1849790\ttotal: 32s\tremaining: 30.5s\n",
      "512:\tlearn: 0.1848978\ttotal: 32s\tremaining: 30.4s\n",
      "513:\tlearn: 0.1848166\ttotal: 32.1s\tremaining: 30.4s\n",
      "514:\tlearn: 0.1847353\ttotal: 32.2s\tremaining: 30.3s\n",
      "515:\tlearn: 0.1846540\ttotal: 32.2s\tremaining: 30.2s\n",
      "516:\tlearn: 0.1845700\ttotal: 32.3s\tremaining: 30.2s\n",
      "517:\tlearn: 0.1844857\ttotal: 32.4s\tremaining: 30.1s\n",
      "518:\tlearn: 0.1844024\ttotal: 32.4s\tremaining: 30.1s\n",
      "519:\tlearn: 0.1843147\ttotal: 32.5s\tremaining: 30s\n",
      "520:\tlearn: 0.1842397\ttotal: 32.6s\tremaining: 29.9s\n",
      "521:\tlearn: 0.1841529\ttotal: 32.6s\tremaining: 29.9s\n",
      "522:\tlearn: 0.1840804\ttotal: 32.7s\tremaining: 29.8s\n",
      "523:\tlearn: 0.1840066\ttotal: 32.7s\tremaining: 29.7s\n",
      "524:\tlearn: 0.1839217\ttotal: 32.8s\tremaining: 29.7s\n",
      "525:\tlearn: 0.1838411\ttotal: 32.9s\tremaining: 29.6s\n",
      "526:\tlearn: 0.1837682\ttotal: 32.9s\tremaining: 29.6s\n",
      "527:\tlearn: 0.1836847\ttotal: 33s\tremaining: 29.5s\n",
      "528:\tlearn: 0.1835961\ttotal: 33s\tremaining: 29.4s\n",
      "529:\tlearn: 0.1835171\ttotal: 33.1s\tremaining: 29.4s\n",
      "530:\tlearn: 0.1834366\ttotal: 33.2s\tremaining: 29.3s\n",
      "531:\tlearn: 0.1833580\ttotal: 33.2s\tremaining: 29.2s\n",
      "532:\tlearn: 0.1832792\ttotal: 33.3s\tremaining: 29.2s\n",
      "533:\tlearn: 0.1832065\ttotal: 33.3s\tremaining: 29.1s\n",
      "534:\tlearn: 0.1831257\ttotal: 33.4s\tremaining: 29s\n",
      "535:\tlearn: 0.1830406\ttotal: 33.5s\tremaining: 29s\n",
      "536:\tlearn: 0.1829686\ttotal: 33.5s\tremaining: 28.9s\n",
      "537:\tlearn: 0.1828853\ttotal: 33.6s\tremaining: 28.8s\n",
      "538:\tlearn: 0.1828106\ttotal: 33.7s\tremaining: 28.8s\n",
      "539:\tlearn: 0.1827235\ttotal: 33.7s\tremaining: 28.7s\n",
      "540:\tlearn: 0.1826469\ttotal: 33.8s\tremaining: 28.7s\n",
      "541:\tlearn: 0.1825680\ttotal: 33.8s\tremaining: 28.6s\n",
      "542:\tlearn: 0.1824897\ttotal: 33.9s\tremaining: 28.5s\n",
      "543:\tlearn: 0.1824148\ttotal: 34s\tremaining: 28.5s\n",
      "544:\tlearn: 0.1823484\ttotal: 34s\tremaining: 28.4s\n",
      "545:\tlearn: 0.1822689\ttotal: 34.1s\tremaining: 28.3s\n",
      "546:\tlearn: 0.1821949\ttotal: 34.1s\tremaining: 28.3s\n",
      "547:\tlearn: 0.1821165\ttotal: 34.2s\tremaining: 28.2s\n",
      "548:\tlearn: 0.1820432\ttotal: 34.3s\tremaining: 28.1s\n",
      "549:\tlearn: 0.1819702\ttotal: 34.3s\tremaining: 28.1s\n",
      "550:\tlearn: 0.1818848\ttotal: 34.4s\tremaining: 28s\n",
      "551:\tlearn: 0.1818123\ttotal: 34.4s\tremaining: 28s\n",
      "552:\tlearn: 0.1817407\ttotal: 34.5s\tremaining: 27.9s\n",
      "553:\tlearn: 0.1816663\ttotal: 34.6s\tremaining: 27.8s\n",
      "554:\tlearn: 0.1815989\ttotal: 34.6s\tremaining: 27.8s\n",
      "555:\tlearn: 0.1815134\ttotal: 34.7s\tremaining: 27.7s\n",
      "556:\tlearn: 0.1814295\ttotal: 34.7s\tremaining: 27.6s\n",
      "557:\tlearn: 0.1813634\ttotal: 34.8s\tremaining: 27.6s\n",
      "558:\tlearn: 0.1812917\ttotal: 34.9s\tremaining: 27.5s\n",
      "559:\tlearn: 0.1812031\ttotal: 34.9s\tremaining: 27.4s\n",
      "560:\tlearn: 0.1811271\ttotal: 35s\tremaining: 27.4s\n",
      "561:\tlearn: 0.1810476\ttotal: 35s\tremaining: 27.3s\n",
      "562:\tlearn: 0.1809720\ttotal: 35.1s\tremaining: 27.2s\n",
      "563:\tlearn: 0.1808939\ttotal: 35.2s\tremaining: 27.2s\n",
      "564:\tlearn: 0.1808118\ttotal: 35.2s\tremaining: 27.1s\n",
      "565:\tlearn: 0.1807353\ttotal: 35.3s\tremaining: 27.1s\n",
      "566:\tlearn: 0.1806595\ttotal: 35.3s\tremaining: 27s\n",
      "567:\tlearn: 0.1805725\ttotal: 35.4s\tremaining: 26.9s\n",
      "568:\tlearn: 0.1804952\ttotal: 35.5s\tremaining: 26.9s\n",
      "569:\tlearn: 0.1804188\ttotal: 35.5s\tremaining: 26.8s\n",
      "570:\tlearn: 0.1803415\ttotal: 35.6s\tremaining: 26.7s\n",
      "571:\tlearn: 0.1802642\ttotal: 35.7s\tremaining: 26.7s\n",
      "572:\tlearn: 0.1801878\ttotal: 35.7s\tremaining: 26.6s\n",
      "573:\tlearn: 0.1801261\ttotal: 35.8s\tremaining: 26.6s\n",
      "574:\tlearn: 0.1800446\ttotal: 35.9s\tremaining: 26.5s\n",
      "575:\tlearn: 0.1799635\ttotal: 35.9s\tremaining: 26.5s\n",
      "576:\tlearn: 0.1798985\ttotal: 36s\tremaining: 26.4s\n",
      "577:\tlearn: 0.1798192\ttotal: 36.1s\tremaining: 26.3s\n",
      "578:\tlearn: 0.1797413\ttotal: 36.1s\tremaining: 26.3s\n",
      "579:\tlearn: 0.1796687\ttotal: 36.2s\tremaining: 26.2s\n",
      "580:\tlearn: 0.1795956\ttotal: 36.2s\tremaining: 26.1s\n",
      "581:\tlearn: 0.1795234\ttotal: 36.3s\tremaining: 26.1s\n",
      "582:\tlearn: 0.1794509\ttotal: 36.4s\tremaining: 26s\n",
      "583:\tlearn: 0.1793808\ttotal: 36.4s\tremaining: 26s\n",
      "584:\tlearn: 0.1792927\ttotal: 36.5s\tremaining: 25.9s\n",
      "585:\tlearn: 0.1792260\ttotal: 36.5s\tremaining: 25.8s\n",
      "586:\tlearn: 0.1791450\ttotal: 36.6s\tremaining: 25.8s\n",
      "587:\tlearn: 0.1790671\ttotal: 36.7s\tremaining: 25.7s\n",
      "588:\tlearn: 0.1789998\ttotal: 36.7s\tremaining: 25.6s\n",
      "589:\tlearn: 0.1789241\ttotal: 36.8s\tremaining: 25.6s\n",
      "590:\tlearn: 0.1788481\ttotal: 36.8s\tremaining: 25.5s\n",
      "591:\tlearn: 0.1787867\ttotal: 36.9s\tremaining: 25.4s\n",
      "592:\tlearn: 0.1787105\ttotal: 37s\tremaining: 25.4s\n",
      "593:\tlearn: 0.1786283\ttotal: 37s\tremaining: 25.3s\n",
      "594:\tlearn: 0.1785626\ttotal: 37.1s\tremaining: 25.3s\n",
      "595:\tlearn: 0.1785019\ttotal: 37.2s\tremaining: 25.2s\n",
      "596:\tlearn: 0.1784291\ttotal: 37.2s\tremaining: 25.1s\n",
      "597:\tlearn: 0.1783577\ttotal: 37.3s\tremaining: 25.1s\n",
      "598:\tlearn: 0.1782795\ttotal: 37.4s\tremaining: 25s\n",
      "599:\tlearn: 0.1781989\ttotal: 37.5s\tremaining: 25s\n",
      "600:\tlearn: 0.1781406\ttotal: 37.5s\tremaining: 24.9s\n",
      "601:\tlearn: 0.1780628\ttotal: 37.6s\tremaining: 24.8s\n",
      "602:\tlearn: 0.1779821\ttotal: 37.6s\tremaining: 24.8s\n",
      "603:\tlearn: 0.1779067\ttotal: 37.7s\tremaining: 24.7s\n",
      "604:\tlearn: 0.1778272\ttotal: 37.8s\tremaining: 24.7s\n",
      "605:\tlearn: 0.1777536\ttotal: 37.8s\tremaining: 24.6s\n",
      "606:\tlearn: 0.1776724\ttotal: 37.9s\tremaining: 24.5s\n",
      "607:\tlearn: 0.1775965\ttotal: 38s\tremaining: 24.5s\n",
      "608:\tlearn: 0.1775295\ttotal: 38s\tremaining: 24.4s\n",
      "609:\tlearn: 0.1774645\ttotal: 38.1s\tremaining: 24.3s\n",
      "610:\tlearn: 0.1773854\ttotal: 38.1s\tremaining: 24.3s\n",
      "611:\tlearn: 0.1773158\ttotal: 38.2s\tremaining: 24.2s\n",
      "612:\tlearn: 0.1772389\ttotal: 38.3s\tremaining: 24.2s\n",
      "613:\tlearn: 0.1771558\ttotal: 38.4s\tremaining: 24.1s\n",
      "614:\tlearn: 0.1770834\ttotal: 38.4s\tremaining: 24.1s\n",
      "615:\tlearn: 0.1770217\ttotal: 38.5s\tremaining: 24s\n",
      "616:\tlearn: 0.1769642\ttotal: 38.5s\tremaining: 23.9s\n",
      "617:\tlearn: 0.1768953\ttotal: 38.6s\tremaining: 23.9s\n",
      "618:\tlearn: 0.1768235\ttotal: 38.7s\tremaining: 23.8s\n",
      "619:\tlearn: 0.1767553\ttotal: 38.7s\tremaining: 23.7s\n",
      "620:\tlearn: 0.1766761\ttotal: 38.8s\tremaining: 23.7s\n",
      "621:\tlearn: 0.1765993\ttotal: 38.9s\tremaining: 23.6s\n",
      "622:\tlearn: 0.1765298\ttotal: 38.9s\tremaining: 23.6s\n",
      "623:\tlearn: 0.1764523\ttotal: 39s\tremaining: 23.5s\n",
      "624:\tlearn: 0.1763785\ttotal: 39s\tremaining: 23.4s\n",
      "625:\tlearn: 0.1763190\ttotal: 39.1s\tremaining: 23.4s\n",
      "626:\tlearn: 0.1762485\ttotal: 39.2s\tremaining: 23.3s\n",
      "627:\tlearn: 0.1761811\ttotal: 39.2s\tremaining: 23.2s\n",
      "628:\tlearn: 0.1761153\ttotal: 39.3s\tremaining: 23.2s\n",
      "629:\tlearn: 0.1760424\ttotal: 39.4s\tremaining: 23.1s\n",
      "630:\tlearn: 0.1759693\ttotal: 39.4s\tremaining: 23.1s\n",
      "631:\tlearn: 0.1759117\ttotal: 39.5s\tremaining: 23s\n",
      "632:\tlearn: 0.1758365\ttotal: 39.6s\tremaining: 22.9s\n",
      "633:\tlearn: 0.1757695\ttotal: 39.6s\tremaining: 22.9s\n",
      "634:\tlearn: 0.1757057\ttotal: 39.7s\tremaining: 22.8s\n",
      "635:\tlearn: 0.1756196\ttotal: 39.8s\tremaining: 22.8s\n",
      "636:\tlearn: 0.1755401\ttotal: 39.8s\tremaining: 22.7s\n",
      "637:\tlearn: 0.1754667\ttotal: 39.9s\tremaining: 22.6s\n",
      "638:\tlearn: 0.1753919\ttotal: 40s\tremaining: 22.6s\n",
      "639:\tlearn: 0.1753149\ttotal: 40s\tremaining: 22.5s\n",
      "640:\tlearn: 0.1752515\ttotal: 40.1s\tremaining: 22.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "641:\tlearn: 0.1751848\ttotal: 40.2s\tremaining: 22.4s\n",
      "642:\tlearn: 0.1751114\ttotal: 40.2s\tremaining: 22.3s\n",
      "643:\tlearn: 0.1750366\ttotal: 40.3s\tremaining: 22.3s\n",
      "644:\tlearn: 0.1749602\ttotal: 40.4s\tremaining: 22.2s\n",
      "645:\tlearn: 0.1748903\ttotal: 40.4s\tremaining: 22.2s\n",
      "646:\tlearn: 0.1748192\ttotal: 40.5s\tremaining: 22.1s\n",
      "647:\tlearn: 0.1747440\ttotal: 40.6s\tremaining: 22s\n",
      "648:\tlearn: 0.1746884\ttotal: 40.6s\tremaining: 22s\n",
      "649:\tlearn: 0.1746259\ttotal: 40.7s\tremaining: 21.9s\n",
      "650:\tlearn: 0.1745734\ttotal: 40.7s\tremaining: 21.8s\n",
      "651:\tlearn: 0.1745134\ttotal: 40.8s\tremaining: 21.8s\n",
      "652:\tlearn: 0.1744416\ttotal: 40.9s\tremaining: 21.7s\n",
      "653:\tlearn: 0.1743679\ttotal: 40.9s\tremaining: 21.6s\n",
      "654:\tlearn: 0.1742949\ttotal: 41s\tremaining: 21.6s\n",
      "655:\tlearn: 0.1742346\ttotal: 41s\tremaining: 21.5s\n",
      "656:\tlearn: 0.1741609\ttotal: 41.1s\tremaining: 21.5s\n",
      "657:\tlearn: 0.1741089\ttotal: 41.2s\tremaining: 21.4s\n",
      "658:\tlearn: 0.1740361\ttotal: 41.2s\tremaining: 21.3s\n",
      "659:\tlearn: 0.1739805\ttotal: 41.3s\tremaining: 21.3s\n",
      "660:\tlearn: 0.1739152\ttotal: 41.4s\tremaining: 21.2s\n",
      "661:\tlearn: 0.1738511\ttotal: 41.4s\tremaining: 21.1s\n",
      "662:\tlearn: 0.1737863\ttotal: 41.5s\tremaining: 21.1s\n",
      "663:\tlearn: 0.1737051\ttotal: 41.5s\tremaining: 21s\n",
      "664:\tlearn: 0.1736360\ttotal: 41.6s\tremaining: 21s\n",
      "665:\tlearn: 0.1735764\ttotal: 41.7s\tremaining: 20.9s\n",
      "666:\tlearn: 0.1735109\ttotal: 41.7s\tremaining: 20.8s\n",
      "667:\tlearn: 0.1734519\ttotal: 41.8s\tremaining: 20.8s\n",
      "668:\tlearn: 0.1733938\ttotal: 41.9s\tremaining: 20.7s\n",
      "669:\tlearn: 0.1733213\ttotal: 41.9s\tremaining: 20.7s\n",
      "670:\tlearn: 0.1732517\ttotal: 42s\tremaining: 20.6s\n",
      "671:\tlearn: 0.1731781\ttotal: 42.1s\tremaining: 20.5s\n",
      "672:\tlearn: 0.1731119\ttotal: 42.1s\tremaining: 20.5s\n",
      "673:\tlearn: 0.1730580\ttotal: 42.2s\tremaining: 20.4s\n",
      "674:\tlearn: 0.1729874\ttotal: 42.3s\tremaining: 20.3s\n",
      "675:\tlearn: 0.1729244\ttotal: 42.3s\tremaining: 20.3s\n",
      "676:\tlearn: 0.1728625\ttotal: 42.4s\tremaining: 20.2s\n",
      "677:\tlearn: 0.1727961\ttotal: 42.4s\tremaining: 20.2s\n",
      "678:\tlearn: 0.1727272\ttotal: 42.5s\tremaining: 20.1s\n",
      "679:\tlearn: 0.1726552\ttotal: 42.6s\tremaining: 20s\n",
      "680:\tlearn: 0.1725807\ttotal: 42.6s\tremaining: 20s\n",
      "681:\tlearn: 0.1725182\ttotal: 42.7s\tremaining: 19.9s\n",
      "682:\tlearn: 0.1724531\ttotal: 42.7s\tremaining: 19.8s\n",
      "683:\tlearn: 0.1723962\ttotal: 42.8s\tremaining: 19.8s\n",
      "684:\tlearn: 0.1723423\ttotal: 42.8s\tremaining: 19.7s\n",
      "685:\tlearn: 0.1722816\ttotal: 42.9s\tremaining: 19.6s\n",
      "686:\tlearn: 0.1722090\ttotal: 43s\tremaining: 19.6s\n",
      "687:\tlearn: 0.1721428\ttotal: 43s\tremaining: 19.5s\n",
      "688:\tlearn: 0.1720794\ttotal: 43.1s\tremaining: 19.4s\n",
      "689:\tlearn: 0.1720114\ttotal: 43.1s\tremaining: 19.4s\n",
      "690:\tlearn: 0.1719308\ttotal: 43.2s\tremaining: 19.3s\n",
      "691:\tlearn: 0.1718844\ttotal: 43.3s\tremaining: 19.3s\n",
      "692:\tlearn: 0.1718091\ttotal: 43.4s\tremaining: 19.2s\n",
      "693:\tlearn: 0.1717520\ttotal: 43.4s\tremaining: 19.1s\n",
      "694:\tlearn: 0.1716994\ttotal: 43.5s\tremaining: 19.1s\n",
      "695:\tlearn: 0.1716349\ttotal: 43.6s\tremaining: 19s\n",
      "696:\tlearn: 0.1715788\ttotal: 43.6s\tremaining: 19s\n",
      "697:\tlearn: 0.1715221\ttotal: 43.7s\tremaining: 18.9s\n",
      "698:\tlearn: 0.1714564\ttotal: 43.8s\tremaining: 18.8s\n",
      "699:\tlearn: 0.1713894\ttotal: 43.8s\tremaining: 18.8s\n",
      "700:\tlearn: 0.1713315\ttotal: 43.9s\tremaining: 18.7s\n",
      "701:\tlearn: 0.1712657\ttotal: 44s\tremaining: 18.7s\n",
      "702:\tlearn: 0.1712143\ttotal: 44s\tremaining: 18.6s\n",
      "703:\tlearn: 0.1711578\ttotal: 44.1s\tremaining: 18.5s\n",
      "704:\tlearn: 0.1711031\ttotal: 44.2s\tremaining: 18.5s\n",
      "705:\tlearn: 0.1710282\ttotal: 44.3s\tremaining: 18.4s\n",
      "706:\tlearn: 0.1709651\ttotal: 44.3s\tremaining: 18.4s\n",
      "707:\tlearn: 0.1709079\ttotal: 44.4s\tremaining: 18.3s\n",
      "708:\tlearn: 0.1708523\ttotal: 44.4s\tremaining: 18.2s\n",
      "709:\tlearn: 0.1707977\ttotal: 44.5s\tremaining: 18.2s\n",
      "710:\tlearn: 0.1707326\ttotal: 44.6s\tremaining: 18.1s\n",
      "711:\tlearn: 0.1706704\ttotal: 44.7s\tremaining: 18.1s\n",
      "712:\tlearn: 0.1706127\ttotal: 44.7s\tremaining: 18s\n",
      "713:\tlearn: 0.1705484\ttotal: 44.8s\tremaining: 17.9s\n",
      "714:\tlearn: 0.1704822\ttotal: 44.9s\tremaining: 17.9s\n",
      "715:\tlearn: 0.1704152\ttotal: 44.9s\tremaining: 17.8s\n",
      "716:\tlearn: 0.1703445\ttotal: 45s\tremaining: 17.8s\n",
      "717:\tlearn: 0.1702785\ttotal: 45.1s\tremaining: 17.7s\n",
      "718:\tlearn: 0.1702186\ttotal: 45.1s\tremaining: 17.6s\n",
      "719:\tlearn: 0.1701541\ttotal: 45.2s\tremaining: 17.6s\n",
      "720:\tlearn: 0.1700822\ttotal: 45.3s\tremaining: 17.5s\n",
      "721:\tlearn: 0.1700251\ttotal: 45.4s\tremaining: 17.5s\n",
      "722:\tlearn: 0.1699676\ttotal: 45.4s\tremaining: 17.4s\n",
      "723:\tlearn: 0.1699014\ttotal: 45.5s\tremaining: 17.3s\n",
      "724:\tlearn: 0.1698319\ttotal: 45.6s\tremaining: 17.3s\n",
      "725:\tlearn: 0.1697781\ttotal: 45.6s\tremaining: 17.2s\n",
      "726:\tlearn: 0.1697124\ttotal: 45.7s\tremaining: 17.2s\n",
      "727:\tlearn: 0.1696373\ttotal: 45.8s\tremaining: 17.1s\n",
      "728:\tlearn: 0.1695743\ttotal: 45.8s\tremaining: 17s\n",
      "729:\tlearn: 0.1695151\ttotal: 45.9s\tremaining: 17s\n",
      "730:\tlearn: 0.1694586\ttotal: 46s\tremaining: 16.9s\n",
      "731:\tlearn: 0.1693905\ttotal: 46s\tremaining: 16.9s\n",
      "732:\tlearn: 0.1693351\ttotal: 46.1s\tremaining: 16.8s\n",
      "733:\tlearn: 0.1692723\ttotal: 46.2s\tremaining: 16.7s\n",
      "734:\tlearn: 0.1692083\ttotal: 46.2s\tremaining: 16.7s\n",
      "735:\tlearn: 0.1691459\ttotal: 46.3s\tremaining: 16.6s\n",
      "736:\tlearn: 0.1690708\ttotal: 46.4s\tremaining: 16.6s\n",
      "737:\tlearn: 0.1690071\ttotal: 46.4s\tremaining: 16.5s\n",
      "738:\tlearn: 0.1689370\ttotal: 46.5s\tremaining: 16.4s\n",
      "739:\tlearn: 0.1688861\ttotal: 46.6s\tremaining: 16.4s\n",
      "740:\tlearn: 0.1688184\ttotal: 46.7s\tremaining: 16.3s\n",
      "741:\tlearn: 0.1687547\ttotal: 46.7s\tremaining: 16.2s\n",
      "742:\tlearn: 0.1687078\ttotal: 46.8s\tremaining: 16.2s\n",
      "743:\tlearn: 0.1686501\ttotal: 46.9s\tremaining: 16.1s\n",
      "744:\tlearn: 0.1685890\ttotal: 47s\tremaining: 16.1s\n",
      "745:\tlearn: 0.1685310\ttotal: 47s\tremaining: 16s\n",
      "746:\tlearn: 0.1684824\ttotal: 47.1s\tremaining: 15.9s\n",
      "747:\tlearn: 0.1684070\ttotal: 47.2s\tremaining: 15.9s\n",
      "748:\tlearn: 0.1683534\ttotal: 47.2s\tremaining: 15.8s\n",
      "749:\tlearn: 0.1682949\ttotal: 47.3s\tremaining: 15.8s\n",
      "750:\tlearn: 0.1682289\ttotal: 47.4s\tremaining: 15.7s\n",
      "751:\tlearn: 0.1681657\ttotal: 47.4s\tremaining: 15.6s\n",
      "752:\tlearn: 0.1681023\ttotal: 47.5s\tremaining: 15.6s\n",
      "753:\tlearn: 0.1680352\ttotal: 47.6s\tremaining: 15.5s\n",
      "754:\tlearn: 0.1679793\ttotal: 47.6s\tremaining: 15.5s\n",
      "755:\tlearn: 0.1679068\ttotal: 47.7s\tremaining: 15.4s\n",
      "756:\tlearn: 0.1678432\ttotal: 47.8s\tremaining: 15.3s\n",
      "757:\tlearn: 0.1677845\ttotal: 47.9s\tremaining: 15.3s\n",
      "758:\tlearn: 0.1677214\ttotal: 47.9s\tremaining: 15.2s\n",
      "759:\tlearn: 0.1676585\ttotal: 48s\tremaining: 15.2s\n",
      "760:\tlearn: 0.1675904\ttotal: 48.1s\tremaining: 15.1s\n",
      "761:\tlearn: 0.1675296\ttotal: 48.1s\tremaining: 15s\n",
      "762:\tlearn: 0.1674710\ttotal: 48.2s\tremaining: 15s\n",
      "763:\tlearn: 0.1674114\ttotal: 48.3s\tremaining: 14.9s\n",
      "764:\tlearn: 0.1673433\ttotal: 48.4s\tremaining: 14.9s\n",
      "765:\tlearn: 0.1672759\ttotal: 48.4s\tremaining: 14.8s\n",
      "766:\tlearn: 0.1672175\ttotal: 48.5s\tremaining: 14.7s\n",
      "767:\tlearn: 0.1671521\ttotal: 48.6s\tremaining: 14.7s\n",
      "768:\tlearn: 0.1670914\ttotal: 48.6s\tremaining: 14.6s\n",
      "769:\tlearn: 0.1670357\ttotal: 48.7s\tremaining: 14.5s\n",
      "770:\tlearn: 0.1669752\ttotal: 48.8s\tremaining: 14.5s\n",
      "771:\tlearn: 0.1669218\ttotal: 48.8s\tremaining: 14.4s\n",
      "772:\tlearn: 0.1668606\ttotal: 48.9s\tremaining: 14.4s\n",
      "773:\tlearn: 0.1668023\ttotal: 49s\tremaining: 14.3s\n",
      "774:\tlearn: 0.1667486\ttotal: 49s\tremaining: 14.2s\n",
      "775:\tlearn: 0.1666878\ttotal: 49.1s\tremaining: 14.2s\n",
      "776:\tlearn: 0.1666240\ttotal: 49.2s\tremaining: 14.1s\n",
      "777:\tlearn: 0.1665687\ttotal: 49.2s\tremaining: 14.1s\n",
      "778:\tlearn: 0.1665059\ttotal: 49.3s\tremaining: 14s\n",
      "779:\tlearn: 0.1664629\ttotal: 49.4s\tremaining: 13.9s\n",
      "780:\tlearn: 0.1663872\ttotal: 49.5s\tremaining: 13.9s\n",
      "781:\tlearn: 0.1663219\ttotal: 49.5s\tremaining: 13.8s\n",
      "782:\tlearn: 0.1662594\ttotal: 49.6s\tremaining: 13.7s\n",
      "783:\tlearn: 0.1662064\ttotal: 49.7s\tremaining: 13.7s\n",
      "784:\tlearn: 0.1661464\ttotal: 49.7s\tremaining: 13.6s\n",
      "785:\tlearn: 0.1661015\ttotal: 49.8s\tremaining: 13.6s\n",
      "786:\tlearn: 0.1660472\ttotal: 49.8s\tremaining: 13.5s\n",
      "787:\tlearn: 0.1659914\ttotal: 49.9s\tremaining: 13.4s\n",
      "788:\tlearn: 0.1659328\ttotal: 50s\tremaining: 13.4s\n",
      "789:\tlearn: 0.1658889\ttotal: 50s\tremaining: 13.3s\n",
      "790:\tlearn: 0.1658240\ttotal: 50.1s\tremaining: 13.2s\n",
      "791:\tlearn: 0.1657672\ttotal: 50.1s\tremaining: 13.2s\n",
      "792:\tlearn: 0.1657083\ttotal: 50.2s\tremaining: 13.1s\n",
      "793:\tlearn: 0.1656399\ttotal: 50.3s\tremaining: 13s\n",
      "794:\tlearn: 0.1655961\ttotal: 50.3s\tremaining: 13s\n",
      "795:\tlearn: 0.1655305\ttotal: 50.4s\tremaining: 12.9s\n",
      "796:\tlearn: 0.1654641\ttotal: 50.5s\tremaining: 12.9s\n",
      "797:\tlearn: 0.1653951\ttotal: 50.5s\tremaining: 12.8s\n",
      "798:\tlearn: 0.1653403\ttotal: 50.6s\tremaining: 12.7s\n",
      "799:\tlearn: 0.1652710\ttotal: 50.7s\tremaining: 12.7s\n",
      "800:\tlearn: 0.1652071\ttotal: 50.7s\tremaining: 12.6s\n",
      "801:\tlearn: 0.1651542\ttotal: 50.8s\tremaining: 12.5s\n",
      "802:\tlearn: 0.1650934\ttotal: 50.8s\tremaining: 12.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "803:\tlearn: 0.1650294\ttotal: 50.9s\tremaining: 12.4s\n",
      "804:\tlearn: 0.1649712\ttotal: 51s\tremaining: 12.3s\n",
      "805:\tlearn: 0.1649169\ttotal: 51s\tremaining: 12.3s\n",
      "806:\tlearn: 0.1648573\ttotal: 51.1s\tremaining: 12.2s\n",
      "807:\tlearn: 0.1647884\ttotal: 51.2s\tremaining: 12.2s\n",
      "808:\tlearn: 0.1647278\ttotal: 51.3s\tremaining: 12.1s\n",
      "809:\tlearn: 0.1646707\ttotal: 51.3s\tremaining: 12s\n",
      "810:\tlearn: 0.1646068\ttotal: 51.4s\tremaining: 12s\n",
      "811:\tlearn: 0.1645607\ttotal: 51.5s\tremaining: 11.9s\n",
      "812:\tlearn: 0.1645031\ttotal: 51.5s\tremaining: 11.9s\n",
      "813:\tlearn: 0.1644493\ttotal: 51.6s\tremaining: 11.8s\n",
      "814:\tlearn: 0.1644056\ttotal: 51.7s\tremaining: 11.7s\n",
      "815:\tlearn: 0.1643498\ttotal: 51.8s\tremaining: 11.7s\n",
      "816:\tlearn: 0.1642974\ttotal: 51.8s\tremaining: 11.6s\n",
      "817:\tlearn: 0.1642404\ttotal: 51.9s\tremaining: 11.5s\n",
      "818:\tlearn: 0.1641956\ttotal: 51.9s\tremaining: 11.5s\n",
      "819:\tlearn: 0.1641401\ttotal: 52s\tremaining: 11.4s\n",
      "820:\tlearn: 0.1641047\ttotal: 52.1s\tremaining: 11.4s\n",
      "821:\tlearn: 0.1640469\ttotal: 52.1s\tremaining: 11.3s\n",
      "822:\tlearn: 0.1639801\ttotal: 52.2s\tremaining: 11.2s\n",
      "823:\tlearn: 0.1639221\ttotal: 52.3s\tremaining: 11.2s\n",
      "824:\tlearn: 0.1638595\ttotal: 52.3s\tremaining: 11.1s\n",
      "825:\tlearn: 0.1638029\ttotal: 52.4s\tremaining: 11s\n",
      "826:\tlearn: 0.1637487\ttotal: 52.5s\tremaining: 11s\n",
      "827:\tlearn: 0.1637109\ttotal: 52.5s\tremaining: 10.9s\n",
      "828:\tlearn: 0.1636407\ttotal: 52.6s\tremaining: 10.8s\n",
      "829:\tlearn: 0.1635871\ttotal: 52.6s\tremaining: 10.8s\n",
      "830:\tlearn: 0.1635427\ttotal: 52.7s\tremaining: 10.7s\n",
      "831:\tlearn: 0.1634919\ttotal: 52.8s\tremaining: 10.7s\n",
      "832:\tlearn: 0.1634383\ttotal: 52.8s\tremaining: 10.6s\n",
      "833:\tlearn: 0.1633772\ttotal: 52.9s\tremaining: 10.5s\n",
      "834:\tlearn: 0.1633275\ttotal: 52.9s\tremaining: 10.5s\n",
      "835:\tlearn: 0.1632755\ttotal: 53s\tremaining: 10.4s\n",
      "836:\tlearn: 0.1632208\ttotal: 53s\tremaining: 10.3s\n",
      "837:\tlearn: 0.1631547\ttotal: 53.1s\tremaining: 10.3s\n",
      "838:\tlearn: 0.1630947\ttotal: 53.2s\tremaining: 10.2s\n",
      "839:\tlearn: 0.1630409\ttotal: 53.2s\tremaining: 10.1s\n",
      "840:\tlearn: 0.1629735\ttotal: 53.3s\tremaining: 10.1s\n",
      "841:\tlearn: 0.1629081\ttotal: 53.4s\tremaining: 10s\n",
      "842:\tlearn: 0.1628589\ttotal: 53.4s\tremaining: 9.95s\n",
      "843:\tlearn: 0.1628036\ttotal: 53.5s\tremaining: 9.89s\n",
      "844:\tlearn: 0.1627517\ttotal: 53.6s\tremaining: 9.82s\n",
      "845:\tlearn: 0.1626932\ttotal: 53.6s\tremaining: 9.76s\n",
      "846:\tlearn: 0.1626304\ttotal: 53.7s\tremaining: 9.7s\n",
      "847:\tlearn: 0.1625736\ttotal: 53.8s\tremaining: 9.64s\n",
      "848:\tlearn: 0.1625130\ttotal: 53.8s\tremaining: 9.57s\n",
      "849:\tlearn: 0.1624569\ttotal: 53.9s\tremaining: 9.51s\n",
      "850:\tlearn: 0.1624079\ttotal: 53.9s\tremaining: 9.44s\n",
      "851:\tlearn: 0.1623532\ttotal: 54s\tremaining: 9.38s\n",
      "852:\tlearn: 0.1622964\ttotal: 54.1s\tremaining: 9.32s\n",
      "853:\tlearn: 0.1622325\ttotal: 54.1s\tremaining: 9.26s\n",
      "854:\tlearn: 0.1621742\ttotal: 54.2s\tremaining: 9.19s\n",
      "855:\tlearn: 0.1621111\ttotal: 54.3s\tremaining: 9.13s\n",
      "856:\tlearn: 0.1620547\ttotal: 54.3s\tremaining: 9.07s\n",
      "857:\tlearn: 0.1619909\ttotal: 54.4s\tremaining: 9s\n",
      "858:\tlearn: 0.1619330\ttotal: 54.5s\tremaining: 8.94s\n",
      "859:\tlearn: 0.1618678\ttotal: 54.5s\tremaining: 8.88s\n",
      "860:\tlearn: 0.1618253\ttotal: 54.6s\tremaining: 8.81s\n",
      "861:\tlearn: 0.1617707\ttotal: 54.6s\tremaining: 8.74s\n",
      "862:\tlearn: 0.1617127\ttotal: 54.7s\tremaining: 8.68s\n",
      "863:\tlearn: 0.1616547\ttotal: 54.7s\tremaining: 8.62s\n",
      "864:\tlearn: 0.1615947\ttotal: 54.8s\tremaining: 8.55s\n",
      "865:\tlearn: 0.1615361\ttotal: 54.9s\tremaining: 8.49s\n",
      "866:\tlearn: 0.1614758\ttotal: 54.9s\tremaining: 8.43s\n",
      "867:\tlearn: 0.1614277\ttotal: 55s\tremaining: 8.36s\n",
      "868:\tlearn: 0.1613849\ttotal: 55s\tremaining: 8.3s\n",
      "869:\tlearn: 0.1613203\ttotal: 55.1s\tremaining: 8.23s\n",
      "870:\tlearn: 0.1612602\ttotal: 55.2s\tremaining: 8.17s\n",
      "871:\tlearn: 0.1612025\ttotal: 55.2s\tremaining: 8.11s\n",
      "872:\tlearn: 0.1611423\ttotal: 55.3s\tremaining: 8.04s\n",
      "873:\tlearn: 0.1610877\ttotal: 55.4s\tremaining: 7.98s\n",
      "874:\tlearn: 0.1610366\ttotal: 55.4s\tremaining: 7.92s\n",
      "875:\tlearn: 0.1609939\ttotal: 55.5s\tremaining: 7.85s\n",
      "876:\tlearn: 0.1609366\ttotal: 55.6s\tremaining: 7.79s\n",
      "877:\tlearn: 0.1608845\ttotal: 55.6s\tremaining: 7.73s\n",
      "878:\tlearn: 0.1608191\ttotal: 55.7s\tremaining: 7.67s\n",
      "879:\tlearn: 0.1607461\ttotal: 55.8s\tremaining: 7.61s\n",
      "880:\tlearn: 0.1606899\ttotal: 55.8s\tremaining: 7.54s\n",
      "881:\tlearn: 0.1606400\ttotal: 55.9s\tremaining: 7.48s\n",
      "882:\tlearn: 0.1605969\ttotal: 56s\tremaining: 7.42s\n",
      "883:\tlearn: 0.1605583\ttotal: 56s\tremaining: 7.35s\n",
      "884:\tlearn: 0.1605116\ttotal: 56.1s\tremaining: 7.29s\n",
      "885:\tlearn: 0.1604620\ttotal: 56.1s\tremaining: 7.22s\n",
      "886:\tlearn: 0.1604066\ttotal: 56.2s\tremaining: 7.16s\n",
      "887:\tlearn: 0.1603472\ttotal: 56.3s\tremaining: 7.1s\n",
      "888:\tlearn: 0.1602977\ttotal: 56.3s\tremaining: 7.03s\n",
      "889:\tlearn: 0.1602431\ttotal: 56.4s\tremaining: 6.97s\n",
      "890:\tlearn: 0.1601755\ttotal: 56.4s\tremaining: 6.91s\n",
      "891:\tlearn: 0.1601091\ttotal: 56.5s\tremaining: 6.84s\n",
      "892:\tlearn: 0.1600642\ttotal: 56.6s\tremaining: 6.78s\n",
      "893:\tlearn: 0.1600107\ttotal: 56.6s\tremaining: 6.71s\n",
      "894:\tlearn: 0.1599577\ttotal: 56.7s\tremaining: 6.65s\n",
      "895:\tlearn: 0.1599013\ttotal: 56.7s\tremaining: 6.58s\n",
      "896:\tlearn: 0.1598661\ttotal: 56.8s\tremaining: 6.52s\n",
      "897:\tlearn: 0.1598049\ttotal: 56.9s\tremaining: 6.46s\n",
      "898:\tlearn: 0.1597572\ttotal: 56.9s\tremaining: 6.39s\n",
      "899:\tlearn: 0.1596864\ttotal: 57s\tremaining: 6.33s\n",
      "900:\tlearn: 0.1596235\ttotal: 57s\tremaining: 6.27s\n",
      "901:\tlearn: 0.1595692\ttotal: 57.1s\tremaining: 6.2s\n",
      "902:\tlearn: 0.1595113\ttotal: 57.2s\tremaining: 6.14s\n",
      "903:\tlearn: 0.1594684\ttotal: 57.2s\tremaining: 6.08s\n",
      "904:\tlearn: 0.1594164\ttotal: 57.3s\tremaining: 6.01s\n",
      "905:\tlearn: 0.1593593\ttotal: 57.3s\tremaining: 5.95s\n",
      "906:\tlearn: 0.1593104\ttotal: 57.4s\tremaining: 5.88s\n",
      "907:\tlearn: 0.1592505\ttotal: 57.5s\tremaining: 5.82s\n",
      "908:\tlearn: 0.1591979\ttotal: 57.5s\tremaining: 5.76s\n",
      "909:\tlearn: 0.1591589\ttotal: 57.6s\tremaining: 5.69s\n",
      "910:\tlearn: 0.1590980\ttotal: 57.6s\tremaining: 5.63s\n",
      "911:\tlearn: 0.1590694\ttotal: 57.7s\tremaining: 5.57s\n",
      "912:\tlearn: 0.1590216\ttotal: 57.8s\tremaining: 5.5s\n",
      "913:\tlearn: 0.1589753\ttotal: 57.8s\tremaining: 5.44s\n",
      "914:\tlearn: 0.1589248\ttotal: 57.9s\tremaining: 5.38s\n",
      "915:\tlearn: 0.1588706\ttotal: 57.9s\tremaining: 5.31s\n",
      "916:\tlearn: 0.1588250\ttotal: 58s\tremaining: 5.25s\n",
      "917:\tlearn: 0.1587670\ttotal: 58.1s\tremaining: 5.19s\n",
      "918:\tlearn: 0.1587058\ttotal: 58.1s\tremaining: 5.12s\n",
      "919:\tlearn: 0.1586456\ttotal: 58.2s\tremaining: 5.06s\n",
      "920:\tlearn: 0.1585911\ttotal: 58.2s\tremaining: 5s\n",
      "921:\tlearn: 0.1585345\ttotal: 58.3s\tremaining: 4.93s\n",
      "922:\tlearn: 0.1584939\ttotal: 58.4s\tremaining: 4.87s\n",
      "923:\tlearn: 0.1584401\ttotal: 58.4s\tremaining: 4.81s\n",
      "924:\tlearn: 0.1584011\ttotal: 58.5s\tremaining: 4.74s\n",
      "925:\tlearn: 0.1583562\ttotal: 58.6s\tremaining: 4.68s\n",
      "926:\tlearn: 0.1583017\ttotal: 58.6s\tremaining: 4.62s\n",
      "927:\tlearn: 0.1582554\ttotal: 58.7s\tremaining: 4.55s\n",
      "928:\tlearn: 0.1582093\ttotal: 58.8s\tremaining: 4.49s\n",
      "929:\tlearn: 0.1581502\ttotal: 58.8s\tremaining: 4.43s\n",
      "930:\tlearn: 0.1580871\ttotal: 58.9s\tremaining: 4.37s\n",
      "931:\tlearn: 0.1580338\ttotal: 59s\tremaining: 4.3s\n",
      "932:\tlearn: 0.1579756\ttotal: 59s\tremaining: 4.24s\n",
      "933:\tlearn: 0.1579217\ttotal: 59.1s\tremaining: 4.17s\n",
      "934:\tlearn: 0.1578784\ttotal: 59.1s\tremaining: 4.11s\n",
      "935:\tlearn: 0.1578374\ttotal: 59.2s\tremaining: 4.05s\n",
      "936:\tlearn: 0.1577821\ttotal: 59.3s\tremaining: 3.98s\n",
      "937:\tlearn: 0.1577283\ttotal: 59.3s\tremaining: 3.92s\n",
      "938:\tlearn: 0.1576826\ttotal: 59.4s\tremaining: 3.86s\n",
      "939:\tlearn: 0.1576244\ttotal: 59.4s\tremaining: 3.79s\n",
      "940:\tlearn: 0.1575767\ttotal: 59.5s\tremaining: 3.73s\n",
      "941:\tlearn: 0.1575266\ttotal: 59.6s\tremaining: 3.67s\n",
      "942:\tlearn: 0.1574778\ttotal: 59.6s\tremaining: 3.6s\n",
      "943:\tlearn: 0.1574323\ttotal: 59.7s\tremaining: 3.54s\n",
      "944:\tlearn: 0.1573986\ttotal: 59.7s\tremaining: 3.48s\n",
      "945:\tlearn: 0.1573550\ttotal: 59.8s\tremaining: 3.41s\n",
      "946:\tlearn: 0.1573053\ttotal: 59.9s\tremaining: 3.35s\n",
      "947:\tlearn: 0.1572518\ttotal: 59.9s\tremaining: 3.29s\n",
      "948:\tlearn: 0.1571905\ttotal: 1m\tremaining: 3.23s\n",
      "949:\tlearn: 0.1571462\ttotal: 1m\tremaining: 3.16s\n",
      "950:\tlearn: 0.1571039\ttotal: 1m\tremaining: 3.1s\n",
      "951:\tlearn: 0.1570502\ttotal: 1m\tremaining: 3.04s\n",
      "952:\tlearn: 0.1569984\ttotal: 1m\tremaining: 2.97s\n",
      "953:\tlearn: 0.1569517\ttotal: 1m\tremaining: 2.91s\n",
      "954:\tlearn: 0.1568924\ttotal: 1m\tremaining: 2.85s\n",
      "955:\tlearn: 0.1568355\ttotal: 1m\tremaining: 2.78s\n",
      "956:\tlearn: 0.1567969\ttotal: 1m\tremaining: 2.72s\n",
      "957:\tlearn: 0.1567528\ttotal: 1m\tremaining: 2.65s\n",
      "958:\tlearn: 0.1567023\ttotal: 1m\tremaining: 2.59s\n",
      "959:\tlearn: 0.1566448\ttotal: 1m\tremaining: 2.53s\n",
      "960:\tlearn: 0.1565992\ttotal: 1m\tremaining: 2.46s\n",
      "961:\tlearn: 0.1565449\ttotal: 1m\tremaining: 2.4s\n",
      "962:\tlearn: 0.1564868\ttotal: 1m\tremaining: 2.34s\n",
      "963:\tlearn: 0.1564312\ttotal: 1m\tremaining: 2.28s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "964:\tlearn: 0.1563915\ttotal: 1m 1s\tremaining: 2.21s\n",
      "965:\tlearn: 0.1563357\ttotal: 1m 1s\tremaining: 2.15s\n",
      "966:\tlearn: 0.1562816\ttotal: 1m 1s\tremaining: 2.09s\n",
      "967:\tlearn: 0.1562279\ttotal: 1m 1s\tremaining: 2.02s\n",
      "968:\tlearn: 0.1561837\ttotal: 1m 1s\tremaining: 1.96s\n",
      "969:\tlearn: 0.1561251\ttotal: 1m 1s\tremaining: 1.9s\n",
      "970:\tlearn: 0.1560741\ttotal: 1m 1s\tremaining: 1.83s\n",
      "971:\tlearn: 0.1560242\ttotal: 1m 1s\tremaining: 1.77s\n",
      "972:\tlearn: 0.1559806\ttotal: 1m 1s\tremaining: 1.71s\n",
      "973:\tlearn: 0.1559325\ttotal: 1m 1s\tremaining: 1.65s\n",
      "974:\tlearn: 0.1558800\ttotal: 1m 1s\tremaining: 1.58s\n",
      "975:\tlearn: 0.1558323\ttotal: 1m 1s\tremaining: 1.52s\n",
      "976:\tlearn: 0.1557812\ttotal: 1m 1s\tremaining: 1.46s\n",
      "977:\tlearn: 0.1557438\ttotal: 1m 1s\tremaining: 1.39s\n",
      "978:\tlearn: 0.1556971\ttotal: 1m 2s\tremaining: 1.33s\n",
      "979:\tlearn: 0.1556453\ttotal: 1m 2s\tremaining: 1.27s\n",
      "980:\tlearn: 0.1556008\ttotal: 1m 2s\tremaining: 1.2s\n",
      "981:\tlearn: 0.1555488\ttotal: 1m 2s\tremaining: 1.14s\n",
      "982:\tlearn: 0.1554950\ttotal: 1m 2s\tremaining: 1.08s\n",
      "983:\tlearn: 0.1554620\ttotal: 1m 2s\tremaining: 1.01s\n",
      "984:\tlearn: 0.1553957\ttotal: 1m 2s\tremaining: 951ms\n",
      "985:\tlearn: 0.1553562\ttotal: 1m 2s\tremaining: 887ms\n",
      "986:\tlearn: 0.1553014\ttotal: 1m 2s\tremaining: 824ms\n",
      "987:\tlearn: 0.1552472\ttotal: 1m 2s\tremaining: 761ms\n",
      "988:\tlearn: 0.1551935\ttotal: 1m 2s\tremaining: 697ms\n",
      "989:\tlearn: 0.1551393\ttotal: 1m 2s\tremaining: 634ms\n",
      "990:\tlearn: 0.1550797\ttotal: 1m 2s\tremaining: 571ms\n",
      "991:\tlearn: 0.1550133\ttotal: 1m 2s\tremaining: 507ms\n",
      "992:\tlearn: 0.1549726\ttotal: 1m 2s\tremaining: 444ms\n",
      "993:\tlearn: 0.1549224\ttotal: 1m 3s\tremaining: 380ms\n",
      "994:\tlearn: 0.1548707\ttotal: 1m 3s\tremaining: 317ms\n",
      "995:\tlearn: 0.1548233\ttotal: 1m 3s\tremaining: 254ms\n",
      "996:\tlearn: 0.1547815\ttotal: 1m 3s\tremaining: 190ms\n",
      "997:\tlearn: 0.1547359\ttotal: 1m 3s\tremaining: 127ms\n",
      "998:\tlearn: 0.1546929\ttotal: 1m 3s\tremaining: 63.4ms\n",
      "999:\tlearn: 0.1546365\ttotal: 1m 3s\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "# Catboost Classifier - Full dataset\n",
    "\n",
    "cb = CatBoostClassifier()\n",
    "    \n",
    "skf = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 1 )\n",
    "\n",
    "cb_full_results    = []\n",
    "cb_full_results_cm = []\n",
    "\n",
    "for train_index, test_index in skf.split(X,y):\n",
    "    \n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    cb.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = cb.predict(X_test)\n",
    "    \n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall    = recall_score(y_test, y_pred)\n",
    "    f1        = f1_score(y_test, y_pred)\n",
    "    cm        = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    list_results   = [precision, recall, f1]\n",
    "    list_cm = [cm]\n",
    "    cb_full_results.append(list_results)\n",
    "    cb_full_results_cm.append(list_cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "1b1384f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-11T00:13:36.127766Z",
     "start_time": "2022-11-11T00:13:36.112766Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRECISION</th>\n",
       "      <th>RECALL</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GaussianNB_full</th>\n",
       "      <td>0.767672</td>\n",
       "      <td>0.336274</td>\n",
       "      <td>0.467646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 PRECISION    RECALL        F1\n",
       "GaussianNB_full   0.767672  0.336274  0.467646"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filas    = ['GaussianNB_full']\n",
    "columnas = [\"PRECISION\", \"RECALL\", \"F1\"]\n",
    "resultados = pd.DataFrame([gmean(cb_full_results)], columns=columnas, index=filas)\n",
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "5baa04fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-11T00:16:07.075583Z",
     "start_time": "2022-11-11T00:16:07.058545Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRECISION</th>\n",
       "      <th>RECALL</th>\n",
       "      <th>F1</th>\n",
       "      <th>TIEMPO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GaussianNB_full</th>\n",
       "      <td>0.767672</td>\n",
       "      <td>0.336274</td>\n",
       "      <td>0.467646</td>\n",
       "      <td>631</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 PRECISION    RECALL        F1  TIEMPO\n",
       "GaussianNB_full   0.767672  0.336274  0.467646     631"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tiempo expresado en segundos\n",
    "resultados['TIEMPO'] = 631\n",
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "9defec56",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-11T00:16:07.657816Z",
     "start_time": "2022-11-11T00:16:07.641816Z"
    }
   },
   "outputs": [],
   "source": [
    "resultados.to_pickle(\"resultados_cb_full.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "4845c00a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-18T00:40:43.182178Z",
     "start_time": "2022-11-18T00:40:43.159188Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRECISION</th>\n",
       "      <th>RECALL</th>\n",
       "      <th>F1</th>\n",
       "      <th>TIEMPO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CatboostClassifier_full</th>\n",
       "      <td>0.767672</td>\n",
       "      <td>0.336274</td>\n",
       "      <td>0.467646</td>\n",
       "      <td>631</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         PRECISION    RECALL        F1  TIEMPO\n",
       "CatboostClassifier_full   0.767672  0.336274  0.467646     631"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Renombro el índice ya que por error le había asignado otro nombre\n",
    "resultados_cb_full = pd.read_pickle('resultados_cb_full.pkl')\n",
    "resultados_cb_full.index= ['CatboostClassifier_full']\n",
    "resultados_cb_full.to_pickle(\"resultados_cb_full2.pkl\")\n",
    "resultados_cb_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "44a6153f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-11T00:16:08.484988Z",
     "start_time": "2022-11-11T00:16:08.467057Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[17785.59555733,   204.21098244],\n",
       "        [ 1333.56875514,   675.8427233 ]]])"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados_cm = gmean(cb_full_results_cm)\n",
    "resultados_cm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "0b40cc58",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-11T00:16:09.071875Z",
     "start_time": "2022-11-11T00:16:09.060260Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('resultados_cb_full_cm.pkl','wb') as f:\n",
    "        pickle.dump(resultados_cm, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "id": "06fe6cd6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T17:43:35.693098Z",
     "start_time": "2022-11-26T17:43:35.677032Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('resultados_cb_full_cm.pkl','rb') as f:\n",
    "        resultados_cm = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "id": "154b501c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T17:43:36.785397Z",
     "start_time": "2022-11-26T17:43:36.679005Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm_display_cb_full = ConfusionMatrixDisplay(confusion_matrix = resultados_cm.reshape(2,2), display_labels = [0, 1])\n",
    "cm_display_cb_full.plot()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9817ee01",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3e5119",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16deb11",
   "metadata": {},
   "source": [
    "<font size='5' style=\"color:orange\">  <b> MLP Classifier - Default </b> </font>\n",
    "<a name=\"mlp_default\"></a>\n",
    "\n",
    "[[ Back to Top ]](#content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "3e400201",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-11T00:53:14.690942Z",
     "start_time": "2022-11-11T00:18:00.095173Z"
    }
   },
   "outputs": [],
   "source": [
    "# Multi-layer Perceptron Classifier - Full dataset\n",
    "\n",
    "# En este caso se definieron los parámetros random_state y max_iter de forma aleatoria, tal que no arrojara un error el modelo.\n",
    "\n",
    "mlpc = MLPClassifier(random_state = 1, max_iter = 30000)\n",
    "\n",
    "skf = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 1 )\n",
    "\n",
    "mlpc_full_results    = []\n",
    "mlpc_full_results_cm = []\n",
    "\n",
    "for train_index, test_index in skf.split(X,y):\n",
    "    \n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    mlpc.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = mlpc.predict(X_test)\n",
    "    \n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall    = recall_score(y_test, y_pred)\n",
    "    f1        = f1_score(y_test, y_pred)\n",
    "    cm        = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    list_results   = [precision, recall, f1]\n",
    "    list_cm = [cm]\n",
    "    mlpc_full_results.append(list_results)\n",
    "    mlpc_full_results_cm.append(list_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "f7e8f234",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-11T00:54:44.523168Z",
     "start_time": "2022-11-11T00:54:44.508830Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRECISION</th>\n",
       "      <th>RECALL</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MLPClassifier</th>\n",
       "      <td>0.56049</td>\n",
       "      <td>0.296374</td>\n",
       "      <td>0.38538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               PRECISION    RECALL       F1\n",
       "MLPClassifier    0.56049  0.296374  0.38538"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filas    = ['MLPClassifier']\n",
    "columnas = [\"PRECISION\", \"RECALL\", \"F1\"]\n",
    "resultados = pd.DataFrame([gmean(mlpc_full_results)], columns=columnas, index=filas)\n",
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "e0b59a17",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-11T00:55:48.851472Z",
     "start_time": "2022-11-11T00:55:48.840472Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRECISION</th>\n",
       "      <th>RECALL</th>\n",
       "      <th>F1</th>\n",
       "      <th>TIEMPO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MLPClassifier</th>\n",
       "      <td>0.56049</td>\n",
       "      <td>0.296374</td>\n",
       "      <td>0.38538</td>\n",
       "      <td>2115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               PRECISION    RECALL       F1  TIEMPO\n",
       "MLPClassifier    0.56049  0.296374  0.38538    2115"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tiempo expresado en segundos\n",
    "\n",
    "resultados['TIEMPO'] = 2115\n",
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "bfca4cee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-11T00:56:18.332359Z",
     "start_time": "2022-11-11T00:56:18.302344Z"
    }
   },
   "outputs": [],
   "source": [
    "resultados.to_pickle(\"resultados_mlpc_full.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "54c00eac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-11T00:56:41.579246Z",
     "start_time": "2022-11-11T00:56:41.561227Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[17785.59555733,   204.21098244],\n",
       "        [ 1333.56875514,   675.8427233 ]]])"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados_cm = gmean(mlpc_full_results_cm)\n",
    "resultados_cm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "18d7e113",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-11T00:57:04.657162Z",
     "start_time": "2022-11-11T00:57:04.642398Z"
    }
   },
   "outputs": [],
   "source": [
    " with open('resultados_mlpc_full_cm.pkl','wb') as f:\n",
    "        pickle.dump(resultados_cm, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e56ae3",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb84813",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c55b319",
   "metadata": {},
   "source": [
    "<font size='5' style=\"color:orange\">  <b> Linear Discriminant Analysis - Default </b> </font>\n",
    "<a name=\"lda_default\"></a>\n",
    "\n",
    "[[ Back to Top ]](#content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "7f13da0d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-09T02:50:51.894831Z",
     "start_time": "2022-11-09T02:50:06.025117Z"
    }
   },
   "outputs": [],
   "source": [
    "# Linear Discriminant Analysis - Full dataset\n",
    "\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "\n",
    "skf = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 1 )\n",
    "\n",
    "lda_full_results    = []\n",
    "lda_full_results_cm = []\n",
    "\n",
    "for train_index, test_index in skf.split(X,y):\n",
    "    \n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    lda.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = lda.predict(X_test)\n",
    "    \n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall    = recall_score(y_test, y_pred)\n",
    "    f1        = f1_score(y_test, y_pred)\n",
    "    cm        = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    list_results   = [precision, recall, f1]\n",
    "    list_cm = [cm]\n",
    "    lda_full_results.append(list_results)\n",
    "    lda_full_results_cm.append(list_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "9787e601",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-09T02:50:51.942681Z",
     "start_time": "2022-11-09T02:50:51.911681Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRECISION</th>\n",
       "      <th>RECALL</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LinearDiscriminantAnalysis_full</th>\n",
       "      <td>0.679732</td>\n",
       "      <td>0.27825</td>\n",
       "      <td>0.394843</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 PRECISION   RECALL        F1\n",
       "LinearDiscriminantAnalysis_full   0.679732  0.27825  0.394843"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filas    = ['LinearDiscriminantAnalysis_full']\n",
    "columnas = [\"PRECISION\", \"RECALL\", \"F1\"]\n",
    "resultados = pd.DataFrame([gmean(lda_full_results)], columns=columnas, index=filas)\n",
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "f840450f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-09T02:51:09.054696Z",
     "start_time": "2022-11-09T02:51:09.035704Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRECISION</th>\n",
       "      <th>RECALL</th>\n",
       "      <th>F1</th>\n",
       "      <th>TIEMPO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LinearDiscriminantAnalysis_full</th>\n",
       "      <td>0.679732</td>\n",
       "      <td>0.27825</td>\n",
       "      <td>0.394843</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 PRECISION   RECALL        F1  TIEMPO\n",
       "LinearDiscriminantAnalysis_full   0.679732  0.27825  0.394843      46"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tiempo expresado en segundos\n",
    "resultados['TIEMPO'] = 46\n",
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "3104aeab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-09T02:51:09.870762Z",
     "start_time": "2022-11-09T02:51:09.862490Z"
    }
   },
   "outputs": [],
   "source": [
    "resultados.to_pickle(\"resultados_lda_full.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "4c38bfc9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-09T02:51:12.216034Z",
     "start_time": "2022-11-09T02:51:12.202502Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[17726.69368638,   263.07119206],\n",
       "        [ 1450.33167718,   559.22620181]]])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados_cm = gmean(lda_full_results_cm)\n",
    "resultados_cm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "6d11a275",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-09T02:51:13.587255Z",
     "start_time": "2022-11-09T02:51:13.576246Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('resultados_lda_full_cm.pkl','wb') as f:\n",
    "        pickle.dump(resultados_cm, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c86260b",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e41bb3b",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248a4ee4",
   "metadata": {},
   "source": [
    "<font size='5' style=\"color:orange\">  <b> Calibrated Classifier with GaussianNB - Default </b> </font>\n",
    "<a name=\"cccv_default\"></a>\n",
    "\n",
    "[[ Back to Top ]](#content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "dbadee0e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-11T00:16:58.892630Z",
     "start_time": "2022-11-11T00:16:35.449803Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calibrated Classifier CV usando el GaussianNB como base_estimator - Full dataset\n",
    "\n",
    "\n",
    "cccv = CalibratedClassifierCV(base_estimator = GaussianNB(), cv=3)\n",
    "\n",
    "skf = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 1 )\n",
    "\n",
    "cccv_full_results    = []\n",
    "cccv_full_results_cm = []\n",
    "\n",
    "for train_index, test_index in skf.split(X,y):\n",
    "    \n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    cccv.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = cccv.predict(X_test)\n",
    "    \n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall    = recall_score(y_test, y_pred)\n",
    "    f1        = f1_score(y_test, y_pred)\n",
    "    cm        = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    list_results   = [precision, recall, f1]\n",
    "    list_cm = [cm]\n",
    "    cccv_full_results.append(list_results)\n",
    "    cccv_full_results_cm.append(list_cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "d493fd41",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-11T00:16:58.956062Z",
     "start_time": "2022-11-11T00:16:58.909980Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRECISION</th>\n",
       "      <th>RECALL</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CalibratedClassifierCV_GNB_full</th>\n",
       "      <td>0.703706</td>\n",
       "      <td>0.374022</td>\n",
       "      <td>0.488408</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 PRECISION    RECALL        F1\n",
       "CalibratedClassifierCV_GNB_full   0.703706  0.374022  0.488408"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filas    = ['CalibratedClassifierCV_GNB_full']\n",
    "columnas = [\"PRECISION\", \"RECALL\", \"F1\"]\n",
    "resultados = pd.DataFrame([gmean(cccv_full_results)], columns=columnas, index=filas)\n",
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "98b93e6d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-11T00:17:11.529723Z",
     "start_time": "2022-11-11T00:17:11.520617Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRECISION</th>\n",
       "      <th>RECALL</th>\n",
       "      <th>F1</th>\n",
       "      <th>TIEMPO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CalibratedClassifierCV_GNB_full</th>\n",
       "      <td>0.703706</td>\n",
       "      <td>0.374022</td>\n",
       "      <td>0.488408</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 PRECISION    RECALL        F1  TIEMPO\n",
       "CalibratedClassifierCV_GNB_full   0.703706  0.374022  0.488408      23"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tiempo expresado en segundos\n",
    "resultados['TIEMPO'] = 23\n",
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "2f884e5f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-11T00:17:12.142889Z",
     "start_time": "2022-11-11T00:17:12.131901Z"
    }
   },
   "outputs": [],
   "source": [
    "resultados.to_pickle(\"resultados_cccv_full.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "6ebec799",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-11T00:17:12.742020Z",
     "start_time": "2022-11-11T00:17:12.731156Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[17673.58940928,   315.99414586],\n",
       "        [ 1257.78470333,   751.70959561]]])"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados_cm= gmean(cccv_full_results_cm)\n",
    "resultados_cm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "072bc0e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-11T00:17:13.327164Z",
     "start_time": "2022-11-11T00:17:13.317160Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('resultados_cccv_full_cm.pkl','wb') as f:\n",
    "        pickle.dump(resultados_cm, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6963fb72",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727272ea",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74851e3",
   "metadata": {},
   "source": [
    "<font size='5' style=\"color:orange\">  <b> SGD Classifier - Default </b> </font>\n",
    "<a name=\"sgdc_default\"></a>\n",
    "\n",
    "[[ Back to Top ]](#content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "a2814dd4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-09T20:15:10.839230Z",
     "start_time": "2022-11-09T20:11:01.436523Z"
    }
   },
   "outputs": [],
   "source": [
    "# Stochastic Gradient Descent Classifier - Full dataset\n",
    "\n",
    "sgd = SGDClassifier()\n",
    "\n",
    "skf = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 1 )\n",
    "\n",
    "sgd_full_results    = []\n",
    "sgd_full_results_cm = []\n",
    "\n",
    "for train_index, test_index in skf.split(X,y):\n",
    "    \n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    sgd.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = sgd.predict(X_test)\n",
    "    \n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall    = recall_score(y_test, y_pred)\n",
    "    f1        = f1_score(y_test, y_pred)\n",
    "    cm        = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    list_results   = [precision, recall, f1]\n",
    "    list_cm = [cm]\n",
    "    sgd_full_results.append(list_results)\n",
    "    sgd_full_results_cm.append(list_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "729bde8c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-09T20:15:10.870737Z",
     "start_time": "2022-11-09T20:15:10.855666Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRECISION</th>\n",
       "      <th>RECALL</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SGDClassifier_full</th>\n",
       "      <td>0.561299</td>\n",
       "      <td>0.142723</td>\n",
       "      <td>0.175951</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    PRECISION    RECALL        F1\n",
       "SGDClassifier_full   0.561299  0.142723  0.175951"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filas    = ['SGDClassifier_full']\n",
    "columnas = [\"PRECISION\", \"RECALL\", \"F1\"]\n",
    "resultados = pd.DataFrame([gmean(sgd_full_results)], columns=columnas, index=filas)\n",
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "38b95001",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-09T20:19:01.331387Z",
     "start_time": "2022-11-09T20:19:01.307856Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRECISION</th>\n",
       "      <th>RECALL</th>\n",
       "      <th>F1</th>\n",
       "      <th>TIEMPO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SGDClassifier_full</th>\n",
       "      <td>0.561299</td>\n",
       "      <td>0.142723</td>\n",
       "      <td>0.175951</td>\n",
       "      <td>249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    PRECISION    RECALL        F1  TIEMPO\n",
       "SGDClassifier_full   0.561299  0.142723  0.175951     249"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tiempo expresado en segundos\n",
    "resultados['TIEMPO'] = 249\n",
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "066b5d08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-09T20:19:03.763297Z",
     "start_time": "2022-11-09T20:19:03.756219Z"
    }
   },
   "outputs": [],
   "source": [
    "resultados.to_pickle(\"resultados_sgd_full.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "b0cefc76",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-09T20:19:05.958907Z",
     "start_time": "2022-11-09T20:19:05.949984Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\stats\\_stats_py.py:279: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in log\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[17026.19606039,     0.        ],\n",
       "        [ 1317.26200083,   286.84415277]]])"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados_cm = gmean(sgd_full_results_cm)\n",
    "resultados_cm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "b06a236c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-09T20:19:07.223690Z",
     "start_time": "2022-11-09T20:19:07.204393Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('resultados_sgd_full_cm.pkl','wb') as f:\n",
    "        pickle.dump(resultados_cm, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4709b66f",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81808268",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db68b62",
   "metadata": {},
   "source": [
    "<font size='5' style=\"color:orange\">  <b> Bagging Classifier - Default </b> </font>\n",
    "<a name=\"bgc_default\"></a>\n",
    "\n",
    "[[ Back to Top ]](#content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "2d6ea73a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-10T02:04:14.056770Z",
     "start_time": "2022-11-09T22:55:11.325674Z"
    }
   },
   "outputs": [],
   "source": [
    "# Bagging Classifier  - Full dataset\n",
    "\n",
    "bgc = BaggingClassifier()\n",
    "\n",
    "skf = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 1 )\n",
    "\n",
    "bgc_full_results    = []\n",
    "bgc_full_results_cm = []\n",
    "\n",
    "for train_index, test_index in skf.split(X,y):\n",
    "    \n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    bgc.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = bgc.predict(X_test)\n",
    "    \n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall    = recall_score(y_test, y_pred)\n",
    "    f1        = f1_score(y_test, y_pred)\n",
    "    cm        = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    list_results   = [precision, recall, f1]\n",
    "    list_cm = [cm]\n",
    "    bgc_full_results.append(list_results)\n",
    "    bgc_full_results_cm.append(list_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "595457b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-10T02:04:14.119245Z",
     "start_time": "2022-11-10T02:04:14.090759Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRECISION</th>\n",
       "      <th>RECALL</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BaggingClassifier_full</th>\n",
       "      <td>0.5046</td>\n",
       "      <td>0.029268</td>\n",
       "      <td>0.055316</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        PRECISION    RECALL        F1\n",
       "BaggingClassifier_full     0.5046  0.029268  0.055316"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filas    = ['BaggingClassifier_full']\n",
    "columnas = [\"PRECISION\", \"RECALL\", \"F1\"]\n",
    "resultados = pd.DataFrame([gmean(bgc_full_results)], columns=columnas, index=filas)\n",
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "23dbf9a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-10T02:14:31.263684Z",
     "start_time": "2022-11-10T02:14:31.245684Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRECISION</th>\n",
       "      <th>RECALL</th>\n",
       "      <th>F1</th>\n",
       "      <th>TIEMPO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BaggingClassifier_full</th>\n",
       "      <td>0.5046</td>\n",
       "      <td>0.029268</td>\n",
       "      <td>0.055316</td>\n",
       "      <td>11163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        PRECISION    RECALL        F1  TIEMPO\n",
       "BaggingClassifier_full     0.5046  0.029268  0.055316   11163"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tiempo expresado en segundos\n",
    "resultados['TIEMPO'] = 11163\n",
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "b43684fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-10T02:14:31.989103Z",
     "start_time": "2022-11-10T02:14:31.956481Z"
    }
   },
   "outputs": [],
   "source": [
    "resultados.to_pickle(\"resultados_bgc_full.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "2cb0ab1b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-10T02:14:33.159294Z",
     "start_time": "2022-11-10T02:14:33.140224Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[17932.29863349,    57.48015103],\n",
       "        [ 1950.69121943,    58.82235827]]])"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados_cm = gmean(bgc_full_results_cm)\n",
    "resultados_cm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "fe075721",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-10T02:14:35.511520Z",
     "start_time": "2022-11-10T02:14:35.493012Z"
    }
   },
   "outputs": [],
   "source": [
    " with open('resultados_bgc_full_cm.pkl','wb') as f:\n",
    "        pickle.dump(resultados_cm, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beef7076",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742fd8d4",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5415b8d9",
   "metadata": {},
   "source": [
    "<font size='5' style=\"color:orange\">  <b> Models with default parameters - Summary </b> </font>\n",
    "<a name=\"summary_default\"></a>\n",
    "\n",
    "[[ Back to Top ]](#content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abcda26",
   "metadata": {},
   "source": [
    "Se realiza un gráfico que permita comparar el recall y el tiempo de ejecución de cada uno de los modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "46e7c835",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-18T01:00:33.762727Z",
     "start_time": "2022-11-18T01:00:33.706683Z"
    }
   },
   "outputs": [],
   "source": [
    "resultados_lgr_full = pd.read_pickle('resultados_lgr_full.pkl')\n",
    "resultados_gnb_full = pd.read_pickle(\"resultados_gnb_full.pkl\")\n",
    "resultados_rfc_full = pd.read_pickle(\"resultados_rfc_full.pkl\")\n",
    "resultados_knc_full = pd.read_pickle('resultados_knc_full.pkl')\n",
    "resultados_xgb_full = pd.read_pickle('resultados_xgb_full.pkl')\n",
    "resultados_cb_full = pd.read_pickle('resultados_cb_full2.pkl')\n",
    "resultados_mlpc_full = pd.read_pickle('resultados_mlpc_full.pkl')\n",
    "resultados_lda_full = pd.read_pickle('resultados_lda_full.pkl')\n",
    "resultados_cccv_full = pd.read_pickle('resultados_cccv_full.pkl')\n",
    "resultados_sgd_full = pd.read_pickle(\"resultados_sgd_full.pkl\")\n",
    "resultados_bgc_full = pd.read_pickle(\"resultados_bgc_full.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "d46c9894",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-18T01:00:39.023463Z",
     "start_time": "2022-11-18T01:00:39.007463Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRECISION</th>\n",
       "      <th>RECALL</th>\n",
       "      <th>F1</th>\n",
       "      <th>TIEMPO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegression_full</th>\n",
       "      <td>0.685480</td>\n",
       "      <td>0.269483</td>\n",
       "      <td>0.386856</td>\n",
       "      <td>1081.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianNB_full</th>\n",
       "      <td>0.647487</td>\n",
       "      <td>0.403787</td>\n",
       "      <td>0.497367</td>\n",
       "      <td>6.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier_full</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5978.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier_full</th>\n",
       "      <td>0.223142</td>\n",
       "      <td>0.003169</td>\n",
       "      <td>0.006247</td>\n",
       "      <td>781.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost_full</th>\n",
       "      <td>0.693811</td>\n",
       "      <td>0.247841</td>\n",
       "      <td>0.365173</td>\n",
       "      <td>1493.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CatboostClassifier_full</th>\n",
       "      <td>0.767672</td>\n",
       "      <td>0.336274</td>\n",
       "      <td>0.467646</td>\n",
       "      <td>631.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLPClassifier</th>\n",
       "      <td>0.560490</td>\n",
       "      <td>0.296374</td>\n",
       "      <td>0.385380</td>\n",
       "      <td>2115.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearDiscriminantAnalysis_full</th>\n",
       "      <td>0.679732</td>\n",
       "      <td>0.278250</td>\n",
       "      <td>0.394843</td>\n",
       "      <td>46.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CalibratedClassifierCV_GNB_full</th>\n",
       "      <td>0.703706</td>\n",
       "      <td>0.374022</td>\n",
       "      <td>0.488408</td>\n",
       "      <td>23.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGDClassifier_full</th>\n",
       "      <td>0.561299</td>\n",
       "      <td>0.142723</td>\n",
       "      <td>0.175951</td>\n",
       "      <td>249.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggingClassifier_full</th>\n",
       "      <td>0.504600</td>\n",
       "      <td>0.029268</td>\n",
       "      <td>0.055316</td>\n",
       "      <td>11163.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 PRECISION    RECALL        F1    TIEMPO\n",
       "LogisticRegression_full           0.685480  0.269483  0.386856   1081.00\n",
       "GaussianNB_full                   0.647487  0.403787  0.497367      6.07\n",
       "RandomForestClassifier_full       0.000000  0.000000  0.000000   5978.00\n",
       "KNeighborsClassifier_full         0.223142  0.003169  0.006247    781.00\n",
       "XGBoost_full                      0.693811  0.247841  0.365173   1493.00\n",
       "CatboostClassifier_full           0.767672  0.336274  0.467646    631.00\n",
       "MLPClassifier                     0.560490  0.296374  0.385380   2115.00\n",
       "LinearDiscriminantAnalysis_full   0.679732  0.278250  0.394843     46.00\n",
       "CalibratedClassifierCV_GNB_full   0.703706  0.374022  0.488408     23.00\n",
       "SGDClassifier_full                0.561299  0.142723  0.175951    249.00\n",
       "BaggingClassifier_full            0.504600  0.029268  0.055316  11163.00"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_resultados_default= pd.concat([resultados_lgr_full,\n",
    "                                  resultados_gnb_full,\n",
    "                                  resultados_rfc_full,\n",
    "                                  resultados_knc_full,\n",
    "                                  resultados_xgb_full,\n",
    "                                  resultados_cb_full,\n",
    "                                  resultados_mlpc_full,\n",
    "                                  resultados_lda_full,\n",
    "                                  resultados_cccv_full,\n",
    "                                  resultados_sgd_full,\n",
    "                                  resultados_bgc_full])\n",
    "df_resultados_default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "b2f8f860",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-18T01:01:38.161324Z",
     "start_time": "2022-11-18T01:01:38.153345Z"
    }
   },
   "outputs": [],
   "source": [
    "df_resultados_default.to_pickle('df_resultados_default.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "60a5f641",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-20T15:49:46.018962Z",
     "start_time": "2022-11-20T15:49:45.414459Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (8, 8))\n",
    "sns.scatterplot(data = df_resultados_default, x = df_resultados_default['TIEMPO'],y = df_resultados_default['RECALL'], \n",
    "                hue = df_resultados_default.index, style = df_resultados_default.index, palette = 'colorblind', s = 300) \n",
    "plt.xlabel('Time (seconds)', y = -0.8, fontsize = 20)\n",
    "plt.ylabel('Recall', x = -1, fontsize = 20)\n",
    "plt.yticks(fontsize = 12)\n",
    "plt.xticks(fontsize = 12)\n",
    "plt.title('Models with default parameters', y = 1.05, fontsize = 30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250d7f2c",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21893037",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8739c8",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967cb6fe",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2aa9f0",
   "metadata": {},
   "source": [
    "<font size='6' style=\"color:orange\">  <b> Models - PCA </b> </font>\n",
    "<a name=\"PCA\"></a>\n",
    "\n",
    "[[ Back to Top ]](#content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2226b2",
   "metadata": {},
   "source": [
    "A continuación se entrenará nuevamente a los modelos Logistic Regression y K Neighbors Classifier  reduciendo su dimensionalidad a 100, 125, 150 y 175 components utilizando PCA (Principal Component Analysis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55fe115f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-12T20:38:44.811588Z",
     "start_time": "2022-11-12T20:38:44.798587Z"
    }
   },
   "outputs": [],
   "source": [
    "pca_100 = PCA(n_components = 100)\n",
    "pca_125 = PCA(n_components = 125)\n",
    "pca_150 = PCA(n_components = 150)\n",
    "pca_175 = PCA(n_components = 175)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6aa5c8",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bff6238",
   "metadata": {},
   "source": [
    "<font size='5' style=\"color:orange\">  <b> Logistic Regression - PCA </b> </font>\n",
    "<a name=\"lgr_pca\"></a>\n",
    "\n",
    "[[ Back to Top ]](#content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccff9d94",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d228594e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T21:47:31.359192Z",
     "start_time": "2022-11-08T21:46:57.800994Z"
    }
   },
   "outputs": [],
   "source": [
    "# Logistic Regression - PCA 100\n",
    "\n",
    "lgr = LogisticRegression(solver='lbfgs', max_iter=7000)\n",
    "    \n",
    "skf = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 1 )\n",
    "\n",
    "lgr_100_results    = []\n",
    "lgr_100_results_cm = []\n",
    "\n",
    "for train_index, test_index in skf.split(X,y):\n",
    "    \n",
    "    X_train, X_test = pca_100.fit_transform(X.iloc[train_index]), pca_100.transform(X.iloc[test_index])\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    lgr.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = lgr.predict(X_test)\n",
    "    \n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall    = recall_score(y_test, y_pred)\n",
    "    f1        = f1_score(y_test, y_pred)\n",
    "    cm        = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    list_results   = [precision, recall, f1]\n",
    "    list_cm = [cm]\n",
    "    lgr_100_results.append(list_results)\n",
    "    lgr_100_results_cm.append(list_cm)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "275efe8b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T21:47:31.390191Z",
     "start_time": "2022-11-08T21:47:31.376191Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRECISION</th>\n",
       "      <th>RECALL</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegression_100</th>\n",
       "      <td>0.639638</td>\n",
       "      <td>0.084301</td>\n",
       "      <td>0.148939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        PRECISION    RECALL        F1\n",
       "LogisticRegression_100   0.639638  0.084301  0.148939"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filas    = ['LogisticRegression_100']\n",
    "columnas = [\"PRECISION\", \"RECALL\", \"F1\"]\n",
    "resultados = pd.DataFrame([gmean(lgr_100_results)], columns=columnas, index=filas)\n",
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fc37979e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T21:48:10.338931Z",
     "start_time": "2022-11-08T21:48:10.316949Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRECISION</th>\n",
       "      <th>RECALL</th>\n",
       "      <th>F1</th>\n",
       "      <th>TIEMPO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegression_100</th>\n",
       "      <td>0.639638</td>\n",
       "      <td>0.084301</td>\n",
       "      <td>0.148939</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        PRECISION    RECALL        F1  TIEMPO\n",
       "LogisticRegression_100   0.639638  0.084301  0.148939      34"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tiempo expresado en segundos\n",
    "resultados['TIEMPO'] = 34\n",
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6e36d538",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T21:48:13.017303Z",
     "start_time": "2022-11-08T21:48:13.000225Z"
    }
   },
   "outputs": [],
   "source": [
    "resultados.to_pickle(\"resultados_lgr_100.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9d872097",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T21:48:14.545581Z",
     "start_time": "2022-11-08T21:48:14.524514Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[17894.49445006,    94.61878469],\n",
       "        [ 1840.07616092,   169.42818354]]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados_cm = gmean(lgr_100_results_cm)\n",
    "resultados_cm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2ea2fe5c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T21:48:16.792720Z",
     "start_time": "2022-11-08T21:48:16.786745Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('resultados_lgr_100_cm.pkl','wb') as f:\n",
    "        pickle.dump(resultados_cm, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa592017",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "77e215d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T21:49:03.656791Z",
     "start_time": "2022-11-08T21:48:20.333796Z"
    }
   },
   "outputs": [],
   "source": [
    "# Logistic Regression - PCA 125\n",
    "\n",
    "lgr = LogisticRegression(solver='lbfgs', max_iter=7000)\n",
    "    \n",
    "skf = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 1 )\n",
    "\n",
    "lgr_125_results    = []\n",
    "lgr_125_results_cm = []\n",
    "\n",
    "for train_index, test_index in skf.split(X,y):\n",
    "    \n",
    "    X_train, X_test = pca_125.fit_transform(X.iloc[train_index]), pca_125.transform(X.iloc[test_index])\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    lgr.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = lgr.predict(X_test)\n",
    "    \n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall    = recall_score(y_test, y_pred)\n",
    "    f1        = f1_score(y_test, y_pred)\n",
    "    cm        = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    list_results   = [precision, recall, f1]\n",
    "    list_cm = [cm]\n",
    "    lgr_125_results.append(list_results)\n",
    "    lgr_125_results_cm.append(list_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "90752c1c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T21:49:03.688793Z",
     "start_time": "2022-11-08T21:49:03.673791Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRECISION</th>\n",
       "      <th>RECALL</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegression_125</th>\n",
       "      <td>0.64735</td>\n",
       "      <td>0.124122</td>\n",
       "      <td>0.208257</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        PRECISION    RECALL        F1\n",
       "LogisticRegression_125    0.64735  0.124122  0.208257"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filas    = ['LogisticRegression_125']\n",
    "columnas = [\"PRECISION\", \"RECALL\", \"F1\"]\n",
    "resultados = pd.DataFrame([gmean(lgr_125_results)], columns=columnas, index=filas)\n",
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "150dd64b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T21:49:24.651095Z",
     "start_time": "2022-11-08T21:49:24.631583Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRECISION</th>\n",
       "      <th>RECALL</th>\n",
       "      <th>F1</th>\n",
       "      <th>TIEMPO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegression_125</th>\n",
       "      <td>0.64735</td>\n",
       "      <td>0.124122</td>\n",
       "      <td>0.208257</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        PRECISION    RECALL        F1  TIEMPO\n",
       "LogisticRegression_125    0.64735  0.124122  0.208257      43"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tiempo expresado en segundos\n",
    "resultados['TIEMPO'] = 43\n",
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2323d665",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T21:49:25.617379Z",
     "start_time": "2022-11-08T21:49:25.601636Z"
    }
   },
   "outputs": [],
   "source": [
    "resultados.to_pickle(\"resultados_lgr_125.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "28be524e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T21:49:26.789560Z",
     "start_time": "2022-11-08T21:49:26.775639Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[17854.09479855,   135.4514716 ],\n",
       "        [ 1759.83630043,   249.46007195]]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados_cm = gmean(lgr_125_results_cm)\n",
    "resultados_cm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "35e06076",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T21:49:27.682363Z",
     "start_time": "2022-11-08T21:49:27.664860Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('resultados_lgr_125_cm.pkl','wb') as f:\n",
    "    pickle.dump(resultados_cm, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc3c9f0",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e5001f02",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T21:50:24.553840Z",
     "start_time": "2022-11-08T21:49:31.824679Z"
    }
   },
   "outputs": [],
   "source": [
    "# Logistic Regression - PCA 150\n",
    "\n",
    "lgr = LogisticRegression(solver='lbfgs', max_iter=7000)\n",
    "\n",
    "skf = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 1 )\n",
    "\n",
    "lgr_150_results    = []\n",
    "lgr_150_results_cm = []\n",
    "\n",
    "for train_index, test_index in skf.split(X,y):\n",
    "    \n",
    "    X_train, X_test = pca_150.fit_transform(X.iloc[train_index]), pca_150.transform(X.iloc[test_index])\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    lgr.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = lgr.predict(X_test)\n",
    "    \n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall    = recall_score(y_test, y_pred)\n",
    "    f1        = f1_score(y_test, y_pred)\n",
    "    cm        = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    list_results   = [precision, recall, f1]\n",
    "    list_cm = [cm]\n",
    "    lgr_150_results.append(list_results)\n",
    "    lgr_150_results_cm.append(list_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "545abcbe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T21:50:24.585835Z",
     "start_time": "2022-11-08T21:50:24.571835Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRECISION</th>\n",
       "      <th>RECALL</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegression_150</th>\n",
       "      <td>0.668582</td>\n",
       "      <td>0.183076</td>\n",
       "      <td>0.287419</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        PRECISION    RECALL        F1\n",
       "LogisticRegression_150   0.668582  0.183076  0.287419"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filas    = ['LogisticRegression_150']\n",
    "columnas = [\"PRECISION\", \"RECALL\", \"F1\"]\n",
    "resultados = pd.DataFrame([gmean(lgr_150_results)], columns=columnas, index=filas)\n",
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c8a30c81",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T21:50:42.703986Z",
     "start_time": "2022-11-08T21:50:42.687478Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRECISION</th>\n",
       "      <th>RECALL</th>\n",
       "      <th>F1</th>\n",
       "      <th>TIEMPO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegression_150</th>\n",
       "      <td>0.668582</td>\n",
       "      <td>0.183076</td>\n",
       "      <td>0.287419</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        PRECISION    RECALL        F1  TIEMPO\n",
       "LogisticRegression_150   0.668582  0.183076  0.287419      53"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tiempo expresado en segundos\n",
    "resultados['TIEMPO'] = 53\n",
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "247a49ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T21:50:43.843127Z",
     "start_time": "2022-11-08T21:50:43.826784Z"
    }
   },
   "outputs": [],
   "source": [
    "resultados.to_pickle(\"resultados_lgr_150.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3988d0fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T21:50:45.883778Z",
     "start_time": "2022-11-08T21:50:45.864896Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[17807.69342463,   181.85701948],\n",
       "        [ 1641.66779244,   367.94606223]]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados_cm = gmean(lgr_150_results_cm)\n",
    "resultados_cm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f083654d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T21:50:47.238695Z",
     "start_time": "2022-11-08T21:50:47.221192Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('resultados_lgr_150_cm.pkl','wb') as f:\n",
    "        pickle.dump(resultados_cm, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecc421c",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7117c045",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T21:51:32.373396Z",
     "start_time": "2022-11-08T21:50:49.143212Z"
    }
   },
   "outputs": [],
   "source": [
    "# Logistic Regression - PCA 175\n",
    "\n",
    "lgr = LogisticRegression(solver='lbfgs', max_iter=7000)\n",
    "\n",
    "skf = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 1 )\n",
    "\n",
    "lgr_175_results    = []\n",
    "lgr_175_results_cm = []\n",
    "\n",
    "for train_index, test_index in skf.split(X,y):\n",
    "    \n",
    "    X_train, X_test = pca_175.fit_transform(X.iloc[train_index]), pca_175.transform(X.iloc[test_index])\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    lgr.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = lgr.predict(X_test)\n",
    "    \n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall    = recall_score(y_test, y_pred)\n",
    "    f1        = f1_score(y_test, y_pred)\n",
    "    cm        = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    list_results   = [precision, recall, f1]\n",
    "    list_cm = [cm]\n",
    "    lgr_175_results.append(list_results)\n",
    "    lgr_175_results_cm.append(list_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "92733d65",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T21:51:32.405493Z",
     "start_time": "2022-11-08T21:51:32.390492Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRECISION</th>\n",
       "      <th>RECALL</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegression_175</th>\n",
       "      <td>0.672872</td>\n",
       "      <td>0.212669</td>\n",
       "      <td>0.323155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        PRECISION    RECALL        F1\n",
       "LogisticRegression_175   0.672872  0.212669  0.323155"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filas    = ['LogisticRegression_175']\n",
    "columnas = [\"PRECISION\", \"RECALL\", \"F1\"]\n",
    "resultados = pd.DataFrame([gmean(lgr_175_results)], columns=columnas, index=filas)\n",
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6d2cd26c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T21:51:47.343874Z",
     "start_time": "2022-11-08T21:51:47.326302Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRECISION</th>\n",
       "      <th>RECALL</th>\n",
       "      <th>F1</th>\n",
       "      <th>TIEMPO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegression_175</th>\n",
       "      <td>0.672872</td>\n",
       "      <td>0.212669</td>\n",
       "      <td>0.323155</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        PRECISION    RECALL        F1  TIEMPO\n",
       "LogisticRegression_175   0.672872  0.212669  0.323155      43"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tiempo expresado en segundos\n",
    "resultados['TIEMPO'] = 43\n",
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "6ffe3321",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T21:51:48.124293Z",
     "start_time": "2022-11-08T21:51:48.094757Z"
    }
   },
   "outputs": [],
   "source": [
    "resultados.to_pickle(\"resultados_lgr_175.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a0d1120c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T21:51:49.619728Z",
     "start_time": "2022-11-08T21:51:49.604668Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[17782.09007249,   207.24470003],\n",
       "        [ 1582.27905521,   427.42203455]]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados_cm = gmean(lgr_175_results_cm)\n",
    "resultados_cm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4b6dd2d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T21:51:52.157650Z",
     "start_time": "2022-11-08T21:51:52.139261Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('resultados_lgr_175_cm.pkl','wb') as f:\n",
    "    pickle.dump(resultados_cm, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e39030",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632fc556",
   "metadata": {},
   "source": [
    "<font size='4' style=\"color:orange\">  <b> Logistic Regression - Summary </b> </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "f6d17420",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-18T01:59:32.534607Z",
     "start_time": "2022-11-18T01:59:32.506084Z"
    }
   },
   "outputs": [],
   "source": [
    "resultados_lgr_100 = pd.read_pickle('resultados_lgr_100.pkl')\n",
    "resultados_lgr_125 = pd.read_pickle('resultados_lgr_125.pkl')\n",
    "resultados_lgr_150 = pd.read_pickle('resultados_lgr_150.pkl')\n",
    "resultados_lgr_175 = pd.read_pickle('resultados_lgr_175.pkl')\n",
    "resultados_lgr_full = pd.read_pickle('resultados_lgr_full.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "e25ecb07",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-18T01:59:40.702165Z",
     "start_time": "2022-11-18T01:59:40.673447Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRECISION</th>\n",
       "      <th>RECALL</th>\n",
       "      <th>F1</th>\n",
       "      <th>TIEMPO</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegression_100</th>\n",
       "      <td>0.639638</td>\n",
       "      <td>0.084301</td>\n",
       "      <td>0.148939</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression_125</th>\n",
       "      <td>0.647350</td>\n",
       "      <td>0.124122</td>\n",
       "      <td>0.208257</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression_150</th>\n",
       "      <td>0.668582</td>\n",
       "      <td>0.183076</td>\n",
       "      <td>0.287419</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression_175</th>\n",
       "      <td>0.672872</td>\n",
       "      <td>0.212669</td>\n",
       "      <td>0.323155</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression_full</th>\n",
       "      <td>0.685480</td>\n",
       "      <td>0.269483</td>\n",
       "      <td>0.386856</td>\n",
       "      <td>1081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         PRECISION    RECALL        F1  TIEMPO\n",
       "                                                              \n",
       "LogisticRegression_100    0.639638  0.084301  0.148939      34\n",
       "LogisticRegression_125    0.647350  0.124122  0.208257      43\n",
       "LogisticRegression_150    0.668582  0.183076  0.287419      53\n",
       "LogisticRegression_175    0.672872  0.212669  0.323155      43\n",
       "LogisticRegression_full   0.685480  0.269483  0.386856    1081"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_resultados_lgr_pca= pd.concat([resultados_lgr_100,\n",
    "                                resultados_lgr_125,\n",
    "                                resultados_lgr_150,\n",
    "                                resultados_lgr_175,\n",
    "                                resultados_lgr_full])\n",
    "df_resultados_lgr_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "a90208eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-18T02:00:13.076863Z",
     "start_time": "2022-11-18T02:00:13.048840Z"
    }
   },
   "outputs": [],
   "source": [
    "df_resultados_lgr_pca.to_pickle('df_resultados_lgr_pca.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "6b63c74a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-20T15:52:36.229489Z",
     "start_time": "2022-11-20T15:52:36.030408Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (8, 8))\n",
    "sns.scatterplot(data = df_resultados_lgr_pca, x = df_resultados_lgr_pca['TIEMPO'],y = df_resultados_lgr_pca['RECALL'], \n",
    "                hue = df_resultados_lgr_pca.index, style = df_resultados_lgr_pca.index, palette = 'colorblind', s = 300) \n",
    "plt.xlabel('Time (seconds)', y = -0.8, fontsize = 20)\n",
    "plt.ylabel('Recall', x = -1, fontsize = 20)\n",
    "plt.yticks(fontsize = 12)\n",
    "plt.xticks(fontsize = 12)\n",
    "plt.title('Logistic Regression', y = 1.05, fontsize = 30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6722ee34",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984e81bc",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40691943",
   "metadata": {},
   "source": [
    "<font size='5' style=\"color:orange\">  <b> K Neighbors Classifier - PCA </b> </font>\n",
    "<a name=\"knc_pca\"></a>\n",
    "\n",
    "[[ Back to Top ]](#content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "bba2477c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-16T22:12:35.833754Z",
     "start_time": "2022-11-16T21:59:17.862427Z"
    }
   },
   "outputs": [],
   "source": [
    "# KNeighborsClassifier - PCA 175\n",
    "\n",
    "knc = KNeighborsClassifier()\n",
    "    \n",
    "skf = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 1 )\n",
    "\n",
    "knc_175_results    = []\n",
    "knc_175_results_cm = []\n",
    "\n",
    "tiempo_ejecucion = []\n",
    "inicio = time.time()\n",
    "\n",
    "for train_index, test_index in skf.split(X,y):\n",
    "    \n",
    "    X_train, X_test = pca_175.fit_transform(X.iloc[train_index]),  pca_175.transform(X.iloc[test_index])\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    knc.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = knc.predict(X_test)\n",
    "    \n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall    = recall_score(y_test, y_pred)\n",
    "    f1        = f1_score(y_test, y_pred)\n",
    "    cm        = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    list_results   = [precision, recall, f1]\n",
    "    list_cm = [cm]\n",
    "    knc_175_results.append(list_results)\n",
    "    knc_175_results_cm.append(list_cm)\n",
    "\n",
    "fin = time.time()\n",
    "tiempo_ejecucion.append(fin - inicio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "6b8223b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-16T22:12:35.865638Z",
     "start_time": "2022-11-16T22:12:35.833754Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRECISION</th>\n",
       "      <th>RECALL</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier_175</th>\n",
       "      <td>0.220253</td>\n",
       "      <td>0.003159</td>\n",
       "      <td>0.006227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          PRECISION    RECALL        F1\n",
       "KNeighborsClassifier_175   0.220253  0.003159  0.006227"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filas    = ['KNeighborsClassifier_175']\n",
    "columnas = [\"PRECISION\", \"RECALL\", \"F1\"]\n",
    "resultados = pd.DataFrame([gmean(knc_175_results)], columns=columnas, index=filas)\n",
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "db047b85",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-16T22:12:35.881641Z",
     "start_time": "2022-11-16T22:12:35.865638Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRECISION</th>\n",
       "      <th>RECALL</th>\n",
       "      <th>F1</th>\n",
       "      <th>TIEMPO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier_175</th>\n",
       "      <td>0.220253</td>\n",
       "      <td>0.003159</td>\n",
       "      <td>0.006227</td>\n",
       "      <td>797.940231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          PRECISION    RECALL        F1      TIEMPO\n",
       "KNeighborsClassifier_175   0.220253  0.003159  0.006227  797.940231"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados['TIEMPO']= tiempo_ejecucion\n",
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "89a87b5c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-16T22:12:35.897638Z",
     "start_time": "2022-11-16T22:12:35.881641Z"
    }
   },
   "outputs": [],
   "source": [
    "resultados.to_pickle(\"resultados_knc_175.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "a2451e0c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-16T22:12:35.913704Z",
     "start_time": "2022-11-16T22:12:35.897638Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1.79683994e+04, 2.12055902e+01],\n",
       "        [2.00229705e+03, 6.34910406e+00]]])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados_cm = gmean(knc_175_results_cm)\n",
    "resultados_cm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "d2ae80ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-16T22:12:35.929638Z",
     "start_time": "2022-11-16T22:12:35.913704Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('resultados_knc_175_cm.pkl','wb') as f:\n",
    "    pickle.dump(resultados_cm, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86b94ae",
   "metadata": {},
   "source": [
    "Teniendo en cuenta que el recall del K Neighbors Classifier es bajo y su tiempo de ejecución alto, no se buscarán las métricas para los PCA 100, 125 y 150."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d08d4a1",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc88900",
   "metadata": {},
   "source": [
    "<font size='4' style=\"color:orange\">  <b> K Neighbors Classifier - Summary </b> </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "bdfb9a82",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-18T02:10:02.633276Z",
     "start_time": "2022-11-18T02:10:02.597024Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRECISION</th>\n",
       "      <th>RECALL</th>\n",
       "      <th>F1</th>\n",
       "      <th>TIEMPO</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier_175</th>\n",
       "      <td>0.220253</td>\n",
       "      <td>0.003159</td>\n",
       "      <td>0.006227</td>\n",
       "      <td>797.940231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier_full</th>\n",
       "      <td>0.223142</td>\n",
       "      <td>0.003169</td>\n",
       "      <td>0.006247</td>\n",
       "      <td>781.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           PRECISION    RECALL        F1      TIEMPO\n",
       "                                                                    \n",
       "KNeighborsClassifier_175    0.220253  0.003159  0.006227  797.940231\n",
       "KNeighborsClassifier_full   0.223142  0.003169  0.006247  781.000000"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados_knc_175 = pd.read_pickle('resultados_knc_175.pkl')\n",
    "resultados_knc_full = pd.read_pickle('resultados_knc_full.pkl')\n",
    "\n",
    "df_resultados_knc_pca = pd.concat([ resultados_knc_175,\n",
    "                                   resultados_knc_full])\n",
    "\n",
    "df_resultados_knc_pca.to_pickle(\"resultados_knc_pca.pkl\")\n",
    "\n",
    "df_resultados_knc_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "3477853b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-20T15:55:23.174807Z",
     "start_time": "2022-11-20T15:55:23.012378Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (8, 8))\n",
    "sns.scatterplot(data = df_resultados_knc_pca, x = df_resultados_knc_pca['TIEMPO'],y = df_resultados_knc_pca['RECALL'], \n",
    "                hue = df_resultados_knc_pca.index, style = df_resultados_knc_pca.index, palette = 'colorblind', s = 300) \n",
    "plt.xlabel('Time (seconds)', y = -0.8, fontsize = 20)\n",
    "plt.ylabel('Recall', x = -1, fontsize = 20)\n",
    "plt.yticks(fontsize = 12)\n",
    "plt.xticks(fontsize = 12)\n",
    "plt.title('K Neighbors Classifier', y = 1.05, fontsize = 30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2e4de0",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ba25b4",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db02f518",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e10c02",
   "metadata": {},
   "source": [
    "<font size='6' style=\"color:orange\">  <b> Optuna </b> </font>\n",
    "<a name=\"optuna\"></a>\n",
    "\n",
    "[[ Back to Top ]](#content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fb85a6",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'> \n",
    "Utilizando la libraría Optuna se buscará optimizar los hipermarámetros de los algoritmos Logistic Regression y K Neighbors Classifier, de forma tal que los modelos arrojen mejores resultados que los obtenidos con los hiperparámetros default.\n",
    "\n",
    "<p style='text-align: justify;'> \n",
    "Cabe aclarar que el dataset completo contiene 201 variables y 200 000 registros, motivo por el cual realizar la optimización de hiperparámetros con el dataset completo requiere de mayor tiempo y poder computacional. Es por ello que se buscará optimizar los modelos utilizando un dataset con reducción de dimensionalidad. Luego se comprobará si esos hiperparámetros optimizados pueden ser también utilizados para los modelos que utilizan el fulldataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd35c38",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f97a48a",
   "metadata": {},
   "source": [
    "<font size='5' style=\"color:orange\">  <b> Logistic Regression - Optuna </b> </font>\n",
    "<a name=\"lgr_opt\"></a>\n",
    "\n",
    "[[ Back to Top ]](#content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a7b2ab",
   "metadata": {},
   "source": [
    "Se optimizarán los hiperparámetros del modelo Logistic Regression para PCA 100, PCA 175 y full dataset.\n",
    "\n",
    "Se debe tener en cuenta que el Recall del modelo Logistic Regression para el full dataset es de 0.269483. Por lo que con la optimización de hiperparámetros se tiene como objetivo el obtener un mejor Recall que el mencionado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3679a77a",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac1a8ea",
   "metadata": {},
   "source": [
    "<font size='4' style=\"color:orange\">  <b> Logistic Regression - PCA 100 </b> </font>\n",
    "<a name=\"lgr_opt_100\"></a>\n",
    "\n",
    "[[ Back to Top ]](#content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb53899",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfec816",
   "metadata": {},
   "source": [
    "Logistic Regression PCA 100 - Study 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "87e51422",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-10T16:14:46.772828Z",
     "start_time": "2022-11-10T16:14:46.736736Z"
    }
   },
   "outputs": [],
   "source": [
    "# Se busca optimizar los hiperparámetros 'solver' y 'max_iter'.\n",
    "\n",
    "def objective_lgr_100_1(trial):\n",
    "    solver_trial = trial.suggest_categorical('solver',['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'])\n",
    "    max_iter_trial = trial.suggest_int('max_iter', 5000,35000)\n",
    "\n",
    "    lgr = LogisticRegression(solver = solver_trial, max_iter = max_iter_trial)\n",
    "\n",
    "    skf = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 1 )\n",
    "\n",
    "    lgr_100_results    = []\n",
    "    \n",
    "    for train_index, test_index in skf.split(X,y):\n",
    "    \n",
    "        X_train, X_test = pca_100.fit_transform(X.iloc[train_index]), pca_100.transform(X.iloc[test_index])\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "        lgr.fit(X_train, y_train)\n",
    "    \n",
    "        y_pred = lgr.predict(X_test)\n",
    "    \n",
    "        recall    = recall_score(y_test, y_pred)\n",
    "\n",
    "        list_results   = [recall]\n",
    "        lgr_100_results.append(list_results)\n",
    "    \n",
    "        \n",
    "    return gmean(lgr_100_results)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "b097f8f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-10T19:14:20.477539Z",
     "start_time": "2022-11-10T16:14:48.095400Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-10 13:14:48,118]\u001b[0m A new study created in memory with name: no-name-28f9ce4e-2365-40b3-b469-7e11f17bfb7e\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 13:16:16,366]\u001b[0m Trial 0 finished with value: 0.08384793266870955 and parameters: {'solver': 'sag', 'max_iter': 8641}. Best is trial 0 with value: 0.08384793266870955.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 13:16:48,639]\u001b[0m Trial 1 finished with value: 0.08552246458808954 and parameters: {'solver': 'lbfgs', 'max_iter': 9731}. Best is trial 1 with value: 0.08552246458808954.\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "\u001b[32m[I 2022-11-10 13:17:45,802]\u001b[0m Trial 2 finished with value: 0.08575965260040483 and parameters: {'solver': 'newton-cg', 'max_iter': 24868}. Best is trial 2 with value: 0.08575965260040483.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 13:19:15,118]\u001b[0m Trial 3 finished with value: 0.083320567156247 and parameters: {'solver': 'sag', 'max_iter': 13766}. Best is trial 2 with value: 0.08575965260040483.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 13:20:26,654]\u001b[0m Trial 4 finished with value: 0.08378730285567043 and parameters: {'solver': 'liblinear', 'max_iter': 11559}. Best is trial 2 with value: 0.08575965260040483.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 13:21:30,173]\u001b[0m Trial 5 finished with value: 0.08370039791321975 and parameters: {'solver': 'saga', 'max_iter': 14098}. Best is trial 2 with value: 0.08575965260040483.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 13:22:32,901]\u001b[0m Trial 6 finished with value: 0.0839801182517697 and parameters: {'solver': 'saga', 'max_iter': 8694}. Best is trial 2 with value: 0.08575965260040483.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 13:23:58,871]\u001b[0m Trial 7 finished with value: 0.08429243792811249 and parameters: {'solver': 'sag', 'max_iter': 31607}. Best is trial 2 with value: 0.08575965260040483.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 13:25:24,523]\u001b[0m Trial 8 finished with value: 0.08468106249680683 and parameters: {'solver': 'sag', 'max_iter': 33705}. Best is trial 2 with value: 0.08575965260040483.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 13:25:56,285]\u001b[0m Trial 9 finished with value: 0.08320002007366244 and parameters: {'solver': 'lbfgs', 'max_iter': 31567}. Best is trial 2 with value: 0.08575965260040483.\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:415: LineSearchWarning:\n",
      "\n",
      "Rounding errors prevent the line search from converging\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "\u001b[32m[I 2022-11-10 13:26:54,613]\u001b[0m Trial 10 finished with value: 0.08468501974608551 and parameters: {'solver': 'newton-cg', 'max_iter': 23775}. Best is trial 2 with value: 0.08575965260040483.\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "\u001b[32m[I 2022-11-10 13:27:52,638]\u001b[0m Trial 11 finished with value: 0.08319432689822374 and parameters: {'solver': 'newton-cg', 'max_iter': 22603}. Best is trial 2 with value: 0.08575965260040483.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 13:28:25,748]\u001b[0m Trial 12 finished with value: 0.08511464870921166 and parameters: {'solver': 'lbfgs', 'max_iter': 19305}. Best is trial 2 with value: 0.08575965260040483.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 13:28:58,915]\u001b[0m Trial 13 finished with value: 0.08202842152072838 and parameters: {'solver': 'lbfgs', 'max_iter': 26578}. Best is trial 2 with value: 0.08575965260040483.\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "\u001b[32m[I 2022-11-10 13:29:54,295]\u001b[0m Trial 14 finished with value: 0.08321255814292702 and parameters: {'solver': 'newton-cg', 'max_iter': 16997}. Best is trial 2 with value: 0.08575965260040483.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 13:31:05,655]\u001b[0m Trial 15 finished with value: 0.0832422568066544 and parameters: {'solver': 'liblinear', 'max_iter': 27051}. Best is trial 2 with value: 0.08575965260040483.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 13:31:38,655]\u001b[0m Trial 16 finished with value: 0.08408480344219565 and parameters: {'solver': 'lbfgs', 'max_iter': 5001}. Best is trial 2 with value: 0.08575965260040483.\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "\u001b[32m[I 2022-11-10 13:32:36,456]\u001b[0m Trial 17 finished with value: 0.08343644753176274 and parameters: {'solver': 'newton-cg', 'max_iter': 18000}. Best is trial 2 with value: 0.08575965260040483.\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "\u001b[32m[I 2022-11-10 13:33:34,421]\u001b[0m Trial 18 finished with value: 0.08457348545427217 and parameters: {'solver': 'newton-cg', 'max_iter': 26280}. Best is trial 2 with value: 0.08575965260040483.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 13:34:08,624]\u001b[0m Trial 19 finished with value: 0.08284013979385754 and parameters: {'solver': 'lbfgs', 'max_iter': 21930}. Best is trial 2 with value: 0.08575965260040483.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 13:35:11,574]\u001b[0m Trial 20 finished with value: 0.0840194450480188 and parameters: {'solver': 'saga', 'max_iter': 15273}. Best is trial 2 with value: 0.08575965260040483.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 13:35:43,969]\u001b[0m Trial 21 finished with value: 0.08273741488474251 and parameters: {'solver': 'lbfgs', 'max_iter': 18468}. Best is trial 2 with value: 0.08575965260040483.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 13:36:16,407]\u001b[0m Trial 22 finished with value: 0.08366994864955699 and parameters: {'solver': 'lbfgs', 'max_iter': 20338}. Best is trial 2 with value: 0.08575965260040483.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 13:36:49,291]\u001b[0m Trial 23 finished with value: 0.08479233167135897 and parameters: {'solver': 'lbfgs', 'max_iter': 29272}. Best is trial 2 with value: 0.08575965260040483.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 13:37:22,545]\u001b[0m Trial 24 finished with value: 0.0858491011869395 and parameters: {'solver': 'lbfgs', 'max_iter': 10926}. Best is trial 24 with value: 0.0858491011869395.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 13:38:33,208]\u001b[0m Trial 25 finished with value: 0.0835106854745721 and parameters: {'solver': 'liblinear', 'max_iter': 5101}. Best is trial 24 with value: 0.0858491011869395.\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "\u001b[32m[I 2022-11-10 13:39:28,768]\u001b[0m Trial 26 finished with value: 0.08259461427019177 and parameters: {'solver': 'newton-cg', 'max_iter': 10378}. Best is trial 24 with value: 0.0858491011869395.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 13:40:01,774]\u001b[0m Trial 27 finished with value: 0.08339074811532299 and parameters: {'solver': 'lbfgs', 'max_iter': 7751}. Best is trial 24 with value: 0.0858491011869395.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 13:40:34,777]\u001b[0m Trial 28 finished with value: 0.0850776851366221 and parameters: {'solver': 'lbfgs', 'max_iter': 12048}. Best is trial 24 with value: 0.0858491011869395.\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "\u001b[32m[I 2022-11-10 13:41:30,980]\u001b[0m Trial 29 finished with value: 0.08659027930342719 and parameters: {'solver': 'newton-cg', 'max_iter': 7590}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "\u001b[32m[I 2022-11-10 13:42:26,766]\u001b[0m Trial 30 finished with value: 0.08303937145604012 and parameters: {'solver': 'newton-cg', 'max_iter': 6985}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "\u001b[32m[I 2022-11-10 13:43:22,027]\u001b[0m Trial 31 finished with value: 0.08535353418150707 and parameters: {'solver': 'newton-cg', 'max_iter': 9572}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "\u001b[32m[I 2022-11-10 13:44:20,089]\u001b[0m Trial 32 finished with value: 0.08316081214816985 and parameters: {'solver': 'newton-cg', 'max_iter': 6713}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 13:45:47,418]\u001b[0m Trial 33 finished with value: 0.0843136368368469 and parameters: {'solver': 'sag', 'max_iter': 12203}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 13:46:59,053]\u001b[0m Trial 34 finished with value: 0.08368325595141432 and parameters: {'solver': 'liblinear', 'max_iter': 14497}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 13:48:02,605]\u001b[0m Trial 35 finished with value: 0.08420548234520572 and parameters: {'solver': 'saga', 'max_iter': 10303}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "\u001b[32m[I 2022-11-10 13:48:58,692]\u001b[0m Trial 36 finished with value: 0.08490141414843982 and parameters: {'solver': 'newton-cg', 'max_iter': 16509}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 13:50:26,904]\u001b[0m Trial 37 finished with value: 0.08321881212817037 and parameters: {'solver': 'sag', 'max_iter': 12586}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 13:51:30,118]\u001b[0m Trial 38 finished with value: 0.08496395417871483 and parameters: {'solver': 'saga', 'max_iter': 8245}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 13:52:02,812]\u001b[0m Trial 39 finished with value: 0.08450204350969334 and parameters: {'solver': 'lbfgs', 'max_iter': 24170}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "\u001b[32m[I 2022-11-10 13:53:00,996]\u001b[0m Trial 40 finished with value: 0.0847010512185223 and parameters: {'solver': 'newton-cg', 'max_iter': 13343}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "\u001b[32m[I 2022-11-10 13:53:56,609]\u001b[0m Trial 41 finished with value: 0.08413044820385893 and parameters: {'solver': 'newton-cg', 'max_iter': 9850}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "\u001b[32m[I 2022-11-10 13:54:50,885]\u001b[0m Trial 42 finished with value: 0.08451340250216038 and parameters: {'solver': 'newton-cg', 'max_iter': 9240}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "\u001b[32m[I 2022-11-10 13:55:44,920]\u001b[0m Trial 43 finished with value: 0.0843859352676376 and parameters: {'solver': 'newton-cg', 'max_iter': 10601}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "\u001b[32m[I 2022-11-10 13:56:38,621]\u001b[0m Trial 44 finished with value: 0.08449858404536016 and parameters: {'solver': 'newton-cg', 'max_iter': 6148}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 13:58:04,104]\u001b[0m Trial 45 finished with value: 0.0828307051748617 and parameters: {'solver': 'sag', 'max_iter': 8396}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "\u001b[32m[I 2022-11-10 13:58:56,709]\u001b[0m Trial 46 finished with value: 0.08414091957839716 and parameters: {'solver': 'newton-cg', 'max_iter': 11471}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 14:00:07,411]\u001b[0m Trial 47 finished with value: 0.08470186580426471 and parameters: {'solver': 'liblinear', 'max_iter': 15580}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 14:00:40,986]\u001b[0m Trial 48 finished with value: 0.08388586467148357 and parameters: {'solver': 'lbfgs', 'max_iter': 29848}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "\u001b[32m[I 2022-11-10 14:01:36,537]\u001b[0m Trial 49 finished with value: 0.08131900480434527 and parameters: {'solver': 'newton-cg', 'max_iter': 13764}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 14:02:09,002]\u001b[0m Trial 50 finished with value: 0.08270808051470402 and parameters: {'solver': 'lbfgs', 'max_iter': 9314}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-10 14:02:41,793]\u001b[0m Trial 51 finished with value: 0.0845807213242351 and parameters: {'solver': 'lbfgs', 'max_iter': 34287}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 14:03:15,322]\u001b[0m Trial 52 finished with value: 0.08563133625168341 and parameters: {'solver': 'lbfgs', 'max_iter': 20256}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 14:03:48,721]\u001b[0m Trial 53 finished with value: 0.08306797227318621 and parameters: {'solver': 'lbfgs', 'max_iter': 22690}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 14:04:22,409]\u001b[0m Trial 54 finished with value: 0.08338501874357081 and parameters: {'solver': 'lbfgs', 'max_iter': 20557}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 14:04:55,805]\u001b[0m Trial 55 finished with value: 0.08368854280752827 and parameters: {'solver': 'lbfgs', 'max_iter': 25110}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 14:05:58,996]\u001b[0m Trial 56 finished with value: 0.08295253310277043 and parameters: {'solver': 'saga', 'max_iter': 21482}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "\u001b[32m[I 2022-11-10 14:06:54,129]\u001b[0m Trial 57 finished with value: 0.0849635814955414 and parameters: {'solver': 'newton-cg', 'max_iter': 18692}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 14:07:27,389]\u001b[0m Trial 58 finished with value: 0.08372663179437177 and parameters: {'solver': 'lbfgs', 'max_iter': 27631}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "\u001b[32m[I 2022-11-10 14:08:22,233]\u001b[0m Trial 59 finished with value: 0.08493295245912277 and parameters: {'solver': 'newton-cg', 'max_iter': 17487}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 14:08:55,265]\u001b[0m Trial 60 finished with value: 0.08485083818752363 and parameters: {'solver': 'lbfgs', 'max_iter': 7460}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 14:09:29,447]\u001b[0m Trial 61 finished with value: 0.08307884430274834 and parameters: {'solver': 'lbfgs', 'max_iter': 19018}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 14:10:02,775]\u001b[0m Trial 62 finished with value: 0.08388430700506938 and parameters: {'solver': 'lbfgs', 'max_iter': 11323}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 14:10:36,456]\u001b[0m Trial 63 finished with value: 0.08441992258849065 and parameters: {'solver': 'lbfgs', 'max_iter': 5948}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 14:11:48,450]\u001b[0m Trial 64 finished with value: 0.08367712930909729 and parameters: {'solver': 'liblinear', 'max_iter': 24969}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 14:12:21,185]\u001b[0m Trial 65 finished with value: 0.08389513975215959 and parameters: {'solver': 'lbfgs', 'max_iter': 28444}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 14:13:48,433]\u001b[0m Trial 66 finished with value: 0.08310633455302849 and parameters: {'solver': 'sag', 'max_iter': 22722}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "\u001b[32m[I 2022-11-10 14:14:45,653]\u001b[0m Trial 67 finished with value: 0.08321115768163646 and parameters: {'solver': 'newton-cg', 'max_iter': 30880}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 14:15:18,993]\u001b[0m Trial 68 finished with value: 0.08485359781200083 and parameters: {'solver': 'lbfgs', 'max_iter': 15950}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "\u001b[32m[I 2022-11-10 14:16:14,673]\u001b[0m Trial 69 finished with value: 0.08452089334155068 and parameters: {'solver': 'newton-cg', 'max_iter': 9059}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 14:17:17,096]\u001b[0m Trial 70 finished with value: 0.08488332957677265 and parameters: {'solver': 'saga', 'max_iter': 14340}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 14:17:49,559]\u001b[0m Trial 71 finished with value: 0.08311132671101214 and parameters: {'solver': 'lbfgs', 'max_iter': 12616}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 14:18:22,515]\u001b[0m Trial 72 finished with value: 0.08404684740266465 and parameters: {'solver': 'lbfgs', 'max_iter': 10784}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 14:18:55,192]\u001b[0m Trial 73 finished with value: 0.08417398080780357 and parameters: {'solver': 'lbfgs', 'max_iter': 8139}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 14:19:28,881]\u001b[0m Trial 74 finished with value: 0.0833399912346974 and parameters: {'solver': 'lbfgs', 'max_iter': 12091}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 14:20:01,654]\u001b[0m Trial 75 finished with value: 0.0847656432978769 and parameters: {'solver': 'lbfgs', 'max_iter': 7418}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "\u001b[32m[I 2022-11-10 14:20:59,038]\u001b[0m Trial 76 finished with value: 0.08442977264890132 and parameters: {'solver': 'newton-cg', 'max_iter': 19364}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 14:22:08,768]\u001b[0m Trial 77 finished with value: 0.08451464898049887 and parameters: {'solver': 'liblinear', 'max_iter': 13221}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 14:22:41,583]\u001b[0m Trial 78 finished with value: 0.08486998711941936 and parameters: {'solver': 'lbfgs', 'max_iter': 33012}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "\u001b[32m[I 2022-11-10 14:23:35,043]\u001b[0m Trial 79 finished with value: 0.08246600752706304 and parameters: {'solver': 'newton-cg', 'max_iter': 9643}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 14:25:01,553]\u001b[0m Trial 80 finished with value: 0.08329542352088011 and parameters: {'solver': 'sag', 'max_iter': 5837}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 14:26:05,180]\u001b[0m Trial 81 finished with value: 0.08398590115763659 and parameters: {'solver': 'saga', 'max_iter': 6848}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 14:27:08,008]\u001b[0m Trial 82 finished with value: 0.08539653668205864 and parameters: {'solver': 'saga', 'max_iter': 8061}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 14:28:09,956]\u001b[0m Trial 83 finished with value: 0.0843215784570197 and parameters: {'solver': 'saga', 'max_iter': 11064}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 14:29:13,443]\u001b[0m Trial 84 finished with value: 0.08317512010160318 and parameters: {'solver': 'saga', 'max_iter': 10191}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 14:30:15,975]\u001b[0m Trial 85 finished with value: 0.08436355323761327 and parameters: {'solver': 'saga', 'max_iter': 8611}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "\u001b[32m[I 2022-11-10 14:31:09,308]\u001b[0m Trial 86 finished with value: 0.08377117151506175 and parameters: {'solver': 'newton-cg', 'max_iter': 14943}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-10 14:31:42,198]\u001b[0m Trial 87 finished with value: 0.08457368972682006 and parameters: {'solver': 'lbfgs', 'max_iter': 23341}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 14:32:15,127]\u001b[0m Trial 88 finished with value: 0.08440213754144776 and parameters: {'solver': 'lbfgs', 'max_iter': 20657}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "\u001b[32m[I 2022-11-10 14:33:08,210]\u001b[0m Trial 89 finished with value: 0.08424602067519382 and parameters: {'solver': 'newton-cg', 'max_iter': 11947}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 14:34:10,436]\u001b[0m Trial 90 finished with value: 0.08474654261067714 and parameters: {'solver': 'saga', 'max_iter': 5200}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 14:35:13,751]\u001b[0m Trial 91 finished with value: 0.08555087518105457 and parameters: {'solver': 'saga', 'max_iter': 8031}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 14:36:16,044]\u001b[0m Trial 92 finished with value: 0.08472339777469422 and parameters: {'solver': 'saga', 'max_iter': 7752}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 14:37:17,880]\u001b[0m Trial 93 finished with value: 0.08262998603680918 and parameters: {'solver': 'saga', 'max_iter': 8991}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 14:38:18,962]\u001b[0m Trial 94 finished with value: 0.08545707256378236 and parameters: {'solver': 'saga', 'max_iter': 9706}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 14:39:21,351]\u001b[0m Trial 95 finished with value: 0.08541180914519574 and parameters: {'solver': 'saga', 'max_iter': 6548}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 14:40:22,609]\u001b[0m Trial 96 finished with value: 0.08269817123142176 and parameters: {'solver': 'saga', 'max_iter': 6722}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 14:41:25,738]\u001b[0m Trial 97 finished with value: 0.08491865750497256 and parameters: {'solver': 'saga', 'max_iter': 9690}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 14:42:28,346]\u001b[0m Trial 98 finished with value: 0.08378241434140914 and parameters: {'solver': 'saga', 'max_iter': 8253}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 14:43:31,646]\u001b[0m Trial 99 finished with value: 0.08535902634064614 and parameters: {'solver': 'saga', 'max_iter': 5958}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 14:44:33,754]\u001b[0m Trial 100 finished with value: 0.08226286402496387 and parameters: {'solver': 'saga', 'max_iter': 5220}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 14:45:35,179]\u001b[0m Trial 101 finished with value: 0.08419927034485361 and parameters: {'solver': 'saga', 'max_iter': 6368}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 14:46:37,540]\u001b[0m Trial 102 finished with value: 0.08116400653817946 and parameters: {'solver': 'saga', 'max_iter': 7554}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 14:47:40,114]\u001b[0m Trial 103 finished with value: 0.0828558354458925 and parameters: {'solver': 'saga', 'max_iter': 5646}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 14:48:42,320]\u001b[0m Trial 104 finished with value: 0.08310017402536402 and parameters: {'solver': 'saga', 'max_iter': 7223}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 14:49:45,913]\u001b[0m Trial 105 finished with value: 0.0843223646605266 and parameters: {'solver': 'saga', 'max_iter': 10201}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 14:50:47,984]\u001b[0m Trial 106 finished with value: 0.08240487701597783 and parameters: {'solver': 'saga', 'max_iter': 8509}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 14:51:50,938]\u001b[0m Trial 107 finished with value: 0.08242222931665863 and parameters: {'solver': 'saga', 'max_iter': 6436}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "\u001b[32m[I 2022-11-10 14:52:45,552]\u001b[0m Trial 108 finished with value: 0.08359175772967214 and parameters: {'solver': 'newton-cg', 'max_iter': 7884}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 14:53:57,336]\u001b[0m Trial 109 finished with value: 0.08394462740923363 and parameters: {'solver': 'liblinear', 'max_iter': 9428}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 14:55:00,568]\u001b[0m Trial 110 finished with value: 0.083061985223366 and parameters: {'solver': 'saga', 'max_iter': 8855}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 14:56:27,247]\u001b[0m Trial 111 finished with value: 0.08369034625950421 and parameters: {'solver': 'sag', 'max_iter': 25192}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "\u001b[32m[I 2022-11-10 14:57:20,714]\u001b[0m Trial 112 finished with value: 0.082781872270277 and parameters: {'solver': 'newton-cg', 'max_iter': 17809}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 14:58:24,134]\u001b[0m Trial 113 finished with value: 0.0825828623668455 and parameters: {'solver': 'saga', 'max_iter': 21367}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "\u001b[32m[I 2022-11-10 14:59:20,334]\u001b[0m Trial 114 finished with value: 0.08451300818286075 and parameters: {'solver': 'newton-cg', 'max_iter': 26226}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 14:59:53,070]\u001b[0m Trial 115 finished with value: 0.0839903366502319 and parameters: {'solver': 'lbfgs', 'max_iter': 7084}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 15:00:55,717]\u001b[0m Trial 116 finished with value: 0.08519372292043827 and parameters: {'solver': 'saga', 'max_iter': 16556}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 15:01:58,607]\u001b[0m Trial 117 finished with value: 0.08423605333429586 and parameters: {'solver': 'saga', 'max_iter': 10596}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 15:03:01,854]\u001b[0m Trial 118 finished with value: 0.08283908208885174 and parameters: {'solver': 'saga', 'max_iter': 16443}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 15:04:03,925]\u001b[0m Trial 119 finished with value: 0.08383873710672506 and parameters: {'solver': 'saga', 'max_iter': 11149}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 15:05:06,482]\u001b[0m Trial 120 finished with value: 0.08358360954542722 and parameters: {'solver': 'saga', 'max_iter': 5827}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-10 15:05:39,316]\u001b[0m Trial 121 finished with value: 0.08382635764202416 and parameters: {'solver': 'lbfgs', 'max_iter': 18149}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "\u001b[32m[I 2022-11-10 15:06:34,939]\u001b[0m Trial 122 finished with value: 0.08420682052500962 and parameters: {'solver': 'newton-cg', 'max_iter': 9909}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 15:07:37,964]\u001b[0m Trial 123 finished with value: 0.08257831374641333 and parameters: {'solver': 'saga', 'max_iter': 19978}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 15:08:10,814]\u001b[0m Trial 124 finished with value: 0.08423535751693607 and parameters: {'solver': 'lbfgs', 'max_iter': 17029}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "\u001b[32m[I 2022-11-10 15:09:04,149]\u001b[0m Trial 125 finished with value: 0.08342299072242298 and parameters: {'solver': 'newton-cg', 'max_iter': 8186}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 15:10:14,841]\u001b[0m Trial 126 finished with value: 0.0843906064421264 and parameters: {'solver': 'liblinear', 'max_iter': 22136}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 15:11:17,807]\u001b[0m Trial 127 finished with value: 0.08509712513252814 and parameters: {'solver': 'saga', 'max_iter': 13011}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 15:11:50,810]\u001b[0m Trial 128 finished with value: 0.08444858198510524 and parameters: {'solver': 'lbfgs', 'max_iter': 8967}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 15:12:52,654]\u001b[0m Trial 129 finished with value: 0.08310470707097592 and parameters: {'solver': 'saga', 'max_iter': 6688}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 15:14:18,967]\u001b[0m Trial 130 finished with value: 0.0848619228259809 and parameters: {'solver': 'sag', 'max_iter': 19718}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 15:15:22,077]\u001b[0m Trial 131 finished with value: 0.08319379080419732 and parameters: {'solver': 'saga', 'max_iter': 12753}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 15:16:23,633]\u001b[0m Trial 132 finished with value: 0.08411048426471968 and parameters: {'solver': 'saga', 'max_iter': 11688}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 15:17:27,057]\u001b[0m Trial 133 finished with value: 0.08559828178889037 and parameters: {'solver': 'saga', 'max_iter': 9488}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 15:18:29,562]\u001b[0m Trial 134 finished with value: 0.08298391479589409 and parameters: {'solver': 'saga', 'max_iter': 9469}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "\u001b[32m[I 2022-11-10 15:19:22,664]\u001b[0m Trial 135 finished with value: 0.08527703862745005 and parameters: {'solver': 'newton-cg', 'max_iter': 7754}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "\u001b[32m[I 2022-11-10 15:20:17,272]\u001b[0m Trial 136 finished with value: 0.08402356517865858 and parameters: {'solver': 'newton-cg', 'max_iter': 7630}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "\u001b[32m[I 2022-11-10 15:21:12,893]\u001b[0m Trial 137 finished with value: 0.08353355863348927 and parameters: {'solver': 'newton-cg', 'max_iter': 8652}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "\u001b[32m[I 2022-11-10 15:22:14,761]\u001b[0m Trial 138 finished with value: 0.08559623797253635 and parameters: {'solver': 'newton-cg', 'max_iter': 7069}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "\u001b[32m[I 2022-11-10 15:23:08,562]\u001b[0m Trial 139 finished with value: 0.08384756669069797 and parameters: {'solver': 'newton-cg', 'max_iter': 6241}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:415: LineSearchWarning:\n",
      "\n",
      "Rounding errors prevent the line search from converging\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "\u001b[32m[I 2022-11-10 15:24:00,727]\u001b[0m Trial 140 finished with value: 0.08260329052765258 and parameters: {'solver': 'newton-cg', 'max_iter': 7355}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "\u001b[32m[I 2022-11-10 15:24:56,169]\u001b[0m Trial 141 finished with value: 0.08439603251040155 and parameters: {'solver': 'newton-cg', 'max_iter': 8189}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "\u001b[32m[I 2022-11-10 15:25:51,914]\u001b[0m Trial 142 finished with value: 0.08555066981676927 and parameters: {'solver': 'newton-cg', 'max_iter': 7042}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:415: LineSearchWarning:\n",
      "\n",
      "Rounding errors prevent the line search from converging\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "\u001b[32m[I 2022-11-10 15:26:47,471]\u001b[0m Trial 143 finished with value: 0.084466817734393 and parameters: {'solver': 'newton-cg', 'max_iter': 7087}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "\u001b[32m[I 2022-11-10 15:27:39,959]\u001b[0m Trial 144 finished with value: 0.08539099897621448 and parameters: {'solver': 'newton-cg', 'max_iter': 5356}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "\u001b[32m[I 2022-11-10 15:28:34,656]\u001b[0m Trial 145 finished with value: 0.08348345804889185 and parameters: {'solver': 'newton-cg', 'max_iter': 5524}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "\u001b[32m[I 2022-11-10 15:29:32,963]\u001b[0m Trial 146 finished with value: 0.08275410491516072 and parameters: {'solver': 'newton-cg', 'max_iter': 5790}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "\u001b[32m[I 2022-11-10 15:30:29,422]\u001b[0m Trial 147 finished with value: 0.08211321194350668 and parameters: {'solver': 'newton-cg', 'max_iter': 6324}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "\u001b[32m[I 2022-11-10 15:31:28,685]\u001b[0m Trial 148 finished with value: 0.08193824948691254 and parameters: {'solver': 'newton-cg', 'max_iter': 5031}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "\u001b[32m[I 2022-11-10 15:32:23,155]\u001b[0m Trial 149 finished with value: 0.08374528952452742 and parameters: {'solver': 'newton-cg', 'max_iter': 6945}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "\u001b[32m[I 2022-11-10 15:33:20,503]\u001b[0m Trial 150 finished with value: 0.0836696049137073 and parameters: {'solver': 'newton-cg', 'max_iter': 8721}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "\u001b[32m[I 2022-11-10 15:34:16,296]\u001b[0m Trial 151 finished with value: 0.08553735468357021 and parameters: {'solver': 'newton-cg', 'max_iter': 8020}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "\u001b[32m[I 2022-11-10 15:35:11,956]\u001b[0m Trial 152 finished with value: 0.08384454351937327 and parameters: {'solver': 'newton-cg', 'max_iter': 9771}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "\u001b[32m[I 2022-11-10 15:36:06,847]\u001b[0m Trial 153 finished with value: 0.08332777919550038 and parameters: {'solver': 'newton-cg', 'max_iter': 7940}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "\u001b[32m[I 2022-11-10 15:37:03,388]\u001b[0m Trial 154 finished with value: 0.08400308077913655 and parameters: {'solver': 'newton-cg', 'max_iter': 10474}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "\u001b[32m[I 2022-11-10 15:38:00,038]\u001b[0m Trial 155 finished with value: 0.08087197465155423 and parameters: {'solver': 'newton-cg', 'max_iter': 6775}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "\u001b[32m[I 2022-11-10 15:38:56,348]\u001b[0m Trial 156 finished with value: 0.08275687219112186 and parameters: {'solver': 'newton-cg', 'max_iter': 6162}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "\u001b[32m[I 2022-11-10 15:39:53,944]\u001b[0m Trial 157 finished with value: 0.08300705816719194 and parameters: {'solver': 'newton-cg', 'max_iter': 9360}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 15:41:06,714]\u001b[0m Trial 158 finished with value: 0.08231461486217997 and parameters: {'solver': 'liblinear', 'max_iter': 8562}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 15:42:09,339]\u001b[0m Trial 159 finished with value: 0.08355524424310672 and parameters: {'solver': 'saga', 'max_iter': 7337}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "\u001b[32m[I 2022-11-10 15:43:04,539]\u001b[0m Trial 160 finished with value: 0.08431897961153681 and parameters: {'solver': 'newton-cg', 'max_iter': 9255}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "\u001b[32m[I 2022-11-10 15:43:56,943]\u001b[0m Trial 161 finished with value: 0.08220349396009516 and parameters: {'solver': 'newton-cg', 'max_iter': 7789}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "\u001b[32m[I 2022-11-10 15:44:53,297]\u001b[0m Trial 162 finished with value: 0.08162279033079872 and parameters: {'solver': 'newton-cg', 'max_iter': 7765}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "\u001b[32m[I 2022-11-10 15:45:53,280]\u001b[0m Trial 163 finished with value: 0.08216430782272735 and parameters: {'solver': 'newton-cg', 'max_iter': 6498}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "\u001b[32m[I 2022-11-10 15:46:50,515]\u001b[0m Trial 164 finished with value: 0.08499604901298187 and parameters: {'solver': 'newton-cg', 'max_iter': 8505}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 15:47:24,478]\u001b[0m Trial 165 finished with value: 0.08262328618878637 and parameters: {'solver': 'lbfgs', 'max_iter': 10137}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 15:48:26,425]\u001b[0m Trial 166 finished with value: 0.08433676088384168 and parameters: {'solver': 'saga', 'max_iter': 5652}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "\u001b[32m[I 2022-11-10 15:49:23,436]\u001b[0m Trial 167 finished with value: 0.08367892762498302 and parameters: {'solver': 'newton-cg', 'max_iter': 7092}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 15:50:49,941]\u001b[0m Trial 168 finished with value: 0.08347143781605103 and parameters: {'solver': 'sag', 'max_iter': 8188}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 15:51:52,168]\u001b[0m Trial 169 finished with value: 0.08293869609619513 and parameters: {'solver': 'saga', 'max_iter': 7475}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "\u001b[32m[I 2022-11-10 15:52:47,106]\u001b[0m Trial 170 finished with value: 0.08383830172204115 and parameters: {'solver': 'newton-cg', 'max_iter': 8991}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 15:53:50,534]\u001b[0m Trial 171 finished with value: 0.08349982958911312 and parameters: {'solver': 'saga', 'max_iter': 5054}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 15:54:52,110]\u001b[0m Trial 172 finished with value: 0.08376050337986983 and parameters: {'solver': 'saga', 'max_iter': 10907}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 15:55:54,993]\u001b[0m Trial 173 finished with value: 0.0833045753797499 and parameters: {'solver': 'saga', 'max_iter': 23497}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 15:56:57,110]\u001b[0m Trial 174 finished with value: 0.08251977631444052 and parameters: {'solver': 'saga', 'max_iter': 6471}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 15:57:59,171]\u001b[0m Trial 175 finished with value: 0.08508667286810963 and parameters: {'solver': 'saga', 'max_iter': 13783}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 15:58:31,574]\u001b[0m Trial 176 finished with value: 0.08335387822078831 and parameters: {'solver': 'lbfgs', 'max_iter': 9839}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-10 15:59:34,132]\u001b[0m Trial 177 finished with value: 0.08367548748830239 and parameters: {'solver': 'saga', 'max_iter': 28786}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "\u001b[32m[I 2022-11-10 16:00:27,777]\u001b[0m Trial 178 finished with value: 0.08406873086573677 and parameters: {'solver': 'newton-cg', 'max_iter': 6014}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 16:01:29,845]\u001b[0m Trial 179 finished with value: 0.08305325119571202 and parameters: {'solver': 'saga', 'max_iter': 27402}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 16:02:02,284]\u001b[0m Trial 180 finished with value: 0.08525747314385433 and parameters: {'solver': 'lbfgs', 'max_iter': 9210}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 16:02:35,322]\u001b[0m Trial 181 finished with value: 0.08383966454599157 and parameters: {'solver': 'lbfgs', 'max_iter': 9209}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 16:03:08,744]\u001b[0m Trial 182 finished with value: 0.08452177720568776 and parameters: {'solver': 'lbfgs', 'max_iter': 8162}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 16:03:41,708]\u001b[0m Trial 183 finished with value: 0.08394535989345239 and parameters: {'solver': 'lbfgs', 'max_iter': 10545}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 16:04:14,413]\u001b[0m Trial 184 finished with value: 0.08550805616988055 and parameters: {'solver': 'lbfgs', 'max_iter': 24158}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 16:04:46,908]\u001b[0m Trial 185 finished with value: 0.08500987194721044 and parameters: {'solver': 'lbfgs', 'max_iter': 24599}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 16:05:19,700]\u001b[0m Trial 186 finished with value: 0.08386593843206734 and parameters: {'solver': 'lbfgs', 'max_iter': 7085}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 16:05:52,454]\u001b[0m Trial 187 finished with value: 0.08543489359209927 and parameters: {'solver': 'lbfgs', 'max_iter': 8608}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 16:06:25,340]\u001b[0m Trial 188 finished with value: 0.08321282457501498 and parameters: {'solver': 'lbfgs', 'max_iter': 25840}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 16:06:58,528]\u001b[0m Trial 189 finished with value: 0.08475238435034523 and parameters: {'solver': 'lbfgs', 'max_iter': 8588}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 16:07:32,227]\u001b[0m Trial 190 finished with value: 0.08491552526847233 and parameters: {'solver': 'lbfgs', 'max_iter': 7572}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 16:08:06,153]\u001b[0m Trial 191 finished with value: 0.08508828371054179 and parameters: {'solver': 'lbfgs', 'max_iter': 24179}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 16:08:39,416]\u001b[0m Trial 192 finished with value: 0.08263616230570539 and parameters: {'solver': 'lbfgs', 'max_iter': 9670}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 16:09:13,109]\u001b[0m Trial 193 finished with value: 0.08390746013645378 and parameters: {'solver': 'lbfgs', 'max_iter': 8930}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 16:09:46,751]\u001b[0m Trial 194 finished with value: 0.08322982567723175 and parameters: {'solver': 'lbfgs', 'max_iter': 25582}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "\u001b[32m[I 2022-11-10 16:10:43,045]\u001b[0m Trial 195 finished with value: 0.08367795285141925 and parameters: {'solver': 'newton-cg', 'max_iter': 7857}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 16:11:16,848]\u001b[0m Trial 196 finished with value: 0.08481958933526465 and parameters: {'solver': 'lbfgs', 'max_iter': 26857}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "\u001b[32m[I 2022-11-10 16:12:11,387]\u001b[0m Trial 197 finished with value: 0.08339564060968528 and parameters: {'solver': 'newton-cg', 'max_iter': 6953}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 16:13:24,572]\u001b[0m Trial 198 finished with value: 0.08309784131029814 and parameters: {'solver': 'liblinear', 'max_iter': 8187}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "\u001b[32m[I 2022-11-10 16:14:20,466]\u001b[0m Trial 199 finished with value: 0.08336943114652365 and parameters: {'solver': 'newton-cg', 'max_iter': 10051}. Best is trial 29 with value: 0.08659027930342719.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study_lgr_100_1 = optuna.create_study(direction='maximize')\n",
    "study_lgr_100_1.optimize(objective_lgr_100_1, n_trials=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "e8d2e079",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-10T19:34:02.619908Z",
     "start_time": "2022-11-10T19:34:02.556800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['study_lgr100_1.pkl']"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(study_lgr_100_1, \"study_lgr100_1.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "0e54ca82",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-19T20:39:56.195378Z",
     "start_time": "2022-11-19T20:39:56.115451Z"
    }
   },
   "outputs": [],
   "source": [
    "study_lgr_100_1 = joblib.load(\"study_lgr100_1.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "5870fc8c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-10T19:34:03.140025Z",
     "start_time": "2022-11-10T19:34:03.135988Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Value: 0.08659027930342719\n",
      "Best Parameters: {'solver': 'newton-cg', 'max_iter': 7590}\n"
     ]
    }
   ],
   "source": [
    "print('Best Value: {}'.format(study_lgr_100_1.best_value))\n",
    "print('Best Parameters: {}'.format(study_lgr_100_1.best_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f29e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study_lgr_100_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe16f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study_lgr_100_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92dcdfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_slice(study_lgr_100_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a974fad",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a297c41",
   "metadata": {},
   "source": [
    "Logistic Regression PCA 100 - Study 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "650acf77",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-12T17:50:20.401720Z",
     "start_time": "2022-11-12T17:50:20.374721Z"
    }
   },
   "outputs": [],
   "source": [
    "# Se utiliza 'max_iter' =  7590 obtenido del study 1 y se busca optimizar el hiperparámetro 'solver'.\n",
    "\n",
    "def objective_lgr_100_2(trial):\n",
    "    solver_trial = trial.suggest_categorical('solver',['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'])\n",
    "\n",
    "    lgr = LogisticRegression(solver = solver_trial, max_iter =  7590)\n",
    "\n",
    "    skf = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 1 )\n",
    "\n",
    "    lgr_100_results    = []\n",
    "    \n",
    "    for train_index, test_index in skf.split(X,y):\n",
    "    \n",
    "        X_train, X_test = pca_100.fit_transform(X.iloc[train_index]), pca_100.transform(X.iloc[test_index])\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "        lgr.fit(X_train, y_train)\n",
    "    \n",
    "        y_pred = lgr.predict(X_test)\n",
    "    \n",
    "        recall    = recall_score(y_test, y_pred)\n",
    "\n",
    "        list_results   = [recall]\n",
    "        lgr_100_results.append(list_results)\n",
    "    \n",
    "        \n",
    "    return gmean(lgr_100_results)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "e622a568",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-12T17:57:09.328379Z",
     "start_time": "2022-11-12T17:50:53.451484Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-12 14:50:53,468]\u001b[0m A new study created in memory with name: no-name-8e783b3c-1272-4ba6-93ae-44b909b05212\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 14:52:08,164]\u001b[0m Trial 0 finished with value: 0.08416825477201041 and parameters: {'solver': 'liblinear'}. Best is trial 0 with value: 0.08416825477201041.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 14:52:40,252]\u001b[0m Trial 1 finished with value: 0.08383175878317704 and parameters: {'solver': 'lbfgs'}. Best is trial 0 with value: 0.08416825477201041.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 14:53:48,206]\u001b[0m Trial 2 finished with value: 0.08215651349960994 and parameters: {'solver': 'saga'}. Best is trial 0 with value: 0.08416825477201041.\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "\u001b[32m[I 2022-11-12 14:54:49,585]\u001b[0m Trial 3 finished with value: 0.08276035353795429 and parameters: {'solver': 'newton-cg'}. Best is trial 0 with value: 0.08416825477201041.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 14:55:54,810]\u001b[0m Trial 4 finished with value: 0.08277169944599141 and parameters: {'solver': 'saga'}. Best is trial 0 with value: 0.08416825477201041.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 14:57:09,317]\u001b[0m Trial 5 finished with value: 0.08448839539839466 and parameters: {'solver': 'liblinear'}. Best is trial 5 with value: 0.08448839539839466.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study_lgr_100_2 = optuna.create_study(direction='maximize')\n",
    "study_lgr_100_2.optimize(objective_lgr_100_2, n_trials=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "cd207fd3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-12T17:57:09.375886Z",
     "start_time": "2022-11-12T17:57:09.330346Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['study_lgr100_2.pkl']"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(study_lgr_100_2, \"study_lgr100_2.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "9cb40aca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-19T20:46:23.386813Z",
     "start_time": "2022-11-19T20:46:23.348724Z"
    }
   },
   "outputs": [],
   "source": [
    "study_lgr_100_2 = joblib.load(\"study_lgr100_2.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "93d6da0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-12T17:57:35.712759Z",
     "start_time": "2022-11-12T17:57:35.707757Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Value: 0.08448839539839466\n",
      "Best Parameters: {'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "print('Best Value: {}'.format(study_lgr_100_2.best_value))\n",
    "print('Best Parameters: {}'.format(study_lgr_100_2.best_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe94d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_slice(study_lgr_100_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e719eb",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3823c136",
   "metadata": {},
   "source": [
    "Logistic Regression PCA 100 - Study 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "d56965e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-12T18:03:01.960591Z",
     "start_time": "2022-11-12T18:03:01.952375Z"
    }
   },
   "outputs": [],
   "source": [
    "# Se busca optimizar de nuevo los hiperparámetros 'solver' y 'max_trial' teniendo en cuenta los rangos donde se obtuvo \n",
    "# mejores resultados en el study 1.\n",
    "\n",
    "def objective_lgr_100_3(trial):\n",
    "    solver_trial = trial.suggest_categorical('solver',['newton-cg', 'lbfgs', 'saga'])\n",
    "    max_iter_trial = trial.suggest_int('max_iter', 7000,11000)\n",
    "\n",
    "    lgr = LogisticRegression(solver = solver_trial, max_iter = max_iter_trial)\n",
    "\n",
    "    skf = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 1 )\n",
    "\n",
    "    lgr_100_results    = []\n",
    "    \n",
    "    for train_index, test_index in skf.split(X,y):\n",
    "    \n",
    "        X_train, X_test = pca_100.fit_transform(X.iloc[train_index]), pca_100.transform(X.iloc[test_index])\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "        lgr.fit(X_train, y_train)\n",
    "    \n",
    "        y_pred = lgr.predict(X_test)\n",
    "    \n",
    "        recall    = recall_score(y_test, y_pred)\n",
    "\n",
    "        list_results   = [recall]\n",
    "        lgr_100_results.append(list_results)\n",
    "    \n",
    "        \n",
    "    return gmean(lgr_100_results)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "f9a310ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-12T19:22:15.423961Z",
     "start_time": "2022-11-12T18:03:36.364128Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-12 15:03:36,366]\u001b[0m A new study created in memory with name: no-name-2a682a03-c9f0-4c78-a179-40653060fa9a\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "\u001b[32m[I 2022-11-12 15:04:30,589]\u001b[0m Trial 0 finished with value: 0.08395747955991308 and parameters: {'solver': 'newton-cg', 'max_iter': 10629}. Best is trial 0 with value: 0.08395747955991308.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 15:05:03,033]\u001b[0m Trial 1 finished with value: 0.08441317618333527 and parameters: {'solver': 'lbfgs', 'max_iter': 7178}. Best is trial 1 with value: 0.08441317618333527.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 15:05:36,183]\u001b[0m Trial 2 finished with value: 0.08453536024421239 and parameters: {'solver': 'lbfgs', 'max_iter': 9291}. Best is trial 2 with value: 0.08453536024421239.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 15:06:40,361]\u001b[0m Trial 3 finished with value: 0.0831558155380223 and parameters: {'solver': 'saga', 'max_iter': 7466}. Best is trial 2 with value: 0.08453536024421239.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 15:07:44,412]\u001b[0m Trial 4 finished with value: 0.08419200840856 and parameters: {'solver': 'saga', 'max_iter': 7651}. Best is trial 2 with value: 0.08453536024421239.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 15:08:17,285]\u001b[0m Trial 5 finished with value: 0.08478694494312886 and parameters: {'solver': 'lbfgs', 'max_iter': 8664}. Best is trial 5 with value: 0.08478694494312886.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 15:08:48,990]\u001b[0m Trial 6 finished with value: 0.08496816195067743 and parameters: {'solver': 'lbfgs', 'max_iter': 7457}. Best is trial 6 with value: 0.08496816195067743.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 15:09:52,645]\u001b[0m Trial 7 finished with value: 0.08274165450135368 and parameters: {'solver': 'saga', 'max_iter': 7246}. Best is trial 6 with value: 0.08496816195067743.\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "\u001b[32m[I 2022-11-12 15:10:45,076]\u001b[0m Trial 8 finished with value: 0.08445341384147856 and parameters: {'solver': 'newton-cg', 'max_iter': 7422}. Best is trial 6 with value: 0.08496816195067743.\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "\u001b[32m[I 2022-11-12 15:11:44,047]\u001b[0m Trial 9 finished with value: 0.08351385530763873 and parameters: {'solver': 'newton-cg', 'max_iter': 10073}. Best is trial 6 with value: 0.08496816195067743.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 15:12:17,251]\u001b[0m Trial 10 finished with value: 0.08409959187530419 and parameters: {'solver': 'lbfgs', 'max_iter': 8428}. Best is trial 6 with value: 0.08496816195067743.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 15:12:50,201]\u001b[0m Trial 11 finished with value: 0.08211381525549782 and parameters: {'solver': 'lbfgs', 'max_iter': 8548}. Best is trial 6 with value: 0.08496816195067743.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 15:13:23,938]\u001b[0m Trial 12 finished with value: 0.08361577313162183 and parameters: {'solver': 'lbfgs', 'max_iter': 9304}. Best is trial 6 with value: 0.08496816195067743.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 15:13:57,233]\u001b[0m Trial 13 finished with value: 0.08298701212712307 and parameters: {'solver': 'lbfgs', 'max_iter': 8163}. Best is trial 6 with value: 0.08496816195067743.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 15:14:30,307]\u001b[0m Trial 14 finished with value: 0.08522639901110489 and parameters: {'solver': 'lbfgs', 'max_iter': 8054}. Best is trial 14 with value: 0.08522639901110489.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 15:15:04,002]\u001b[0m Trial 15 finished with value: 0.08304054604457901 and parameters: {'solver': 'lbfgs', 'max_iter': 7847}. Best is trial 14 with value: 0.08522639901110489.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 15:15:37,168]\u001b[0m Trial 16 finished with value: 0.08414985285453 and parameters: {'solver': 'lbfgs', 'max_iter': 8011}. Best is trial 14 with value: 0.08522639901110489.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 15:16:10,343]\u001b[0m Trial 17 finished with value: 0.08174415888533658 and parameters: {'solver': 'lbfgs', 'max_iter': 9025}. Best is trial 14 with value: 0.08522639901110489.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 15:17:14,268]\u001b[0m Trial 18 finished with value: 0.084107114492616 and parameters: {'solver': 'saga', 'max_iter': 8130}. Best is trial 14 with value: 0.08522639901110489.\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "\u001b[32m[I 2022-11-12 15:18:11,889]\u001b[0m Trial 19 finished with value: 0.08320190642681452 and parameters: {'solver': 'newton-cg', 'max_iter': 9764}. Best is trial 14 with value: 0.08522639901110489.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 15:18:44,996]\u001b[0m Trial 20 finished with value: 0.08401199420778184 and parameters: {'solver': 'lbfgs', 'max_iter': 7030}. Best is trial 14 with value: 0.08522639901110489.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 15:19:18,940]\u001b[0m Trial 21 finished with value: 0.085058142683163 and parameters: {'solver': 'lbfgs', 'max_iter': 8558}. Best is trial 14 with value: 0.08522639901110489.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 15:19:52,362]\u001b[0m Trial 22 finished with value: 0.08429502845290944 and parameters: {'solver': 'lbfgs', 'max_iter': 8877}. Best is trial 14 with value: 0.08522639901110489.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 15:20:25,266]\u001b[0m Trial 23 finished with value: 0.08495333402937771 and parameters: {'solver': 'lbfgs', 'max_iter': 7746}. Best is trial 14 with value: 0.08522639901110489.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 15:20:58,827]\u001b[0m Trial 24 finished with value: 0.08251712191459953 and parameters: {'solver': 'lbfgs', 'max_iter': 8316}. Best is trial 14 with value: 0.08522639901110489.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 15:21:34,599]\u001b[0m Trial 25 finished with value: 0.08448580060657303 and parameters: {'solver': 'lbfgs', 'max_iter': 7751}. Best is trial 14 with value: 0.08522639901110489.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 15:22:10,692]\u001b[0m Trial 26 finished with value: 0.0841061516795488 and parameters: {'solver': 'lbfgs', 'max_iter': 8805}. Best is trial 14 with value: 0.08522639901110489.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 15:23:17,192]\u001b[0m Trial 27 finished with value: 0.08452654952967911 and parameters: {'solver': 'saga', 'max_iter': 10991}. Best is trial 14 with value: 0.08522639901110489.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 15:23:50,401]\u001b[0m Trial 28 finished with value: 0.0840718110407455 and parameters: {'solver': 'lbfgs', 'max_iter': 9146}. Best is trial 14 with value: 0.08522639901110489.\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "\u001b[32m[I 2022-11-12 15:24:47,308]\u001b[0m Trial 29 finished with value: 0.08544975224618068 and parameters: {'solver': 'newton-cg', 'max_iter': 9861}. Best is trial 29 with value: 0.08544975224618068.\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "\u001b[32m[I 2022-11-12 15:25:46,763]\u001b[0m Trial 30 finished with value: 0.08438166241337382 and parameters: {'solver': 'newton-cg', 'max_iter': 9727}. Best is trial 29 with value: 0.08544975224618068.\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "\u001b[32m[I 2022-11-12 15:26:50,502]\u001b[0m Trial 31 finished with value: 0.08353226471726483 and parameters: {'solver': 'newton-cg', 'max_iter': 10314}. Best is trial 29 with value: 0.08544975224618068.\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "\u001b[32m[I 2022-11-12 15:27:48,131]\u001b[0m Trial 32 finished with value: 0.08145268786116154 and parameters: {'solver': 'newton-cg', 'max_iter': 9535}. Best is trial 29 with value: 0.08544975224618068.\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "\u001b[32m[I 2022-11-12 15:28:42,755]\u001b[0m Trial 33 finished with value: 0.08401535872514987 and parameters: {'solver': 'newton-cg', 'max_iter': 10669}. Best is trial 29 with value: 0.08544975224618068.\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "\u001b[32m[I 2022-11-12 15:29:41,364]\u001b[0m Trial 34 finished with value: 0.08415453362158824 and parameters: {'solver': 'newton-cg', 'max_iter': 7469}. Best is trial 29 with value: 0.08544975224618068.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 15:30:14,495]\u001b[0m Trial 35 finished with value: 0.0844530155664707 and parameters: {'solver': 'lbfgs', 'max_iter': 8340}. Best is trial 29 with value: 0.08544975224618068.\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "\u001b[32m[I 2022-11-12 15:31:08,282]\u001b[0m Trial 36 finished with value: 0.08129232425963351 and parameters: {'solver': 'newton-cg', 'max_iter': 7956}. Best is trial 29 with value: 0.08544975224618068.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 15:32:11,847]\u001b[0m Trial 37 finished with value: 0.08533152075361425 and parameters: {'solver': 'saga', 'max_iter': 7564}. Best is trial 29 with value: 0.08544975224618068.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 15:33:15,264]\u001b[0m Trial 38 finished with value: 0.0827527257776593 and parameters: {'solver': 'saga', 'max_iter': 8671}. Best is trial 29 with value: 0.08544975224618068.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 15:34:18,392]\u001b[0m Trial 39 finished with value: 0.08437967439071249 and parameters: {'solver': 'saga', 'max_iter': 10063}. Best is trial 29 with value: 0.08544975224618068.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 15:35:21,768]\u001b[0m Trial 40 finished with value: 0.0848124576776295 and parameters: {'solver': 'saga', 'max_iter': 7215}. Best is trial 29 with value: 0.08544975224618068.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 15:36:37,541]\u001b[0m Trial 41 finished with value: 0.08478834009503797 and parameters: {'solver': 'saga', 'max_iter': 7453}. Best is trial 29 with value: 0.08544975224618068.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 15:37:57,634]\u001b[0m Trial 42 finished with value: 0.08299589149033587 and parameters: {'solver': 'saga', 'max_iter': 7625}. Best is trial 29 with value: 0.08544975224618068.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 15:38:37,734]\u001b[0m Trial 43 finished with value: 0.08371667031259786 and parameters: {'solver': 'lbfgs', 'max_iter': 7023}. Best is trial 29 with value: 0.08544975224618068.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 15:39:18,672]\u001b[0m Trial 44 finished with value: 0.08358519155631491 and parameters: {'solver': 'lbfgs', 'max_iter': 7288}. Best is trial 29 with value: 0.08544975224618068.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 15:40:38,159]\u001b[0m Trial 45 finished with value: 0.08391264579089942 and parameters: {'solver': 'saga', 'max_iter': 7570}. Best is trial 29 with value: 0.08544975224618068.\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "\u001b[32m[I 2022-11-12 15:41:44,529]\u001b[0m Trial 46 finished with value: 0.08411527391088772 and parameters: {'solver': 'newton-cg', 'max_iter': 8183}. Best is trial 29 with value: 0.08544975224618068.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 15:42:23,995]\u001b[0m Trial 47 finished with value: 0.08373105401597816 and parameters: {'solver': 'lbfgs', 'max_iter': 8524}. Best is trial 29 with value: 0.08544975224618068.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 15:43:05,401]\u001b[0m Trial 48 finished with value: 0.08413092808401784 and parameters: {'solver': 'lbfgs', 'max_iter': 8025}. Best is trial 29 with value: 0.08544975224618068.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 15:44:25,176]\u001b[0m Trial 49 finished with value: 0.08207878715948588 and parameters: {'solver': 'saga', 'max_iter': 7816}. Best is trial 29 with value: 0.08544975224618068.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 15:45:05,723]\u001b[0m Trial 50 finished with value: 0.0842990995045485 and parameters: {'solver': 'lbfgs', 'max_iter': 9375}. Best is trial 29 with value: 0.08544975224618068.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 15:45:45,968]\u001b[0m Trial 51 finished with value: 0.08621953266938626 and parameters: {'solver': 'lbfgs', 'max_iter': 7711}. Best is trial 51 with value: 0.08621953266938626.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 15:46:26,216]\u001b[0m Trial 52 finished with value: 0.0851962666137545 and parameters: {'solver': 'lbfgs', 'max_iter': 7363}. Best is trial 51 with value: 0.08621953266938626.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 15:47:07,177]\u001b[0m Trial 53 finished with value: 0.08420521773366685 and parameters: {'solver': 'lbfgs', 'max_iter': 7900}. Best is trial 51 with value: 0.08621953266938626.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 15:47:46,484]\u001b[0m Trial 54 finished with value: 0.08454826247511851 and parameters: {'solver': 'lbfgs', 'max_iter': 7312}. Best is trial 51 with value: 0.08621953266938626.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 15:48:21,122]\u001b[0m Trial 55 finished with value: 0.08339150146037169 and parameters: {'solver': 'lbfgs', 'max_iter': 7638}. Best is trial 51 with value: 0.08621953266938626.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 15:48:53,732]\u001b[0m Trial 56 finished with value: 0.08413703293360335 and parameters: {'solver': 'lbfgs', 'max_iter': 8187}. Best is trial 51 with value: 0.08621953266938626.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 15:49:26,824]\u001b[0m Trial 57 finished with value: 0.08278910255362869 and parameters: {'solver': 'lbfgs', 'max_iter': 8687}. Best is trial 51 with value: 0.08621953266938626.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "\u001b[32m[I 2022-11-12 15:50:21,369]\u001b[0m Trial 58 finished with value: 0.08387277065757845 and parameters: {'solver': 'newton-cg', 'max_iter': 8442}. Best is trial 51 with value: 0.08621953266938626.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 15:50:54,647]\u001b[0m Trial 59 finished with value: 0.08512185961438197 and parameters: {'solver': 'lbfgs', 'max_iter': 8016}. Best is trial 51 with value: 0.08621953266938626.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 15:51:27,683]\u001b[0m Trial 60 finished with value: 0.08508352992455007 and parameters: {'solver': 'lbfgs', 'max_iter': 7133}. Best is trial 51 with value: 0.08621953266938626.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 15:52:00,727]\u001b[0m Trial 61 finished with value: 0.08299927169860628 and parameters: {'solver': 'lbfgs', 'max_iter': 7191}. Best is trial 51 with value: 0.08621953266938626.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 15:52:33,757]\u001b[0m Trial 62 finished with value: 0.08317259227152128 and parameters: {'solver': 'lbfgs', 'max_iter': 7374}. Best is trial 51 with value: 0.08621953266938626.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 15:53:08,118]\u001b[0m Trial 63 finished with value: 0.08432018693462968 and parameters: {'solver': 'lbfgs', 'max_iter': 7128}. Best is trial 51 with value: 0.08621953266938626.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 15:53:41,940]\u001b[0m Trial 64 finished with value: 0.08444367657077166 and parameters: {'solver': 'lbfgs', 'max_iter': 7548}. Best is trial 51 with value: 0.08621953266938626.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 15:54:15,617]\u001b[0m Trial 65 finished with value: 0.08474775054969953 and parameters: {'solver': 'lbfgs', 'max_iter': 7763}. Best is trial 51 with value: 0.08621953266938626.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 15:54:49,048]\u001b[0m Trial 66 finished with value: 0.08498931666958369 and parameters: {'solver': 'lbfgs', 'max_iter': 8058}. Best is trial 51 with value: 0.08621953266938626.\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "\u001b[32m[I 2022-11-12 15:55:45,494]\u001b[0m Trial 67 finished with value: 0.08171915541526917 and parameters: {'solver': 'newton-cg', 'max_iter': 7694}. Best is trial 51 with value: 0.08621953266938626.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 15:56:19,695]\u001b[0m Trial 68 finished with value: 0.08383725792246054 and parameters: {'solver': 'lbfgs', 'max_iter': 7136}. Best is trial 51 with value: 0.08621953266938626.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 15:57:25,038]\u001b[0m Trial 69 finished with value: 0.08187749919186209 and parameters: {'solver': 'saga', 'max_iter': 7391}. Best is trial 51 with value: 0.08621953266938626.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 15:57:59,591]\u001b[0m Trial 70 finished with value: 0.08345386675073453 and parameters: {'solver': 'lbfgs', 'max_iter': 7522}. Best is trial 51 with value: 0.08621953266938626.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 15:58:34,421]\u001b[0m Trial 71 finished with value: 0.08262618882098717 and parameters: {'solver': 'lbfgs', 'max_iter': 8283}. Best is trial 51 with value: 0.08621953266938626.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 15:59:08,680]\u001b[0m Trial 72 finished with value: 0.08495215886073831 and parameters: {'solver': 'lbfgs', 'max_iter': 8982}. Best is trial 51 with value: 0.08621953266938626.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 15:59:42,451]\u001b[0m Trial 73 finished with value: 0.08423293684277643 and parameters: {'solver': 'lbfgs', 'max_iter': 7903}. Best is trial 51 with value: 0.08621953266938626.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 16:00:16,331]\u001b[0m Trial 74 finished with value: 0.08276442989880611 and parameters: {'solver': 'lbfgs', 'max_iter': 10137}. Best is trial 51 with value: 0.08621953266938626.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "\u001b[32m[I 2022-11-12 16:01:15,113]\u001b[0m Trial 75 finished with value: 0.08353018881179503 and parameters: {'solver': 'newton-cg', 'max_iter': 8088}. Best is trial 51 with value: 0.08621953266938626.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 16:01:48,515]\u001b[0m Trial 76 finished with value: 0.08480768224916746 and parameters: {'solver': 'lbfgs', 'max_iter': 7799}. Best is trial 51 with value: 0.08621953266938626.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 16:02:51,970]\u001b[0m Trial 77 finished with value: 0.08469574737996763 and parameters: {'solver': 'saga', 'max_iter': 7004}. Best is trial 51 with value: 0.08621953266938626.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 16:03:26,145]\u001b[0m Trial 78 finished with value: 0.08227752735595315 and parameters: {'solver': 'lbfgs', 'max_iter': 8267}. Best is trial 51 with value: 0.08621953266938626.\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "\u001b[32m[I 2022-11-12 16:04:22,088]\u001b[0m Trial 79 finished with value: 0.08469245184094842 and parameters: {'solver': 'newton-cg', 'max_iter': 7281}. Best is trial 51 with value: 0.08621953266938626.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 16:04:55,748]\u001b[0m Trial 80 finished with value: 0.08413105683124039 and parameters: {'solver': 'lbfgs', 'max_iter': 7685}. Best is trial 51 with value: 0.08621953266938626.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 16:05:29,358]\u001b[0m Trial 81 finished with value: 0.0833548000430342 and parameters: {'solver': 'lbfgs', 'max_iter': 7979}. Best is trial 51 with value: 0.08621953266938626.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 16:06:02,631]\u001b[0m Trial 82 finished with value: 0.08357502960582218 and parameters: {'solver': 'lbfgs', 'max_iter': 8065}. Best is trial 51 with value: 0.08621953266938626.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 16:06:36,011]\u001b[0m Trial 83 finished with value: 0.08455599788437805 and parameters: {'solver': 'lbfgs', 'max_iter': 8431}. Best is trial 51 with value: 0.08621953266938626.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 16:07:10,034]\u001b[0m Trial 84 finished with value: 0.08561590216624973 and parameters: {'solver': 'lbfgs', 'max_iter': 8595}. Best is trial 51 with value: 0.08621953266938626.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 16:08:13,348]\u001b[0m Trial 85 finished with value: 0.08550223473795866 and parameters: {'solver': 'saga', 'max_iter': 10480}. Best is trial 51 with value: 0.08621953266938626.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 16:09:16,474]\u001b[0m Trial 86 finished with value: 0.08446036343359607 and parameters: {'solver': 'saga', 'max_iter': 10955}. Best is trial 51 with value: 0.08621953266938626.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 16:10:18,531]\u001b[0m Trial 87 finished with value: 0.0848695751839223 and parameters: {'solver': 'saga', 'max_iter': 10516}. Best is trial 51 with value: 0.08621953266938626.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 16:11:20,972]\u001b[0m Trial 88 finished with value: 0.0836083552153215 and parameters: {'solver': 'saga', 'max_iter': 9986}. Best is trial 51 with value: 0.08621953266938626.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 16:12:22,725]\u001b[0m Trial 89 finished with value: 0.08559021587220954 and parameters: {'solver': 'saga', 'max_iter': 10346}. Best is trial 51 with value: 0.08621953266938626.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 16:13:25,093]\u001b[0m Trial 90 finished with value: 0.08447780711894394 and parameters: {'solver': 'saga', 'max_iter': 10489}. Best is trial 51 with value: 0.08621953266938626.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 16:14:28,175]\u001b[0m Trial 91 finished with value: 0.08331783668133472 and parameters: {'solver': 'saga', 'max_iter': 10793}. Best is trial 51 with value: 0.08621953266938626.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-12 16:15:31,790]\u001b[0m Trial 92 finished with value: 0.08314203219455693 and parameters: {'solver': 'saga', 'max_iter': 9699}. Best is trial 51 with value: 0.08621953266938626.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 16:16:33,512]\u001b[0m Trial 93 finished with value: 0.08400924496250205 and parameters: {'solver': 'saga', 'max_iter': 10207}. Best is trial 51 with value: 0.08621953266938626.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 16:17:36,542]\u001b[0m Trial 94 finished with value: 0.08403206934079979 and parameters: {'solver': 'saga', 'max_iter': 10400}. Best is trial 51 with value: 0.08621953266938626.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 16:18:40,510]\u001b[0m Trial 95 finished with value: 0.08283700141402592 and parameters: {'solver': 'saga', 'max_iter': 9961}. Best is trial 51 with value: 0.08621953266938626.\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "\u001b[32m[I 2022-11-12 16:19:35,654]\u001b[0m Trial 96 finished with value: 0.08261785270685353 and parameters: {'solver': 'newton-cg', 'max_iter': 10282}. Best is trial 51 with value: 0.08621953266938626.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 16:20:38,310]\u001b[0m Trial 97 finished with value: 0.08469429695084368 and parameters: {'solver': 'saga', 'max_iter': 10727}. Best is trial 51 with value: 0.08621953266938626.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 16:21:43,014]\u001b[0m Trial 98 finished with value: 0.08237611331075222 and parameters: {'solver': 'saga', 'max_iter': 9802}. Best is trial 51 with value: 0.08621953266938626.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 16:22:15,418]\u001b[0m Trial 99 finished with value: 0.08582594931249134 and parameters: {'solver': 'lbfgs', 'max_iter': 10579}. Best is trial 51 with value: 0.08621953266938626.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study_lgr_100_3 = optuna.create_study(direction='maximize')\n",
    "study_lgr_100_3.optimize(objective_lgr_100_3, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "ef1a9a40",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-12T19:33:39.440046Z",
     "start_time": "2022-11-12T19:33:39.355018Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['study_lgr100_3.pkl']"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(study_lgr_100_3, \"study_lgr100_3.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "094ac2b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-19T20:47:22.504899Z",
     "start_time": "2022-11-19T20:47:22.468897Z"
    }
   },
   "outputs": [],
   "source": [
    "study_lgr_100_3 = joblib.load(\"study_lgr100_3.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "241fb855",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-12T19:34:29.199318Z",
     "start_time": "2022-11-12T19:34:29.182365Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Value: 0.08621953266938626\n",
      "Best Parameters: {'solver': 'lbfgs', 'max_iter': 7711}\n"
     ]
    }
   ],
   "source": [
    "print('Best Value: {}'.format(study_lgr_100_3.best_value))\n",
    "print('Best Parameters: {}'.format(study_lgr_100_3.best_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acf59cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_slice(study_lgr_100_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2d0081",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study_lgr_100_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97e685b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study_lgr_100_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078ee225",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0cfd38",
   "metadata": {},
   "source": [
    "Se utilizarán en el full dataset los hiperparámetros con los que se obtuvo mejores resultados en la Logistic Regression PCA 100. Dichos hiperparámetros son 'solver' = 'newton-cg' y 'max_iter' = 7590."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "id": "b1f9dc68",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-21T22:27:13.788715Z",
     "start_time": "2022-11-21T22:19:45.017893Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression - Full dataset\n",
    "\n",
    "lgr = LogisticRegression( max_iter= 7590 , solver = 'newton-cg')\n",
    "\n",
    "\n",
    "skf = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 1 )\n",
    "\n",
    "lgr_full_results    = []\n",
    "lgr_full_results_cm = []\n",
    "tiempo_ejecucion = []\n",
    "inicio = time.time()\n",
    "\n",
    "for train_index, test_index in skf.split(X,y):\n",
    "    \n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    lgr.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = lgr.predict(X_test)\n",
    "    \n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall    = recall_score(y_test, y_pred)\n",
    "    f1        = f1_score(y_test, y_pred)\n",
    "    cm        = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    list_results   = [precision, recall, f1]\n",
    "    list_cm = [cm]\n",
    "    lgr_full_results.append(list_results)\n",
    "    lgr_full_results_cm.append(list_cm)\n",
    "    \n",
    "fin = time.time()\n",
    "tiempo_ejecucion.append(fin - inicio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "id": "1ca70b0e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-21T22:27:13.804722Z",
     "start_time": "2022-11-21T22:27:13.791714Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRECISION</th>\n",
       "      <th>RECALL</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegression_full_opt(PCA100)</th>\n",
       "      <td>0.685319</td>\n",
       "      <td>0.26778</td>\n",
       "      <td>0.385072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     PRECISION   RECALL        F1\n",
       "LogisticRegression_full_opt(PCA100)   0.685319  0.26778  0.385072"
      ]
     },
     "execution_count": 555,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filas    = ['LogisticRegression_full_opt(PCA100)']\n",
    "columnas = [\"PRECISION\", \"RECALL\", \"F1\"]\n",
    "resultados = pd.DataFrame([gmean(lgr_full_results)], columns=columnas, index=filas)\n",
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "id": "7c0b49ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-21T22:27:21.615772Z",
     "start_time": "2022-11-21T22:27:21.592289Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRECISION</th>\n",
       "      <th>RECALL</th>\n",
       "      <th>F1</th>\n",
       "      <th>TIEMPO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegression_full_opt(PCA100)</th>\n",
       "      <td>0.685319</td>\n",
       "      <td>0.26778</td>\n",
       "      <td>0.385072</td>\n",
       "      <td>448.738785</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     PRECISION   RECALL        F1      TIEMPO\n",
       "LogisticRegression_full_opt(PCA100)   0.685319  0.26778  0.385072  448.738785"
      ]
     },
     "execution_count": 556,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados['TIEMPO']= tiempo_ejecucion\n",
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "id": "87d6e84b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-21T22:27:22.673284Z",
     "start_time": "2022-11-21T22:27:22.643230Z"
    }
   },
   "outputs": [],
   "source": [
    "resultados.to_pickle(\"resultados_lgr_full_opt_PCA100.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "id": "241acad3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-21T22:27:23.541591Z",
     "start_time": "2022-11-21T22:27:23.528590Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[17743.09527386,   246.75603909],\n",
       "        [ 1471.32100098,   538.18511381]]])"
      ]
     },
     "execution_count": 558,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados_cm= gmean(lgr_full_results_cm)\n",
    "resultados_cm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "id": "0eb308c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-21T22:27:24.285511Z",
     "start_time": "2022-11-21T22:27:24.277328Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('LogisticRegression_full_opt_PCA100_cm.pkl','wb') as f:\n",
    "        pickle.dump(resultados_cm, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0b6a5f",
   "metadata": {},
   "source": [
    "El resultado obtenido por el modelo que emplea los hiperparámetros 'solver' = 'newton-cg' y 'max_iter' = 7590 en el fulldataset es inferior al obtenido con los hiperparámetros default."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22651922",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed7f5db",
   "metadata": {},
   "source": [
    "<font size='4' style=\"color:orange\">  <b> Logistic Regression - PCA 175 </b> </font>\n",
    "<a name=\"lgr_opt_175\"></a>\n",
    "\n",
    "[[ Back to Top ]](#content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be1db9c",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee08a4c",
   "metadata": {},
   "source": [
    "Logistic Regression PCA 175 - Study 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e0e32abe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T22:22:22.220971Z",
     "start_time": "2022-11-08T22:22:22.190953Z"
    }
   },
   "outputs": [],
   "source": [
    "# Se busca optimizar los hiperparámetros 'solver' y 'max_iter'.\n",
    "\n",
    "def objective_lgr_175_1(trial):\n",
    "    solver_trial = trial.suggest_categorical('solver',['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'])\n",
    "    max_iter_trial = trial.suggest_int('max_iter', 5000,35000)\n",
    "\n",
    "    lgr = LogisticRegression(solver = solver_trial, max_iter = max_iter_trial)\n",
    "\n",
    "    skf = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 1 )\n",
    "\n",
    "    lgr_175_results    = []\n",
    "    \n",
    "    for train_index, test_index in skf.split(X,y):\n",
    "    \n",
    "        X_train, X_test = pca_175.fit_transform(X.iloc[train_index]), pca_175.transform(X.iloc[test_index])\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "        lgr.fit(X_train, y_train)\n",
    "    \n",
    "        y_pred = lgr.predict(X_test)\n",
    "    \n",
    "        recall    = recall_score(y_test, y_pred)\n",
    "\n",
    "        list_results   = [recall]\n",
    "        lgr_175_results.append(list_results)\n",
    "    \n",
    "        \n",
    "    return gmean(lgr_175_results)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e7fb00e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-09T01:19:08.111635Z",
     "start_time": "2022-11-08T22:23:26.920709Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-08 19:23:26,941]\u001b[0m A new study created in memory with name: no-name-30c82a41-4d92-4b76-9dc5-4986b0767b4c\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 19:24:29,564]\u001b[0m Trial 0 finished with value: 0.21261873260391223 and parameters: {'solver': 'saga', 'max_iter': 11138}. Best is trial 0 with value: 0.21261873260391223.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 19:25:11,554]\u001b[0m Trial 1 finished with value: 0.21266894368678335 and parameters: {'solver': 'lbfgs', 'max_iter': 25721}. Best is trial 1 with value: 0.21266894368678335.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 19:26:11,045]\u001b[0m Trial 2 finished with value: 0.21266733674707322 and parameters: {'solver': 'saga', 'max_iter': 21922}. Best is trial 1 with value: 0.21266894368678335.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 19:27:48,238]\u001b[0m Trial 3 finished with value: 0.21242008752364527 and parameters: {'solver': 'sag', 'max_iter': 30647}. Best is trial 1 with value: 0.21266894368678335.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 19:29:35,681]\u001b[0m Trial 4 finished with value: 0.21242008752364527 and parameters: {'solver': 'sag', 'max_iter': 24598}. Best is trial 1 with value: 0.21266894368678335.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 19:31:15,408]\u001b[0m Trial 5 finished with value: 0.21242044200347368 and parameters: {'solver': 'sag', 'max_iter': 25733}. Best is trial 1 with value: 0.21266894368678335.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 19:31:59,197]\u001b[0m Trial 6 finished with value: 0.21266894368678335 and parameters: {'solver': 'lbfgs', 'max_iter': 27735}. Best is trial 1 with value: 0.21266894368678335.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 19:33:01,597]\u001b[0m Trial 7 finished with value: 0.21276673741075677 and parameters: {'solver': 'saga', 'max_iter': 18740}. Best is trial 7 with value: 0.21276673741075677.\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "\u001b[32m[I 2022-11-08 19:34:11,180]\u001b[0m Trial 8 finished with value: 0.21261873260391223 and parameters: {'solver': 'newton-cg', 'max_iter': 13603}. Best is trial 7 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 19:35:14,227]\u001b[0m Trial 9 finished with value: 0.21266733674707322 and parameters: {'solver': 'saga', 'max_iter': 25136}. Best is trial 7 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 19:37:33,604]\u001b[0m Trial 10 finished with value: 0.21261908574747276 and parameters: {'solver': 'liblinear', 'max_iter': 5386}. Best is trial 7 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 19:38:16,042]\u001b[0m Trial 11 finished with value: 0.21266894368678335 and parameters: {'solver': 'lbfgs', 'max_iter': 34683}. Best is trial 7 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 19:38:58,570]\u001b[0m Trial 12 finished with value: 0.21266894368678335 and parameters: {'solver': 'lbfgs', 'max_iter': 16779}. Best is trial 7 with value: 0.21276673741075677.\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "\u001b[32m[I 2022-11-08 19:40:09,568]\u001b[0m Trial 13 finished with value: 0.21261873260391223 and parameters: {'solver': 'newton-cg', 'max_iter': 18707}. Best is trial 7 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 19:42:33,874]\u001b[0m Trial 14 finished with value: 0.21261908574747276 and parameters: {'solver': 'liblinear', 'max_iter': 19969}. Best is trial 7 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 19:43:38,868]\u001b[0m Trial 15 finished with value: 0.21271869664963308 and parameters: {'solver': 'saga', 'max_iter': 30379}. Best is trial 7 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 19:44:43,032]\u001b[0m Trial 16 finished with value: 0.21266847382010026 and parameters: {'solver': 'saga', 'max_iter': 34081}. Best is trial 7 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 19:45:47,907]\u001b[0m Trial 17 finished with value: 0.21266733674707322 and parameters: {'solver': 'saga', 'max_iter': 15033}. Best is trial 7 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 19:46:48,717]\u001b[0m Trial 18 finished with value: 0.21261873260391223 and parameters: {'solver': 'saga', 'max_iter': 9746}. Best is trial 7 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 19:47:49,782]\u001b[0m Trial 19 finished with value: 0.21261747918449223 and parameters: {'solver': 'saga', 'max_iter': 31542}. Best is trial 7 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 19:48:50,194]\u001b[0m Trial 20 finished with value: 0.21271708933398648 and parameters: {'solver': 'saga', 'max_iter': 21580}. Best is trial 7 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 19:49:50,078]\u001b[0m Trial 21 finished with value: 0.21271869664963308 and parameters: {'solver': 'saga', 'max_iter': 22579}. Best is trial 7 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 19:51:02,333]\u001b[0m Trial 22 finished with value: 0.21261873260391223 and parameters: {'solver': 'saga', 'max_iter': 27932}. Best is trial 7 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 19:52:22,581]\u001b[0m Trial 23 finished with value: 0.21271869664963308 and parameters: {'solver': 'saga', 'max_iter': 17741}. Best is trial 7 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 19:53:37,364]\u001b[0m Trial 24 finished with value: 0.21266733674707322 and parameters: {'solver': 'saga', 'max_iter': 17699}. Best is trial 7 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 19:56:27,075]\u001b[0m Trial 25 finished with value: 0.21261908574747276 and parameters: {'solver': 'liblinear', 'max_iter': 21582}. Best is trial 7 with value: 0.21276673741075677.\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "\u001b[32m[I 2022-11-08 19:57:47,149]\u001b[0m Trial 26 finished with value: 0.21261873260391223 and parameters: {'solver': 'newton-cg', 'max_iter': 14998}. Best is trial 7 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 19:58:51,006]\u001b[0m Trial 27 finished with value: 0.21271708933398648 and parameters: {'solver': 'saga', 'max_iter': 12050}. Best is trial 7 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 19:59:53,604]\u001b[0m Trial 28 finished with value: 0.21266847382010026 and parameters: {'solver': 'saga', 'max_iter': 23440}. Best is trial 7 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 20:00:57,781]\u001b[0m Trial 29 finished with value: 0.21266733674707322 and parameters: {'solver': 'saga', 'max_iter': 18888}. Best is trial 7 with value: 0.21276673741075677.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-08 20:02:03,858]\u001b[0m Trial 30 finished with value: 0.21266847382010026 and parameters: {'solver': 'saga', 'max_iter': 10058}. Best is trial 7 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 20:03:10,911]\u001b[0m Trial 31 finished with value: 0.21266733674707322 and parameters: {'solver': 'saga', 'max_iter': 16259}. Best is trial 7 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 20:04:18,490]\u001b[0m Trial 32 finished with value: 0.21271708933398648 and parameters: {'solver': 'saga', 'max_iter': 29333}. Best is trial 7 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 20:05:24,371]\u001b[0m Trial 33 finished with value: 0.21266847382010026 and parameters: {'solver': 'saga', 'max_iter': 23049}. Best is trial 7 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 20:06:27,752]\u001b[0m Trial 34 finished with value: 0.21266847382010026 and parameters: {'solver': 'saga', 'max_iter': 20608}. Best is trial 7 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 20:08:10,626]\u001b[0m Trial 35 finished with value: 0.2123701709017896 and parameters: {'solver': 'sag', 'max_iter': 32978}. Best is trial 7 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 20:09:16,294]\u001b[0m Trial 36 finished with value: 0.21271708933398648 and parameters: {'solver': 'saga', 'max_iter': 26573}. Best is trial 7 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 20:11:00,378]\u001b[0m Trial 37 finished with value: 0.21242008752364527 and parameters: {'solver': 'sag', 'max_iter': 29959}. Best is trial 7 with value: 0.21276673741075677.\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "\u001b[32m[I 2022-11-08 20:12:14,171]\u001b[0m Trial 38 finished with value: 0.21261873260391223 and parameters: {'solver': 'newton-cg', 'max_iter': 13054}. Best is trial 7 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 20:13:00,486]\u001b[0m Trial 39 finished with value: 0.21266894368678335 and parameters: {'solver': 'lbfgs', 'max_iter': 23220}. Best is trial 7 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 20:15:25,948]\u001b[0m Trial 40 finished with value: 0.21261908574747276 and parameters: {'solver': 'liblinear', 'max_iter': 19552}. Best is trial 7 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 20:16:25,895]\u001b[0m Trial 41 finished with value: 0.21266847382010026 and parameters: {'solver': 'saga', 'max_iter': 20784}. Best is trial 7 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 20:17:27,731]\u001b[0m Trial 42 finished with value: 0.21266733674707322 and parameters: {'solver': 'saga', 'max_iter': 7313}. Best is trial 7 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 20:18:28,131]\u001b[0m Trial 43 finished with value: 0.21271708933398648 and parameters: {'solver': 'saga', 'max_iter': 27051}. Best is trial 7 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 20:19:28,690]\u001b[0m Trial 44 finished with value: 0.21271869664963308 and parameters: {'solver': 'saga', 'max_iter': 25804}. Best is trial 7 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 20:21:03,527]\u001b[0m Trial 45 finished with value: 0.21242008752364527 and parameters: {'solver': 'sag', 'max_iter': 24754}. Best is trial 7 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 20:21:48,953]\u001b[0m Trial 46 finished with value: 0.21266894368678335 and parameters: {'solver': 'lbfgs', 'max_iter': 28218}. Best is trial 7 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 20:22:52,711]\u001b[0m Trial 47 finished with value: 0.21261873260391223 and parameters: {'solver': 'saga', 'max_iter': 25636}. Best is trial 7 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 20:23:57,450]\u001b[0m Trial 48 finished with value: 0.21266847382010026 and parameters: {'solver': 'saga', 'max_iter': 17535}. Best is trial 7 with value: 0.21276673741075677.\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "\u001b[32m[I 2022-11-08 20:25:11,405]\u001b[0m Trial 49 finished with value: 0.21261873260391223 and parameters: {'solver': 'newton-cg', 'max_iter': 32323}. Best is trial 7 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 20:27:38,614]\u001b[0m Trial 50 finished with value: 0.21261908574747276 and parameters: {'solver': 'liblinear', 'max_iter': 29036}. Best is trial 7 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 20:28:40,488]\u001b[0m Trial 51 finished with value: 0.21261873260391223 and parameters: {'solver': 'saga', 'max_iter': 29763}. Best is trial 7 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 20:29:45,178]\u001b[0m Trial 52 finished with value: 0.21256888643604827 and parameters: {'solver': 'saga', 'max_iter': 27215}. Best is trial 7 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 20:30:50,321]\u001b[0m Trial 53 finished with value: 0.21266733674707322 and parameters: {'solver': 'saga', 'max_iter': 30768}. Best is trial 7 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 20:32:00,963]\u001b[0m Trial 54 finished with value: 0.21261873260391223 and parameters: {'solver': 'saga', 'max_iter': 24437}. Best is trial 7 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 20:33:00,375]\u001b[0m Trial 55 finished with value: 0.21266847382010026 and parameters: {'solver': 'saga', 'max_iter': 25933}. Best is trial 7 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 20:34:06,295]\u001b[0m Trial 56 finished with value: 0.21261861599094484 and parameters: {'solver': 'saga', 'max_iter': 28633}. Best is trial 7 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 20:34:52,189]\u001b[0m Trial 57 finished with value: 0.21266894368678335 and parameters: {'solver': 'lbfgs', 'max_iter': 21369}. Best is trial 7 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 20:36:00,057]\u001b[0m Trial 58 finished with value: 0.21261873260391223 and parameters: {'solver': 'saga', 'max_iter': 21921}. Best is trial 7 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 20:37:08,364]\u001b[0m Trial 59 finished with value: 0.21271869664963308 and parameters: {'solver': 'saga', 'max_iter': 12344}. Best is trial 7 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 20:38:15,700]\u001b[0m Trial 60 finished with value: 0.21266733674707322 and parameters: {'solver': 'saga', 'max_iter': 15570}. Best is trial 7 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 20:39:21,001]\u001b[0m Trial 61 finished with value: 0.21271755930807992 and parameters: {'solver': 'saga', 'max_iter': 13207}. Best is trial 7 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 20:40:27,105]\u001b[0m Trial 62 finished with value: 0.2127673236443402 and parameters: {'solver': 'saga', 'max_iter': 11661}. Best is trial 62 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 20:41:32,273]\u001b[0m Trial 63 finished with value: 0.21261873260391223 and parameters: {'solver': 'saga', 'max_iter': 8746}. Best is trial 62 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 20:42:39,060]\u001b[0m Trial 64 finished with value: 0.21271869664963308 and parameters: {'solver': 'saga', 'max_iter': 14343}. Best is trial 62 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 20:43:45,250]\u001b[0m Trial 65 finished with value: 0.21271708933398648 and parameters: {'solver': 'saga', 'max_iter': 11824}. Best is trial 62 with value: 0.2127673236443402.\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "\u001b[32m[I 2022-11-08 20:44:58,803]\u001b[0m Trial 66 finished with value: 0.21261873260391223 and parameters: {'solver': 'newton-cg', 'max_iter': 14194}. Best is trial 62 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 20:46:06,065]\u001b[0m Trial 67 finished with value: 0.21261873260391223 and parameters: {'solver': 'saga', 'max_iter': 17970}. Best is trial 62 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 20:47:47,111]\u001b[0m Trial 68 finished with value: 0.21246941814194314 and parameters: {'solver': 'sag', 'max_iter': 11156}. Best is trial 62 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 20:50:13,470]\u001b[0m Trial 69 finished with value: 0.21261908574747276 and parameters: {'solver': 'liblinear', 'max_iter': 16792}. Best is trial 62 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 20:51:17,533]\u001b[0m Trial 70 finished with value: 0.21271708933398648 and parameters: {'solver': 'saga', 'max_iter': 14696}. Best is trial 62 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 20:52:25,365]\u001b[0m Trial 71 finished with value: 0.21271708933398648 and parameters: {'solver': 'saga', 'max_iter': 12594}. Best is trial 62 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 20:53:27,741]\u001b[0m Trial 72 finished with value: 0.21271869664963308 and parameters: {'solver': 'saga', 'max_iter': 19167}. Best is trial 62 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 20:54:34,328]\u001b[0m Trial 73 finished with value: 0.21271685654476272 and parameters: {'solver': 'saga', 'max_iter': 19001}. Best is trial 62 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 20:55:39,026]\u001b[0m Trial 74 finished with value: 0.21266733674707322 and parameters: {'solver': 'saga', 'max_iter': 10300}. Best is trial 62 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 20:56:48,114]\u001b[0m Trial 75 finished with value: 0.21266847382010026 and parameters: {'solver': 'saga', 'max_iter': 16122}. Best is trial 62 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 20:57:51,990]\u001b[0m Trial 76 finished with value: 0.21266733674707322 and parameters: {'solver': 'saga', 'max_iter': 22634}. Best is trial 62 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 20:58:56,838]\u001b[0m Trial 77 finished with value: 0.21266847382010026 and parameters: {'solver': 'saga', 'max_iter': 13991}. Best is trial 62 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 20:59:40,296]\u001b[0m Trial 78 finished with value: 0.21266894368678335 and parameters: {'solver': 'lbfgs', 'max_iter': 20109}. Best is trial 62 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 21:00:45,257]\u001b[0m Trial 79 finished with value: 0.21266847382010026 and parameters: {'solver': 'saga', 'max_iter': 23940}. Best is trial 62 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 21:02:24,884]\u001b[0m Trial 80 finished with value: 0.21242044200347368 and parameters: {'solver': 'sag', 'max_iter': 7102}. Best is trial 62 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 21:03:26,154]\u001b[0m Trial 81 finished with value: 0.21271708933398648 and parameters: {'solver': 'saga', 'max_iter': 18064}. Best is trial 62 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 21:04:26,887]\u001b[0m Trial 82 finished with value: 0.21266894368678335 and parameters: {'solver': 'saga', 'max_iter': 16892}. Best is trial 62 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 21:05:27,007]\u001b[0m Trial 83 finished with value: 0.21271708933398648 and parameters: {'solver': 'saga', 'max_iter': 19347}. Best is trial 62 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 21:06:30,572]\u001b[0m Trial 84 finished with value: 0.21266847382010026 and parameters: {'solver': 'saga', 'max_iter': 20454}. Best is trial 62 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 21:07:35,397]\u001b[0m Trial 85 finished with value: 0.21261873260391223 and parameters: {'solver': 'saga', 'max_iter': 18487}. Best is trial 62 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 21:10:06,923]\u001b[0m Trial 86 finished with value: 0.21261908574747276 and parameters: {'solver': 'liblinear', 'max_iter': 15785}. Best is trial 62 with value: 0.2127673236443402.\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "\u001b[32m[I 2022-11-08 21:11:19,147]\u001b[0m Trial 87 finished with value: 0.21261873260391223 and parameters: {'solver': 'newton-cg', 'max_iter': 22569}. Best is trial 62 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 21:12:24,477]\u001b[0m Trial 88 finished with value: 0.21256751617754654 and parameters: {'solver': 'saga', 'max_iter': 8430}. Best is trial 62 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 21:13:29,190]\u001b[0m Trial 89 finished with value: 0.21261873260391223 and parameters: {'solver': 'saga', 'max_iter': 10813}. Best is trial 62 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 21:14:33,617]\u001b[0m Trial 90 finished with value: 0.21271869664963308 and parameters: {'solver': 'saga', 'max_iter': 17227}. Best is trial 62 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 21:15:35,893]\u001b[0m Trial 91 finished with value: 0.21266733674707322 and parameters: {'solver': 'saga', 'max_iter': 17342}. Best is trial 62 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 21:16:37,107]\u001b[0m Trial 92 finished with value: 0.21261861599094484 and parameters: {'solver': 'saga', 'max_iter': 12218}. Best is trial 62 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 21:17:41,824]\u001b[0m Trial 93 finished with value: 0.21261747918449223 and parameters: {'solver': 'saga', 'max_iter': 15016}. Best is trial 62 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 21:18:42,449]\u001b[0m Trial 94 finished with value: 0.21261747918449223 and parameters: {'solver': 'saga', 'max_iter': 19834}. Best is trial 62 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 21:19:44,258]\u001b[0m Trial 95 finished with value: 0.21271708933398648 and parameters: {'solver': 'saga', 'max_iter': 21026}. Best is trial 62 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 21:20:45,385]\u001b[0m Trial 96 finished with value: 0.21271755930807992 and parameters: {'solver': 'saga', 'max_iter': 13672}. Best is trial 62 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 21:21:28,336]\u001b[0m Trial 97 finished with value: 0.21266894368678335 and parameters: {'solver': 'lbfgs', 'max_iter': 18544}. Best is trial 62 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 21:22:30,996]\u001b[0m Trial 98 finished with value: 0.21271755930807992 and parameters: {'solver': 'saga', 'max_iter': 11543}. Best is trial 62 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 21:23:33,580]\u001b[0m Trial 99 finished with value: 0.21261873260391223 and parameters: {'solver': 'saga', 'max_iter': 14498}. Best is trial 62 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 21:24:35,002]\u001b[0m Trial 100 finished with value: 0.21271755930807992 and parameters: {'solver': 'saga', 'max_iter': 12803}. Best is trial 62 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 21:25:37,501]\u001b[0m Trial 101 finished with value: 0.21266847382010026 and parameters: {'solver': 'saga', 'max_iter': 34666}. Best is trial 62 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 21:26:38,929]\u001b[0m Trial 102 finished with value: 0.21261873260391223 and parameters: {'solver': 'saga', 'max_iter': 15680}. Best is trial 62 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 21:27:40,642]\u001b[0m Trial 103 finished with value: 0.21266733674707322 and parameters: {'solver': 'saga', 'max_iter': 11338}. Best is trial 62 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 21:28:43,703]\u001b[0m Trial 104 finished with value: 0.21266733674707322 and parameters: {'solver': 'saga', 'max_iter': 13515}. Best is trial 62 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 21:29:45,453]\u001b[0m Trial 105 finished with value: 0.21266733674707322 and parameters: {'solver': 'saga', 'max_iter': 9413}. Best is trial 62 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 21:31:20,628]\u001b[0m Trial 106 finished with value: 0.212570381320076 and parameters: {'solver': 'sag', 'max_iter': 30871}. Best is trial 62 with value: 0.2127673236443402.\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "\u001b[32m[I 2022-11-08 21:32:29,135]\u001b[0m Trial 107 finished with value: 0.21261873260391223 and parameters: {'solver': 'newton-cg', 'max_iter': 11847}. Best is trial 62 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 21:33:29,287]\u001b[0m Trial 108 finished with value: 0.21261861599094484 and parameters: {'solver': 'saga', 'max_iter': 16590}. Best is trial 62 with value: 0.2127673236443402.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-08 21:35:46,461]\u001b[0m Trial 109 finished with value: 0.21261908574747276 and parameters: {'solver': 'liblinear', 'max_iter': 12460}. Best is trial 62 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 21:36:47,163]\u001b[0m Trial 110 finished with value: 0.21271708933398648 and parameters: {'solver': 'saga', 'max_iter': 32942}. Best is trial 62 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 21:37:46,225]\u001b[0m Trial 111 finished with value: 0.21271708933398648 and parameters: {'solver': 'saga', 'max_iter': 13173}. Best is trial 62 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 21:38:47,282]\u001b[0m Trial 112 finished with value: 0.21266722010744832 and parameters: {'solver': 'saga', 'max_iter': 17241}. Best is trial 62 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 21:39:51,953]\u001b[0m Trial 113 finished with value: 0.21266733674707322 and parameters: {'solver': 'saga', 'max_iter': 11466}. Best is trial 62 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 21:40:55,637]\u001b[0m Trial 114 finished with value: 0.2127673236443402 and parameters: {'solver': 'saga', 'max_iter': 10674}. Best is trial 62 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 21:41:59,530]\u001b[0m Trial 115 finished with value: 0.21266894368678335 and parameters: {'solver': 'saga', 'max_iter': 13807}. Best is trial 62 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 21:43:03,466]\u001b[0m Trial 116 finished with value: 0.21266733674707322 and parameters: {'solver': 'saga', 'max_iter': 10220}. Best is trial 62 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 21:44:08,380]\u001b[0m Trial 117 finished with value: 0.21266733674707322 and parameters: {'solver': 'saga', 'max_iter': 19364}. Best is trial 62 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 21:45:12,831]\u001b[0m Trial 118 finished with value: 0.21276673741075677 and parameters: {'solver': 'saga', 'max_iter': 10833}. Best is trial 62 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 21:46:16,824]\u001b[0m Trial 119 finished with value: 0.21266733674707322 and parameters: {'solver': 'saga', 'max_iter': 9037}. Best is trial 62 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 21:47:00,741]\u001b[0m Trial 120 finished with value: 0.21266894368678335 and parameters: {'solver': 'lbfgs', 'max_iter': 7917}. Best is trial 62 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 21:48:05,986]\u001b[0m Trial 121 finished with value: 0.21266847382010026 and parameters: {'solver': 'saga', 'max_iter': 10506}. Best is trial 62 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 21:49:07,988]\u001b[0m Trial 122 finished with value: 0.21281698344577693 and parameters: {'solver': 'saga', 'max_iter': 15176}. Best is trial 122 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 21:50:08,734]\u001b[0m Trial 123 finished with value: 0.21266687018511915 and parameters: {'solver': 'saga', 'max_iter': 17720}. Best is trial 122 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 21:51:13,085]\u001b[0m Trial 124 finished with value: 0.21266733674707322 and parameters: {'solver': 'saga', 'max_iter': 9717}. Best is trial 122 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 21:52:18,052]\u001b[0m Trial 125 finished with value: 0.21261771516537686 and parameters: {'solver': 'saga', 'max_iter': 15023}. Best is trial 122 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 21:53:23,678]\u001b[0m Trial 126 finished with value: 0.21261747918449223 and parameters: {'solver': 'saga', 'max_iter': 16034}. Best is trial 122 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 21:54:28,294]\u001b[0m Trial 127 finished with value: 0.21271708933398648 and parameters: {'solver': 'saga', 'max_iter': 25953}. Best is trial 122 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 21:56:11,812]\u001b[0m Trial 128 finished with value: 0.2123701709017896 and parameters: {'solver': 'sag', 'max_iter': 18538}. Best is trial 122 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 21:57:12,862]\u001b[0m Trial 129 finished with value: 0.21271755930807992 and parameters: {'solver': 'saga', 'max_iter': 10932}. Best is trial 122 with value: 0.21281698344577693.\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "\u001b[32m[I 2022-11-08 21:58:20,687]\u001b[0m Trial 130 finished with value: 0.21261873260391223 and parameters: {'solver': 'newton-cg', 'max_iter': 27678}. Best is trial 122 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 21:59:21,653]\u001b[0m Trial 131 finished with value: 0.21261908574747276 and parameters: {'solver': 'saga', 'max_iter': 13137}. Best is trial 122 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 22:00:22,652]\u001b[0m Trial 132 finished with value: 0.21261873260391223 and parameters: {'solver': 'saga', 'max_iter': 11641}. Best is trial 122 with value: 0.21281698344577693.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-08 22:01:22,463]\u001b[0m Trial 133 finished with value: 0.21266847382010026 and parameters: {'solver': 'saga', 'max_iter': 14015}. Best is trial 122 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 22:02:24,789]\u001b[0m Trial 134 finished with value: 0.21271708933398648 and parameters: {'solver': 'saga', 'max_iter': 15338}. Best is trial 122 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 22:03:25,528]\u001b[0m Trial 135 finished with value: 0.21276673741075677 and parameters: {'solver': 'saga', 'max_iter': 20260}. Best is trial 122 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 22:04:26,261]\u001b[0m Trial 136 finished with value: 0.21266733674707322 and parameters: {'solver': 'saga', 'max_iter': 20203}. Best is trial 122 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 22:06:50,679]\u001b[0m Trial 137 finished with value: 0.21261908574747276 and parameters: {'solver': 'liblinear', 'max_iter': 20937}. Best is trial 122 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 22:07:51,537]\u001b[0m Trial 138 finished with value: 0.2127673236443402 and parameters: {'solver': 'saga', 'max_iter': 19026}. Best is trial 122 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 22:08:51,441]\u001b[0m Trial 139 finished with value: 0.21256888643604827 and parameters: {'solver': 'saga', 'max_iter': 19125}. Best is trial 122 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 22:09:56,098]\u001b[0m Trial 140 finished with value: 0.21271708933398648 and parameters: {'solver': 'saga', 'max_iter': 22232}. Best is trial 122 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 22:11:05,137]\u001b[0m Trial 141 finished with value: 0.21271811055003065 and parameters: {'solver': 'saga', 'max_iter': 17913}. Best is trial 122 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 22:12:09,703]\u001b[0m Trial 142 finished with value: 0.21266733674707322 and parameters: {'solver': 'saga', 'max_iter': 19702}. Best is trial 122 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 22:13:11,539]\u001b[0m Trial 143 finished with value: 0.21266722010744832 and parameters: {'solver': 'saga', 'max_iter': 16681}. Best is trial 122 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 22:14:14,160]\u001b[0m Trial 144 finished with value: 0.21276834510155027 and parameters: {'solver': 'saga', 'max_iter': 18288}. Best is trial 122 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 22:15:13,278]\u001b[0m Trial 145 finished with value: 0.21271755930807992 and parameters: {'solver': 'saga', 'max_iter': 23563}. Best is trial 122 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 22:16:11,975]\u001b[0m Trial 146 finished with value: 0.21271708933398648 and parameters: {'solver': 'saga', 'max_iter': 21567}. Best is trial 122 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 22:17:11,728]\u001b[0m Trial 147 finished with value: 0.21271811055003065 and parameters: {'solver': 'saga', 'max_iter': 18590}. Best is trial 122 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 22:18:10,350]\u001b[0m Trial 148 finished with value: 0.21261873260391223 and parameters: {'solver': 'saga', 'max_iter': 17248}. Best is trial 122 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 22:19:08,075]\u001b[0m Trial 149 finished with value: 0.21271708933398648 and parameters: {'solver': 'saga', 'max_iter': 18039}. Best is trial 122 with value: 0.21281698344577693.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study_lgr_175_1 = optuna.create_study(direction='maximize')\n",
    "study_lgr_175_1.optimize(objective_lgr_175_1, n_trials=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8f502423",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-09T01:28:53.041627Z",
     "start_time": "2022-11-09T01:28:52.967633Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['study_lgr175_1.pkl']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(study_lgr_175_1, \"study_lgr175_1.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "1955474c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-19T20:48:08.495941Z",
     "start_time": "2022-11-19T20:48:08.443856Z"
    }
   },
   "outputs": [],
   "source": [
    "study_lgr_175_1 = joblib.load(\"study_lgr175_1.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "0a246e4b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-09T01:28:54.687665Z",
     "start_time": "2022-11-09T01:28:54.668574Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Value: 0.21281698344577693\n",
      "Best Parameters: {'solver': 'saga', 'max_iter': 15176}\n"
     ]
    }
   ],
   "source": [
    "print('Best Value: {}'.format(study_lgr_175_1.best_value))\n",
    "print('Best Parameters: {}'.format(study_lgr_175_1.best_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f360fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study_lgr_175_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4497ed04",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study_lgr_175_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8452a212",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_slice(study_lgr_175_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e0d1d3",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2045d6a",
   "metadata": {},
   "source": [
    "Logistic Regression PCA 175 - Study 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f13dd6b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-09T01:31:24.418696Z",
     "start_time": "2022-11-09T01:31:24.384623Z"
    }
   },
   "outputs": [],
   "source": [
    "# Se utiliza 'solver' = 'saga' obtenido del study 1 y se busca optimizar el hiperparámetro 'max_iter'.\n",
    "\n",
    "def objective_lgr_175_2(trial):\n",
    "\n",
    "    max_iter_trial = trial.suggest_int('max_iter', 10000,23000)\n",
    "\n",
    "    lgr = LogisticRegression(solver = 'saga', max_iter = max_iter_trial)\n",
    "\n",
    "    skf = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 1 )\n",
    "\n",
    "    lgr_175_results    = []\n",
    "    \n",
    "    for train_index, test_index in skf.split(X,y):\n",
    "    \n",
    "        X_train, X_test = pca_175.fit_transform(X.iloc[train_index]), pca_175.transform(X.iloc[test_index])\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "        lgr.fit(X_train, y_train)\n",
    "    \n",
    "        y_pred = lgr.predict(X_test)\n",
    "    \n",
    "        recall    = recall_score(y_test, y_pred)\n",
    "\n",
    "        list_results   = [recall]\n",
    "        lgr_175_results.append(list_results)\n",
    "    \n",
    "        \n",
    "    return gmean(lgr_175_results) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "32e57f6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-09T02:41:45.937570Z",
     "start_time": "2022-11-09T01:31:27.947070Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-08 22:31:27,961]\u001b[0m A new study created in memory with name: no-name-0691a5d1-3a93-4309-a466-fecb0e3ddb31\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 22:32:27,349]\u001b[0m Trial 0 finished with value: 0.21261873260391223 and parameters: {'max_iter': 14608}. Best is trial 0 with value: 0.21261873260391223.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 22:33:27,968]\u001b[0m Trial 1 finished with value: 0.21271755930807992 and parameters: {'max_iter': 20523}. Best is trial 1 with value: 0.21271755930807992.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 22:34:28,210]\u001b[0m Trial 2 finished with value: 0.21276673741075677 and parameters: {'max_iter': 16367}. Best is trial 2 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 22:35:32,553]\u001b[0m Trial 3 finished with value: 0.21266894368678335 and parameters: {'max_iter': 20314}. Best is trial 2 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 22:36:31,784]\u001b[0m Trial 4 finished with value: 0.21266733674707322 and parameters: {'max_iter': 12563}. Best is trial 2 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 22:37:31,889]\u001b[0m Trial 5 finished with value: 0.21271708933398648 and parameters: {'max_iter': 15529}. Best is trial 2 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 22:38:30,796]\u001b[0m Trial 6 finished with value: 0.21266733674707322 and parameters: {'max_iter': 12659}. Best is trial 2 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 22:39:28,982]\u001b[0m Trial 7 finished with value: 0.21261747918449223 and parameters: {'max_iter': 14659}. Best is trial 2 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 22:40:28,926]\u001b[0m Trial 8 finished with value: 0.21271755930807992 and parameters: {'max_iter': 13443}. Best is trial 2 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 22:41:28,253]\u001b[0m Trial 9 finished with value: 0.21261873260391223 and parameters: {'max_iter': 20947}. Best is trial 2 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 22:42:28,785]\u001b[0m Trial 10 finished with value: 0.21271755930807992 and parameters: {'max_iter': 17685}. Best is trial 2 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 22:43:28,793]\u001b[0m Trial 11 finished with value: 0.21261873260391223 and parameters: {'max_iter': 18254}. Best is trial 2 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 22:44:28,811]\u001b[0m Trial 12 finished with value: 0.21261873260391223 and parameters: {'max_iter': 22618}. Best is trial 2 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 22:45:27,475]\u001b[0m Trial 13 finished with value: 0.21271708933398648 and parameters: {'max_iter': 17594}. Best is trial 2 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 22:46:26,862]\u001b[0m Trial 14 finished with value: 0.21266733674707322 and parameters: {'max_iter': 19887}. Best is trial 2 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 22:47:24,355]\u001b[0m Trial 15 finished with value: 0.21266733674707322 and parameters: {'max_iter': 16795}. Best is trial 2 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 22:48:22,312]\u001b[0m Trial 16 finished with value: 0.21256888643604827 and parameters: {'max_iter': 22756}. Best is trial 2 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 22:49:21,611]\u001b[0m Trial 17 finished with value: 0.21266824108407942 and parameters: {'max_iter': 10765}. Best is trial 2 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 22:50:20,543]\u001b[0m Trial 18 finished with value: 0.21261873260391223 and parameters: {'max_iter': 12917}. Best is trial 2 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 22:51:18,886]\u001b[0m Trial 19 finished with value: 0.21266847382010026 and parameters: {'max_iter': 18826}. Best is trial 2 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 22:52:17,513]\u001b[0m Trial 20 finished with value: 0.21261747918449223 and parameters: {'max_iter': 21262}. Best is trial 2 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 22:53:16,863]\u001b[0m Trial 21 finished with value: 0.21261873260391223 and parameters: {'max_iter': 16416}. Best is trial 2 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 22:54:14,916]\u001b[0m Trial 22 finished with value: 0.21261873260391223 and parameters: {'max_iter': 19216}. Best is trial 2 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 22:55:14,155]\u001b[0m Trial 23 finished with value: 0.21266733674707322 and parameters: {'max_iter': 13918}. Best is trial 2 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 22:56:13,526]\u001b[0m Trial 24 finished with value: 0.21266733674707322 and parameters: {'max_iter': 15429}. Best is trial 2 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 22:57:11,561]\u001b[0m Trial 25 finished with value: 0.21271708933398648 and parameters: {'max_iter': 10160}. Best is trial 2 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 22:58:14,393]\u001b[0m Trial 26 finished with value: 0.21266733674707322 and parameters: {'max_iter': 11430}. Best is trial 2 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 22:59:15,206]\u001b[0m Trial 27 finished with value: 0.21266733674707322 and parameters: {'max_iter': 16389}. Best is trial 2 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 23:00:14,246]\u001b[0m Trial 28 finished with value: 0.21266733674707322 and parameters: {'max_iter': 13436}. Best is trial 2 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 23:01:13,561]\u001b[0m Trial 29 finished with value: 0.21266733674707322 and parameters: {'max_iter': 14390}. Best is trial 2 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 23:02:12,625]\u001b[0m Trial 30 finished with value: 0.21271708933398648 and parameters: {'max_iter': 11731}. Best is trial 2 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 23:03:10,865]\u001b[0m Trial 31 finished with value: 0.21266733674707322 and parameters: {'max_iter': 17442}. Best is trial 2 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 23:04:11,208]\u001b[0m Trial 32 finished with value: 0.21271869664963308 and parameters: {'max_iter': 15388}. Best is trial 2 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 23:05:10,435]\u001b[0m Trial 33 finished with value: 0.21271755930807992 and parameters: {'max_iter': 15136}. Best is trial 2 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 23:06:08,504]\u001b[0m Trial 34 finished with value: 0.21266847382010026 and parameters: {'max_iter': 15212}. Best is trial 2 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 23:07:07,459]\u001b[0m Trial 35 finished with value: 0.21266847382010026 and parameters: {'max_iter': 16401}. Best is trial 2 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 23:08:06,045]\u001b[0m Trial 36 finished with value: 0.21271708933398648 and parameters: {'max_iter': 15591}. Best is trial 2 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 23:09:05,103]\u001b[0m Trial 37 finished with value: 0.21266722010744832 and parameters: {'max_iter': 17816}. Best is trial 2 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 23:10:03,824]\u001b[0m Trial 38 finished with value: 0.21261873260391223 and parameters: {'max_iter': 13772}. Best is trial 2 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 23:11:01,109]\u001b[0m Trial 39 finished with value: 0.21266733674707322 and parameters: {'max_iter': 21649}. Best is trial 2 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 23:12:01,452]\u001b[0m Trial 40 finished with value: 0.21271708933398648 and parameters: {'max_iter': 14403}. Best is trial 2 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 23:12:58,274]\u001b[0m Trial 41 finished with value: 0.21261873260391223 and parameters: {'max_iter': 14878}. Best is trial 2 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 23:13:58,086]\u001b[0m Trial 42 finished with value: 0.21266733674707322 and parameters: {'max_iter': 15903}. Best is trial 2 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 23:14:57,978]\u001b[0m Trial 43 finished with value: 0.21256888643604827 and parameters: {'max_iter': 16982}. Best is trial 2 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 23:15:55,995]\u001b[0m Trial 44 finished with value: 0.21266733674707322 and parameters: {'max_iter': 18314}. Best is trial 2 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 23:16:55,175]\u001b[0m Trial 45 finished with value: 0.21266733674707322 and parameters: {'max_iter': 19563}. Best is trial 2 with value: 0.21276673741075677.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-08 23:17:53,151]\u001b[0m Trial 46 finished with value: 0.21266733674707322 and parameters: {'max_iter': 20268}. Best is trial 2 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 23:18:50,593]\u001b[0m Trial 47 finished with value: 0.21271708933398648 and parameters: {'max_iter': 12507}. Best is trial 2 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 23:19:49,632]\u001b[0m Trial 48 finished with value: 0.21266733674707322 and parameters: {'max_iter': 15910}. Best is trial 2 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 23:20:48,416]\u001b[0m Trial 49 finished with value: 0.21261873260391223 and parameters: {'max_iter': 14971}. Best is trial 2 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 23:21:48,333]\u001b[0m Trial 50 finished with value: 0.21261747918449223 and parameters: {'max_iter': 17150}. Best is trial 2 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 23:22:47,558]\u001b[0m Trial 51 finished with value: 0.21266768997136143 and parameters: {'max_iter': 18279}. Best is trial 2 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 23:23:48,996]\u001b[0m Trial 52 finished with value: 0.2125189348479183 and parameters: {'max_iter': 21789}. Best is trial 2 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 23:24:52,289]\u001b[0m Trial 53 finished with value: 0.21266733674707322 and parameters: {'max_iter': 13408}. Best is trial 2 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 23:25:56,858]\u001b[0m Trial 54 finished with value: 0.21261873260391223 and parameters: {'max_iter': 14271}. Best is trial 2 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 23:27:00,339]\u001b[0m Trial 55 finished with value: 0.21266733674707322 and parameters: {'max_iter': 12281}. Best is trial 2 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 23:28:02,242]\u001b[0m Trial 56 finished with value: 0.21261873260391223 and parameters: {'max_iter': 15966}. Best is trial 2 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 23:29:03,421]\u001b[0m Trial 57 finished with value: 0.21266847382010026 and parameters: {'max_iter': 18921}. Best is trial 2 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 23:30:06,072]\u001b[0m Trial 58 finished with value: 0.21266768997136143 and parameters: {'max_iter': 13116}. Best is trial 2 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 23:31:10,213]\u001b[0m Trial 59 finished with value: 0.21276673741075677 and parameters: {'max_iter': 20946}. Best is trial 2 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 23:32:13,681]\u001b[0m Trial 60 finished with value: 0.21256888643604827 and parameters: {'max_iter': 20747}. Best is trial 2 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 23:33:18,368]\u001b[0m Trial 61 finished with value: 0.21261873260391223 and parameters: {'max_iter': 22388}. Best is trial 2 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 23:34:21,084]\u001b[0m Trial 62 finished with value: 0.21261747918449223 and parameters: {'max_iter': 20363}. Best is trial 2 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 23:35:22,928]\u001b[0m Trial 63 finished with value: 0.2127673236443402 and parameters: {'max_iter': 20968}. Best is trial 63 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 23:36:28,907]\u001b[0m Trial 64 finished with value: 0.21271708933398648 and parameters: {'max_iter': 22180}. Best is trial 63 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 23:37:32,411]\u001b[0m Trial 65 finished with value: 0.21261747918449223 and parameters: {'max_iter': 21036}. Best is trial 63 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 23:38:35,242]\u001b[0m Trial 66 finished with value: 0.2127673236443402 and parameters: {'max_iter': 19797}. Best is trial 63 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 23:39:38,914]\u001b[0m Trial 67 finished with value: 0.21261873260391223 and parameters: {'max_iter': 19909}. Best is trial 63 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 23:40:40,521]\u001b[0m Trial 68 finished with value: 0.21266733674707322 and parameters: {'max_iter': 21457}. Best is trial 63 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 23:41:45,932]\u001b[0m Trial 69 finished with value: 0.21266847382010026 and parameters: {'max_iter': 20701}. Best is trial 63 with value: 0.2127673236443402.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study_lgr_175_2 = optuna.create_study(direction='maximize')\n",
    "study_lgr_175_2.optimize(objective_lgr_175_2, n_trials=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ad0b3798",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-09T02:41:58.604590Z",
     "start_time": "2022-11-09T02:41:58.569680Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['study_lgr175_2.pkl']"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(study_lgr_175_2, \"study_lgr175_2.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "bd1e5dea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-19T20:48:46.945992Z",
     "start_time": "2022-11-19T20:48:46.890246Z"
    }
   },
   "outputs": [],
   "source": [
    "study_lgr_175_2 = joblib.load(\"study_lgr175_2.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "a36c4797",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-09T02:42:00.670272Z",
     "start_time": "2022-11-09T02:42:00.656917Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Value: 0.2127673236443402\n",
      "Best Parameters: {'max_iter': 20968}\n"
     ]
    }
   ],
   "source": [
    "print('Best Value: {}'.format(study_lgr_175_2.best_value))\n",
    "print('Best Parameters: {}'.format(study_lgr_175_2.best_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6b5c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study_lgr_175_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ff608e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_slice(study_lgr_175_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d95fcd",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820e137e",
   "metadata": {},
   "source": [
    "Logistic Regression PCA 175 - Study 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "743db690",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-09T20:20:00.470104Z",
     "start_time": "2022-11-09T20:20:00.448104Z"
    }
   },
   "outputs": [],
   "source": [
    "# Se utiliza 'solver' = 'saga' obtenido del study 1 y se busca optimizar el hiperparámetro 'max_iter' reduciendo el rango \n",
    "# que se había empleado en el study 2 e incrementando la cantidad de trials. \n",
    "\n",
    "def objective_lgr_175_3(trial):\n",
    "    max_iter_trial = trial.suggest_int('max_iter', 15000,22000)\n",
    "\n",
    "    lgr = LogisticRegression(solver = 'saga', max_iter = max_iter_trial)\n",
    "\n",
    "    skf = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 1 )\n",
    "\n",
    "    lgr_175_results    = []\n",
    "    \n",
    "    for train_index, test_index in skf.split(X,y):\n",
    "    \n",
    "        X_train, X_test = pca_175.fit_transform(X.iloc[train_index]), pca_175.transform(X.iloc[test_index])\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "        lgr.fit(X_train, y_train)\n",
    "    \n",
    "        y_pred = lgr.predict(X_test)\n",
    "    \n",
    "        recall    = recall_score(y_test, y_pred)\n",
    "\n",
    "        list_results   = [recall]\n",
    "        lgr_175_results.append(list_results)\n",
    "    \n",
    "        \n",
    "    return gmean(lgr_175_results) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "efb5aa74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-09T22:52:53.933860Z",
     "start_time": "2022-11-09T20:20:01.508366Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-09 17:20:01,510]\u001b[0m A new study created in memory with name: no-name-eb108a76-81b8-45c2-891a-eb8f8982bba6\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 17:21:03,058]\u001b[0m Trial 0 finished with value: 0.21266847382010026 and parameters: {'max_iter': 17763}. Best is trial 0 with value: 0.21266847382010026.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 17:22:02,708]\u001b[0m Trial 1 finished with value: 0.21266733674707322 and parameters: {'max_iter': 15810}. Best is trial 0 with value: 0.21266847382010026.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 17:23:01,301]\u001b[0m Trial 2 finished with value: 0.21261873260391223 and parameters: {'max_iter': 16469}. Best is trial 0 with value: 0.21266847382010026.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 17:24:00,976]\u001b[0m Trial 3 finished with value: 0.21261747918449223 and parameters: {'max_iter': 20579}. Best is trial 0 with value: 0.21266847382010026.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 17:25:02,003]\u001b[0m Trial 4 finished with value: 0.21261873260391223 and parameters: {'max_iter': 19657}. Best is trial 0 with value: 0.21266847382010026.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 17:26:04,000]\u001b[0m Trial 5 finished with value: 0.21261861599094484 and parameters: {'max_iter': 17913}. Best is trial 0 with value: 0.21266847382010026.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 17:27:03,065]\u001b[0m Trial 6 finished with value: 0.21271708933398648 and parameters: {'max_iter': 16386}. Best is trial 6 with value: 0.21271708933398648.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 17:28:01,743]\u001b[0m Trial 7 finished with value: 0.21266733674707322 and parameters: {'max_iter': 18325}. Best is trial 6 with value: 0.21271708933398648.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 17:28:59,474]\u001b[0m Trial 8 finished with value: 0.2127673236443402 and parameters: {'max_iter': 20444}. Best is trial 8 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 17:29:58,159]\u001b[0m Trial 9 finished with value: 0.21261873260391223 and parameters: {'max_iter': 18259}. Best is trial 8 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 17:30:57,188]\u001b[0m Trial 10 finished with value: 0.21261873260391223 and parameters: {'max_iter': 21741}. Best is trial 8 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 17:31:56,915]\u001b[0m Trial 11 finished with value: 0.21266733674707322 and parameters: {'max_iter': 19740}. Best is trial 8 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 17:32:55,603]\u001b[0m Trial 12 finished with value: 0.21256888643604827 and parameters: {'max_iter': 15088}. Best is trial 8 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 17:33:53,889]\u001b[0m Trial 13 finished with value: 0.21266733674707322 and parameters: {'max_iter': 16858}. Best is trial 8 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 17:34:51,798]\u001b[0m Trial 14 finished with value: 0.2127184638586504 and parameters: {'max_iter': 21937}. Best is trial 8 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 17:35:50,377]\u001b[0m Trial 15 finished with value: 0.21266733674707322 and parameters: {'max_iter': 21662}. Best is trial 8 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 17:36:48,153]\u001b[0m Trial 16 finished with value: 0.21271811055003065 and parameters: {'max_iter': 20648}. Best is trial 8 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 17:37:47,604]\u001b[0m Trial 17 finished with value: 0.21271755930807992 and parameters: {'max_iter': 20953}. Best is trial 8 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 17:38:46,165]\u001b[0m Trial 18 finished with value: 0.21271708933398648 and parameters: {'max_iter': 19556}. Best is trial 8 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 17:39:46,358]\u001b[0m Trial 19 finished with value: 0.21266733674707322 and parameters: {'max_iter': 21878}. Best is trial 8 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 17:40:46,749]\u001b[0m Trial 20 finished with value: 0.21271708933398648 and parameters: {'max_iter': 20998}. Best is trial 8 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 17:41:46,898]\u001b[0m Trial 21 finished with value: 0.21271755930807992 and parameters: {'max_iter': 20532}. Best is trial 8 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 17:42:46,128]\u001b[0m Trial 22 finished with value: 0.21266733674707322 and parameters: {'max_iter': 19060}. Best is trial 8 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 17:43:44,887]\u001b[0m Trial 23 finished with value: 0.21266733674707322 and parameters: {'max_iter': 21173}. Best is trial 8 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 17:44:44,254]\u001b[0m Trial 24 finished with value: 0.21266733674707322 and parameters: {'max_iter': 20113}. Best is trial 8 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 17:45:42,725]\u001b[0m Trial 25 finished with value: 0.21266733674707322 and parameters: {'max_iter': 21332}. Best is trial 8 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 17:46:41,011]\u001b[0m Trial 26 finished with value: 0.21266733674707322 and parameters: {'max_iter': 19126}. Best is trial 8 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 17:47:39,127]\u001b[0m Trial 27 finished with value: 0.21271708933398648 and parameters: {'max_iter': 20352}. Best is trial 8 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 17:48:37,851]\u001b[0m Trial 28 finished with value: 0.2127673236443402 and parameters: {'max_iter': 21933}. Best is trial 8 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 17:49:36,273]\u001b[0m Trial 29 finished with value: 0.21266733674707322 and parameters: {'max_iter': 21895}. Best is trial 8 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 17:50:34,436]\u001b[0m Trial 30 finished with value: 0.21261873260391223 and parameters: {'max_iter': 21394}. Best is trial 8 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 17:51:33,580]\u001b[0m Trial 31 finished with value: 0.21266733674707322 and parameters: {'max_iter': 20708}. Best is trial 8 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 17:52:34,209]\u001b[0m Trial 32 finished with value: 0.21271755930807992 and parameters: {'max_iter': 20174}. Best is trial 8 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 17:53:32,199]\u001b[0m Trial 33 finished with value: 0.21271869664963308 and parameters: {'max_iter': 21480}. Best is trial 8 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 17:54:30,548]\u001b[0m Trial 34 finished with value: 0.21261873260391223 and parameters: {'max_iter': 21973}. Best is trial 8 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 17:55:29,164]\u001b[0m Trial 35 finished with value: 0.21261873260391223 and parameters: {'max_iter': 21438}. Best is trial 8 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 17:56:27,976]\u001b[0m Trial 36 finished with value: 0.21261873260391223 and parameters: {'max_iter': 21100}. Best is trial 8 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 17:57:26,612]\u001b[0m Trial 37 finished with value: 0.21261873260391223 and parameters: {'max_iter': 21513}. Best is trial 8 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 17:58:25,709]\u001b[0m Trial 38 finished with value: 0.21271755930807992 and parameters: {'max_iter': 17347}. Best is trial 8 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 17:59:24,807]\u001b[0m Trial 39 finished with value: 0.21266894368678335 and parameters: {'max_iter': 20847}. Best is trial 8 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 18:00:22,052]\u001b[0m Trial 40 finished with value: 0.2127182266730268 and parameters: {'max_iter': 20061}. Best is trial 8 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 18:01:21,801]\u001b[0m Trial 41 finished with value: 0.21271755930807992 and parameters: {'max_iter': 20029}. Best is trial 8 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 18:02:19,924]\u001b[0m Trial 42 finished with value: 0.21261873260391223 and parameters: {'max_iter': 19070}. Best is trial 8 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 18:03:18,249]\u001b[0m Trial 43 finished with value: 0.21261747918449223 and parameters: {'max_iter': 21985}. Best is trial 8 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 18:04:18,137]\u001b[0m Trial 44 finished with value: 0.21271708933398648 and parameters: {'max_iter': 19758}. Best is trial 8 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 18:05:17,439]\u001b[0m Trial 45 finished with value: 0.21266733674707322 and parameters: {'max_iter': 21496}. Best is trial 8 with value: 0.2127673236443402.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-09 18:06:18,661]\u001b[0m Trial 46 finished with value: 0.21266847382010026 and parameters: {'max_iter': 19347}. Best is trial 8 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 18:07:35,696]\u001b[0m Trial 47 finished with value: 0.21261873260391223 and parameters: {'max_iter': 18721}. Best is trial 8 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 18:08:52,520]\u001b[0m Trial 48 finished with value: 0.21266733674707322 and parameters: {'max_iter': 21175}. Best is trial 8 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 18:10:09,340]\u001b[0m Trial 49 finished with value: 0.21266733674707322 and parameters: {'max_iter': 21620}. Best is trial 8 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 18:11:26,586]\u001b[0m Trial 50 finished with value: 0.21271869664963308 and parameters: {'max_iter': 20341}. Best is trial 8 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 18:12:45,002]\u001b[0m Trial 51 finished with value: 0.21271708933398648 and parameters: {'max_iter': 20473}. Best is trial 8 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 18:14:01,145]\u001b[0m Trial 52 finished with value: 0.21266847382010026 and parameters: {'max_iter': 20821}. Best is trial 8 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 18:15:17,253]\u001b[0m Trial 53 finished with value: 0.21266733674707322 and parameters: {'max_iter': 20320}. Best is trial 8 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 18:16:35,721]\u001b[0m Trial 54 finished with value: 0.21271708933398648 and parameters: {'max_iter': 19804}. Best is trial 8 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 18:17:52,722]\u001b[0m Trial 55 finished with value: 0.21266894368678335 and parameters: {'max_iter': 21665}. Best is trial 8 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 18:19:08,804]\u001b[0m Trial 56 finished with value: 0.21266733674707322 and parameters: {'max_iter': 21173}. Best is trial 8 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 18:20:22,772]\u001b[0m Trial 57 finished with value: 0.21261747918449223 and parameters: {'max_iter': 17996}. Best is trial 8 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 18:21:22,160]\u001b[0m Trial 58 finished with value: 0.21266894368678335 and parameters: {'max_iter': 15413}. Best is trial 8 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 18:22:20,863]\u001b[0m Trial 59 finished with value: 0.21271755930807992 and parameters: {'max_iter': 19490}. Best is trial 8 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 18:23:19,501]\u001b[0m Trial 60 finished with value: 0.21271708933398648 and parameters: {'max_iter': 18748}. Best is trial 8 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 18:24:17,552]\u001b[0m Trial 61 finished with value: 0.21266733674707322 and parameters: {'max_iter': 20619}. Best is trial 8 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 18:25:21,534]\u001b[0m Trial 62 finished with value: 0.21271708933398648 and parameters: {'max_iter': 20010}. Best is trial 8 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 18:26:21,168]\u001b[0m Trial 63 finished with value: 0.21271708933398648 and parameters: {'max_iter': 20934}. Best is trial 8 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 18:27:18,360]\u001b[0m Trial 64 finished with value: 0.21261747918449223 and parameters: {'max_iter': 20625}. Best is trial 8 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 18:28:16,073]\u001b[0m Trial 65 finished with value: 0.21261873260391223 and parameters: {'max_iter': 21253}. Best is trial 8 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 18:29:14,220]\u001b[0m Trial 66 finished with value: 0.21266733674707322 and parameters: {'max_iter': 21801}. Best is trial 8 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 18:30:10,996]\u001b[0m Trial 67 finished with value: 0.21261873260391223 and parameters: {'max_iter': 20335}. Best is trial 8 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 18:31:09,418]\u001b[0m Trial 68 finished with value: 0.21266847382010026 and parameters: {'max_iter': 21025}. Best is trial 8 with value: 0.2127673236443402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 18:32:06,561]\u001b[0m Trial 69 finished with value: 0.21281698344577693 and parameters: {'max_iter': 16186}. Best is trial 69 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 18:33:05,401]\u001b[0m Trial 70 finished with value: 0.21266733674707322 and parameters: {'max_iter': 17771}. Best is trial 69 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 18:34:04,429]\u001b[0m Trial 71 finished with value: 0.21266894368678335 and parameters: {'max_iter': 16455}. Best is trial 69 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 18:35:03,963]\u001b[0m Trial 72 finished with value: 0.21256888643604827 and parameters: {'max_iter': 21835}. Best is trial 69 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 18:36:05,220]\u001b[0m Trial 73 finished with value: 0.21266847382010026 and parameters: {'max_iter': 16837}. Best is trial 69 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 18:37:06,111]\u001b[0m Trial 74 finished with value: 0.21271869664963308 and parameters: {'max_iter': 19883}. Best is trial 69 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 18:38:05,842]\u001b[0m Trial 75 finished with value: 0.21266847382010026 and parameters: {'max_iter': 19885}. Best is trial 69 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 18:39:03,610]\u001b[0m Trial 76 finished with value: 0.21271755930807992 and parameters: {'max_iter': 19576}. Best is trial 69 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 18:40:03,318]\u001b[0m Trial 77 finished with value: 0.21276673741075677 and parameters: {'max_iter': 16121}. Best is trial 69 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 18:41:04,000]\u001b[0m Trial 78 finished with value: 0.21271755930807992 and parameters: {'max_iter': 16089}. Best is trial 69 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 18:42:03,704]\u001b[0m Trial 79 finished with value: 0.21271811055003065 and parameters: {'max_iter': 15921}. Best is trial 69 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 18:43:03,336]\u001b[0m Trial 80 finished with value: 0.21266847382010026 and parameters: {'max_iter': 15242}. Best is trial 69 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 18:44:08,049]\u001b[0m Trial 81 finished with value: 0.21261861599094484 and parameters: {'max_iter': 16822}. Best is trial 69 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 18:45:12,898]\u001b[0m Trial 82 finished with value: 0.21266847382010026 and parameters: {'max_iter': 16237}. Best is trial 69 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 18:46:13,573]\u001b[0m Trial 83 finished with value: 0.21276673741075677 and parameters: {'max_iter': 17352}. Best is trial 69 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 18:47:13,685]\u001b[0m Trial 84 finished with value: 0.21261747918449223 and parameters: {'max_iter': 15635}. Best is trial 69 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 18:48:13,575]\u001b[0m Trial 85 finished with value: 0.21261908574747276 and parameters: {'max_iter': 17171}. Best is trial 69 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 18:49:13,789]\u001b[0m Trial 86 finished with value: 0.21271708933398648 and parameters: {'max_iter': 17274}. Best is trial 69 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 18:50:13,506]\u001b[0m Trial 87 finished with value: 0.21271708933398648 and parameters: {'max_iter': 16559}. Best is trial 69 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 18:51:12,519]\u001b[0m Trial 88 finished with value: 0.21276673741075677 and parameters: {'max_iter': 17517}. Best is trial 69 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 18:52:12,457]\u001b[0m Trial 89 finished with value: 0.21266847382010026 and parameters: {'max_iter': 17512}. Best is trial 69 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 18:53:11,408]\u001b[0m Trial 90 finished with value: 0.21271708933398648 and parameters: {'max_iter': 16596}. Best is trial 69 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 18:54:11,410]\u001b[0m Trial 91 finished with value: 0.21266733674707322 and parameters: {'max_iter': 17979}. Best is trial 69 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 18:55:10,981]\u001b[0m Trial 92 finished with value: 0.21261873260391223 and parameters: {'max_iter': 18407}. Best is trial 69 with value: 0.21281698344577693.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-09 18:56:09,188]\u001b[0m Trial 93 finished with value: 0.21266847382010026 and parameters: {'max_iter': 15698}. Best is trial 69 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 18:57:08,119]\u001b[0m Trial 94 finished with value: 0.21261747918449223 and parameters: {'max_iter': 18134}. Best is trial 69 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 18:58:08,227]\u001b[0m Trial 95 finished with value: 0.21271869664963308 and parameters: {'max_iter': 17087}. Best is trial 69 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 18:59:07,966]\u001b[0m Trial 96 finished with value: 0.21271708933398648 and parameters: {'max_iter': 17044}. Best is trial 69 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 19:00:08,555]\u001b[0m Trial 97 finished with value: 0.21271755930807992 and parameters: {'max_iter': 17489}. Best is trial 69 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 19:01:07,406]\u001b[0m Trial 98 finished with value: 0.2127673236443402 and parameters: {'max_iter': 17608}. Best is trial 69 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 19:02:06,287]\u001b[0m Trial 99 finished with value: 0.21266733674707322 and parameters: {'max_iter': 17669}. Best is trial 69 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 19:03:06,827]\u001b[0m Trial 100 finished with value: 0.21266847382010026 and parameters: {'max_iter': 16276}. Best is trial 69 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 19:04:05,927]\u001b[0m Trial 101 finished with value: 0.21266847382010026 and parameters: {'max_iter': 17041}. Best is trial 69 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 19:05:05,765]\u001b[0m Trial 102 finished with value: 0.21261873260391223 and parameters: {'max_iter': 17029}. Best is trial 69 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 19:06:05,035]\u001b[0m Trial 103 finished with value: 0.21266733674707322 and parameters: {'max_iter': 17512}. Best is trial 69 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 19:07:02,756]\u001b[0m Trial 104 finished with value: 0.21266733674707322 and parameters: {'max_iter': 18606}. Best is trial 69 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 19:08:03,720]\u001b[0m Trial 105 finished with value: 0.21256888643604827 and parameters: {'max_iter': 16655}. Best is trial 69 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 19:09:04,403]\u001b[0m Trial 106 finished with value: 0.21266847382010026 and parameters: {'max_iter': 17774}. Best is trial 69 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 19:10:04,329]\u001b[0m Trial 107 finished with value: 0.21266847382010026 and parameters: {'max_iter': 16010}. Best is trial 69 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 19:11:03,172]\u001b[0m Trial 108 finished with value: 0.21256888643604827 and parameters: {'max_iter': 17357}. Best is trial 69 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 19:12:04,123]\u001b[0m Trial 109 finished with value: 0.21271708933398648 and parameters: {'max_iter': 20446}. Best is trial 69 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 19:13:05,381]\u001b[0m Trial 110 finished with value: 0.21266733674707322 and parameters: {'max_iter': 19251}. Best is trial 69 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 19:14:04,709]\u001b[0m Trial 111 finished with value: 0.21266733674707322 and parameters: {'max_iter': 21665}. Best is trial 69 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 19:15:04,789]\u001b[0m Trial 112 finished with value: 0.21276673741075677 and parameters: {'max_iter': 21985}. Best is trial 69 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 19:16:04,824]\u001b[0m Trial 113 finished with value: 0.21266847382010026 and parameters: {'max_iter': 21556}. Best is trial 69 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 19:17:04,475]\u001b[0m Trial 114 finished with value: 0.21266733674707322 and parameters: {'max_iter': 21995}. Best is trial 69 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 19:18:04,179]\u001b[0m Trial 115 finished with value: 0.21271755930807992 and parameters: {'max_iter': 21397}. Best is trial 69 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 19:19:05,581]\u001b[0m Trial 116 finished with value: 0.21271811055003065 and parameters: {'max_iter': 20202}. Best is trial 69 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 19:20:06,212]\u001b[0m Trial 117 finished with value: 0.21261873260391223 and parameters: {'max_iter': 17675}. Best is trial 69 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 19:21:06,919]\u001b[0m Trial 118 finished with value: 0.21261873260391223 and parameters: {'max_iter': 21771}. Best is trial 69 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 19:22:09,554]\u001b[0m Trial 119 finished with value: 0.21266733674707322 and parameters: {'max_iter': 21256}. Best is trial 69 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 19:23:10,179]\u001b[0m Trial 120 finished with value: 0.21271708933398648 and parameters: {'max_iter': 18173}. Best is trial 69 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 19:24:09,887]\u001b[0m Trial 121 finished with value: 0.21266733674707322 and parameters: {'max_iter': 21883}. Best is trial 69 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 19:25:09,494]\u001b[0m Trial 122 finished with value: 0.21261747918449223 and parameters: {'max_iter': 21694}. Best is trial 69 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 19:26:09,560]\u001b[0m Trial 123 finished with value: 0.21266733674707322 and parameters: {'max_iter': 20809}. Best is trial 69 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 19:27:10,059]\u001b[0m Trial 124 finished with value: 0.21266882704627713 and parameters: {'max_iter': 21471}. Best is trial 69 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 19:28:06,012]\u001b[0m Trial 125 finished with value: 0.2127673236443402 and parameters: {'max_iter': 21991}. Best is trial 69 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 19:29:06,409]\u001b[0m Trial 126 finished with value: 0.21266894368678335 and parameters: {'max_iter': 16775}. Best is trial 69 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 19:30:04,978]\u001b[0m Trial 127 finished with value: 0.21261747918449223 and parameters: {'max_iter': 21852}. Best is trial 69 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 19:31:05,262]\u001b[0m Trial 128 finished with value: 0.21271755930807992 and parameters: {'max_iter': 17242}. Best is trial 69 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 19:32:07,812]\u001b[0m Trial 129 finished with value: 0.21261873260391223 and parameters: {'max_iter': 15831}. Best is trial 69 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 19:33:09,628]\u001b[0m Trial 130 finished with value: 0.21266733674707322 and parameters: {'max_iter': 19939}. Best is trial 69 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 19:34:13,079]\u001b[0m Trial 131 finished with value: 0.21271869664963308 and parameters: {'max_iter': 21620}. Best is trial 69 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 19:35:15,337]\u001b[0m Trial 132 finished with value: 0.21256888643604827 and parameters: {'max_iter': 18948}. Best is trial 69 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 19:36:20,594]\u001b[0m Trial 133 finished with value: 0.21276673741075677 and parameters: {'max_iter': 21546}. Best is trial 69 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 19:37:28,088]\u001b[0m Trial 134 finished with value: 0.2127184638586504 and parameters: {'max_iter': 21347}. Best is trial 69 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 19:38:30,787]\u001b[0m Trial 135 finished with value: 0.21266733674707322 and parameters: {'max_iter': 21717}. Best is trial 69 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 19:39:29,866]\u001b[0m Trial 136 finished with value: 0.21266894368678335 and parameters: {'max_iter': 21543}. Best is trial 69 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 19:40:30,989]\u001b[0m Trial 137 finished with value: 0.21261873260391223 and parameters: {'max_iter': 21990}. Best is trial 69 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 19:41:32,165]\u001b[0m Trial 138 finished with value: 0.21256888643604827 and parameters: {'max_iter': 16143}. Best is trial 69 with value: 0.21281698344577693.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-09 19:42:30,262]\u001b[0m Trial 139 finished with value: 0.21266847382010026 and parameters: {'max_iter': 16380}. Best is trial 69 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 19:43:30,703]\u001b[0m Trial 140 finished with value: 0.21266847382010026 and parameters: {'max_iter': 21066}. Best is trial 69 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 19:44:32,296]\u001b[0m Trial 141 finished with value: 0.21266847382010026 and parameters: {'max_iter': 21626}. Best is trial 69 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 19:45:35,868]\u001b[0m Trial 142 finished with value: 0.21266733674707322 and parameters: {'max_iter': 21835}. Best is trial 69 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 19:46:41,121]\u001b[0m Trial 143 finished with value: 0.21266733674707322 and parameters: {'max_iter': 21507}. Best is trial 69 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 19:47:49,233]\u001b[0m Trial 144 finished with value: 0.21271708933398648 and parameters: {'max_iter': 21325}. Best is trial 69 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 19:48:54,024]\u001b[0m Trial 145 finished with value: 0.21261861599094484 and parameters: {'max_iter': 20727}. Best is trial 69 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 19:49:54,657]\u001b[0m Trial 146 finished with value: 0.21266733674707322 and parameters: {'max_iter': 17410}. Best is trial 69 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 19:50:58,159]\u001b[0m Trial 147 finished with value: 0.21266894368678335 and parameters: {'max_iter': 15615}. Best is trial 69 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 19:51:57,034]\u001b[0m Trial 148 finished with value: 0.21266847382010026 and parameters: {'max_iter': 17170}. Best is trial 69 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 19:52:53,917]\u001b[0m Trial 149 finished with value: 0.21266894368678335 and parameters: {'max_iter': 21740}. Best is trial 69 with value: 0.21281698344577693.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study_lgr_175_3 = optuna.create_study(direction='maximize')\n",
    "study_lgr_175_3.optimize(objective_lgr_175_3, n_trials=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "3209d661",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-09T22:53:51.993305Z",
     "start_time": "2022-11-09T22:53:51.967303Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['study_lgr175_3.pkl']"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(study_lgr_175_3, \"study_lgr175_3.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "2de087a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-19T20:49:38.573897Z",
     "start_time": "2022-11-19T20:49:38.509496Z"
    }
   },
   "outputs": [],
   "source": [
    "study_lgr_175_3 = joblib.load(\"study_lgr175_3.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "ad9cadb3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-09T22:53:53.412780Z",
     "start_time": "2022-11-09T22:53:53.396262Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Value: 0.21281698344577693\n",
      "Best Parameters: {'max_iter': 16186}\n"
     ]
    }
   ],
   "source": [
    "print('Best Value: {}'.format(study_lgr_175_3.best_value))\n",
    "print('Best Parameters: {}'.format(study_lgr_175_3.best_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d107b56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study_lgr_175_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b31924d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_slice(study_lgr_175_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b7e2ec",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abc797e",
   "metadata": {},
   "source": [
    "Logistic Regression PCA 175 - Study 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "2dccf492",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-10T20:49:23.884221Z",
     "start_time": "2022-11-10T20:49:23.867777Z"
    }
   },
   "outputs": [],
   "source": [
    "# Se utiliza 'solver' = 'saga' obtenido del study 1 y se busca optimizar el hiperparámetro 'max_iter'. \n",
    "# A su vez, se incluye el hiperparámetro 'penalty' para optimizar.\n",
    "\n",
    "def objective_lgr_175_4(trial):\n",
    " \n",
    "    max_iter_trial = trial.suggest_int('max_iter', 16000,22000)\n",
    "    penalty_trial = trial.suggest_categorical('penalty',['l2', 'none'])\n",
    "\n",
    "    lgr = LogisticRegression(solver = 'saga', max_iter = max_iter_trial, penalty = penalty_trial)\n",
    "\n",
    "    skf = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 1 )\n",
    "\n",
    "    lgr_175_results    = []\n",
    "    \n",
    "    for train_index, test_index in skf.split(X,y):\n",
    "    \n",
    "        X_train, X_test = pca_175.fit_transform(X.iloc[train_index]), pca_175.transform(X.iloc[test_index])\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "        lgr.fit(X_train, y_train)\n",
    "    \n",
    "        y_pred = lgr.predict(X_test)\n",
    "    \n",
    "        recall    = recall_score(y_test, y_pred)\n",
    "\n",
    "        list_results   = [recall]\n",
    "        lgr_175_results.append(list_results)\n",
    "    \n",
    "        \n",
    "    return gmean(lgr_175_results) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "86956d4e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-10T23:41:21.408744Z",
     "start_time": "2022-11-10T20:49:24.427749Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-10 17:49:24,429]\u001b[0m A new study created in memory with name: no-name-7b6c2d04-8386-4716-98a9-9ccbca74f421\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 17:50:31,946]\u001b[0m Trial 0 finished with value: 0.21271744264091 and parameters: {'max_iter': 21145, 'penalty': 'none'}. Best is trial 0 with value: 0.21271744264091.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 17:51:37,181]\u001b[0m Trial 1 finished with value: 0.21266733674707322 and parameters: {'max_iter': 19086, 'penalty': 'l2'}. Best is trial 0 with value: 0.21271744264091.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 17:52:41,123]\u001b[0m Trial 2 finished with value: 0.21256888643604827 and parameters: {'max_iter': 20154, 'penalty': 'none'}. Best is trial 0 with value: 0.21271744264091.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 17:53:50,671]\u001b[0m Trial 3 finished with value: 0.21266733674707322 and parameters: {'max_iter': 17177, 'penalty': 'l2'}. Best is trial 0 with value: 0.21271744264091.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 17:54:55,797]\u001b[0m Trial 4 finished with value: 0.21266733674707322 and parameters: {'max_iter': 21963, 'penalty': 'l2'}. Best is trial 0 with value: 0.21271744264091.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 17:56:00,737]\u001b[0m Trial 5 finished with value: 0.21266847382010026 and parameters: {'max_iter': 19399, 'penalty': 'l2'}. Best is trial 0 with value: 0.21271744264091.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 17:57:06,212]\u001b[0m Trial 6 finished with value: 0.21266733674707322 and parameters: {'max_iter': 21002, 'penalty': 'none'}. Best is trial 0 with value: 0.21271744264091.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 17:58:10,833]\u001b[0m Trial 7 finished with value: 0.21261861599094484 and parameters: {'max_iter': 16869, 'penalty': 'l2'}. Best is trial 0 with value: 0.21271744264091.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 17:59:15,712]\u001b[0m Trial 8 finished with value: 0.21266847382010026 and parameters: {'max_iter': 17334, 'penalty': 'none'}. Best is trial 0 with value: 0.21271744264091.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 18:00:21,484]\u001b[0m Trial 9 finished with value: 0.21261873260391223 and parameters: {'max_iter': 19912, 'penalty': 'l2'}. Best is trial 0 with value: 0.21271744264091.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 18:01:25,151]\u001b[0m Trial 10 finished with value: 0.21261783232597087 and parameters: {'max_iter': 21929, 'penalty': 'none'}. Best is trial 0 with value: 0.21271744264091.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 18:02:29,736]\u001b[0m Trial 11 finished with value: 0.21266733674707322 and parameters: {'max_iter': 18403, 'penalty': 'none'}. Best is trial 0 with value: 0.21271744264091.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 18:03:36,195]\u001b[0m Trial 12 finished with value: 0.21266733674707322 and parameters: {'max_iter': 20597, 'penalty': 'l2'}. Best is trial 0 with value: 0.21271744264091.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 18:04:40,589]\u001b[0m Trial 13 finished with value: 0.21271811055003065 and parameters: {'max_iter': 18995, 'penalty': 'none'}. Best is trial 13 with value: 0.21271811055003065.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 18:05:44,987]\u001b[0m Trial 14 finished with value: 0.21271708933398648 and parameters: {'max_iter': 18031, 'penalty': 'none'}. Best is trial 13 with value: 0.21271811055003065.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 18:06:49,373]\u001b[0m Trial 15 finished with value: 0.21276673741075677 and parameters: {'max_iter': 16184, 'penalty': 'none'}. Best is trial 15 with value: 0.21276673741075677.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 18:07:57,452]\u001b[0m Trial 16 finished with value: 0.21281698344577693 and parameters: {'max_iter': 16457, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 18:09:02,404]\u001b[0m Trial 17 finished with value: 0.21256888643604827 and parameters: {'max_iter': 16009, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 18:10:07,527]\u001b[0m Trial 18 finished with value: 0.21281698344577693 and parameters: {'max_iter': 16030, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 18:11:10,748]\u001b[0m Trial 19 finished with value: 0.21271708933398648 and parameters: {'max_iter': 16638, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 18:12:15,752]\u001b[0m Trial 20 finished with value: 0.2127673236443402 and parameters: {'max_iter': 17792, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 18:13:19,688]\u001b[0m Trial 21 finished with value: 0.21261861599094484 and parameters: {'max_iter': 17988, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 18:14:24,946]\u001b[0m Trial 22 finished with value: 0.21261908574747276 and parameters: {'max_iter': 17602, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 18:15:28,470]\u001b[0m Trial 23 finished with value: 0.21271755930807992 and parameters: {'max_iter': 16655, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 18:16:32,539]\u001b[0m Trial 24 finished with value: 0.21261873260391223 and parameters: {'max_iter': 16413, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 18:17:38,486]\u001b[0m Trial 25 finished with value: 0.21266847382010026 and parameters: {'max_iter': 17103, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 18:18:43,390]\u001b[0m Trial 26 finished with value: 0.21266847382010026 and parameters: {'max_iter': 17639, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 18:19:48,219]\u001b[0m Trial 27 finished with value: 0.21266847382010026 and parameters: {'max_iter': 18466, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 18:20:51,869]\u001b[0m Trial 28 finished with value: 0.21266733674707322 and parameters: {'max_iter': 16397, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 18:21:58,372]\u001b[0m Trial 29 finished with value: 0.21261873260391223 and parameters: {'max_iter': 16874, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 18:23:03,234]\u001b[0m Trial 30 finished with value: 0.21266733674707322 and parameters: {'max_iter': 17617, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 18:24:07,127]\u001b[0m Trial 31 finished with value: 0.21266733674707322 and parameters: {'max_iter': 16163, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 18:25:12,224]\u001b[0m Trial 32 finished with value: 0.21266733674707322 and parameters: {'max_iter': 16107, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 18:26:18,416]\u001b[0m Trial 33 finished with value: 0.21266733674707322 and parameters: {'max_iter': 16441, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 18:27:23,181]\u001b[0m Trial 34 finished with value: 0.21261747918449223 and parameters: {'max_iter': 16883, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 18:28:27,679]\u001b[0m Trial 35 finished with value: 0.21276673741075677 and parameters: {'max_iter': 17246, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 18:29:32,052]\u001b[0m Trial 36 finished with value: 0.21271755930807992 and parameters: {'max_iter': 18089, 'penalty': 'l2'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 18:30:36,683]\u001b[0m Trial 37 finished with value: 0.21266733674707322 and parameters: {'max_iter': 17233, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 18:31:42,048]\u001b[0m Trial 38 finished with value: 0.21271708933398648 and parameters: {'max_iter': 17373, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 18:32:45,149]\u001b[0m Trial 39 finished with value: 0.21261873260391223 and parameters: {'max_iter': 18906, 'penalty': 'l2'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 18:33:48,483]\u001b[0m Trial 40 finished with value: 0.21266847382010026 and parameters: {'max_iter': 17063, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 18:34:53,169]\u001b[0m Trial 41 finished with value: 0.21271755930807992 and parameters: {'max_iter': 16598, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-10 18:35:57,596]\u001b[0m Trial 42 finished with value: 0.21261747918449223 and parameters: {'max_iter': 16011, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 18:37:02,268]\u001b[0m Trial 43 finished with value: 0.21261873260391223 and parameters: {'max_iter': 16293, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 18:38:07,816]\u001b[0m Trial 44 finished with value: 0.21266733674707322 and parameters: {'max_iter': 16787, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 18:39:14,620]\u001b[0m Trial 45 finished with value: 0.21261873260391223 and parameters: {'max_iter': 17482, 'penalty': 'l2'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 18:40:20,839]\u001b[0m Trial 46 finished with value: 0.21271708933398648 and parameters: {'max_iter': 17019, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 18:41:24,991]\u001b[0m Trial 47 finished with value: 0.21271869664963308 and parameters: {'max_iter': 19749, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 18:42:27,605]\u001b[0m Trial 48 finished with value: 0.21266847382010026 and parameters: {'max_iter': 16520, 'penalty': 'l2'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 18:43:31,271]\u001b[0m Trial 49 finished with value: 0.21276673741075677 and parameters: {'max_iter': 17785, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 18:44:35,077]\u001b[0m Trial 50 finished with value: 0.21261873260391223 and parameters: {'max_iter': 18668, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 18:45:39,167]\u001b[0m Trial 51 finished with value: 0.21261873260391223 and parameters: {'max_iter': 17863, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 18:46:42,875]\u001b[0m Trial 52 finished with value: 0.21266847382010026 and parameters: {'max_iter': 18340, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 18:47:47,228]\u001b[0m Trial 53 finished with value: 0.21271708933398648 and parameters: {'max_iter': 17817, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 18:48:52,502]\u001b[0m Trial 54 finished with value: 0.21256888643604827 and parameters: {'max_iter': 16228, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 18:49:57,883]\u001b[0m Trial 55 finished with value: 0.21276673741075677 and parameters: {'max_iter': 19414, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 18:51:04,204]\u001b[0m Trial 56 finished with value: 0.21271708933398648 and parameters: {'max_iter': 19313, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 18:52:08,536]\u001b[0m Trial 57 finished with value: 0.21271869664963308 and parameters: {'max_iter': 20063, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 18:53:14,004]\u001b[0m Trial 58 finished with value: 0.21261873260391223 and parameters: {'max_iter': 21346, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 18:54:17,911]\u001b[0m Trial 59 finished with value: 0.21271755930807992 and parameters: {'max_iter': 16688, 'penalty': 'l2'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 18:55:22,176]\u001b[0m Trial 60 finished with value: 0.21266847382010026 and parameters: {'max_iter': 19126, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 18:56:28,382]\u001b[0m Trial 61 finished with value: 0.21271708933398648 and parameters: {'max_iter': 18224, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 18:57:31,963]\u001b[0m Trial 62 finished with value: 0.21261873260391223 and parameters: {'max_iter': 19801, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 18:58:37,564]\u001b[0m Trial 63 finished with value: 0.21271755930807992 and parameters: {'max_iter': 19479, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 18:59:42,026]\u001b[0m Trial 64 finished with value: 0.21266824108407942 and parameters: {'max_iter': 18760, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 19:00:46,686]\u001b[0m Trial 65 finished with value: 0.2127673236443402 and parameters: {'max_iter': 20449, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 19:01:52,093]\u001b[0m Trial 66 finished with value: 0.21266722010744832 and parameters: {'max_iter': 20827, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 19:02:56,800]\u001b[0m Trial 67 finished with value: 0.21266733674707322 and parameters: {'max_iter': 20257, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 19:04:02,322]\u001b[0m Trial 68 finished with value: 0.21261861599094484 and parameters: {'max_iter': 21368, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 19:05:10,697]\u001b[0m Trial 69 finished with value: 0.21271708933398648 and parameters: {'max_iter': 20358, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 19:06:23,842]\u001b[0m Trial 70 finished with value: 0.21266733674707322 and parameters: {'max_iter': 16274, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 19:07:31,995]\u001b[0m Trial 71 finished with value: 0.21271708933398648 and parameters: {'max_iter': 17274, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 19:08:42,939]\u001b[0m Trial 72 finished with value: 0.21261873260391223 and parameters: {'max_iter': 17737, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 19:10:04,505]\u001b[0m Trial 73 finished with value: 0.21271755930807992 and parameters: {'max_iter': 16426, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 19:11:14,538]\u001b[0m Trial 74 finished with value: 0.21271708933398648 and parameters: {'max_iter': 20568, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 19:12:25,050]\u001b[0m Trial 75 finished with value: 0.21271708933398648 and parameters: {'max_iter': 16883, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 19:13:33,691]\u001b[0m Trial 76 finished with value: 0.21261747918449223 and parameters: {'max_iter': 17441, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 19:14:39,387]\u001b[0m Trial 77 finished with value: 0.21271869664963308 and parameters: {'max_iter': 16093, 'penalty': 'l2'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 19:15:44,298]\u001b[0m Trial 78 finished with value: 0.21261873260391223 and parameters: {'max_iter': 18612, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 19:16:51,882]\u001b[0m Trial 79 finished with value: 0.21261861599094484 and parameters: {'max_iter': 18058, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 19:17:58,247]\u001b[0m Trial 80 finished with value: 0.21266733674707322 and parameters: {'max_iter': 17083, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 19:19:05,051]\u001b[0m Trial 81 finished with value: 0.2127673236443402 and parameters: {'max_iter': 19752, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 19:20:10,996]\u001b[0m Trial 82 finished with value: 0.21271708933398648 and parameters: {'max_iter': 19388, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 19:21:17,318]\u001b[0m Trial 83 finished with value: 0.2127673236443402 and parameters: {'max_iter': 19188, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-10 19:22:24,181]\u001b[0m Trial 84 finished with value: 0.21261873260391223 and parameters: {'max_iter': 19651, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 19:23:32,707]\u001b[0m Trial 85 finished with value: 0.21271869664963308 and parameters: {'max_iter': 19192, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 19:24:36,960]\u001b[0m Trial 86 finished with value: 0.21266847382010026 and parameters: {'max_iter': 18958, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 19:25:42,096]\u001b[0m Trial 87 finished with value: 0.21271708933398648 and parameters: {'max_iter': 19974, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 19:26:50,050]\u001b[0m Trial 88 finished with value: 0.21266768997136143 and parameters: {'max_iter': 19515, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 19:27:59,114]\u001b[0m Trial 89 finished with value: 0.21271869664963308 and parameters: {'max_iter': 19242, 'penalty': 'l2'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 19:29:11,233]\u001b[0m Trial 90 finished with value: 0.21266733674707322 and parameters: {'max_iter': 16598, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 19:30:23,099]\u001b[0m Trial 91 finished with value: 0.21271708933398648 and parameters: {'max_iter': 19643, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 19:31:34,172]\u001b[0m Trial 92 finished with value: 0.21251905195408055 and parameters: {'max_iter': 18782, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 19:32:43,044]\u001b[0m Trial 93 finished with value: 0.21271708933398648 and parameters: {'max_iter': 16010, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 19:33:50,918]\u001b[0m Trial 94 finished with value: 0.21271869664963308 and parameters: {'max_iter': 16334, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 19:35:01,320]\u001b[0m Trial 95 finished with value: 0.21256888643604827 and parameters: {'max_iter': 19048, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 19:36:12,237]\u001b[0m Trial 96 finished with value: 0.21261873260391223 and parameters: {'max_iter': 18487, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 19:37:25,179]\u001b[0m Trial 97 finished with value: 0.21266733674707322 and parameters: {'max_iter': 16715, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 19:38:38,455]\u001b[0m Trial 98 finished with value: 0.21266733674707322 and parameters: {'max_iter': 17533, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 19:39:47,759]\u001b[0m Trial 99 finished with value: 0.21261873260391223 and parameters: {'max_iter': 16179, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 19:40:57,450]\u001b[0m Trial 100 finished with value: 0.21271708933398648 and parameters: {'max_iter': 20450, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 19:42:07,965]\u001b[0m Trial 101 finished with value: 0.21261747918449223 and parameters: {'max_iter': 19176, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 19:43:16,500]\u001b[0m Trial 102 finished with value: 0.21266847382010026 and parameters: {'max_iter': 16221, 'penalty': 'l2'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 19:44:27,604]\u001b[0m Trial 103 finished with value: 0.21261873260391223 and parameters: {'max_iter': 16510, 'penalty': 'l2'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 19:45:37,062]\u001b[0m Trial 104 finished with value: 0.21271755930807992 and parameters: {'max_iter': 16006, 'penalty': 'l2'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 19:46:43,576]\u001b[0m Trial 105 finished with value: 0.21261873260391223 and parameters: {'max_iter': 19850, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 19:47:54,301]\u001b[0m Trial 106 finished with value: 0.21266733674707322 and parameters: {'max_iter': 19709, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 19:49:06,083]\u001b[0m Trial 107 finished with value: 0.21261747918449223 and parameters: {'max_iter': 20132, 'penalty': 'l2'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 19:50:18,395]\u001b[0m Trial 108 finished with value: 0.21266733674707322 and parameters: {'max_iter': 19311, 'penalty': 'l2'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 19:51:29,806]\u001b[0m Trial 109 finished with value: 0.21266894368678335 and parameters: {'max_iter': 18170, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 19:52:38,412]\u001b[0m Trial 110 finished with value: 0.21271755930807992 and parameters: {'max_iter': 16102, 'penalty': 'l2'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 19:53:47,531]\u001b[0m Trial 111 finished with value: 0.21266722010744832 and parameters: {'max_iter': 19998, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 19:54:57,001]\u001b[0m Trial 112 finished with value: 0.21271708933398648 and parameters: {'max_iter': 17932, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 19:56:10,912]\u001b[0m Trial 113 finished with value: 0.21271708933398648 and parameters: {'max_iter': 19472, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 19:57:23,689]\u001b[0m Trial 114 finished with value: 0.21266733674707322 and parameters: {'max_iter': 20953, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 19:58:35,262]\u001b[0m Trial 115 finished with value: 0.21261747918449223 and parameters: {'max_iter': 20023, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 19:59:45,211]\u001b[0m Trial 116 finished with value: 0.21266722010744832 and parameters: {'max_iter': 20238, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 20:00:52,168]\u001b[0m Trial 117 finished with value: 0.21271708933398648 and parameters: {'max_iter': 18814, 'penalty': 'l2'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 20:02:02,840]\u001b[0m Trial 118 finished with value: 0.21266733674707322 and parameters: {'max_iter': 16422, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 20:03:14,665]\u001b[0m Trial 119 finished with value: 0.21271708933398648 and parameters: {'max_iter': 20710, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 20:04:27,016]\u001b[0m Trial 120 finished with value: 0.21261908574747276 and parameters: {'max_iter': 19570, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 20:05:37,201]\u001b[0m Trial 121 finished with value: 0.21256888643604827 and parameters: {'max_iter': 19298, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 20:06:45,584]\u001b[0m Trial 122 finished with value: 0.21266722010744832 and parameters: {'max_iter': 20096, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 20:07:54,596]\u001b[0m Trial 123 finished with value: 0.21261873260391223 and parameters: {'max_iter': 16401, 'penalty': 'l2'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 20:09:03,394]\u001b[0m Trial 124 finished with value: 0.2127673236443402 and parameters: {'max_iter': 16331, 'penalty': 'l2'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 20:10:08,472]\u001b[0m Trial 125 finished with value: 0.21266882704627713 and parameters: {'max_iter': 16137, 'penalty': 'l2'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-10 20:11:15,288]\u001b[0m Trial 126 finished with value: 0.21271755930807992 and parameters: {'max_iter': 16545, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 20:12:23,751]\u001b[0m Trial 127 finished with value: 0.21261873260391223 and parameters: {'max_iter': 19198, 'penalty': 'l2'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 20:13:32,532]\u001b[0m Trial 128 finished with value: 0.21266847382010026 and parameters: {'max_iter': 16304, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 20:14:41,508]\u001b[0m Trial 129 finished with value: 0.21266722010744832 and parameters: {'max_iter': 19802, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 20:15:51,871]\u001b[0m Trial 130 finished with value: 0.21266847382010026 and parameters: {'max_iter': 16787, 'penalty': 'l2'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 20:17:04,575]\u001b[0m Trial 131 finished with value: 0.21266847382010026 and parameters: {'max_iter': 17701, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 20:18:18,819]\u001b[0m Trial 132 finished with value: 0.21261873260391223 and parameters: {'max_iter': 19110, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 20:19:33,457]\u001b[0m Trial 133 finished with value: 0.21261873260391223 and parameters: {'max_iter': 16961, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 20:20:39,991]\u001b[0m Trial 134 finished with value: 0.21266733674707322 and parameters: {'max_iter': 16291, 'penalty': 'l2'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 20:21:50,310]\u001b[0m Trial 135 finished with value: 0.21266894368678335 and parameters: {'max_iter': 21719, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 20:23:00,080]\u001b[0m Trial 136 finished with value: 0.21266847382010026 and parameters: {'max_iter': 20322, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 20:24:10,403]\u001b[0m Trial 137 finished with value: 0.21266722010744832 and parameters: {'max_iter': 17199, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 20:25:32,305]\u001b[0m Trial 138 finished with value: 0.21261873260391223 and parameters: {'max_iter': 16323, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 20:27:01,148]\u001b[0m Trial 139 finished with value: 0.21261861599094484 and parameters: {'max_iter': 20529, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 20:28:31,264]\u001b[0m Trial 140 finished with value: 0.21266733674707322 and parameters: {'max_iter': 19715, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 20:30:02,205]\u001b[0m Trial 141 finished with value: 0.21266894368678335 and parameters: {'max_iter': 16163, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 20:31:34,215]\u001b[0m Trial 142 finished with value: 0.21271708933398648 and parameters: {'max_iter': 18950, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 20:33:09,669]\u001b[0m Trial 143 finished with value: 0.21266722010744832 and parameters: {'max_iter': 16064, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 20:34:42,837]\u001b[0m Trial 144 finished with value: 0.21261747918449223 and parameters: {'max_iter': 19400, 'penalty': 'l2'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 20:36:13,600]\u001b[0m Trial 145 finished with value: 0.21261873260391223 and parameters: {'max_iter': 17355, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 20:37:52,812]\u001b[0m Trial 146 finished with value: 0.21266733674707322 and parameters: {'max_iter': 16632, 'penalty': 'none'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 20:39:13,473]\u001b[0m Trial 147 finished with value: 0.21271708933398648 and parameters: {'max_iter': 18617, 'penalty': 'l2'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 20:40:17,149]\u001b[0m Trial 148 finished with value: 0.21271708933398648 and parameters: {'max_iter': 16452, 'penalty': 'l2'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 20:41:21,396]\u001b[0m Trial 149 finished with value: 0.21271869664963308 and parameters: {'max_iter': 19247, 'penalty': 'l2'}. Best is trial 16 with value: 0.21281698344577693.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study_lgr_175_4 = optuna.create_study(direction='maximize')\n",
    "study_lgr_175_4.optimize(objective_lgr_175_4, n_trials=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "042f044b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-10T23:42:10.323718Z",
     "start_time": "2022-11-10T23:42:10.256275Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['study_lgr175_4.pkl']"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(study_lgr_175_4, \"study_lgr175_4.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "e0155897",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-19T20:50:29.634576Z",
     "start_time": "2022-11-19T20:50:29.592609Z"
    }
   },
   "outputs": [],
   "source": [
    "study_lgr_175_4 = joblib.load(\"study_lgr175_4.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "cfba2c3f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-10T23:42:35.373677Z",
     "start_time": "2022-11-10T23:42:35.367138Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Value: 0.21281698344577693\n",
      "Best Parameters: {'max_iter': 16457, 'penalty': 'none'}\n"
     ]
    }
   ],
   "source": [
    "print('Best Value: {}'.format(study_lgr_175_4.best_value))\n",
    "print('Best Parameters: {}'.format(study_lgr_175_4.best_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23cea60",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study_lgr_175_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37ef360",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study_lgr_175_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77638ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_slice(study_lgr_175_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14152619",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9debe840",
   "metadata": {},
   "source": [
    "Logistic Regression PCA 175 - Study 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "id": "0306eff1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-21T23:21:16.501470Z",
     "start_time": "2022-11-21T23:21:16.480469Z"
    }
   },
   "outputs": [],
   "source": [
    "# Se utiliza 'solver' = 'saga' obtenido del study 1 y 'max_iter' = 16457 obtenido del study 4.\n",
    "# Se busca optimizar el hiperparámetro 'penalty'.\n",
    "\n",
    "def objective_lgr_175_5(trial):\n",
    "\n",
    "    penalty_trial = trial.suggest_categorical('penalty',['l2', 'none'])\n",
    "\n",
    "    lgr = LogisticRegression(solver = 'saga', max_iter = 16457, penalty = penalty_trial)\n",
    "\n",
    "    skf = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 1 )\n",
    "\n",
    "    lgr_175_results    = []\n",
    "    \n",
    "    for train_index, test_index in skf.split(X,y):\n",
    "    \n",
    "        X_train, X_test = pca_175.fit_transform(X.iloc[train_index]), pca_175.transform(X.iloc[test_index])\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "        lgr.fit(X_train, y_train)\n",
    "    \n",
    "        y_pred = lgr.predict(X_test)\n",
    "    \n",
    "        recall    = recall_score(y_test, y_pred)\n",
    "\n",
    "        list_results   = [recall]\n",
    "        lgr_175_results.append(list_results)\n",
    "    \n",
    "        \n",
    "    return gmean(lgr_175_results) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "id": "acd6e981",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-21T23:31:32.645526Z",
     "start_time": "2022-11-21T23:25:03.173368Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-21 20:25:03,175]\u001b[0m A new study created in memory with name: no-name-354eacbc-cbf2-4b2c-a4e2-cb311e25db3f\u001b[0m\n",
      "\u001b[32m[I 2022-11-21 20:26:13,436]\u001b[0m Trial 0 finished with value: 0.21281698344577693 and parameters: {'penalty': 'none'}. Best is trial 0 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-21 20:27:16,484]\u001b[0m Trial 1 finished with value: 0.21261747918449223 and parameters: {'penalty': 'none'}. Best is trial 0 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-21 20:28:18,362]\u001b[0m Trial 2 finished with value: 0.21266894368678335 and parameters: {'penalty': 'none'}. Best is trial 0 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-21 20:29:22,337]\u001b[0m Trial 3 finished with value: 0.21266847382010026 and parameters: {'penalty': 'none'}. Best is trial 0 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-21 20:30:24,570]\u001b[0m Trial 4 finished with value: 0.21266894368678335 and parameters: {'penalty': 'l2'}. Best is trial 0 with value: 0.21281698344577693.\u001b[0m\n",
      "\u001b[32m[I 2022-11-21 20:31:32,628]\u001b[0m Trial 5 finished with value: 0.21266733674707322 and parameters: {'penalty': 'none'}. Best is trial 0 with value: 0.21281698344577693.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study_lgr_175_5 = optuna.create_study(direction='maximize')\n",
    "study_lgr_175_5.optimize(objective_lgr_175_5, n_trials= 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "id": "a95b4445",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-21T23:35:29.041253Z",
     "start_time": "2022-11-21T23:35:29.013853Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Value: 0.21281698344577693\n",
      "Best Parameters: {'penalty': 'none'}\n"
     ]
    }
   ],
   "source": [
    "print('Best Value: {}'.format(study_lgr_175_5.best_value))\n",
    "print('Best Parameters: {}'.format(study_lgr_175_5.best_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "id": "72b12c3f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-21T23:31:32.661081Z",
     "start_time": "2022-11-21T23:31:32.647525Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['study_lgr175_5.pkl']"
      ]
     },
     "execution_count": 571,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(study_lgr_175_5, \"study_lgr175_5.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "id": "804bc0a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-21T23:31:32.709143Z",
     "start_time": "2022-11-21T23:31:32.662592Z"
    }
   },
   "outputs": [],
   "source": [
    "study_lgr_175_5 = joblib.load(\"study_lgr175_5.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4436f62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study_lgr_175_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e56786",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_slice(study_lgr_175_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2542ee6",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea809da",
   "metadata": {},
   "source": [
    "Se utilizarán en el full dataset los hiperparámetros con los que se obtuvo mejores resultados en la Logistic Regression PCA 175. Dichos hiperparámetros son 'solver' = 'saga', 'max_iter' = 16457 y 'penalty' = 'none'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "id": "8435ae13",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-21T23:43:48.236758Z",
     "start_time": "2022-11-21T23:36:05.752176Z"
    }
   },
   "outputs": [],
   "source": [
    "# Logistic Regression - Full dataset\n",
    "\n",
    "lgr = LogisticRegression( max_iter= 16457 , solver = 'saga', penalty = 'none')\n",
    "\n",
    "\n",
    "skf = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 1 )\n",
    "\n",
    "lgr_full_results    = []\n",
    "lgr_full_results_cm = []\n",
    "tiempo_ejecucion = []\n",
    "inicio = time.time()\n",
    "\n",
    "for train_index, test_index in skf.split(X,y):\n",
    "    \n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    lgr.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = lgr.predict(X_test)\n",
    "    \n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall    = recall_score(y_test, y_pred)\n",
    "    f1        = f1_score(y_test, y_pred)\n",
    "    cm        = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    list_results   = [precision, recall, f1]\n",
    "    list_cm = [cm]\n",
    "    lgr_full_results.append(list_results)\n",
    "    lgr_full_results_cm.append(list_cm)\n",
    "    \n",
    "fin = time.time()\n",
    "tiempo_ejecucion.append(fin - inicio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "id": "13eaf4a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-21T23:43:48.252217Z",
     "start_time": "2022-11-21T23:43:48.238672Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRECISION</th>\n",
       "      <th>RECALL</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegression_full_opt(PCA175)</th>\n",
       "      <td>0.691913</td>\n",
       "      <td>0.257079</td>\n",
       "      <td>0.374857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     PRECISION    RECALL        F1\n",
       "LogisticRegression_full_opt(PCA175)   0.691913  0.257079  0.374857"
      ]
     },
     "execution_count": 577,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filas    = ['LogisticRegression_full_opt(PCA175)']\n",
    "columnas = [\"PRECISION\", \"RECALL\", \"F1\"]\n",
    "resultados = pd.DataFrame([gmean(lgr_full_results)], columns=columnas, index=filas)\n",
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "id": "f60c5c83",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-21T23:43:48.299481Z",
     "start_time": "2022-11-21T23:43:48.253181Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRECISION</th>\n",
       "      <th>RECALL</th>\n",
       "      <th>F1</th>\n",
       "      <th>TIEMPO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegression_full_opt(PCA175)</th>\n",
       "      <td>0.691913</td>\n",
       "      <td>0.257079</td>\n",
       "      <td>0.374857</td>\n",
       "      <td>462.47266</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     PRECISION    RECALL        F1     TIEMPO\n",
       "LogisticRegression_full_opt(PCA175)   0.691913  0.257079  0.374857  462.47266"
      ]
     },
     "execution_count": 578,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados['TIEMPO']= tiempo_ejecucion\n",
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "id": "5f807ed0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-21T23:43:48.315481Z",
     "start_time": "2022-11-21T23:43:48.301481Z"
    }
   },
   "outputs": [],
   "source": [
    "resultados.to_pickle(\"resultados_lgr_full_opt_PCA175\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "id": "46e0bf69",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-21T23:43:48.330559Z",
     "start_time": "2022-11-21T23:43:48.317481Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[17760.09394508,   229.61845735],\n",
       "        [ 1492.95722629,   516.67663606]]])"
      ]
     },
     "execution_count": 580,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados_cm= gmean(lgr_full_results_cm)\n",
    "resultados_cm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "id": "d8236c64",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-21T23:43:48.346481Z",
     "start_time": "2022-11-21T23:43:48.332481Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('LogisticRegression_full_opt_PCA175_cm.pkl','wb') as f:\n",
    "    pickle.dump(resultados_cm, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6147dfa2",
   "metadata": {},
   "source": [
    "El resultado obtenido por el modelo que emplea los hiperparámetros 'solver' = 'saga', 'max_iter' = 16457 y penalty = 'none' en el fulldataset es inferior al obtenido con los hiperparámetros default."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebe1979",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda83774",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf33b575",
   "metadata": {},
   "source": [
    "<font size='4' style=\"color:orange\">  <b> Logistic Regression - Full Dataset </b> </font>\n",
    "<a name=\"lgr_opt_full\"></a>\n",
    "\n",
    "[[ Back to Top ]](#content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c823a18",
   "metadata": {},
   "source": [
    "Teniendo en cuenta que los hiperparámetros optimizados con PCA 100 y 175 no se pueden extrapolar al fulldataset, se buscará optimizar el dataset completo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67435eb6",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72675b11",
   "metadata": {},
   "source": [
    "Logistic Regression Full Dataset - Study 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "10f7aa1c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-16T01:04:39.621899Z",
     "start_time": "2022-11-16T01:04:39.614857Z"
    }
   },
   "outputs": [],
   "source": [
    "# Se busca optimizar los hiperparámetros 'solver' y 'max_iter'.\n",
    "\n",
    "def objective_lgr_1(trial):\n",
    "    \n",
    "    solver_trial = trial.suggest_categorical('solver',['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'])\n",
    "    max_iter_trial = trial.suggest_int('max_iter', 7000,30000, 250)\n",
    "\n",
    "\n",
    "    lgr = LogisticRegression(solver = solver_trial, max_iter = max_iter_trial)\n",
    "\n",
    "    skf = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 1 )\n",
    "\n",
    "    lgr_results    = []\n",
    "    \n",
    "    for train_index, test_index in skf.split(X,y):\n",
    "    \n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "        lgr.fit(X_train, y_train)\n",
    "    \n",
    "        y_pred = lgr.predict(X_test)\n",
    "    \n",
    "        recall    = recall_score(y_test, y_pred)\n",
    "\n",
    "        list_results   = [recall]\n",
    "        lgr_results.append(list_results)\n",
    "    \n",
    "        \n",
    "    return gmean(lgr_results)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "37fd1be4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-16T08:24:55.099558Z",
     "start_time": "2022-11-16T01:04:40.618939Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-15 22:04:40,622]\u001b[0m A new study created in memory with name: no-name-14845ca1-fd6e-4ae8-a38d-0fbb42fbba5f\u001b[0m\n",
      "\u001b[32m[I 2022-11-15 22:12:17,471]\u001b[0m Trial 0 finished with value: 0.2571786091744804 and parameters: {'solver': 'saga', 'max_iter': 9750}. Best is trial 0 with value: 0.2571786091744804.\u001b[0m\n",
      "\u001b[32m[I 2022-11-15 22:42:03,337]\u001b[0m Trial 1 finished with value: 0.269193094004635 and parameters: {'solver': 'liblinear', 'max_iter': 20000}. Best is trial 1 with value: 0.269193094004635.\u001b[0m\n",
      "\u001b[32m[I 2022-11-15 22:48:03,940]\u001b[0m Trial 2 finished with value: 0.26211328355076136 and parameters: {'solver': 'sag', 'max_iter': 18500}. Best is trial 1 with value: 0.269193094004635.\u001b[0m\n",
      "\u001b[32m[I 2022-11-15 23:15:17,239]\u001b[0m Trial 3 finished with value: 0.269193094004635 and parameters: {'solver': 'liblinear', 'max_iter': 11750}. Best is trial 1 with value: 0.269193094004635.\u001b[0m\n",
      "\u001b[32m[I 2022-11-15 23:21:57,701]\u001b[0m Trial 4 finished with value: 0.25718269642735475 and parameters: {'solver': 'saga', 'max_iter': 9500}. Best is trial 1 with value: 0.269193094004635.\u001b[0m\n",
      "\u001b[32m[I 2022-11-15 23:28:39,113]\u001b[0m Trial 5 finished with value: 0.2570804025468871 and parameters: {'solver': 'saga', 'max_iter': 20250}. Best is trial 1 with value: 0.269193094004635.\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "\u001b[32m[I 2022-11-15 23:35:54,945]\u001b[0m Trial 6 finished with value: 0.26778043809025587 and parameters: {'solver': 'newton-cg', 'max_iter': 13750}. Best is trial 1 with value: 0.269193094004635.\u001b[0m\n",
      "\u001b[32m[I 2022-11-16 00:05:42,928]\u001b[0m Trial 7 finished with value: 0.269193094004635 and parameters: {'solver': 'liblinear', 'max_iter': 25000}. Best is trial 1 with value: 0.269193094004635.\u001b[0m\n",
      "\u001b[32m[I 2022-11-16 00:12:24,428]\u001b[0m Trial 8 finished with value: 0.26206325806393294 and parameters: {'solver': 'sag', 'max_iter': 23000}. Best is trial 1 with value: 0.269193094004635.\u001b[0m\n",
      "\u001b[32m[I 2022-11-16 00:30:37,081]\u001b[0m Trial 9 finished with value: 0.26948326587553645 and parameters: {'solver': 'lbfgs', 'max_iter': 18500}. Best is trial 9 with value: 0.26948326587553645.\u001b[0m\n",
      "\u001b[32m[I 2022-11-16 00:47:31,516]\u001b[0m Trial 10 finished with value: 0.26948326587553645 and parameters: {'solver': 'lbfgs', 'max_iter': 15750}. Best is trial 9 with value: 0.26948326587553645.\u001b[0m\n",
      "\u001b[32m[I 2022-11-16 01:04:12,943]\u001b[0m Trial 11 finished with value: 0.26948326587553645 and parameters: {'solver': 'lbfgs', 'max_iter': 16000}. Best is trial 9 with value: 0.26948326587553645.\u001b[0m\n",
      "\u001b[32m[I 2022-11-16 01:20:51,824]\u001b[0m Trial 12 finished with value: 0.26948326587553645 and parameters: {'solver': 'lbfgs', 'max_iter': 28250}. Best is trial 9 with value: 0.26948326587553645.\u001b[0m\n",
      "\u001b[32m[I 2022-11-16 01:37:34,724]\u001b[0m Trial 13 finished with value: 0.26948326587553645 and parameters: {'solver': 'lbfgs', 'max_iter': 16000}. Best is trial 9 with value: 0.26948326587553645.\u001b[0m\n",
      "\u001b[32m[I 2022-11-16 01:54:14,966]\u001b[0m Trial 14 finished with value: 0.26948326587553645 and parameters: {'solver': 'lbfgs', 'max_iter': 7250}. Best is trial 9 with value: 0.26948326587553645.\u001b[0m\n",
      "\u001b[32m[I 2022-11-16 02:10:57,757]\u001b[0m Trial 15 finished with value: 0.26948326587553645 and parameters: {'solver': 'lbfgs', 'max_iter': 16750}. Best is trial 9 with value: 0.26948326587553645.\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "\u001b[32m[I 2022-11-16 02:18:03,820]\u001b[0m Trial 16 finished with value: 0.26778043809025587 and parameters: {'solver': 'newton-cg', 'max_iter': 22500}. Best is trial 9 with value: 0.26948326587553645.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-16 02:34:45,332]\u001b[0m Trial 17 finished with value: 0.26948326587553645 and parameters: {'solver': 'lbfgs', 'max_iter': 8500}. Best is trial 9 with value: 0.26948326587553645.\u001b[0m\n",
      "\u001b[32m[I 2022-11-16 02:51:28,581]\u001b[0m Trial 18 finished with value: 0.26948326587553645 and parameters: {'solver': 'lbfgs', 'max_iter': 7000}. Best is trial 9 with value: 0.26948326587553645.\u001b[0m\n",
      "\u001b[32m[I 2022-11-16 03:08:10,674]\u001b[0m Trial 19 finished with value: 0.26948326587553645 and parameters: {'solver': 'lbfgs', 'max_iter': 29750}. Best is trial 9 with value: 0.26948326587553645.\u001b[0m\n",
      "\u001b[32m[I 2022-11-16 03:14:02,507]\u001b[0m Trial 20 finished with value: 0.2617676429011556 and parameters: {'solver': 'sag', 'max_iter': 12750}. Best is trial 9 with value: 0.26948326587553645.\u001b[0m\n",
      "\u001b[32m[I 2022-11-16 03:30:43,024]\u001b[0m Trial 21 finished with value: 0.26948326587553645 and parameters: {'solver': 'lbfgs', 'max_iter': 7000}. Best is trial 9 with value: 0.26948326587553645.\u001b[0m\n",
      "\u001b[32m[I 2022-11-16 03:47:30,637]\u001b[0m Trial 22 finished with value: 0.26948326587553645 and parameters: {'solver': 'lbfgs', 'max_iter': 29500}. Best is trial 9 with value: 0.26948326587553645.\u001b[0m\n",
      "\u001b[32m[I 2022-11-16 04:04:20,286]\u001b[0m Trial 23 finished with value: 0.26948326587553645 and parameters: {'solver': 'lbfgs', 'max_iter': 25500}. Best is trial 9 with value: 0.26948326587553645.\u001b[0m\n",
      "\u001b[32m[I 2022-11-16 04:21:05,167]\u001b[0m Trial 24 finished with value: 0.26948326587553645 and parameters: {'solver': 'lbfgs', 'max_iter': 26250}. Best is trial 9 with value: 0.26948326587553645.\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning:\n",
      "\n",
      "Line Search failed\n",
      "\n",
      "\u001b[32m[I 2022-11-16 04:28:15,289]\u001b[0m Trial 25 finished with value: 0.26778043809025587 and parameters: {'solver': 'newton-cg', 'max_iter': 30000}. Best is trial 9 with value: 0.26948326587553645.\u001b[0m\n",
      "\u001b[32m[I 2022-11-16 04:44:57,333]\u001b[0m Trial 26 finished with value: 0.26948326587553645 and parameters: {'solver': 'lbfgs', 'max_iter': 27750}. Best is trial 9 with value: 0.26948326587553645.\u001b[0m\n",
      "\u001b[32m[I 2022-11-16 05:01:38,610]\u001b[0m Trial 27 finished with value: 0.26948326587553645 and parameters: {'solver': 'lbfgs', 'max_iter': 25750}. Best is trial 9 with value: 0.26948326587553645.\u001b[0m\n",
      "\u001b[32m[I 2022-11-16 05:18:17,906]\u001b[0m Trial 28 finished with value: 0.26948326587553645 and parameters: {'solver': 'lbfgs', 'max_iter': 25250}. Best is trial 9 with value: 0.26948326587553645.\u001b[0m\n",
      "\u001b[32m[I 2022-11-16 05:24:55,057]\u001b[0m Trial 29 finished with value: 0.25717889450857384 and parameters: {'solver': 'saga', 'max_iter': 28000}. Best is trial 9 with value: 0.26948326587553645.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study_lgr_1 = optuna.create_study(direction='maximize')\n",
    "study_lgr_1.optimize(objective_lgr_1, n_trials=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "aa05e7db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-16T09:32:15.371660Z",
     "start_time": "2022-11-16T09:32:15.306670Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['study_lgr_1.pkl']"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(study_lgr_1, \"study_lgr_1.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244b8743",
   "metadata": {},
   "outputs": [],
   "source": [
    "study_lgr_1 = joblib.load(\"study_lgr_1.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "3882070b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-16T21:00:39.220028Z",
     "start_time": "2022-11-16T21:00:39.212107Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Value: 0.26948326587553645\n",
      "Best Parameters: {'solver': 'lbfgs', 'max_iter': 18500}\n"
     ]
    }
   ],
   "source": [
    "print('Best Value: {}'.format(study_lgr_1.best_value))\n",
    "print('Best Parameters: {}'.format(study_lgr_1.best_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e112747",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study_lgr_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2996c5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study_lgr_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ebc7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_slice(study_lgr_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ef0375",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd8553a",
   "metadata": {},
   "source": [
    "Logistic Regression Full Dataset - Study 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "1d3e9dda",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T01:03:32.066416Z",
     "start_time": "2022-11-17T01:03:32.043454Z"
    }
   },
   "outputs": [],
   "source": [
    "# Se utiliza 'solver' = 'lbfgs' obtenido del study 1 y se busca optimizar el hiperparámetro 'max_iter'.\n",
    "\n",
    "def objective_lgr_2(trial):\n",
    "    \n",
    "    max_iter_trial = trial.suggest_int('max_iter', 7000,30000)\n",
    "\n",
    "\n",
    "    lgr = LogisticRegression(solver = 'lbfgs', max_iter = max_iter_trial)\n",
    "\n",
    "    skf = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 1 )\n",
    "\n",
    "    lgr_results    = []\n",
    "    \n",
    "    for train_index, test_index in skf.split(X,y):\n",
    "    \n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "        lgr.fit(X_train, y_train)\n",
    "    \n",
    "        y_pred = lgr.predict(X_test)\n",
    "    \n",
    "        recall    = recall_score(y_test, y_pred)\n",
    "\n",
    "        list_results   = [recall]\n",
    "        lgr_results.append(list_results)\n",
    "    \n",
    "        \n",
    "    return gmean(lgr_results)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "6b74e0d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T09:20:38.226823Z",
     "start_time": "2022-11-17T01:04:09.767418Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-16 22:04:09,788]\u001b[0m A new study created in memory with name: no-name-550f3c9e-2392-476f-bf26-0f6546616aac\u001b[0m\n",
      "\u001b[32m[I 2022-11-16 22:20:35,194]\u001b[0m Trial 0 finished with value: 0.26948326587553645 and parameters: {'max_iter': 17689}. Best is trial 0 with value: 0.26948326587553645.\u001b[0m\n",
      "\u001b[32m[I 2022-11-16 22:37:03,000]\u001b[0m Trial 1 finished with value: 0.26948326587553645 and parameters: {'max_iter': 7966}. Best is trial 0 with value: 0.26948326587553645.\u001b[0m\n",
      "\u001b[32m[I 2022-11-16 22:53:33,839]\u001b[0m Trial 2 finished with value: 0.26948326587553645 and parameters: {'max_iter': 8742}. Best is trial 0 with value: 0.26948326587553645.\u001b[0m\n",
      "\u001b[32m[I 2022-11-16 23:09:59,769]\u001b[0m Trial 3 finished with value: 0.26948326587553645 and parameters: {'max_iter': 20262}. Best is trial 0 with value: 0.26948326587553645.\u001b[0m\n",
      "\u001b[32m[I 2022-11-16 23:26:45,209]\u001b[0m Trial 4 finished with value: 0.26948326587553645 and parameters: {'max_iter': 16872}. Best is trial 0 with value: 0.26948326587553645.\u001b[0m\n",
      "\u001b[32m[I 2022-11-16 23:43:13,283]\u001b[0m Trial 5 finished with value: 0.26948326587553645 and parameters: {'max_iter': 18920}. Best is trial 0 with value: 0.26948326587553645.\u001b[0m\n",
      "\u001b[32m[I 2022-11-16 23:59:42,781]\u001b[0m Trial 6 finished with value: 0.26948326587553645 and parameters: {'max_iter': 22750}. Best is trial 0 with value: 0.26948326587553645.\u001b[0m\n",
      "\u001b[32m[I 2022-11-17 00:16:14,859]\u001b[0m Trial 7 finished with value: 0.26948326587553645 and parameters: {'max_iter': 15765}. Best is trial 0 with value: 0.26948326587553645.\u001b[0m\n",
      "\u001b[32m[I 2022-11-17 00:32:47,641]\u001b[0m Trial 8 finished with value: 0.26948326587553645 and parameters: {'max_iter': 12904}. Best is trial 0 with value: 0.26948326587553645.\u001b[0m\n",
      "\u001b[32m[I 2022-11-17 00:49:19,148]\u001b[0m Trial 9 finished with value: 0.26948326587553645 and parameters: {'max_iter': 27216}. Best is trial 0 with value: 0.26948326587553645.\u001b[0m\n",
      "\u001b[32m[I 2022-11-17 01:05:53,365]\u001b[0m Trial 10 finished with value: 0.26948326587553645 and parameters: {'max_iter': 27789}. Best is trial 0 with value: 0.26948326587553645.\u001b[0m\n",
      "\u001b[32m[I 2022-11-17 01:22:27,493]\u001b[0m Trial 11 finished with value: 0.26948326587553645 and parameters: {'max_iter': 7626}. Best is trial 0 with value: 0.26948326587553645.\u001b[0m\n",
      "\u001b[32m[I 2022-11-17 01:39:05,152]\u001b[0m Trial 12 finished with value: 0.26948326587553645 and parameters: {'max_iter': 11860}. Best is trial 0 with value: 0.26948326587553645.\u001b[0m\n",
      "\u001b[32m[I 2022-11-17 01:55:43,055]\u001b[0m Trial 13 finished with value: 0.26948326587553645 and parameters: {'max_iter': 23822}. Best is trial 0 with value: 0.26948326587553645.\u001b[0m\n",
      "\u001b[32m[I 2022-11-17 02:12:28,453]\u001b[0m Trial 14 finished with value: 0.26948326587553645 and parameters: {'max_iter': 11987}. Best is trial 0 with value: 0.26948326587553645.\u001b[0m\n",
      "\u001b[32m[I 2022-11-17 02:29:04,693]\u001b[0m Trial 15 finished with value: 0.26948326587553645 and parameters: {'max_iter': 13284}. Best is trial 0 with value: 0.26948326587553645.\u001b[0m\n",
      "\u001b[32m[I 2022-11-17 02:45:42,009]\u001b[0m Trial 16 finished with value: 0.26948326587553645 and parameters: {'max_iter': 9726}. Best is trial 0 with value: 0.26948326587553645.\u001b[0m\n",
      "\u001b[32m[I 2022-11-17 03:02:18,346]\u001b[0m Trial 17 finished with value: 0.26948326587553645 and parameters: {'max_iter': 15355}. Best is trial 0 with value: 0.26948326587553645.\u001b[0m\n",
      "\u001b[32m[I 2022-11-17 03:18:48,665]\u001b[0m Trial 18 finished with value: 0.26948326587553645 and parameters: {'max_iter': 21363}. Best is trial 0 with value: 0.26948326587553645.\u001b[0m\n",
      "\u001b[32m[I 2022-11-17 03:35:19,323]\u001b[0m Trial 19 finished with value: 0.26948326587553645 and parameters: {'max_iter': 29958}. Best is trial 0 with value: 0.26948326587553645.\u001b[0m\n",
      "\u001b[32m[I 2022-11-17 03:51:51,558]\u001b[0m Trial 20 finished with value: 0.26948326587553645 and parameters: {'max_iter': 15986}. Best is trial 0 with value: 0.26948326587553645.\u001b[0m\n",
      "\u001b[32m[I 2022-11-17 04:08:21,733]\u001b[0m Trial 21 finished with value: 0.26948326587553645 and parameters: {'max_iter': 21458}. Best is trial 0 with value: 0.26948326587553645.\u001b[0m\n",
      "\u001b[32m[I 2022-11-17 04:24:57,648]\u001b[0m Trial 22 finished with value: 0.26948326587553645 and parameters: {'max_iter': 25437}. Best is trial 0 with value: 0.26948326587553645.\u001b[0m\n",
      "\u001b[32m[I 2022-11-17 04:41:29,095]\u001b[0m Trial 23 finished with value: 0.26948326587553645 and parameters: {'max_iter': 29841}. Best is trial 0 with value: 0.26948326587553645.\u001b[0m\n",
      "\u001b[32m[I 2022-11-17 04:57:59,866]\u001b[0m Trial 24 finished with value: 0.26948326587553645 and parameters: {'max_iter': 17981}. Best is trial 0 with value: 0.26948326587553645.\u001b[0m\n",
      "\u001b[32m[I 2022-11-17 05:14:30,869]\u001b[0m Trial 25 finished with value: 0.26948326587553645 and parameters: {'max_iter': 25049}. Best is trial 0 with value: 0.26948326587553645.\u001b[0m\n",
      "\u001b[32m[I 2022-11-17 05:31:03,417]\u001b[0m Trial 26 finished with value: 0.26948326587553645 and parameters: {'max_iter': 29779}. Best is trial 0 with value: 0.26948326587553645.\u001b[0m\n",
      "\u001b[32m[I 2022-11-17 05:47:36,613]\u001b[0m Trial 27 finished with value: 0.26948326587553645 and parameters: {'max_iter': 17954}. Best is trial 0 with value: 0.26948326587553645.\u001b[0m\n",
      "\u001b[32m[I 2022-11-17 06:04:07,803]\u001b[0m Trial 28 finished with value: 0.26948326587553645 and parameters: {'max_iter': 19209}. Best is trial 0 with value: 0.26948326587553645.\u001b[0m\n",
      "\u001b[32m[I 2022-11-17 06:20:38,209]\u001b[0m Trial 29 finished with value: 0.26948326587553645 and parameters: {'max_iter': 25654}. Best is trial 0 with value: 0.26948326587553645.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study_lgr_2 = optuna.create_study(direction='maximize')\n",
    "study_lgr_2.optimize(objective_lgr_2, n_trials=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "e9cb06f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T09:36:30.358950Z",
     "start_time": "2022-11-17T09:36:30.294790Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['study_lgr_2.pkl']"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(study_lgr_2, \"study_lgr_2.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f16f1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "study_lgr_2 = joblib.load(\"study_lgr_2.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "9eaa9bf6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T21:18:16.787398Z",
     "start_time": "2022-11-17T21:18:16.755641Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Value: 0.26948326587553645\n",
      "Best Parameters: {'max_iter': 17689}\n"
     ]
    }
   ],
   "source": [
    "print('Best Value: {}'.format(study_lgr_2.best_value))\n",
    "print('Best Parameters: {}'.format(study_lgr_2.best_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ae582c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study_lgr_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b720ad92",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_slice(study_lgr_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36786a51",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af725a40",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e77ae54",
   "metadata": {},
   "source": [
    "Se utilizarán en el full dataset los hiperparámetros con los que se obtuvo mejores resultados en la optimización del modelo Logistic Regression fulldataset. Dichos hiperparámetros son 'solver' = 'lbfgs', 'max_iter' = 17689."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "c3a1af4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T21:37:41.331393Z",
     "start_time": "2022-11-17T21:20:14.093441Z"
    }
   },
   "outputs": [],
   "source": [
    "# Logistic Regression - Full dataset\n",
    "\n",
    "lgr = LogisticRegression( max_iter=17689, solver = 'lbfgs')\n",
    "\n",
    "\n",
    "skf = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 1 )\n",
    "\n",
    "lgr_full_results    = []\n",
    "lgr_full_results_cm = []\n",
    "\n",
    "for train_index, test_index in skf.split(X,y):\n",
    "    \n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    lgr.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = lgr.predict(X_test)\n",
    "    \n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall    = recall_score(y_test, y_pred)\n",
    "    f1        = f1_score(y_test, y_pred)\n",
    "    cm        = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    list_results   = [precision, recall, f1]\n",
    "    list_cm = [cm]\n",
    "    lgr_full_results.append(list_results)\n",
    "    lgr_full_results_cm.append(list_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "3534a77b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T21:37:41.362709Z",
     "start_time": "2022-11-17T21:37:41.331393Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRECISION</th>\n",
       "      <th>RECALL</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegression_full</th>\n",
       "      <td>0.68548</td>\n",
       "      <td>0.269483</td>\n",
       "      <td>0.386856</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         PRECISION    RECALL        F1\n",
       "LogisticRegression_full    0.68548  0.269483  0.386856"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filas    = ['LogisticRegression_full']\n",
    "columnas = [\"PRECISION\", \"RECALL\", \"F1\"]\n",
    "resultados = pd.DataFrame([gmean(lgr_full_results)], columns=columnas, index=filas)\n",
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "d9b0f9f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T23:35:01.797208Z",
     "start_time": "2022-11-17T23:35:01.753593Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRECISION</th>\n",
       "      <th>RECALL</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegression_full_opt</th>\n",
       "      <td>0.68548</td>\n",
       "      <td>0.269483</td>\n",
       "      <td>0.386856</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             PRECISION    RECALL        F1\n",
       "LogisticRegression_full_opt    0.68548  0.269483  0.386856"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filas    = ['LogisticRegression_full_opt']\n",
    "columnas = [\"PRECISION\", \"RECALL\", \"F1\"]\n",
    "resultados = pd.DataFrame([gmean(lgr_full_results)], columns=columnas, index=filas)\n",
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "9ae43368",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T23:35:36.638236Z",
     "start_time": "2022-11-17T23:35:36.616200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRECISION</th>\n",
       "      <th>RECALL</th>\n",
       "      <th>F1</th>\n",
       "      <th>TIEMPO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegression_full_opt</th>\n",
       "      <td>0.68548</td>\n",
       "      <td>0.269483</td>\n",
       "      <td>0.386856</td>\n",
       "      <td>797.940231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             PRECISION    RECALL        F1      TIEMPO\n",
       "LogisticRegression_full_opt    0.68548  0.269483  0.386856  797.940231"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados['TIEMPO']= tiempo_ejecucion\n",
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "7cc81c8b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T23:37:25.962016Z",
     "start_time": "2022-11-17T23:37:25.891660Z"
    }
   },
   "outputs": [],
   "source": [
    "resultados.to_pickle(\"resultados_lgr_full_opt.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "14794264",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T23:41:54.902646Z",
     "start_time": "2022-11-17T23:41:54.881150Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[17741.69449217,   248.10252564],\n",
       "       [ 1467.9280316 ,   541.60745703]])"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados_cm= gmean(lgr_full_results_cm)\n",
    "resultados_cm= resultados_cm.reshape(2,2)\n",
    "resultados_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "1aca3042",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-18T00:00:56.855532Z",
     "start_time": "2022-11-18T00:00:56.835875Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('resultados_sgd_full_opt_cm.pkl','wb') as f:\n",
    "    pickle.dump(resultados_cm, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7b1de1",
   "metadata": {},
   "source": [
    "La Regresión Logística fulldataset con sus parámetros default (max_iter = 7000) da el mismo resultado que con los parámetros optimizados. Es por ello que continuaremos utilizando los parámetros default (con max_iter = 7000)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ccb85b",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058d3a27",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9405cd9a",
   "metadata": {},
   "source": [
    "<font size='5' style=\"color:orange\">  <b> K Neighbors Classifier - Optuna </b> </font>\n",
    "<a name=\"knc_opt\"></a>\n",
    "\n",
    "[[ Back to Top ]](#content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0304e350",
   "metadata": {},
   "source": [
    "Se optimizarán los hiperparámetros del modelo K Neighbor Classifier para PCA 175.\n",
    "\n",
    "Se debe tener en cuenta que el Recall del modelo K Neighbor Classifier para el full dataset es de 0.006247. Por lo que con la optimización de hiperparámetros se tiene como objetivo el obtener un mejor Recall que el mencionado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a812945c",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45cde46",
   "metadata": {},
   "source": [
    "<font size='4' style=\"color:orange\">  <b> K Neighbors Classifier - PCA 175 </b> </font>\n",
    "<a name=\"knc_opt_175\"></a>\n",
    "\n",
    "[[ Back to Top ]](#content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d2d027",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378f1571",
   "metadata": {},
   "source": [
    "K Neighbors Classifier PCA 175 - Study 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c4b6810f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-12T23:36:10.081235Z",
     "start_time": "2022-11-12T23:36:10.064235Z"
    }
   },
   "outputs": [],
   "source": [
    "# Se busca optimizar los hiperparámetros 'n_neighbors', 'weights' y 'metric'.\n",
    "\n",
    "def objective_knc_175_1(trial):\n",
    "    \n",
    "    n_neighbors_trial = trial.suggest_int('n_neighbors', 2, 10)\n",
    "    weights_trial = trial.suggest_categorical('weights', [\"uniform\", \"distance\"])\n",
    "    metric_trial = trial.suggest_categorical(\"metric\", [\"euclidean\", \"manhattan\", \"minkowski\"])\n",
    "                                              \n",
    "    knc = KNeighborsClassifier(n_neighbors = n_neighbors_trial, weights = weights_trial, metric = metric_trial)\n",
    "\n",
    "    skf = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 1 )\n",
    "\n",
    "    knc_175_results    = []\n",
    "    \n",
    "    for train_index, test_index in skf.split(X,y):\n",
    "    \n",
    "        X_train, X_test = pca_175.fit_transform(X.iloc[train_index]), pca_175.transform(X.iloc[test_index])\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "        knc.fit(X_train, y_train)\n",
    "    \n",
    "        y_pred = knc.predict(X_test)\n",
    "    \n",
    "        recall    = recall_score(y_test, y_pred)\n",
    "\n",
    "        list_results   = [recall]\n",
    "        knc_175_results.append(list_results)\n",
    "    \n",
    "        \n",
    "    return gmean(knc_175_results) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "96b3aac0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T10:58:31.025963Z",
     "start_time": "2022-11-12T23:36:10.971155Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-12 20:36:10,973]\u001b[0m A new study created in memory with name: no-name-9b73a776-626a-43d1-b443-d610de70f072\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\stats\\_stats_py.py:279: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in log\n",
      "\n",
      "\u001b[32m[I 2022-11-12 20:48:32,779]\u001b[0m Trial 0 finished with value: 0.0 and parameters: {'n_neighbors': 7, 'weights': 'uniform', 'metric': 'minkowski'}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\stats\\_stats_py.py:279: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in log\n",
      "\n",
      "\u001b[32m[I 2022-11-12 21:00:58,517]\u001b[0m Trial 1 finished with value: 0.0 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'metric': 'minkowski'}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\stats\\_stats_py.py:279: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in log\n",
      "\n",
      "\u001b[32m[I 2022-11-12 21:14:09,426]\u001b[0m Trial 2 finished with value: 0.0 and parameters: {'n_neighbors': 9, 'weights': 'uniform', 'metric': 'minkowski'}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 21:24:48,125]\u001b[0m Trial 3 finished with value: 0.014510688065054407 and parameters: {'n_neighbors': 3, 'weights': 'uniform', 'metric': 'minkowski'}. Best is trial 3 with value: 0.014510688065054407.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 22:46:36,949]\u001b[0m Trial 4 finished with value: 0.0019880013069121967 and parameters: {'n_neighbors': 5, 'weights': 'uniform', 'metric': 'manhattan'}. Best is trial 3 with value: 0.014510688065054407.\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\stats\\_stats_py.py:279: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in log\n",
      "\n",
      "\u001b[32m[I 2022-11-12 22:58:46,972]\u001b[0m Trial 5 finished with value: 0.0 and parameters: {'n_neighbors': 7, 'weights': 'uniform', 'metric': 'minkowski'}. Best is trial 3 with value: 0.014510688065054407.\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\stats\\_stats_py.py:279: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in log\n",
      "\n",
      "\u001b[32m[I 2022-11-12 23:11:15,406]\u001b[0m Trial 6 finished with value: 0.0 and parameters: {'n_neighbors': 9, 'weights': 'distance', 'metric': 'minkowski'}. Best is trial 3 with value: 0.014510688065054407.\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\stats\\_stats_py.py:279: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in log\n",
      "\n",
      "\u001b[32m[I 2022-11-12 23:23:48,841]\u001b[0m Trial 7 finished with value: 0.0 and parameters: {'n_neighbors': 6, 'weights': 'uniform', 'metric': 'euclidean'}. Best is trial 3 with value: 0.014510688065054407.\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\stats\\_stats_py.py:279: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in log\n",
      "\n",
      "\u001b[32m[I 2022-11-12 23:36:27,975]\u001b[0m Trial 8 finished with value: 0.0 and parameters: {'n_neighbors': 9, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 3 with value: 0.014510688065054407.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 23:47:29,251]\u001b[0m Trial 9 finished with value: 0.06593657095568582 and parameters: {'n_neighbors': 2, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 9 with value: 0.06593657095568582.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 23:58:04,976]\u001b[0m Trial 10 finished with value: 0.06593657095568582 and parameters: {'n_neighbors': 2, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 9 with value: 0.06593657095568582.\u001b[0m\n",
      "\u001b[32m[I 2022-11-13 00:07:58,223]\u001b[0m Trial 11 finished with value: 0.06593657095568582 and parameters: {'n_neighbors': 2, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 9 with value: 0.06593657095568582.\u001b[0m\n",
      "\u001b[32m[I 2022-11-13 00:18:05,785]\u001b[0m Trial 12 finished with value: 0.014510688065054407 and parameters: {'n_neighbors': 3, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 9 with value: 0.06593657095568582.\u001b[0m\n",
      "\u001b[32m[I 2022-11-13 00:27:45,744]\u001b[0m Trial 13 finished with value: 0.06593657095568582 and parameters: {'n_neighbors': 2, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 9 with value: 0.06593657095568582.\u001b[0m\n",
      "\u001b[32m[I 2022-11-13 01:49:29,189]\u001b[0m Trial 14 finished with value: 0.010141006800878073 and parameters: {'n_neighbors': 4, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 9 with value: 0.06593657095568582.\u001b[0m\n",
      "\u001b[32m[I 2022-11-13 02:00:53,486]\u001b[0m Trial 15 finished with value: 0.014610307771774 and parameters: {'n_neighbors': 4, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 9 with value: 0.06593657095568582.\u001b[0m\n",
      "\u001b[32m[I 2022-11-13 02:10:30,296]\u001b[0m Trial 16 finished with value: 0.06593657095568582 and parameters: {'n_neighbors': 2, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 9 with value: 0.06593657095568582.\u001b[0m\n",
      "\u001b[32m[I 2022-11-13 02:21:58,302]\u001b[0m Trial 17 finished with value: 0.014610307771774 and parameters: {'n_neighbors': 4, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 9 with value: 0.06593657095568582.\u001b[0m\n",
      "\u001b[32m[I 2022-11-13 03:42:03,447]\u001b[0m Trial 18 finished with value: 0.010196298674172752 and parameters: {'n_neighbors': 3, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 9 with value: 0.06593657095568582.\u001b[0m\n",
      "\u001b[32m[I 2022-11-13 03:53:26,590]\u001b[0m Trial 19 finished with value: 0.003159072636496866 and parameters: {'n_neighbors': 5, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 9 with value: 0.06593657095568582.\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\stats\\_stats_py.py:279: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in log\n",
      "\n",
      "\u001b[32m[I 2022-11-13 04:04:50,034]\u001b[0m Trial 20 finished with value: 0.0 and parameters: {'n_neighbors': 10, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 9 with value: 0.06593657095568582.\u001b[0m\n",
      "\u001b[32m[I 2022-11-13 04:14:26,238]\u001b[0m Trial 21 finished with value: 0.06593657095568582 and parameters: {'n_neighbors': 2, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 9 with value: 0.06593657095568582.\u001b[0m\n",
      "\u001b[32m[I 2022-11-13 04:24:07,035]\u001b[0m Trial 22 finished with value: 0.06593657095568582 and parameters: {'n_neighbors': 2, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 9 with value: 0.06593657095568582.\u001b[0m\n",
      "\u001b[32m[I 2022-11-13 04:34:20,517]\u001b[0m Trial 23 finished with value: 0.014510688065054407 and parameters: {'n_neighbors': 3, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 9 with value: 0.06593657095568582.\u001b[0m\n",
      "\u001b[32m[I 2022-11-13 04:44:06,364]\u001b[0m Trial 24 finished with value: 0.06593657095568582 and parameters: {'n_neighbors': 2, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 9 with value: 0.06593657095568582.\u001b[0m\n",
      "\u001b[32m[I 2022-11-13 06:04:12,998]\u001b[0m Trial 25 finished with value: 0.010196298674172752 and parameters: {'n_neighbors': 3, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 9 with value: 0.06593657095568582.\u001b[0m\n",
      "\u001b[32m[I 2022-11-13 06:15:33,318]\u001b[0m Trial 26 finished with value: 0.003159072636496866 and parameters: {'n_neighbors': 5, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 9 with value: 0.06593657095568582.\u001b[0m\n",
      "\u001b[32m[I 2022-11-13 06:26:54,653]\u001b[0m Trial 27 finished with value: 0.014610307771774 and parameters: {'n_neighbors': 4, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 9 with value: 0.06593657095568582.\u001b[0m\n",
      "\u001b[32m[I 2022-11-13 06:36:38,210]\u001b[0m Trial 28 finished with value: 0.06593657095568582 and parameters: {'n_neighbors': 2, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 9 with value: 0.06593657095568582.\u001b[0m\n",
      "C:\\Users\\denun\\miniconda3\\lib\\site-packages\\scipy\\stats\\_stats_py.py:279: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in log\n",
      "\n",
      "\u001b[32m[I 2022-11-13 07:58:31,010]\u001b[0m Trial 29 finished with value: 0.0 and parameters: {'n_neighbors': 6, 'weights': 'uniform', 'metric': 'manhattan'}. Best is trial 9 with value: 0.06593657095568582.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study_knc_175_1 = optuna.create_study(direction='maximize')\n",
    "study_knc_175_1.optimize(objective_knc_175_1, n_trials=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0d56af79",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T12:11:34.739302Z",
     "start_time": "2022-11-13T12:11:34.705468Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['study_knc175_1.pkl']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(study_knc_175_1, \"study_knc175_1.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567113aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "study_knc_175_1 = joblib.load(\"study_knc175_1.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "35620c19",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T23:18:34.235613Z",
     "start_time": "2022-11-13T23:18:34.208094Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Value: 0.06593657095568582\n",
      "Best Parameters: {'n_neighbors': 2, 'weights': 'distance', 'metric': 'euclidean'}\n"
     ]
    }
   ],
   "source": [
    "print('Best Value: {}'.format(study_knc_175_1.best_value))\n",
    "print('Best Parameters: {}'.format(study_knc_175_1.best_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e11017",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study_knc_175_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bb57e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_slice(study_knc_175_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f664f1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study_knc_175_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adab4ea6",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489ba68e",
   "metadata": {},
   "source": [
    "K Neighbors Classifier PCA 175 - Study 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8ecf394e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T23:21:37.750304Z",
     "start_time": "2022-11-13T23:21:37.711247Z"
    }
   },
   "outputs": [],
   "source": [
    "# Se utiliza 'n_neighbors' =  2 obtenido del study 1 y se busca optimizar los hiperparámetros 'weights' y 'metric'.\n",
    "\n",
    "def objective_knc_175_2(trial):\n",
    "    \n",
    "    weights_trial = trial.suggest_categorical('weights', [\"uniform\", \"distance\"])\n",
    "    metric_trial = trial.suggest_categorical(\"metric\", [\"euclidean\", \"manhattan\", \"minkowski\"])\n",
    "                                              \n",
    "    knc = KNeighborsClassifier(n_neighbors = 2, weights = weights_trial, metric = metric_trial)\n",
    "\n",
    "    skf = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 1 )\n",
    "\n",
    "    knc_175_results    = []\n",
    "    \n",
    "    for train_index, test_index in skf.split(X,y):\n",
    "    \n",
    "        X_train, X_test = pca_175.fit_transform(X.iloc[train_index]), pca_175.transform(X.iloc[test_index])\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "        knc.fit(X_train, y_train)\n",
    "    \n",
    "        y_pred = knc.predict(X_test)\n",
    "    \n",
    "        recall    = recall_score(y_test, y_pred)\n",
    "\n",
    "        list_results   = [recall]\n",
    "        knc_175_results.append(list_results)\n",
    "    \n",
    "        \n",
    "    return gmean(knc_175_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "779f9f65",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-14T03:41:38.035454Z",
     "start_time": "2022-11-13T23:22:17.071650Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-13 20:22:17,074]\u001b[0m A new study created in memory with name: no-name-aae14e6a-1f05-4c7d-908f-3880df751682\u001b[0m\n",
      "\u001b[32m[I 2022-11-13 21:52:40,175]\u001b[0m Trial 0 finished with value: 0.05530845532828079 and parameters: {'weights': 'distance', 'metric': 'manhattan'}. Best is trial 0 with value: 0.05530845532828079.\u001b[0m\n",
      "\u001b[32m[I 2022-11-13 22:04:09,547]\u001b[0m Trial 1 finished with value: 0.005131470002126095 and parameters: {'weights': 'uniform', 'metric': 'minkowski'}. Best is trial 0 with value: 0.05530845532828079.\u001b[0m\n",
      "\u001b[32m[I 2022-11-13 22:15:10,942]\u001b[0m Trial 2 finished with value: 0.06593657095568582 and parameters: {'weights': 'distance', 'metric': 'minkowski'}. Best is trial 2 with value: 0.06593657095568582.\u001b[0m\n",
      "\u001b[32m[I 2022-11-13 23:43:08,325]\u001b[0m Trial 3 finished with value: 0.0033719345045480735 and parameters: {'weights': 'uniform', 'metric': 'manhattan'}. Best is trial 2 with value: 0.06593657095568582.\u001b[0m\n",
      "\u001b[32m[I 2022-11-13 23:52:42,219]\u001b[0m Trial 4 finished with value: 0.06593657095568582 and parameters: {'weights': 'distance', 'metric': 'euclidean'}. Best is trial 2 with value: 0.06593657095568582.\u001b[0m\n",
      "\u001b[32m[I 2022-11-14 00:02:23,576]\u001b[0m Trial 5 finished with value: 0.005131470002126095 and parameters: {'weights': 'uniform', 'metric': 'euclidean'}. Best is trial 2 with value: 0.06593657095568582.\u001b[0m\n",
      "\u001b[32m[I 2022-11-14 00:12:08,390]\u001b[0m Trial 6 finished with value: 0.06593657095568582 and parameters: {'weights': 'distance', 'metric': 'minkowski'}. Best is trial 2 with value: 0.06593657095568582.\u001b[0m\n",
      "\u001b[32m[I 2022-11-14 00:21:54,929]\u001b[0m Trial 7 finished with value: 0.06593657095568582 and parameters: {'weights': 'distance', 'metric': 'euclidean'}. Best is trial 2 with value: 0.06593657095568582.\u001b[0m\n",
      "\u001b[32m[I 2022-11-14 00:31:43,373]\u001b[0m Trial 8 finished with value: 0.06593657095568582 and parameters: {'weights': 'distance', 'metric': 'minkowski'}. Best is trial 2 with value: 0.06593657095568582.\u001b[0m\n",
      "\u001b[32m[I 2022-11-14 00:41:38,003]\u001b[0m Trial 9 finished with value: 0.06593657095568582 and parameters: {'weights': 'distance', 'metric': 'euclidean'}. Best is trial 2 with value: 0.06593657095568582.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study_knc_175_2 = optuna.create_study(direction='maximize')\n",
    "study_knc_175_2.optimize(objective_knc_175_2, n_trials=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e5bf4828",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-14T03:47:30.734754Z",
     "start_time": "2022-11-14T03:47:30.690671Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['study_knc175_2.pkl']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(study_knc_175_2, \"study_knc175_2.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4768c094",
   "metadata": {},
   "outputs": [],
   "source": [
    "study_knc_175_2 = joblib.load(\"study_knc175_2.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "ddc5ffc3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-16T22:16:14.777501Z",
     "start_time": "2022-11-16T22:16:14.753188Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Value: 0.06593657095568582\n",
      "Best Parameters: {'weights': 'distance', 'metric': 'minkowski'}\n"
     ]
    }
   ],
   "source": [
    "print('Best Value: {}'.format(study_knc_175_2.best_value))\n",
    "print('Best Parameters: {}'.format(study_knc_175_2.best_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a17a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study_knc_175_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a7b095",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_slice(study_knc_175_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f0033e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study_knc_175_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b187ac",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5345d455",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ae7faf",
   "metadata": {},
   "source": [
    "Se utilizarán en el dataset PCA 175 los hiperparámetros con los que se obtuvo mejores resultados en la optimización del modelo K Neighbors Classifier PCA 175. Dichos hiperparámetros son n_neighbors = 2, weights = 'distance' y metric = 'minkowski'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "dd201b9c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-20T16:08:06.799780Z",
     "start_time": "2022-11-20T15:57:06.940334Z"
    }
   },
   "outputs": [],
   "source": [
    "knc = KNeighborsClassifier(n_neighbors = 2, weights = 'distance', metric = 'minkowski')\n",
    "    \n",
    "skf = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 1 )\n",
    "\n",
    "knc_175_results    = []\n",
    "knc_175_results_cm = []\n",
    "\n",
    "tiempo_ejecucion = []\n",
    "inicio = time.time()\n",
    "\n",
    "for train_index, test_index in skf.split(X,y):\n",
    "    \n",
    "    X_train, X_test = pca_175.fit_transform(X.iloc[train_index]),  pca_175.transform(X.iloc[test_index])\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    knc.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = knc.predict(X_test)\n",
    "    \n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall    = recall_score(y_test, y_pred)\n",
    "    f1        = f1_score(y_test, y_pred)\n",
    "    cm        = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    list_results   = [precision, recall, f1]\n",
    "    list_cm = [cm]\n",
    "    knc_175_results.append(list_results)\n",
    "    knc_175_results_cm.append(list_cm)\n",
    "\n",
    "fin = time.time()\n",
    "tiempo_ejecucion.append(fin - inicio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "24e002ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-20T16:08:06.830867Z",
     "start_time": "2022-11-20T16:08:06.801708Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRECISION</th>\n",
       "      <th>RECALL</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier_175_opt</th>\n",
       "      <td>0.143837</td>\n",
       "      <td>0.065937</td>\n",
       "      <td>0.090416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              PRECISION    RECALL        F1\n",
       "KNeighborsClassifier_175_opt   0.143837  0.065937  0.090416"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filas    = ['KNeighborsClassifier_175_opt']\n",
    "columnas = [\"PRECISION\", \"RECALL\", \"F1\"]\n",
    "resultados = pd.DataFrame([gmean(knc_175_results)], columns=columnas, index=filas)\n",
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "e4572fb5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-20T16:08:06.846867Z",
     "start_time": "2022-11-20T16:08:06.832866Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRECISION</th>\n",
       "      <th>RECALL</th>\n",
       "      <th>F1</th>\n",
       "      <th>TIEMPO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier_175_opt</th>\n",
       "      <td>0.143837</td>\n",
       "      <td>0.065937</td>\n",
       "      <td>0.090416</td>\n",
       "      <td>659.815858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              PRECISION    RECALL        F1      TIEMPO\n",
       "KNeighborsClassifier_175_opt   0.143837  0.065937  0.090416  659.815858"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tiempo expresado en segundos\n",
    "resultados['TIEMPO'] = tiempo_ejecucion\n",
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "08486c14",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-20T16:08:06.862867Z",
     "start_time": "2022-11-20T16:08:06.849902Z"
    }
   },
   "outputs": [],
   "source": [
    "resultados.to_pickle(\"resultados_knc_175_opt.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "c74b949b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-20T16:08:06.878945Z",
     "start_time": "2022-11-20T16:08:06.865868Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[17201.27870291,   788.42332739],\n",
       "        [ 1877.08605376,   132.51931768]]])"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados_cm = gmean(knc_175_results_cm)\n",
    "resultados_cm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "69b27184",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-20T16:08:06.894912Z",
     "start_time": "2022-11-20T16:08:06.880867Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('resultados_knc_175_cm_opt.pkl','wb') as f:\n",
    "    pickle.dump(resultados_cm, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d806d118",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61056822",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512d0c98",
   "metadata": {},
   "source": [
    "Se utilizarán en el full dataset los hiperparámetros con los que se obtuvo mejores resultados en la optimización del modelo K Neighbors Classifier PCA 175. Dichos hiperparámetros son n_neighbors = 2, weights = 'distance' y metric = 'minkowski'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "ed2e327e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-18T02:50:34.827417Z",
     "start_time": "2022-11-18T02:39:13.461598Z"
    }
   },
   "outputs": [],
   "source": [
    "knc = KNeighborsClassifier(n_neighbors = 2, weights = 'distance', metric = 'minkowski')\n",
    "    \n",
    "skf = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 1 )\n",
    "\n",
    "knc_full_results    = []\n",
    "knc_full_results_cm = []\n",
    "tiempo_ejecucion = []\n",
    "inicio = time.time()\n",
    "\n",
    "\n",
    "for train_index, test_index in skf.split(X,y):\n",
    "    \n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    knc.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = knc.predict(X_test)\n",
    "    \n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall    = recall_score(y_test, y_pred)\n",
    "    f1        = f1_score(y_test, y_pred)\n",
    "    cm        = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    list_results   = [precision, recall, f1]\n",
    "    list_cm = [cm]\n",
    "    knc_full_results.append(list_results)\n",
    "    knc_full_results_cm.append(list_cm)\n",
    "    \n",
    "fin = time.time()\n",
    "tiempo_ejecucion.append(fin - inicio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "d99049f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-18T02:50:34.843459Z",
     "start_time": "2022-11-18T02:50:34.827417Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRECISION</th>\n",
       "      <th>RECALL</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier_full_opt</th>\n",
       "      <td>0.143201</td>\n",
       "      <td>0.065738</td>\n",
       "      <td>0.090104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               PRECISION    RECALL        F1\n",
       "KNeighborsClassifier_full_opt   0.143201  0.065738  0.090104"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filas    = ['KNeighborsClassifier_full_opt']\n",
    "columnas = [\"PRECISION\", \"RECALL\", \"F1\"]\n",
    "resultados = pd.DataFrame([gmean(knc_full_results)], columns=columnas, index=filas)\n",
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "186654bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-18T02:50:34.875404Z",
     "start_time": "2022-11-18T02:50:34.843459Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRECISION</th>\n",
       "      <th>RECALL</th>\n",
       "      <th>F1</th>\n",
       "      <th>TIEMPO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier_full_opt</th>\n",
       "      <td>0.143201</td>\n",
       "      <td>0.065738</td>\n",
       "      <td>0.090104</td>\n",
       "      <td>681.339257</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               PRECISION    RECALL        F1      TIEMPO\n",
       "KNeighborsClassifier_full_opt   0.143201  0.065738  0.090104  681.339257"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tiempo expresado en segundos\n",
    "resultados['TIEMPO'] = tiempo_ejecucion\n",
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "2f82106a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-18T02:50:34.891465Z",
     "start_time": "2022-11-18T02:50:34.875404Z"
    }
   },
   "outputs": [],
   "source": [
    "resultados.to_pickle(\"resultados_knc_full_opt.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "0fba8266",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-18T02:50:34.907389Z",
     "start_time": "2022-11-18T02:50:34.891465Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[17199.57910538,   790.13434095],\n",
       "        [ 1877.48622971,   132.12061859]]])"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados_cm = gmean(knc_full_results_cm)\n",
    "resultados_cm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "12c8a491",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-18T02:50:34.923387Z",
     "start_time": "2022-11-18T02:50:34.907389Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('resultados_knc_full_cm_opt.pkl','wb') as f:\n",
    "    pickle.dump(resultados_cm, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f97833",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d333e0",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d2e495",
   "metadata": {},
   "source": [
    "<font size='4' style=\"color:orange\">  <b> K Neighbors Classifier - Summary </b> </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "5dd3d670",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-20T16:28:31.304658Z",
     "start_time": "2022-11-20T16:28:31.221091Z"
    }
   },
   "outputs": [],
   "source": [
    "resultados_knc_175 = pd.read_pickle('resultados_knc_175.pkl')\n",
    "resultados_knc_full = pd.read_pickle('resultados_knc_full.pkl')\n",
    "resultados_knc_175_opt = pd.read_pickle('resultados_knc_175_opt.pkl')\n",
    "resultados_knc_full_opt = pd.read_pickle('resultados_knc_full_opt.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "aafafdcc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-20T16:28:32.793111Z",
     "start_time": "2022-11-20T16:28:32.757044Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRECISION</th>\n",
       "      <th>RECALL</th>\n",
       "      <th>F1</th>\n",
       "      <th>TIEMPO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier_175</th>\n",
       "      <td>0.220253</td>\n",
       "      <td>0.003159</td>\n",
       "      <td>0.006227</td>\n",
       "      <td>797.940231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier_full</th>\n",
       "      <td>0.223142</td>\n",
       "      <td>0.003169</td>\n",
       "      <td>0.006247</td>\n",
       "      <td>781.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier_175_opt</th>\n",
       "      <td>0.143837</td>\n",
       "      <td>0.065937</td>\n",
       "      <td>0.090416</td>\n",
       "      <td>659.815858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier_full_opt</th>\n",
       "      <td>0.143201</td>\n",
       "      <td>0.065738</td>\n",
       "      <td>0.090104</td>\n",
       "      <td>681.339257</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               PRECISION    RECALL        F1      TIEMPO\n",
       "KNeighborsClassifier_175        0.220253  0.003159  0.006227  797.940231\n",
       "KNeighborsClassifier_full       0.223142  0.003169  0.006247  781.000000\n",
       "KNeighborsClassifier_175_opt    0.143837  0.065937  0.090416  659.815858\n",
       "KNeighborsClassifier_full_opt   0.143201  0.065738  0.090104  681.339257"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_resultados_knc_opt = pd.concat([resultados_knc_175,\n",
    "                                  resultados_knc_full,\n",
    "                                   resultados_knc_175_opt,\n",
    "                                  resultados_knc_full_opt])\n",
    "df_resultados_knc_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "559feb8d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-20T16:28:41.453212Z",
     "start_time": "2022-11-20T16:28:41.420692Z"
    }
   },
   "outputs": [],
   "source": [
    "df_resultados_knc_opt.to_pickle('df_resultados_knc_opt.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "26609cc9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-20T16:31:40.157952Z",
     "start_time": "2022-11-20T16:31:40.002880Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgUAAAIfCAYAAADg0a/wAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAABgm0lEQVR4nO3deXxU1f3/8dcHiEISwhqw4oJYASFAgCSiCGIRtaCyaStqJSiKK37r8lP7tYoYsbSI2taK1lZQUQEVVEQRaUHgqwRQQIkIgiBgla0QAoQlOb8/7s0wmUySycaQ8H4+HvPIzLnn3nvOzGTmM+eexZxziIiIiNSKdgFERETk2KCgQERERAAFBSIiIuJTUCAiIiKAggIRERHxKSgQERERQEGBSJmY2QYzc2a24SicK90/lzOz9Ko+nxRmZr2Cnv9R0S5PVTGzlkH1nFhK3nZm9g8z+9bM9gXtNyMoT0HavCouulQBBQUSVtA/dqkTWZjZiWY2PWifn8ysUznOOS/4vGZ2fwT7nKQPIQnHzFqY2Ugze8fM1prZf83soJltM7MvzOwFMxtoZidEu6zVgZldACwDbgDOBOpFt0RSFepEuwBSvZlZLPAOcJGftAm4yDm3phIO///MbIJzbnclHEuOE2bWAMgAbgJODJOlqX9L9vNsM7MM4Dnn3KGjVc5q6C9AXf/+y8A84L/+4/9Eo0BS+RQUSLn5H77vA939pLV4AcH3lXSKxsB9wEOVdLwKc861jHYZpHhm9nPgPaBtUHImMAfYAOwGmuD90r0USAISgWeAlXhfdMcV59wGwErKY2anAB38h7Odc0NLOF6Jx5Jjm4ICKRczawrMBrr4SV8CFzvnfqykU+wDYoH/MbM/O+e2VtJxpYYysybAXOA0P2klcItz7tNidrnPzNKAxznS0iXhnRp0/4uolUKqnPoUSJmZ2cnAfI4EBJlAr0oMCMD75QYQxzHUUiDHtEkcCQg+BXqUEBAA4JzLdM71Ae4GdOmgeMGXYQ5ErRRS5RQUSJmYWUtgAdDOT5oH9HbO7azkU00ANvr3R5jZ6ZVxUDM7zcweN7NMv8PZQTP70czmmNmtpXU6i3T0gZmdYGb/Y2af+R3ccszsazP7k5md5ueZGNRJsmWE5e9uZq/55cj1y/6Omf2yDM/B2Wb2jJl9ZWa7zWy/mW00s6lmNjCC/Qs9B2ZW1+/Qt9DvZJof2unTz3Ob/zz/x8wO+M/JBjNb4vdov6q8nf7M7Fygn/9wDzDEOZcd6f7Ouaecc4vKcV4zsx7+e+pfZvaDX7e9Zvadmb1hZpdHeKyGZna/mc03s63+ezPbzNab2adm9qyZ/dLMwjbPm1kXM5tgZl/6+x3yj5NlZh+a2e/N7Kww+xU7+sD8zr/Av4OSH7HCHYJdyD4Rd/w1s/ZmNt7MlpvZTv+522Jm75rZtWZW7HdUuHKb17n0cTNb6f/f1eiRI1XCOaebbkVugCu4BaW1BTYHbZsJ1K3Ec84LOvZJQHrQ44nF7HNSUJ55pRz/QSA3uG5hbmuA1iUcY4Ofb0MJeVoAX5Vwjp3AL4CJQWktwxwnuP7pwANAXgnHfQGoVcpz8ChwuJTn4N9A40ieA+CMYuo6Lyj/mXj9TUo6Z8EtuZzvnSlBx3imkt6PvYKOOaqYPC9FWK8PgIQSzpUK/BThsRqG2X8UkB/BvjPC7NsyaPvEkG3zIilTMZ8dxf4/4l26fqaU97MDPgNOKuYYhcoNXIL3vxV6jLCvnW7hb+pTIBExs2TgI7xOWeB9CP/GVW1v7VeA/wecDfzGzP7onMsqz4HM7Cngf/yHu4A3gCV4vyp/BgwALgTOAuabWWdXjsshZlYPr1Pb2X7SD8A/gVV4l0IuAn4FTKNs12YHAP2BvcA//LLXBnoC1+N9yN4EZAP3FlO2J/ACC/A+jN8A/gXsx+tEdgPQHO/L8N9mdo5zLreEMp0IvA20BxYCb/n1TfSPg/+rdhrwc3+f5cCbwHq85vpGeM/VhXijAcrMP0fvoKRXynOccqqH15w+H+8y2jq81ygRaA38Bq/D7KV4PfYHhB7AvBE804FmftIneAH393hf9E3xOkT2BtqE2b8/8Ij/cD/wOt6X6U680QKnAClAn3LU76Gg8z/mp03Be++Ui/96TQUKWqX+4x9vBV5fotOBq4GuwDnAXDNLdc7tK+GwP8d7n8X55ZuL979wBrClvGU9LkU7KtHt2LxRONI+F2/oUcHjv1PKL9JynnNe0DlO8tMGBaW9HWafUlsK8L5MC/LMAZoUk29EUL43ismzgRJaCvA+OIN/5TQIk+cSirZYtAyTLz0kzxbgrDD5uuF9ADq8L/vUMHnO5cgvyRygZ5g8jfGCjYLz/amU56Dg9tsSXtOUoHzvAbVLyNuuuNemlPfN2UHn2AfUqaT3Y6+g444qJk8PwvxyD9oeh/cFWHCcC8LkuTJo+99KKVM34MSQtJn+voeB80rYty6QFia9ZdD5J5b3uQjKW9r/411BeV4BYsPkMbwOoAX5/lBKuR1egF/kfa1bGd/30S6AbsfmLeSfLSfo/vgqPOe8oPOcFJSeGZSeFrJPJEHBCn/790BcKWV4OegD9tQw2wu+EDeE2XYisN3fvh84vYTzjAp5jluGyZMekueSEo53S1C+18Nsfzto+60lHOd0vF+6BR+yDUt4DsIGaiF5rw7KO7CK3jcXBZ3j60o8bsRfhKUcp37Q/9CLYbY/EHSezuU4/mp/3xXlLF/wl+vEij4XJf0/4gUmBZdJMin9ctcnft7dhFyqpGhQMLIq3l/H200dDSUScf7fPXgTmBxtvwu6P6YsO5o3s2JH/+Fzzrm9pezyqv+3NoWbpCNxPt4YeIB3nHMbS8j7LF7gEalVzrnZJWz/J0cmkrnczGoXbDCzE4G+/sMdeJcfwvLL/Lr/MB64uJRylfZ+CG7ybV9K3vJqEnR/VxWdo9ycc3vwhuyC1xweqqLPUcH+p5g3d8ix7BKOXCZ5yjmXX0r+gv/HBLxWkuLso4T3tUROfQokEl/hXVOsj3et+YJSvvAqlXPuYzP7F17nvN5m1ts5NzfC3XsE3T/RzAaUkr9F0P2zi80VXkrQ/X+XlNE5t83MsjgSsJSmxPo65w6a2SLgMrwgrh1Hvog6cWRI2Tzn3MFSzvURcKN//xy85u9w8vCG/pVkIV6rST28XuuNgEnOuZWl7Fdt+EHXr/AuU3XC608RT/gJgU4Jk/Yx3i9dAyaY2ZnAa865tREWYQ7QGe/yz3wzGwu878ow+uIoCv5/bFSO/8d5xeT7IoKAXyKgoEAi0RuvQ1p7vOblf5tZL1d5MxdG4nd41+jBay0I94srnJZB9x8p4zkblTH/yUH310eQfz2RBwXfljHPyRwJCn4WlB7J9NPBeX5WbC7Y4UruiIhzbqeZ/RZ4Du/z5m7gbjPbCvwf3vDWD5xzX0dQrmLLEXS/YQWOU2Zm1gGvg2WRoX7FSAhNcM5lmdkf8EbHxOFdWhplZpvwnqNP8L7kiwvE/4AXDLbDC0peA/LMbDmwCC9Ane2c2x9hGatSy6D7z5Zx35L+H9WZsJLo8oGUynmzCf4CKPjgPgMvMDi1+L0qvQyLgRn+wzSLYDy9ryLNqWUdMx8XdL+kntIFyvLLpqzHiw+6X7+M58wpZt9QEX3JOOeexxtdMBevsyN4TcgDgCeBLDNbZN7sguXxQ9D9083sqPzYMbPGeL/yCwKCTXjBz13ANXidZAf6t1V+nrCfuc653/n5Fwclnwr8Gu/L8zszm2VmrcPs+1+8pvXH8a7Xg3f5qyswEm9kw09mNrq880BUoqr6fzwWAp4aQUGBRCQoMFjtJ7XCCwzCNYdWlYc48qWSUdLEJkGCv+B+4ZyzMtzSy1i+4C/c2Ajyx5WepdzHC673njKeMzig2FNsrjJwzs13zl2EFwwMBP6I9wVY8HqeByw0s17lOPzXeMPvwLtMkVyRspbBHRy5Pj4JaOWcu80592fn3OvOuenOuRnOuRlE8KXl5++G12R+NfBnvKmawbu08Esg08yKXNZyzu1xzj2E10LUBbgTb2jedj9LfeD3wLvFTX50lAS/L1uV8f9xVLQKfTxRUCARc964/V8A3/hJZ+IFBi2K36tSz7+KIx2P2uGNAS9NcLNiVQcwwb9YW0WQP5I8BX5eepZCeYLLEryCXSTN3MF5fig2Vzk453b4X5T3+1+Ap+E1dwPEAOPKcUyH94u9QCTvi8pQsF7CYeB/nHMldRw9PdKDOud+cM5Ncc7d5ZzrhDffQUH9GnBkvoBw++Y7575wzv3VOXc1Xv+GgRwJmi7hyMyP0XA0/x+lHBQUSJk45/6DFxgUXHf+OV5gcHLxe1WqR4CCjnKjKL2Jf37Q/dJ60lfU0qD7F5aU0cwSOTJVdCR+UcrxTuDIapV7geBJnlZwZL76XmYWU8q5gp+nzDKUscycc1uAoUDBRFFd/QmgyuqZoPvDrJKmxS5Fc//vDufcruIymVlnjkz6VWZ+h8Mr8Tp2gjfKJdJ98/2WioeDkiPevwoczf9HKQcFBVJmzrkf8L70Cjq2nQX8y8xOOgrn3oA3nS94nZZGlLLLUo5cz/21mVXVsDjwetoXdHrrX8oX0+2UraNvkpmVNCNdOkc6Yr3rnCv4AsE5dwBviWvwZqdLL+4gfj+RIf7DHLyVMKuU/wt7c1BSmfsEOOf+D5jlP6wPvG5mJfWHKMS8dSrOK+NpC/p5NCvlXA+XsC0izrndHBlyWp4+ExuC7kezg/ksjlzSuM3MSurIKlGgoEDKJSgwWOcntcFrMajywADI4Mj1+7tKyug3LT/oP4wBZplZakn7mFk7M3uurIXyv3wL9qsLTAk3btzMLuHIdMNl8U9/uFro8dKAP/kP84Gnwuz7J45cv3/SzLqHZvCHC77JkX4HE/wvo3LzF7UZVtKvfzPrhjekDmC9P66/PIZyJLg4F6+PQklj2zGzNDP7CO85K2snvCUFh8F7T4Ye28zsMcJMbRySb6SZDS6pBcfMrsIL6MBr+Qne9oKZJZWwb8EU2AVWFJe3qvnDBh/1HzYGPrQwizQFM7NzzOyPVV44ATQkUSrAObfZzC7EGzvcCm/BpH/5wxW3VuF5fzKzZ/CGKZbacc45956Zjcb7xXYasNj/IviYIws8NcEbctkLr1k/D7i1HMUbAwzGG1N9Dl7P+n/gNefH4s0//yu8SXYWceSyQGmTuLyDNw5+uX+80LUPCr5QnnLOLQnd2Tn3mT9+/UG8X9Lzzex1jqx9kAQM50iT+Eoq4RcuXivSI8BfzGyOX+5NeJczmuGNWx/g1wXKODlVMOfcdjPrjTedcmu84Z6fmtlivLH8G/Cmg26M1x/mUrw1H8rrb3jrRdQGRvrrg7yNdynkVLwRCJ3xXvv9eKMBwumCd/njv/77chnetfd8vBk7L8brCwDee/WJkP1vAm4ys1V4ww+/wutDEIf3f3k1R/qJrMEL/KLGOfdXPzC/Hu81yjKzd/GGXv4H7/lMxHtteuONdlqHtw6KVLVIpz7U7fi6ETR9aAR5T8Mbc1+wz1dAYjnOOS/oGGFXRgvK25CiK6LNK2Wf4XjTpboIbhuKOcaGkrb7eVrgXbIo7tgFqyS+GpTWKMxx0oO2pwP3U/KqcqWuSQGMpvRVEudRwhoEkTwHQXkfifD5PgjcX0nv3YZ4X9gHIjz3f4DbCFkzgcjWPri1lNckC6/fTeC9HeYYL0VYzhy8RciK/V8t5baC8NNptwzKM7GYepb6XIQpT7H/j3itKw9R+qqlxR4rknLrVvabLh9IhTlvEqMLOXLdsj1ei0G5O1dFcM5dwNgy7vMiXi/we/Bm7fsB74vjAN6vu0/wmtl7U7aRAaHn2YL36+9uvI562XjXn7/BG5ef7Jz7F0em583z85R23LF4LQNv4K3jcBDYhrcgTl/n3E2ulGljnXMP4/06+wveF9YevPpvxpuEZ7BzrpdzbkfxRymTx/G+UB7D65+wAe9X82G8a+SZeK9jO79+Feac2+Wcuw2vNeC3eM/Perzn+DBev48v8Pqm9Mdb4+JvruTRA8Wd6zm8Dp7T8N5Dh4CCiZnuBlKcc6VNPHUr3nDDP+L90t+C95ocxrv+vhAvuGrtnAu3AmQLvBkoJwKf4z2veXjP8wa8eQquBbo4r09O1DlPBl4rwMN4HRB/xHtP5+K9Hz/Ge9+c65zrFaWiHnfMj7hE5Cjy51j4Ea+ZdKXzhp6JiESVWgpEouPXHBmm9u9oFkREpICCApFKZmYpZlZsB0i/53/BvO/5eH0BRESiTqMPRCrfLcCvzGw23lS+m/G+/FvgzYL3S46soDfeeTM1iohEnYICkapRH28WuiuL2e7whqHdf9RKJCJSCnU0FKlkZnYG3tjwC/B6VzfBm7M+B2+M/ifA351zUZtERkQkHAUFIiIiAqijoYiIiPgUFIiIiAigoEBERER8CgpEREQEUFAgIiIiPgUFIiIiAigoEBEREZ+CAhEREQEUFIiIiIhPQYGIiIgACgpERETEp6BAREREAAUFIiIi4lNQICIiIoCCAhEREfEpKBARERFAQYGIiIj4FBSIiIgIoKBAREREfAoKREREBFBQICIiIr460S5AtDVt2tS1bNky2sUQERE5KpYtW7bdOZcYbttxHxS0bNmSpUuXRrsYIiIiR4WZbSxumy4fiIiICKCgQERERHwKCkRERARQnwIROY4dOnSIzZs3k5ubG+2iiFS6unXrcsoppxATExPxPgoKROS4tXnzZurXr0/Lli0xs2gXR6TSOOfYsWMHmzdv5owzzoh4P10+EJHjVm5uLk2aNFFAIDWOmdGkSZMyt4IpKBCR45oCAqmpyvPeVlAgIiIigIICEZGoio+PD9yfNWsWrVu3ZuPGjYwaNYrY2Fi2bt0aNm9x+vbty65du0rM06tXr7CTtk2cOJE77rgj8sKXwbhx42jbti3Jycmkpqby8ssvl1iW8li6dCkjR44E4MCBA1x00UUkJyczZcoUhg8fTlZWVoXPMW3aNNq3b0+tWrUKlXvy5MkkJycHbrVq1WL58uWAV8c2bdoEtgW/pscadTQUEYnQa8s287sPVrNp135ObViPMb9syzVdT6mUY8+dO5eRI0cye/ZsTj/9dACaNm3Kk08+ydixYyM+zqxZsyqlPGXlnMM5R61aRX9rTpgwgTlz5pCZmUlCQgLZ2dlMnz690suQkpJCSkoKAF988QVA4Iv517/+dZmOlZeXR+3atYukJyUl8fbbbzNixIhC6ddeey3XXnstAF9++SUDBgwgOTk5sH3y5MmBsh3L1FIgIhKB15Zt5uY3V/L9rv044Ptd+7n5zZW8tmxzhY/9ySefcNNNNzFz5kzOPPPMQPoNN9zAlClT2LlzZ5F9Xn31VdLS0khOTmbEiBHk5eUB3tTt27dvB+Cxxx6jTZs2nH/++QwZMoRx48YF9p82bRppaWm0bt2aBQsWBNI3bdpEr169OOuss3j00UcD6ePHjycpKYmkpCSefvppADZs2ECbNm24/vrrSUpKYtOmTaSnp5OUlESHDh146qmnABgzZgzPPfccCQkJACQkJDB06NAidbr11ltJSUmhffv2PPLII4H0Bx54gHbt2tGxY0fuvffeQPmTkpLo1KkTPXv2BGDevHlcdtllbN26leuuu44lS5aQnJzMunXrCrVIfPTRR5x77rl06dKFq666ipycnMBzd//999OlSxemTZsW9rU6++yzadOmTdhtBV5//XWuvvrqEvMcq9RSIBW2+bkhHPxhdeDxCSe35ZRbX49iiUQq3+8+WM2+Q3mF0vYdyuN3H6yuUGvBgQMHGDBgAPPmzaNt27aFtsXHx3PDDTfwzDPPFPqC/vrrr5kyZQqLFi0iJiaG2267jcmTJ3P99dcH8ixZsoS33nqLFStWcOjQIbp06ULXrl0D2w8fPkxmZiazZs3i0Ucf5eOPPwYgMzOTr776itjYWFJTU+nXrx9mxksvvcTixYtxznHOOedwwQUX0KhRI9auXcukSZPo1q0by5YtY8uWLXz11VcA7Nq1i+zsbPbs2UOrVq1KfS4ef/xxGjduTF5eHr1792blypW0aNGC6dOns3r1aswscGlk9OjRzJ49mxYtWhS5XNKsWTNefPFFxo0bx8yZMwtt2759OxkZGXz88cfExcUxduxYxo8fz8MPPwxAkyZN+Pzzz0sta0mmTJnCO++8Uyht2LBh1K5dm8GDB/PQQw8dsx1c1VIgFXbwh9Xkfr88cAsOEERqik279pcpPVIxMTGcd955/OMf/wi7feTIkUyaNIk9e/YE0ubOncuyZctITU0lOTmZuXPnsn79+kL7LVq0iP79+1O3bl3q16/P5ZdfXmj7oEGDAOjatSsbNmwIpPfp04cmTZpQr149Bg0axMKFC1m4cCEDBw4kLi6O+Ph4Bg0aFGhdOP300+nWrRsArVq1Yv369dx55518+OGHgZaBSE2dOpUuXbrQuXNnVq1aRVZWFg0aNKBu3brceOONvP3228TGxgLQvXt30tPT+fvf/x5oJYnEZ599RlZWFt27dyc5OZlJkyaxceOR9YHKepkh1OLFi4mNjSUpKSmQNnnyZL788ksWLFjAggULeOWVVyp0jqqkloIKuHbeq6zeXXqHkbYNmjG513VHoUQiUlVObViP78MEAKc2rFeh49aqVYupU6fSu3dvxowZw+9+97tC2xs2bMg111zDs88+G0hzzjF06FCeeOKJcp/3xBNPBKB27docPnw4kB76C7a0X7RxcXGB+40aNWLFihXMnj2bCRMmMHXqVP75z38SHx/P+vXrS2wt+O677xg3bhxLliyhUaNGpKenk5ubS506dcjMzGTu3Lm8+eab/PWvf+Vf//oXEyZMYPHixbz//vt07dqVZcuWRVRv5xx9+vTh9dfDt2YG16c83njjDYYMGVIorUWLFgDUr1+fa665hszMzEKtOscStRRUwOrdW1m+84dSb5EEDiJybBvzy7bExhTueBYbU5sxv2xbzB6Ri42N5f3332fy5MlhWwzuvvtunn/++cCXd+/evXnzzTcDvdh37txZ6NcueL+k33vvPXJzc8nJySnSjF6cOXPmsHPnTvbv38+MGTPo3r07PXr0YMaMGezbt4+9e/cyffp0evToUWTf7du3k5+fz+DBg8nIyAg0wz/44IPcfvvtZGdnA5CTkxMYfVAgOzubuLg4GjRowE8//cQHH3wQyLt792769u3LU089xYoVKwBYt24d55xzDqNHjyYxMZFNmzZFVL9u3bqxaNEivv32WwD27t3LmjVrItq3NPn5+UydOrVQf4LDhw8H+ngcOnSImTNnFmpFONaopUBEJAIF/QaqavRB48aN+fDDD+nZsyeJiYmFtjVt2pSBAwcGOu61a9eOjIwMLr74YvLz84mJieHZZ58NjFoASE1N5YorrqBjx440b96cDh060KBBg1LLkZaWxuDBg9m8eTPXXXddoMd8eno6aWlpAAwfPpzOnTsXuuwAsGXLFoYNG0Z+fj5AoCXj1ltvJScnh9TUVGJiYoiJieGee+4ptG+nTp3o3Lkzbdu25dRTT6V79+4A7Nmzh/79+5Obm4tzjvHjxwNw3333sXbtWpxz9O7dm06dOjF//vxS65eYmMjEiRMZMmQIBw4cACAjI4PWrVuXui/A9OnTufPOO9m2bRv9+vUjOTmZ2bNnA16H0VNPPbVQi8iBAwe45JJLOHToEHl5eVx00UXcdNNNEZ0rGsw5F+0yRFVKSoor7xjZru+MZ/nOH0rNl9z4ZJb1v7tc56gO1t73cw5tXRd4HNPsTM7607dRLJFIZL7++mvOPvvsaBejyuTk5BAfH8++ffvo2bMnL7zwAl26dIl2seQoCvceN7Nlzrmw4yPVUiARCx1lAJCXu6dQQABwaOs61t73c2rXrV8oXaMSRI6um2++maysLHJzcxk6dKgCAimVggKJWMEog0gc2rqOQ1VbHBEpxWuvvRbtIlRbt99+O4sWLSqUdtdddzFs2LAolejoUFAgIiISIni0x/FEow9EREQEUEuBlMEJJxcdehWuTwF4nQ3D9SkQEZFjl4ICiVhxnQQ1+kBEpGZQUFABbRs0q9R81VXtuvULdSoMbSEQEZHqQX0KKmByr+tY1v/uUm+a4lhEihMfHx+4P2vWLFq3bs3GjRsZNWoUsbGxgVkLQ/MWp2/fvkUWCAoVvGJgsIkTJ3LHHXdEXvgyGDduHG3btiU5OZnU1NTAjIbFlaU8li5dysiRIwFv0qCLLrqI5ORkpkyZwvDhw8nKyqrwOVavXk1ycjKdO3dm3bqil04LpKen8+abbwKVW8eqppYCEZEIuLyD/PSut4hQs35vsPV9byrb5le8jdU+ocLHnzt3LiNHjmT27NmBmQmbNm3Kk08+ydixYyM+zqxZsypclvJwzuGco1ator81J0yYwJw5c8jMzCQhIYHs7GymT59e6WVISUkJzMD4xRdfALB8+XKg7Asd5eXlUbt27SLpM2bM4Morr+Shhx6qWGGPUWopEBGJwE/vDiJ3ywJytyzg+xfPCNwvCBQq4pNPPuGmm25i5syZnHnmmYH0G264gSlTprBz584i+7z66qukpaWRnJzMiBEjAisFtmzZMjDX/mOPPUabNm04//zzGTJkCOPGjQvsP23aNNLS0mjdunVgxUOATZs20atXL84666xCyzWPHz+epKQkkpKSePrppwHYsGEDbdq04frrrycpKYlNmzaRnp5OUlISHTp0CEzLPGbMGJ577rnAqokJCQkMHTq0SJ1uvfVWUlJSaN++PY888kgg/YEHHqBdu3Z07NiRe++9N1D+pKQkOnXqRM+ePQGYN28el112GVu3buW6665jyZIlJCcns27dukK/1j/66CPOPfdcunTpwlVXXUVOTk7gubv//vvp0qUL06ZNK1K+WbNm8fTTT/Pcc89x4YUXsmHDhkLrGIwbN45Ro0YV2a86UUuBVFjoqAKNMpCazB3eD3irJVqdiq2QCF4z94ABA5g3bx5t2xb+34mPj+eGG27gmWeeKfQF/fXXXzNlyhQWLVpETEwMt912G5MnTy608t6SJUt46623WLFiBYcOHaJLly507do1sP3w4cNkZmYya9YsHn30UT7++GMAMjMz+eqrr4iNjSU1NZV+/fphZrz00kssXrwY5xznnHMOF1xwAY0aNWLt2rVMmjSJbt26sWzZMrZs2cJXX30FwK5du8jOzmbPnj0lrpBY4PHHH6dx48bk5eXRu3dvVq5cSYsWLZg+fTqrV6/GzAKXRkaPHs3s2bNp0aJFkcslzZo148UXX2TcuHFFFoLavn07GRkZfPzxx8TFxTF27FjGjx/Pww8/DECTJk0CCzmF6tu3L7fccgvx8fHce++9RdZ+qAkUFEiFaepiOR406/cG3794BgUBAQC1TqDZZVMqdNyYmBjOO+88/vGPf/DMM88U2T5y5EiSk5MDv5DBu9SwbNkyUlNTAdi/fz/NmhXu0Lxo0SL69+9P3bp1qVu3Lpdffnmh7YMGeS0cXbt2LfTl1qdPH5o0aRLIs3DhQsyMgQMHBpYVHjRoEAsWLOCKK67g9NNPp1u3bgC0atWK9evXc+edd9KvXz8uvvjiwK/wSEydOpUXXniBw4cP85///IesrCzatWtH3bp1ufHGG7nsssu47LLLAG8VyPT0dH71q18F6hKJzz77jKysrMCCSwcPHuTcc88NbC/rZYaaRpcPREQisPX9qyH/YOHE/INsnVmxL5FatWoxdepUMjMzGTNmTJHtDRs25Jprrik0w55zjqFDh7J8+XKWL1/ON998U+Zm6xNPPBGA2rVrB5ZkBjCzQvlCH4cqCBQAGjVqxIoVK+jVqxcTJkxg+PDhJCQkEB8fz/r160s8znfffce4ceOYO3cuK1eupF+/fuTm5lKnTh0yMzO58sormTlzJpdeeing9VPIyMhg06ZNdO3alR07dkRUb+ccffr0CTx3WVlZhZarDq5PaerUqRNYERIgNzc34n2PVQoKRETKwOrUw05oUCmXDgrExsby/vvvM3ny5EJfUAXuvvtunn/++cCXd+/evXnzzTcDIxN27tzJxo0bC+3TvXt33nvvPXJzc8nJySnSjF6cOXPmsHPnTvbv38+MGTPo3r07PXr0YMaMGezbt4+9e/cyffp0evToUWTf7du3k5+fz+DBg8nIyAg0wz/44IPcfvvtZGdnA97qjQWjDwpkZ2cTFxdHgwYN+Omnn/jggw8CeXfv3k3fvn156qmnWLFiBQDr1q3jnHPOYfTo0SQmJrJp06aI6tetWzcWLVrEt996c6ns3buXNWvWRLRvqObNm7N161Z27NjBgQMHIn6Oj2W6fCAiEoHmV7xd7OiDytC4cWM+/PBDevbsSWJiYqFtTZs2ZeDAgYGOe+3atSMjI4OLL76Y/Px8YmJiePbZZwOjFgBSU1O54oor6NixI82bN6dDhw40aNCg1HKkpaUxePBgNm/ezHXXXRfozZ+enk5aWhoAw4cPp3PnzkWuqW/ZsoVhw4YFfj0/8cQTgNeBMCcnh9TUVGJiYoiJieGee+4ptG+nTp3o3Lkzbdu25dRTTw007+/Zs4f+/fuTm5uLc47x48cDcN9997F27Vqcc/Tu3ZtOnToxf/78UuuXmJjIxIkTGTJkCAcOHAAgIyOD1q1bl7pvqJiYGB5++GHS0tJo0aJFkT4h1ZE556JdhqhKSUlx1WX8qIhUrnBrzdckOTk5xMfHs2/fPnr27MkLL7yg5ZOPM+He42a2zDmXEi6/WgpERGqom2++maysLHJzcxk6dKgCAimVggIRkRrqtddei3YRqq3bb7+dRYsWFUq76667GDZsWJRKdHQoKBAREQkRPNrjeKLRByIiIgIoKBARERGfggIREREBFBSIiIiIT0GBiEgUxcfHB+7PmjWL1q1bs3HjRkaNGkVsbGxg1sLQvMXp27dvkQWCQgWvGBhs4sSJ3HHHHZEXvgzGjRtH27ZtSU5OJjU1NTCjYXFlKY+lS5cycuRIwFto6qKLLiI5OZkpU6YwfPhwsrKyKnyOadOm0b59e2rVqlWo3JMnTyY5OTlwq1WrVmDZ5l69etGmTZvAtuDXtKKWL19eqctla/SBiMgxYO7cuYwcOZLZs2cHZiZs2rQpTz75JGPHjo34OJX5BVEWzjmcc9SqVfS35oQJE5gzZw6ZmZkkJCSQnZ3N9OnTK70MKSkpgRkYv/jiC4DAF3NZFzrKy8ujdu3aRdKTkpJ4++23GTFiRKH0a6+9lmuvvRaAL7/8kgEDBpCcnBzYPnny5EDZKtPy5ctZunQpffv2rZTjqaVARCRCDV/9X2q/dG/g1vDV/62U437yySfcdNNNzJw5kzPPPDOQfsMNNzBlyhR27txZZJ9XX32VtLQ0kpOTGTFiBHl5eQC0bNmS7du3A/DYY4/Rpk0bzj//fIYMGcK4ceMC+0+bNo20tDRat27NggULAumbNm2iV69enHXWWYWWax4/fjxJSUkkJSXx9NNPA7BhwwbatGnD9ddfT1JSEps2bSI9PZ2kpCQ6dOgQmJZ5zJgxPPfccyQkJACQkJDA0KFDi9Tp1ltvJSUlhfbt2/PII48E0h944AHatWtHx44dA6tFTps2jaSkJDp16kTPnj0BmDdvHpdddhlbt27luuuuY8mSJSQnJ7Nu3bpCLRIfffQR5557Ll26dOGqq64KrOTYsmVL7r//frp06cK0adPCvlZnn302bdq0CbutwOuvv87VV19dYp7ibNiwgV/84hd07NiR3r178/333wPeNNO33HILKSkptG7dmpkzZ3Lw4EEefvhhpkyZEmgRqSi1FIiIRGjPoQMlPi6PAwcOMGDAAObNm1dk7vz4+HhuuOEGnnnmmUJf0F9//TVTpkxh0aJFxMTEcNtttzF58mSuv/76QJ4lS5bw1ltvsWLFCg4dOkSXLl3o2rVrYPvhw4fJzMxk1qxZPProo3z88ccAZGZm8tVXXxEbG0tqair9+vXDzHjppZdYvHgxzjnOOeccLrjgAho1asTatWuZNGkS3bp1Y9myZWzZsoWvvvoKgF27dpGdnc2ePXto1apVqc/F448/TuPGjcnLy6N3796sXLmSFi1aMH36dFavXo2ZBS6NjB49mtmzZ9OiRYsil0uaNWvGiy++yLhx44osUrR9+3YyMjL4+OOPiYuLY+zYsYwfP56HH34YgCZNmgQWciqvKVOm8M477xRKGzZsGLVr12bw4ME89NBDxa4+eeeddzJ06FCGDh3KP//5T0aOHMmMGTMAL2DIzMxk3bp1XHjhhXz77beMHj2apUuX8te//rVCZS6glgIRkSiKiYnhvPPOC7s6IsDIkSOZNGkSe/bsCaTNnTuXZcuWkZqaSnJyMnPnzi2yNPGiRYvo378/devWpX79+lx++eWFtg8a5C3u1LVr10ILG/Xp04cmTZpQr149Bg0axMKFC1m4cCEDBw4kLi6O+Ph4Bg0aFGhdOP300+nWrRsArVq1Yv369dx55518+OGHgZaBSE2dOpUuXbrQuXNnVq1aRVZWFg0aNKBu3brceOONvP3228TGxgLeKpDp6en8/e9/D7SSROKzzz4jKyuL7t27k5yczKRJkwqtMFnWywyhFi9eTGxsLElJSYG0yZMn8+WXX7JgwQIWLFjAK6+8Uuz+n376Kddccw0Av/nNb1i4cGFg269+9Stq1arFWWedRatWrVi9enWFyhqOggIRkSiqVasWU6dOJTMzkzFjxhTZ3rBhQ6655ppCM+w55xg6dCjLly9n+fLlfPPNN4waNapM5z3xxBMBqF27dmBJZqDIL9jiftEWiIuLC9xv1KgRK1asoFevXkyYMIHhw4eTkJBAfHx8kaAl1Hfffce4ceOYO3cuK1eupF+/fuTm5lKnTh0yMzO58sormTlzJpdeeing9VPIyMhg06ZNdO3alR07dkRUb+ccffr0CTx3WVlZhQKy4PqUxxtvvMGQIUMKpbVo0QKA+vXrc80115CZmVmuY5f1tSkPBQUiIhGqH3NiiY/LKzY2lvfff5/JkyeHbTG4++67ef755wNf3r179+bNN98M9GLfuXNnoV+74P2Sfu+998jNzSUnJ6dIM3px5syZw86dO9m/fz8zZsyge/fu9OjRgxkzZrBv3z727t3L9OnT6dGjR5F9t2/fTn5+PoMHDyYjIyPQDP/ggw9y++23k52dDXirNxaMPiiQnZ1NXFwcDRo04KeffuKDDz4I5N29ezd9+/blqaeeYsWKFQCsW7eOc845h9GjR5OYmMimTZsiql+3bt1YtGgR3377LQB79+5lzZo1Ee1bmvz8fKZOnVqoP8Hhw4cDfTwOHTrEzJkzC7UihDrvvPN44403AK+FIfh5njZtGvn5+axbt47169fTpk0b6tevX6gVqaLUp0BEJEK7rnu8yo7duHFjPvzwQ3r27EliYmKhbU2bNmXgwIGBjnvt2rUjIyODiy++mPz8fGJiYnj22WcDoxYAUlNTueKKK+jYsSPNmzenQ4cONGjQoNRypKWlMXjwYDZv3sx1110X6DGfnp5OWloaAMOHD6dz586FLjsAbNmyhWHDhpGfnw/AE088AXgdCHNyckhNTSUmJoaYmBjuueeeQvt26tSJzp0707ZtW0499VS6d+8OwJ49e+jfvz+5ubk45xg/fjwA9913H2vXrsU5R+/evenUqRPz588vtX6JiYlMnDiRIUOGcOCA1yckIyOD1q1bl7ovwPTp07nzzjvZtm0b/fr1Izk5mdmzZwNeh9FTTz21UP+JAwcOcMkll3Do0CHy8vK46KKLuOmmm4o9/l/+8heGDRvGn/70JxITE3nppZcC20477TTS0tLIzs5mwoQJ1K1blwsvvJA//OEPJCcn8+CDD1b48oc55yp0gOouJSXFVdYYWRGpXsKtNV+T5OTkEB8fz759++jZsycvvPCClk+uptLT07nsssu48sory7RfuPe4mS1zzoUdH6mWAhGRGurmm28mKyuL3Nxchg4dqoBASqWgQESkhnrttdeiXYRq6/bbb2fRokWF0u666y6GDRtWKcd//PHHi8yFcNVVV/G//xt+7ouJEydWynlLE/XLB2bWGPgHcDGwHXjQOVfknWxeN8s/AMP9pBeBB5xfATOrDTwK3ADUB74FLnTO7Srp/Lp8IHL8qumXD0Sq4+WDZ4GDQHMgGXjfzFY451aF5LsZGAB0AhwwB/gOmOBvfxQ4DzgX+B5oD+RWcdlFRERqjKgOSTSzOGAw8HvnXI5zbiHwLvCbMNmHAk865zY757YATwLp/nEaAf8D3OSc2+g8XznnFBSIiIhEKNrzFLQGDjvnggeJrsD7lR+qvb8tXL4OwGHgSjP70czWmNntVVFgERGRmiralw/igeyQtN14fQLC5d0dki/e72twCtAAL8g4AzgLmGtma5xzc0IPZGY3412O4LTTTqtoHURERGqEaLcU5AChk2MnAOGmZwrNmwDk+B0N9/tpo51z+51zK4E3gLBrSTrnXnDOpTjnUkInCREROZri4+MD92fNmkXr1q3ZuHEjo0aNIjY2NjBrYWje4vTt27fIAkGhglcMDDZx4kTuuOOOyAtfBuPGjaNt27YkJyeTmpoamNGwuLKUx9KlSxk5ciTgTRp00UUXBVYPHD58OFlZWRU+x+rVq0lOTqZz586sW7eu2Hzp6em8+eabQOXWEbzX6Ycffqi04wWLdkvBGqCOmZ3lnFvrp3UCQjsZ4qd1AjLD5Fvp/w0eSnF8z8okIlVi9YgE8nP3UKtufdo+H9rQWX5z585l5MiRzJ49OzAzYdOmTXnyyScZO3ZsxMeZNWtWpZWpLJxzOOeoVavob80JEyYwZ84cMjMzSUhIIDs7m+nTp1d6GVJSUgIzMH7xxRcALF++HCj7Qkd5eXnUrl27SPqMGTO48soreeihhypW2AqYOHEiSUlJnHzyyZV+7Ki2FDjn9gJvA6PNLM7MugP9gXBLSL0M3G1mLczsZOAeYKJ/nHXAAuB/zexEMzsbuBqIbLJvEZEI5efuKfS3MnzyySfcdNNNzJw5kzPPPDOQfsMNNzBlyhR27txZZJ9XX32VtLQ0kpOTGTFiRGClwJYtWwbm2n/sscdo06YN559/PkOGDGHcuHGB/adNm0ZaWhqtW7cOrHgIsGnTJnr16sVZZ51VaLnm8ePHk5SURFJSEk8//TTgLeXbpk0brr/+epKSkti0aRPp6ekkJSXRoUOHwLTMY8aM4bnnngusmpiQkMDQoUOL1OnWW28lJSWF9u3b88gjjwTSH3jgAdq1a0fHjh259957A+VPSkqiU6dO9OzZE4B58+Zx2WWXsXXrVq677jqWLFlCcnIy69atK/Rr/aOPPuLcc8+lS5cuXHXVVeTk5ASeu/vvv58uXboUmUMAvIDr6aef5rnnnuPCCy9kw4YNhdYxGDduXJkXpgJ4/fXX6dChA0lJSdx///2B9Pj4eH7729/Svn17evfuzbZt23jzzTdZunQp1157LcnJyezfv7+EI5ddtC8fANwG1AO2Aq8DtzrnVplZDzPLCcr3PPAe8CXwFfC+n1ZgCHA6sMPf9nvn3NyjUH4ROQ6sHpFA1lCDWn4Da606ZA01Vo8o2/LAoQ4cOMCAAQOYMWMGbdu2LbQtPj6eG264gWeeeaZQ+tdff82UKVNYtGgRy5cvp3bt2kyePLlQniVLlvDWW2+xYsUKPvjggyLN14cPHyYzM5Onn3660Jd/ZmYmb731FitXrmTatGksXbqUZcuW8dJLL7F48WI+++wz/v73vwd+ia9du5bbbruNVatWsX37drZs2cJXX33Fl19+ybBhw8jOzmbPnj2F1gMozuOPP87SpUtZuXIl8+fPZ+XKlezYsYPp06ezatUqVq5cGfiFPnr0aGbPns2KFSt49913Cx2nWbNmvPjii/To0YPly5cXCrS2b99ORkYGH3/8MZ9//jkpKSmB9RQAmjRpwueff15oUaMCffv25ZZbbuG3v/0t//73v0utTyR++OEH7r//fv71r3+xfPlylixZwowZMwBvsaaUlBRWrVrFBRdcwKOPPsqVV15JSkoKkydPZvny5dSrV69SylEg6kGBc26nc26Acy7OOXdawcRFzrkFzrn4oHzOOff/nHON/dv/K5i4yN++xTl3qXMu3jnXyjn3fLjziYiUR6BlIP9wob8VbTGIiYnhvPPOC7s6IsDIkSOZNGlSoZXw5s6dy7Jly0hNTSU5OZm5c+cWWZp40aJF9O/fn7p161K/fn0uv/zyQtsHDRoEQNeuXQstbNSnTx+aNGlCvXr1GDRoEAsXLmThwoUMHDiQuLg44uPjGTRoUKB14fTTT6dbt24AtGrVivXr13PnnXfy4YcfBloGIjV16lS6dOlC586dWbVqFVlZWTRo0IC6dety44038vbbbxMbGwt4q0Cmp6fz97//PdBKEonPPvuMrKwsunfvTnJyMpMmTSq0wmRFFxQqqyVLltCrVy8SExOpU6cO1157LZ988gngLatdUJ7rrruOhQsXVnl5oh4UiIhUB7Xq+oOigloKCqWX97i1ajF16lQyMzMZM2ZMke0NGzbkmmuu4dlnnw2kOecYOnQoy5cvZ/ny5XzzzTdlbrY+8URv2efatWsHlmQG8AZ0UezjUHFxcYH7jRo1YsWKFfTq1YsJEyYwfPhwEhISiI+PLxK0hPruu+8YN24cc+fOZeXKlfTr14/c3Fzq1KlDZmYmV155JTNnzuTSSy8FvH4KGRkZbNq0ia5du7Jjx46I6u2co0+fPoHnLisrq1BAFlyf0tSpUyewIiRAbm7VTo1T2mtRGRQUiIhEoO3z2bSb5Aq1FLSb5Cqls2FsbCzvv/8+kydPDtticPfdd/P8888Hvrx79+7Nm2++GRiZsHPnzkK/dsH7Jf3ee++Rm5tLTk4OM2dG1sVqzpw57Ny5k/379zNjxgy6d+9Ojx49mDFjBvv27WPv3r1Mnz6dHj16FNl3+/bt5OfnM3jwYDIyMvj8888BePDBB7n99tvJzvaeq5ycnMDogwLZ2dnExcXRoEEDfvrpJz744INA3t27d9O3b1+eeuopVqzwpqtZt24d55xzDqNHjyYxMZFNmzZFVL9u3bqxaNEivv32W8Brol+zZk0pe4XXvHlztm7dyo4dOzhw4EDEz3GwtLQ05s+fz/bt28nLy+P111/nggsuACA/Pz8wguG1117j/PPPB6B+/fqFWo4qU7RHH4iIVCu16tYPjD6oTI0bN+bDDz+kZ8+ehA6Vbtq0KQMHDgx03GvXrh0ZGRlcfPHF5OfnExMTw7PPPhsYtQCQmprKFVdcQceOHWnevDkdOnSgQYMGpZYjLS2NwYMHs3nzZq677rpAb/709HTS0tIAGD58OJ07dy502QFgy5YtDBs2LPDr+YknngC8DoQ5OTmkpqYSExNDTEwM99xzT6F9O3XqROfOnWnbti2nnnoq3bt3B2DPnj3079+f3NxcnHOB6//33Xcfa9euxTlH79696dSpE/Pnzy+1fomJiUycOJEhQ4Zw4MABADIyMmjdunWp+4aKiYnh4YcfJi0tjRYtWhTpExKJn/3sZ/zhD3/gwgsvxDlHv3796N+/P+C1WmRmZpKRkUGzZs2YMmUK4L0Wt9xyC/Xq1ePTTz+t1H4FUV8QKdq0IJLI8aumL4iUk5NDfHw8+/bto2fPnrzwwgtaPrkaiY+PD4yMKK/quCCSiIhUgZtvvpmsrCxyc3MZOnSoAgIplYICEZEa6rXXiqxCLxG6/fbbWbRoUaG0u+66i2HDhpX7mOecc07gkkWBV155hQ4dOoTNX9FWgvJQUCAiIhIieLRHZVm8eHGlH7OyafSBiBzXjvd+VVJzlee9raBARI5bdevWZceOHQoMpMZxzrFjxw7q1q1bpv10+UBEjlunnHIKmzdvZtu2bdEuikilq1u3LqecckqZ9lFQICLHrZiYGM4444xoF0PkmKHLByIiIgIoKBARERGfggIREREBFBSIiIiIT0GBiIiIAAoKRERExKegQERERAAFBSIiIuJTUCAiIiKAggIRERHxKSgQERERQEGBiIiI+BQUiIiICKCgQERERHwKCkRERARQUCAiIiI+BQUiIiICKCgQERERn4ICERERARQUiIiIiE9BgYiIiAAKCkRERMSnoEBEREQABQUiIiLiU1AgIiIigIICERER8SkoEBEREUBBgYiIiPgUFIiIiAigoEBERER8CgpEREQEUFAgIiIiPgUFIiIiAigoEBEREZ+CAhEREQEUFIiIiIhPQYGIiIgACgpERETEp6BAREREAAUFIiIi4lNQICIiIoCCAhEREfFFPSgws8ZmNt3M9prZRjO7pph8ZmZjzWyHfxtrZha03fnHyPFvLx69WoiIiFR/daJdAOBZ4CDQHEgG3jezFc65VSH5bgYGAJ0AB8wBvgMmBOXp5Jz7tqoLLCIiUhNFtaXAzOKAwcDvnXM5zrmFwLvAb8JkHwo86Zzb7JzbAjwJpB+1woqIiNRw0b580Bo47JxbE5S2AmgfJm97f1tJ+T4xsx/N7G0za1mpJRUREanhoh0UxAPZIWm7gfrF5N0dki8+qF/BBUBLoC3wAzDTzMJeHjGzm81sqZkt3bZtWwWKLyIiUnNEOyjIARJC0hKAPRHkTQBynHMOwDn3iXPuoHNuF3AXcAZwdriTOudecM6lOOdSEhMTK1gFERGRmiHaQcEaoI6ZnRWU1gkI7WSIn9YpgnwFHGAlbBcREZEgUQ0KnHN7gbeB0WYWZ2bdgf7AK2GyvwzcbWYtzOxk4B5gIoCZtTezZDOrbWbxeJ0QtwBfH416iIiI1ATRbikAuA2oB2wFXgdudc6tMrMeZpYTlO954D3gS+Ar4H0/DbzhjFPw+iesx+tbcJlz7tBRqYGIiEgNYP4l+eNWSkqKW7p0abSLISIiclSY2TLnXEq4bcdCS4GIiIgcAxQUiIiICKCgQERERHwKCkRERARQUCAiIiI+BQUiIiICKCgQERERn4ICERERARQUiIiIiE9BgYiIiAAKCkRERMSnoEBEREQABQUiIiLiU1AgIiIigIICERER8SkoEBEREUBBgYiIiPgUFIiIiAigoEBERER8CgpEREQEUFAgIiIiPgUFIiIiAigoEBEREZ+CAhEREQEUFIiIiIhPQYGIiIgACgpERETEp6BAREREAAUFIiIi4lNQICIiIoCCAhEREfEpKBARERFAQYGIiIj4FBSIiIgIoKBAREREfAoKREREBFBQICIiIj4FBSIiIgIoKBARERGfggIREREBFBSIiIiIT0GBiIiIAAoKRERExKegQERERAAFBSIiIuJTUCAiIiKAggIRERHxKSgQERERQEGBiIiI+BQUiIiICKCgQERERHwKCkRERARQUCAiIiK+qAcFZtbYzKab2V4z22hm1xSTz8xsrJnt8G9jzczC5LvezJyZDa/60ouIiNQcdaJdAOBZ4CDQHEgG3jezFc65VSH5bgYGAJ0AB8wBvgMmFGQws0bA74DQfUVERKQUUW0pMLM4YDDwe+dcjnNuIfAu8Jsw2YcCTzrnNjvntgBPAukheZ4A/gxsr7pSi4iI1EzRvnzQGjjsnFsTlLYCaB8mb3t/W9h8ZpYGpBDUciAiIiKRi3ZQEA9kh6TtBuoXk3d3SL54v69BbeBvwB3OufzSTmpmN5vZUjNbum3btnIWXUREpGaJdlCQAySEpCUAeyLImwDkOOcccBuw0jn3WSQndc694JxLcc6lJCYmlqPYIiIiNU+0g4I1QB0zOysorRPhOwqu8reFy9cbGGhmP5rZj8B5wJNm9tcqKLOIiEiNFNXRB865vWb2NjDaH0KYDPTH+1IP9TJwt5nNwht9cA/wF39bOlA3KO/bwJvAP6qm5CIiIjXPsTAk8Tbgn8BWYAdwq3NulZn1AD5wzsX7+Z4HWgFf+o9f9NNwzu0KPqCZHQSynXPBfRBERESkBOZdkj9+paSkuKVLl0a7GCIiIkeFmS1zzqWE2xbtPgUiIiJyjFBQICIiIoCCAhEREfGV2tHQzNaX89jOOXdmOfcVERGRoyyS0Qe18IYAllWRFQxFRETk2FVqUOCca3kUyiEiIiJRpj4FIiIiAigoEBEREV8kHQ2vL+/BnXMvl3dfEREROboi6Wg4kbJ3NDR/HwUFIiIi1UQkQcGwKi+FiIiIRF0kow8mHY2CiIiISHSpo6GIiIgACgpERETEF0mfgiLMLA64DbgEaAGcGCabpjkWERGpRsocFJhZQ2Ah0A7IBhKA3cAJQD0/2w/AocopooiIiBwN5bl88BBeQHAj0MhPewqIB84DPgfWAWdXRgFFRETk6ChPUHAF8Ilz7iXnXGD+Auf5DOgLtAX+t5LKKCIiIkdBeYKCU4FlQY/zCepT4JzbCnwAXF2xoomIiMjRVJ6gYB9eIFBgN3BSSJ6f8DogioiISDVRnqBgE15rQYEsoKeZBR/rfODHihRMREREjq7yBAXzgQvMzPzHU4AzgVlmdruZTQO6AbMqqYwiIiJyFJRnnoJJeMMPT8FrNZgA/AIYAFzs51mEN0pBREREqokyBwXOuc+BW4MeHwYGmVlX4OfABmCJcy4//BFERETkWFSuGQ3Dcc4to/CoBBEREalGytynwMzqmdlpZnZCMdtP9LfXrXjxRERE5GgpT0fDh4Fv8GYwDCcOWA38rryFEhERkaOvPEHBL4GPnXM7w2300z8GLqtIwUREROToKk9Q0BJYU0qeNX4+ERERqSbKExTEUHhGw3AcoD4FIiIi1Uh5goL1wAWl5OkFbCzHsUVERCRKyhMUvAt0NbP/F26jmT0AdAFmVKBcIiIicpSVZ56CccC1wBNm9ivgI2AL3gJIlwDJwPfAHyupjCIiInIUlGdGw/+aWS/gNbw1Drrg9SEoWAvh/4DrnHP/raQyioiIyFFQrhkNnXMbgPPMrAteYNAQ2AV85k+DLCIiItVMhaY59gMABQEiIiI1QIWCAjOLA1oD8c65BZVTJBEREYmG8ow+wMxOMbO3gP8CS4F/B20738yy/H4HIiIiUk2UZ0GknwGLgf7ATOBTjnQyxN/WDPh1ZRRQREREjo7ytBQ8gvel38c5NwiYE7zROXcIWAB0r3jxRERE5GgpT1DQF3jXOffvEvJ8D5xcviKJiIhINJQnKGgOrC0lzyG8JZRFRESkmihPULATOLWUPK2BH8txbBEREYmS8gQFi4ArzOykcBvN7CzgUoJGJIiIiMixrzxBwZ/wlkWeb2a/BGLBm7PAf/we3tLKT1ZaKUVERKTKlWftg8VmNgJ4Dm9IYoFs/+9h4Abn3KpKKJ+IiIgcJeVd++CfZrYAuA1v7YMmwG7gM+CvzrlvKq+IIiIicjSUe5pj59xa4LfFbTezROfctvIeX0RERI6uck1zXBIza2BmY4B1lX1sERERqTplaikws9OBrnjzEGQ6534K2lYXr+XgXqARsK8SyykiIiJVLOKWAjP7M96v/2nADGCDmd3mb+sFfANk4I1GeAZoVblFFRERkaoUUUuBmQ0F7sAbavi1n9wW+LOZ7QWeB2r7fzOccz9UQVlFRESkCkV6+SAdOAhc6Jz7FMDMeuIthvQPYDNwuXPuy6oopIiIiFS9SC8fdASmFwQEAM65T/AuIxjevATlCgjMrLGZTTezvWa20cyuKSafmdlYM9vh38aamfnbmprZIj99l5l9amZapVFERKQMIm0paAB8Gya9YGGkT8Nsi9SzeK0QzYFk4H0zWxFm8qObgQFAJ8DhtVJ8B0wAcoAb/PI4oD/wnpk1c84drkDZREREjhuRthTUwhtxEOoQgHNuf3lObmZxwGDg9865HOfcQuBd4Ddhsg8FnnTObXbObcGbRjndP3+uc+4b51w+XstFHt4IiMblKZeIiMjxqCxDEl0VnL81cNg5tyYobQVwQZi87f1twfnaB2cws5V4HSBjgBedc1srt7giIiI1V1mCglFmNircBjPLC5PsnHOlHT+eI2smFNgN1C8m7+6QfPFmZs4555+woz9fwkDghOJOamY3412O4LTTTiuliCIiIseHssxoaGW8RXLsHCAhJC0B2BNB3gQgpyAgKOBfSngdeMDMOoU7qXPuBedcinMuJTExMYJiioiI1HwRBQXOuVrluUVw6DVAHTM7KyitExBuhcVV/rbS8hWIQRMoiYiIRKzS1z4oC+fcXuBtYLSZxfnDCPsDr4TJ/jJwt5m1MLOTgXuAiQBm1s3MzjezE8ysnpndjzeaYfFRqYiIiEgNUO5VEivRbcA/ga3ADuBW59wqM+sBfOCci/fzPY/3y79gPoQX/TSAE4E/+9sP+Xn6aWZFERGRyFnIJfnjTkpKilu6dGm0iyEiInJUmNky51xKuG1RvXwgIiIixw4FBSIiIgIoKBARERGfggIREREBFBSIiIiIT0GBiIiIAAoKRERExKegQERERAAFBSIiIuJTUCAiIiKAggIRERHxKSgQERERQEGBiIiI+BQUiIiICKCgQERERHwKCkRERARQUCAiIiI+BQUiIiICKCgQERERn4ICERERARQUiIiIiE9BgYiIiAAKCkRERMSnoEBEREQABQUiIiLiU1AgIiIigIICERER8SkoEBEREUBBgYiIiPgUFIiIiAigoEBERER8CgpEREQEUFAgIiIiPgUFIiIiAigoEBEREZ+CAhEREQEUFIiIiIhPQYGIiIgACgpERETEp6BAREREAAUFIiIi4lNQICIiIoCCAhEREfEpKBARERFAQYGIiIj4FBSIiIgIoKBAREREfAoKREREBFBQICIiIj4FBSIiIgIoKBARERGfggIREREBFBSIiIiIL+pBgZk1NrPpZrbXzDaa2TXF5DMzG2tmO/zbWDMzf1trM3vHzLaZ2U4zm21mbY5uTURERKq3qAcFwLPAQaA5cC3wnJm1D5PvZmAA0AnoCFwOjPC3NQTeBdr4x8kE3qnKQouIiNQ0UQ0KzCwOGAz83jmX45xbiPfl/psw2YcCTzrnNjvntgBPAukAzrlM59w/nHM7nXOHgKeANmbW5KhUREREpAaIdktBa+Cwc25NUNoKIFxLQXt/W2n5AHoCPzrndlRKKUVERI4D0Q4K4oHskLTdQP1i8u4OyRdf0K+ggJmdgndJ4u7iTmpmN5vZUjNbum3btnIVXEREpKaJdlCQAySEpCUAeyLImwDkOOdcQYKZJQIfAX9zzr1e3Emdcy8451KccymJiYnlLryIiEhNEu2gYA1Qx8zOCkrrBKwKk3eVvy1sPjNrhBcQvOuce7wKyioiIlKjRTUocM7tBd4GRptZnJl1B/oDr4TJ/jJwt5m1MLOTgXuAiQBmlgDMBhY55x44KoUXERGpYaLdUgBwG1AP2Aq8DtzqnFtlZj3MLCco3/PAe8CXwFfA+34awEAgFRhmZjlBt9OOWi1ERESqOQu6JH9cSklJcUuXLo12MURERI4KM1vmnEsJt+1YaCkQERGRY4CCAhEREQEUFIiIiIhPQYGIiIgACgpERETEp6BAREREAAUFIiIi4lNQICIiIoCCAhEREfEpKBARERFAQYGIiIj4FBSIiIgIoKBAREREfAoKREREBFBQICIiIj4FBSIiIgIoKBARERGfggIREREBFBSIiIiIT0GBiIiIAAoKRERExKegQERERAAFBSIiIuJTUCAiIiKAggIRERHxKSgQERERQEGBiIiI+BQUiIiICKCgQERERHwKCkRERARQUCAiIiI+BQUiIiICKCgQERERn4ICERERARQUiIiIiE9BgYiIiAAKCkRERMSnoEBEREQABQUiIiLiU1AgIiIigIICERER8SkoEBEREUBBgYiIiPgUFIiIiAigoEBERER8CgpEREQEUFAgIiIiPgUFIiIiAigoEBEREZ+CAhEREQEUFIiIiIhPQYGIiIgACgpERETEF/WgwMwam9l0M9trZhvN7Jpi8pmZjTWzHf5trJlZ0PYXzOwbM8s3s/SjVgEREZEaIupBAfAscBBoDlwLPGdm7cPkuxkYAHQCOgKXAyOCtq8AbgM+r8rCioiI1FRRDQrMLA4YDPzeOZfjnFsIvAv8Jkz2ocCTzrnNzrktwJNAesFG59yzzrm5QG7Vl1xERKTmiXZLQWvgsHNuTVDaCiBcS0F7f1tp+URERKQcoh0UxAPZIWm7gfrF5N0dki8+uF9BpMzsZjNbamZLt23bVtbdRUREaqRoBwU5QEJIWgKwJ4K8CUCOc86V9aTOuReccynOuZTExMSy7i4iIlIjRTsoWAPUMbOzgtI6AavC5F3lbystn4iIiJRDVIMC59xe4G1gtJnFmVl3oD/wSpjsLwN3m1kLMzsZuAeYWLDRzE4ws7qAATFmVtfMoh30iIiIVBvHwpfmbUA9YCvwOnCrc26VmfUws5ygfM8D7wFfAl8B7/tpBT4C9gPnAS/493tWffFFRERqBivHJfkaJSUlxS1dujTaxRARETkqzGyZcy4l3LZjoaVAREREjgEKCkRERARQUCAiIiI+BQUiIiICKCgQERERn4ICERERARQUiIiIiE9BgYiIiAAKCkRERMSnoEBEREQABQUiIiLiU1AgIiIigIICERER8SkoEBEREUBBgYiIiPgUFIiIiAigoEBERER8CgpEREQEUFAgIiIiPgUFIiIiAigoEBEREZ+CAhEREQEUFIiIiIhPQYGIiIgACgpERETEp6BAREREAAUFIiIi4lNQICIiIoCCAhERqeacc97f/Lzi8+QfOlrFqbB858j36xTsUF5+lZ+7TpWfQUREpIp4AYFj97KnSOh0Gw6wWrUL58k/RN7+Hexf/z71O9wYlXJG4nBePnVq12L9jn38deF3fLB6K7tyD1EvpjZJJ9VnxLmn069tc/Jx1KlVNb/pFRSIiEi1VBAQbJ8zgpysSez77gNOGvBeocCgICD4z7RfcHjXt+Qf3E2DrndHtdzhHMrLZ+e+Q1z/+hfMWbOtyPbv/7ufWV9v5bRG9XimfxKXt29OLbNKL4cuH4iISLUTGhAA5G6ez48zLof8Q7j8vCIBAcDOBQ+we9n4KJa8qEN5+fy45wCpT38SNiAI9v1/9zN40hJeyvw+7CWGilJQICIi1Y6ZsWvxmEBAUCA4MAgNCArsXPAAe9dOP5rFLdUlL3zG5t25EeXNd3DLW1+y8Ludld7PQEGBiIhUOy7/MAnJtxPTJKnIttzN89kyOYUfJqcVCQgA6p3Rl9hWl+Fc1XfcK82hvHymrviB1VtzyrRfXr5jzMdrialduV/jCgpERKTasVp1qHVCfX521dywgcGh/64hb9+PRdLrndGX5pdNg1q1MYv+V2BM7Vr8bdGGcu07Z+02NuzcFxh9URmi/4yIiIiUQ2mBQahjLSAA2PjffXy68b/l2tc5mLhkE3n5CgpEREQKBQa1Y08qNt+JJ6UecwEBwOZdkfUjKM6W3bnUqcRLCMfOMyMiIlIuDpd3AOcOF58j7xC4PO/n9TGkoiMIHJVbHwUFIiJSbQUPO8zfv73YfAe3LefHGZcFhiseK1o0qFuh/U+qX5fDlTgCQUGBiIhUS+HmIShJ7uZPjrnAoFWTOLqe0qDc+1+fcgq1alXeJEYKCkREpNopLSA4ITGZOgkti6Qfa4HBobx8bj2vZbn2veDMJrROjK/UmQ0VFIiISLVjtWLIWTWp2HkITr56ESdfs7iYeQwWsG/jHDgGOhzG1K7FtV1OoWXjemXazwwe/MXPNXmRiIgIQMO0+0lIvqNQWvCww/DDFY0mvf9GbKvLsCpYO6A8ahnMvqkbifEnRLzPuMva0ad1oiYvEhERKdCk1/hAYBA6D0HReQy8gKB+0g3HTEAAXmtBy8axZN7Vg9RTG5aYt0nsCUy8OpnfXnBmldTBKnMmpOooJSXFLV26NNrFEBGRCtjz5T+Ib3d92HkIXP5h8g/uYf/3HxN31pXHVEAQ7FBePjG1a7Fs0y7+sshfOnm/t3Ry++b1ueW80/l1pxbUrmXUrkDnQjNb5pxLCbtNQYGCAhGRmsC5/GInJnL5h8FqH7MBQbC8fBf2S78gaKiokoKCOhU+uoiIyDGgpJkKrVb1+borrhWgsvsPhKM+BSIiIgIoKBARERGfggIREREBFBSIiIiIT0GBiIiIAAoKRERExKegQERERAAFBSIiIuJTUCAiIiKAggIRERHxHfdrH5jZNmBjJR6yKbC9Eo93LFNda6bjpa7HSz1Bda2pylvX051zieE2HPdBQWUzs6XFLTRR06iuNdPxUtfjpZ6gutZUVVFXXT4QERERQEGBiIiI+BQUVL4Xol2Ao0h1rZmOl7oeL/UE1bWmqvS6qk+BiIiIAGopEBEREZ+CAhEREQEUFJSZmV1tZl+b2V4zW2dmPfz0WDP7m5ltN7PdZvZJ0D5mZmPNbId/G2tmFr1aRKaEuv7KT99jZllmNiBkv9+a2Y9mlm1m/zSzE6NSgQiYWU7ILc/M/hK0vbeZrTazfWb2bzM7PWjbiX79sv363h2dWpSupHqaWTczm2NmO81sm5lNM7OfBe1brd6/pb2mQfkeNjNnZhcFpVWb1xQiev/WmM+lCOpakz6XWprZLDP7r1/mv5pZHX9bspkt8z+TlplZctB+FX9NnXO6RXgD+uBNdNQNL6BqAbTwt70KvAEkArWBrkH7jQC+AU7x98kCbol2fcpTV/92EPglYEA/YB/QzN/vEuAnoD3QCJgH/CHa9YmwzvFADtDTf9wU2A1cBdQF/gR8FpT/CWCBX8+zgR+BS6Ndj3LU85d+HROAWOCfwIfV+f1bXF2D0s8EvgR+AC6q7q9pcXWtaZ9LxdW1pn0uAbOAif7nzkn+e3UkcIL/ufxb4EQ/bSNwQmW9plGvfHW6Af8H3BgmvS2QDSSUsN/NQY9vDP5yORZvJdT1HGBrSNo24Fz//mvAmKBtvYEfo12fCOs8FFjPkQ64NwP/F7Q9DtgPtPUf/wBcHLT9MeCNaNejrPUMs70LsCfkvVCt3r+l1RX4EOgLbKBwUFAtX9Nwda2Jn0sl1LVGfS4BXwN9gx7/CXgeuBjYEvx+Br7HD1wr4zXV5YMImVltIAVINLNvzWyz36RTD0jDi9Ye9ZvpvjSzwUG7twdWBD1e4acdk0qp61LgazO7wsxq+010B4CV/u7h6trczJocxSqU11DgZef/NxFSF+fcXmAd0N7MGgE/oxq9rkFC6xmqJ7Aq6HG1ev+GKFJXM7sKOOCcmxWcsZq/plC0rjXqcylEaF1r2ufS08DV/uWfFngtIB/i1WNlyP/uSo68bhV+TRUURK45EANcCfQAkoHOwEN4TTVJeE3NJwN3AJPM7Gx/33h/W4HdQPwxfP2u2Lo65/KAl/Ei7wP+3xH+FyaErytA/aovdvmZ11fgAmBSUHJoXfAf1/e3QdG6Vsd6Bm/vCDwM3BeUXN3ev0D4uppZfWAMcFeYXarlawrFvq417XMJCF/XGvi59Anel3k2sBkv6JlByZ9JhNle5tdUQUHk9vt//+Kc+49zbjswHq8Jcj9wCMhwzh10zs0H/o3X1APeta+EoGMlADkl/FKLtmLr6nfK+iPQC+/61gXAi0GdXcLVFWBPVRe6gn4DLHTOfReUFloX/Md7/G1QtK7VsZ4AmNnPgQ+Au5xzC4I2Vbf3b4FwdR0FvOKc2xAmf3V9TSF8XWva51KBInWtSZ9LZlYLr1XgbbxLlk3x+kGMpeTPJMJsL/NrqqAgQs65/+JFbMFPbsH9lUX3KJRvFdAp6HEnCjfPHlNKqWsy8IlzbqlzLt85twRYDBT04A5X15+cczuqttQVdj1Ffz0XqouZxeF1UFvlP0f/oRq9rr5w9Sz49fUx8Jhz7pWQzdXq/RskXF17AyP9Ht0/AqcCU83s/mr8mkL4utaoz6Ug4eqaTM35XGoMnAb81Tl3wC/jS3g/QFcBHUN++XfkyOtW8dc02h0qqtMNGA0sAZrhRW4L8DoixQDfAr8H6gDd8SK3gg5pt+B1HGmB14y3imO8l28Jdb0Ab6nOZD9fZ2AHfucs4FK8HtvtgIbAvziGe/n6ZT4P2AvUD0lPxGt+G4zXC3gshUcf/AGY7z8/bfG+UI7Znuol1LMFXl+Je4vZrzq+f4uraxO83twFt014Iy/iq+NrWkpda+LnUnF1rVGfS3idKB/wX7eGwHS8SyIFow/uwht9cAeFRx9U+DWNeuWr083/J/sbsMt/g/0ZqOtvaw986r9hs4CBQfsZXtPWTv/2R4rp+X2s3Eqp6x3+h80e/817T8i+d+MN/8nGi3BPjHZ9Sqnr83hNyuG2XQSsxmuKnQe0DNp2It7wvWy/vndHuy7lqSfwCN4vyJzgW9D26vj+LfY1Dcm3gcKjD6rVa1paXWvg51JJda0xn0t4LR/zgP/iBTtTgeb+ts7AMv8z6XOgc2W+plr7QERERAD1KRARERGfggIREREBFBSIiIiIT0GBiIiIAAoKRERExKegQERERAAFBSJRY2bpZubMLD3aZSkLM2tiZjvN7G/RLsuxyMwm+q9ry3Lsa2a2wswWlJ5bpPIpKBCpBP6XQFlu6dEucwU8CtQDMqJdkJrGeRPHPAycb2ZXRrs8cvypE+0CiNQQj4ZJ+x+gAfAM3syQwZYD3wGf4U2lWy2Y2WnACOAl59wP0S5PTeSce8fMvgYeN7O3nGaYk6NIQYFIJXDOjQpN81sDGgBPu/Cr8kHRZVCPdSPwPjcmRrkcNd0kvHUYeuMtVCVyVOjygUiUFNenwMw2+Ld4M3vKzDaZ2X4zW25mA/w8dczsf81srZnlmtk6M7ujhHNdYmazzGy7mR3w8//JzBqWobwGDAM2Oef+L8z25mY2zsy+MbO9ZrbLvz/RzFpVtExmdoqZ/dmv836/X0Ommf0+TN6uZvaWmW31j73RzP5mZj8LkzfQB8DMRpjZl/5z+pOZvWBmDYopz0VmtsCv604zm2FmbUt4/q4ws7lm9h+/TD+Y2Xwzuy1M9jf8vzcWdzyRqqCWApFjUwwwB28Z1XfwVkcbArxlZhcDtwHnAB8AB/BW+vuLmW1zzk0JPpCZPQKMwlsgZSawFW+51XuBvmZ2rnMuO4IytQd+xpEvrOBzxAKL8JaWngO8h7c4y+lAf+BNvEVqylUmM0sBZvvPxyd4a83H4q16NwpvBc+CvJcBb/nnfxNvFbmuwK1AfzM73zn3XZj6/RG4xC/7R8CFwE3Az4FfhNT3SmAKcND/+x/gfLzFh4osWWxmN+Mt5vOjf/zteCuQdsQLtAp12nTObTSzLcBFZma6hCBHTbRXg9JNt5p6w1uBzxG0smLI9nR/e3ox+71H0EpuQA8/fSfestYNg7a1wvuC+iLkWBf6+/xfcP6Q8z8VYX1u8fPfE2bb5cUdCy+gqV/eMvn7f+enXxPm+KcE3Y/HWzI3D+gRku9+/xgfhaRP9NO/B04LSq+DF4A4IC3MOQ4BKSHHesrPX+h1x1vV7gDQLEz5mxbzfE/3j9Mu2u9l3Y6fmy4fiBy7/sc5d6DggXNuAd6XYyPgfufcrqBt6/F+qSeZWe2gY4z0/94UnN/fZyJeh8drIyzPaf7fkjpG7g9NcM4ddM7tqUCZLgdaAu86514Lc/zNQQ/747UmTPGfr2BP4gVcffwOk6FGO+e+DzruYbwldgHSwpzjNefc0pBjjKL4fiKH8QKJ0PJvLyb/j/7fcGUVqRK6fCBybNrlnFsXJv0H4Ay8X56htuD9T5/k3wc4F++L6CozuyrMPicAiWbWxDm3o5QyNfH//jfMtvn+OR8wsy7ALLwgZblzLi8kb1nL1M1P/6CU8gF08f/+K3SDc+6wmX2CF2B0xmsZCBb6BQ+wyf/bKMw55oc5x24zWw5cELJpMl5QkmVmb/j7LnLObSu2Jl6LEEDTEvKIVCoFBSLHppJ+beKcC7f9sP83JiitCd7/+SOlnK+gSbwkBa0AdUM3OOeyzawb3tDMK/CuzQNsN2+SowznXMGv5LKWqaH/eEvxWQMKOgUW15pRkN4wzLZdYdIKntPg1peCc/xUzDl+DE1wzo03s+14fUFG4g1XdWY2H7gvTIsDeHNBQJjWF5GqoqBApGbbDdRyzjWuhGNt9f82CbfRb8a/0R+l0A6vc97teJPx1AIKRgmUtUy7/L8tIshbECydVMz2n4XkK4+CfZsXsz3suZ1zLwMv+6MrzgMGAjcAs82sbZhWg4LneSsiR4n6FIjUbJ8BjcysfSUcq6BXfbHD7sCblc85t8o59xegj588oAJl+sz/+8sI8n7h/+0VusHM6uB11gT4PMJzh1Owb+glAvzhi8kl7eyc2+Wcm+Wcuwmvk2NjoGeYrG2BfODLCpRVpEwUFIjUbE/5f/9uZieHbjSzOL/ZPxIL8Hr1F8lvZu3NLNwv54K0fRUo03t4HQSvMLMhYfKfEvRwBt61+CFh6vU/eP0xPg7uUFgO7+D1q7jGHyoZbBRHLi8El/FCvwUlVDP/776Q/CfiBRdfhHbGFKlKunwgUoM55+aa2QPAE8BaM5uFN4IhHm8OgQuAhcClERxrt5nNBXqZWSPnXHCHwz7An8zsU2ANXpP3KXg99fOBP5W3TM65g36HxI+A18xsBF7rQV3gbLxZ/+r4eXPM7AZgGjDfzKbhdSjsClyMd71/RBmewnDPQ44/78AUYIGZBc9TkIQ3jDH0l/90IMfMPsMLcAyv1SIVr9No6KyFvfA6XL5VkbKKlJWCApEazjk31swW4XVwOx/vi3o3Xse9F4Aiw/xK8De8L9ergeeC0mfjDZ3r6R8/Ae+Lcg4w3oXMgFjWMjnnlppZMvAA3mWE84A9wLd4fRaC875jZt2B3+F1eGyAFwxMAB5zlbBmg3PuTTO7FK+z5K/w5iD4BG9kxQMUDQoe8MvSBegL5OJNqnQ/8FxQJ8wCQ/HmnfhHRcsqUhbmnCbKEpHI+HMgfIn3hdXZ6QOk0plZM7zWhNecc8OjXBw5zqhPgYhEzJ9z4F6gEzAoysWpqX6H13ejyJoOIlVNQYGIlIlzbhZwF2HmK5CK8Tsj/gf4jXOu2iypLTWHLh+IiIgIoJYCERER8SkoEBEREUBBgYiIiPgUFIiIiAigoEBERER8CgpEREQEUFAgIiIivv8Pdg8m+02+068AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (8, 8))\n",
    "sns.scatterplot(data = df_resultados_knc_opt, x = df_resultados_knc_opt['TIEMPO'],y = df_resultados_knc_opt['RECALL'], \n",
    "                hue = df_resultados_knc_opt.index, style = df_resultados_knc_opt.index, palette = 'colorblind', s = 300) \n",
    "plt.xlabel('Time (seconds)', y = -0.8, fontsize = 20)\n",
    "plt.ylabel('Recall', x = -1, fontsize = 20)\n",
    "plt.yticks(fontsize = 12)\n",
    "plt.xticks(fontsize = 12)\n",
    "plt.title('K Neigbors Classifier', y = 1.05, fontsize = 30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e853f4c",
   "metadata": {},
   "source": [
    "El modelo K Neighbors Classifier fulldataset con los hiperparámetros optimizados obtiene un mejor resultado que el modelo que utiliza los hiperparámetros default. Es por ello que en la etapa de Model Stacking se utilizarán esos hiperparámetros optimizados. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a25b12",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60137534",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83ef748",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d01ee05",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b2e0e8",
   "metadata": {},
   "source": [
    "\n",
    "<font size='6' style=\"color:orange\">  <b> Model Stacking </b> </font>\n",
    "<a name=\"stacking\"></a>\n",
    "\n",
    "[[ Back to Top ]](#content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5545663",
   "metadata": {},
   "source": [
    "Se realizará stacking de modelos de forma tal que se pueda encontrar un modelo que arroje el mejor resultado, buscando la relación más óptima entre el recall y el tiempo de ejecución del modelo. Para ello se utilizarán tanto modelos optimizados como sin optimizar. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2dff31",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5da74c9a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T18:29:54.983272Z",
     "start_time": "2022-11-26T18:29:54.968185Z"
    }
   },
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2160b72f",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb68ecb",
   "metadata": {},
   "source": [
    "<font size='5' style=\"color:orange\">  <b> GaussianNB x 3</b> </font>\n",
    "<a name=\"ensemble_2\"></a>\n",
    "\n",
    "[[ Back to Top ]](#content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8759867",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T18:31:00.558690Z",
     "start_time": "2022-11-26T18:31:00.541714Z"
    }
   },
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb2 = GaussianNB()\n",
    "gnb3 = GaussianNB()\n",
    "gnb_final = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2945f2bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T18:31:02.683542Z",
     "start_time": "2022-11-26T18:31:02.677383Z"
    }
   },
   "outputs": [],
   "source": [
    "ensemble_2 =  StackingClassifier (estimators = [ ('gnb',gnb), ('gnb2',gnb2), ('gnb3',gnb3)], final_estimator = gnb_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e3bee90",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T18:33:22.334089Z",
     "start_time": "2022-11-26T18:31:05.223241Z"
    }
   },
   "outputs": [],
   "source": [
    "e2_results    = []\n",
    "e2_results_cm = []\n",
    "tiempo_ejecucion = []\n",
    "inicio = time.time()\n",
    "\n",
    "for train_index, test_index in skf.split(X,y):\n",
    "    \n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    ensemble_2.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = ensemble_2.predict(X_test)\n",
    "    \n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall    = recall_score(y_test, y_pred)\n",
    "    f1        = f1_score(y_test, y_pred)\n",
    "    cm        = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    list_results   = [precision, recall, f1]\n",
    "    list_cm = [cm]\n",
    "    e2_results.append(list_results)\n",
    "    e2_results_cm.append(list_cm)\n",
    "    \n",
    "fin = time.time()\n",
    "tiempo_ejecucion.append(fin - inicio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21f78ef5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T18:33:22.349171Z",
     "start_time": "2022-11-26T18:33:22.335110Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRECISION</th>\n",
       "      <th>RECALL</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ensemble GaussianNB x 3 + Final GassianNB</th>\n",
       "      <td>0.541327</td>\n",
       "      <td>0.561671</td>\n",
       "      <td>0.551273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           PRECISION    RECALL        F1\n",
       "Ensemble GaussianNB x 3 + Final GassianNB   0.541327  0.561671  0.551273"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filas    = ['Ensemble GaussianNB x 3 + Final GassianNB']\n",
    "columnas = [\"PRECISION\", \"RECALL\", \"F1\"]\n",
    "resultados = pd.DataFrame([gmean(e2_results)], columns=columnas, index=filas)\n",
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2395d4ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T18:33:22.365182Z",
     "start_time": "2022-11-26T18:33:22.351096Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRECISION</th>\n",
       "      <th>RECALL</th>\n",
       "      <th>F1</th>\n",
       "      <th>TIEMPO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ensemble GaussianNB x 3 + Final GassianNB</th>\n",
       "      <td>0.541327</td>\n",
       "      <td>0.561671</td>\n",
       "      <td>0.551273</td>\n",
       "      <td>137.101123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           PRECISION    RECALL        F1  \\\n",
       "Ensemble GaussianNB x 3 + Final GassianNB   0.541327  0.561671  0.551273   \n",
       "\n",
       "                                               TIEMPO  \n",
       "Ensemble GaussianNB x 3 + Final GassianNB  137.101123  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados['TIEMPO']= tiempo_ejecucion\n",
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3dfd5ebe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T18:33:22.381105Z",
     "start_time": "2022-11-26T18:33:22.366097Z"
    }
   },
   "outputs": [],
   "source": [
    "resultados.to_pickle(\"resultados_e2.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91e3fcdd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T18:33:22.397096Z",
     "start_time": "2022-11-26T18:33:22.382096Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[17033.23701796,   955.79182738],\n",
       "        [  880.5975707 ,  1128.84563809]]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados_cm= gmean(e2_results_cm)\n",
    "resultados_cm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "acb6dd7e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T18:33:22.412096Z",
     "start_time": "2022-11-26T18:33:22.398097Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('resultados_e2_cm.pkl','wb') as f:\n",
    "    pickle.dump(resultados_cm, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b8e716",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4071b4",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55016299",
   "metadata": {},
   "source": [
    "<font size='5' style=\"color:orange\">  <b> GaussianNB x 6</b> </font>\n",
    "<a name=\"ensemble_3\"></a>\n",
    "\n",
    "[[ Back to Top ]](#content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "00a03748",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T18:34:54.446383Z",
     "start_time": "2022-11-26T18:34:54.437291Z"
    }
   },
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb2 = GaussianNB()\n",
    "gnb3 = GaussianNB()\n",
    "gnb4 = GaussianNB()\n",
    "gnb5 = GaussianNB()\n",
    "gnb6 = GaussianNB()\n",
    "gnb_final = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ce15aad3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T18:34:56.477020Z",
     "start_time": "2022-11-26T18:34:56.468862Z"
    }
   },
   "outputs": [],
   "source": [
    "ensemble_3 =  StackingClassifier (estimators = [ ('gnb',gnb), ('gnb2',gnb2), ('gnb3',gnb3), \n",
    "                                                 ('gnb4',gnb4), ('gnb5',gnb5), ('gnb6',gnb6)], final_estimator = gnb_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "251a5219",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T18:39:33.263381Z",
     "start_time": "2022-11-26T18:34:57.008589Z"
    }
   },
   "outputs": [],
   "source": [
    "e3_results    = []\n",
    "e3_results_cm = []\n",
    "tiempo_ejecucion = []\n",
    "inicio = time.time()\n",
    "\n",
    "for train_index, test_index in skf.split(X,y):\n",
    "    \n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    ensemble_3.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = ensemble_3.predict(X_test)\n",
    "    \n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall    = recall_score(y_test, y_pred)\n",
    "    f1        = f1_score(y_test, y_pred)\n",
    "    cm        = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    list_results   = [precision, recall, f1]\n",
    "    list_cm = [cm]\n",
    "    e3_results.append(list_results)\n",
    "    e3_results_cm.append(list_cm)\n",
    "    \n",
    "fin = time.time()\n",
    "tiempo_ejecucion.append(fin - inicio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "41f72cce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T18:39:33.278489Z",
     "start_time": "2022-11-26T18:39:33.264387Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRECISION</th>\n",
       "      <th>RECALL</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ensemble GaussianNB x 6 + Final GaussianNB</th>\n",
       "      <td>0.51998</td>\n",
       "      <td>0.58331</td>\n",
       "      <td>0.549795</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            PRECISION   RECALL        F1\n",
       "Ensemble GaussianNB x 6 + Final GaussianNB    0.51998  0.58331  0.549795"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filas    = ['Ensemble GaussianNB x 6 + Final GaussianNB']\n",
    "columnas = [\"PRECISION\", \"RECALL\", \"F1\"]\n",
    "resultados = pd.DataFrame([gmean(e3_results)], columns=columnas, index=filas)\n",
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c886d501",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T18:39:33.310095Z",
     "start_time": "2022-11-26T18:39:33.280095Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRECISION</th>\n",
       "      <th>RECALL</th>\n",
       "      <th>F1</th>\n",
       "      <th>TIEMPO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ensemble GaussianNB x 6 + Final GaussianNB</th>\n",
       "      <td>0.51998</td>\n",
       "      <td>0.58331</td>\n",
       "      <td>0.549795</td>\n",
       "      <td>276.241724</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            PRECISION   RECALL        F1  \\\n",
       "Ensemble GaussianNB x 6 + Final GaussianNB    0.51998  0.58331  0.549795   \n",
       "\n",
       "                                                TIEMPO  \n",
       "Ensemble GaussianNB x 6 + Final GaussianNB  276.241724  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados['TIEMPO']= tiempo_ejecucion\n",
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4baae16c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T18:39:33.326094Z",
     "start_time": "2022-11-26T18:39:33.312095Z"
    }
   },
   "outputs": [],
   "source": [
    "resultados.to_pickle(\"resultados_e3.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1e28fe5b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T18:39:33.342094Z",
     "start_time": "2022-11-26T18:39:33.327094Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[16907.54416649,  1081.7287435 ],\n",
       "        [  837.06552723,  1172.33607711]]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados_cm= gmean(e3_results_cm)\n",
    "resultados_cm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f8d52adc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T18:39:33.358169Z",
     "start_time": "2022-11-26T18:39:33.343094Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('resultados_e3_cm.pkl','wb') as f:\n",
    "    pickle.dump(resultados_cm, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84185c5",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84d836d",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5baff041",
   "metadata": {},
   "source": [
    "<font size='5' style=\"color:orange\">  <b> GaussianNB x 12</b> </font>\n",
    "<a name=\"ensemble_4\"></a>\n",
    "\n",
    "[[ Back to Top ]](#content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6cd57281",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T18:39:33.374135Z",
     "start_time": "2022-11-26T18:39:33.359095Z"
    }
   },
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb2 = GaussianNB()\n",
    "gnb3 = GaussianNB()\n",
    "gnb4 = GaussianNB()\n",
    "gnb5 = GaussianNB()\n",
    "gnb6 = GaussianNB()\n",
    "gnb7 = GaussianNB()\n",
    "gnb8 = GaussianNB()\n",
    "gnb9 = GaussianNB()\n",
    "gnb10 = GaussianNB()\n",
    "gnb11 = GaussianNB()\n",
    "gnb12 = GaussianNB()\n",
    "gnb_final = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d311f703",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T18:39:33.389095Z",
     "start_time": "2022-11-26T18:39:33.375094Z"
    }
   },
   "outputs": [],
   "source": [
    "ensemble_4 =  StackingClassifier (estimators = [ ('gnb',gnb), ('gnb2',gnb2), ('gnb3',gnb3), \n",
    "                                                 ('gnb4',gnb4), ('gnb5',gnb5), ('gnb6',gnb6),\n",
    "                                                 ('gnb7',gnb7), ('gnb8',gnb8), ('gnb9',gnb9), \n",
    "                                                 ('gnb10',gnb10), ('gnb11',gnb11), ('gnb12',gnb12)],\n",
    "                                                 final_estimator = gnb_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "405ed646",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T18:48:27.906658Z",
     "start_time": "2022-11-26T18:39:33.391096Z"
    }
   },
   "outputs": [],
   "source": [
    "e4_results    = []\n",
    "e4_results_cm = []\n",
    "tiempo_ejecucion = []\n",
    "inicio = time.time()\n",
    "\n",
    "for train_index, test_index in skf.split(X,y):\n",
    "    \n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    ensemble_4.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = ensemble_4.predict(X_test)\n",
    "    \n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall    = recall_score(y_test, y_pred)\n",
    "    f1        = f1_score(y_test, y_pred)\n",
    "    cm        = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    list_results   = [precision, recall, f1]\n",
    "    list_cm = [cm]\n",
    "    e4_results.append(list_results)\n",
    "    e4_results_cm.append(list_cm)\n",
    "    \n",
    "fin = time.time()\n",
    "tiempo_ejecucion.append(fin - inicio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1ad2a2a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T18:48:27.922355Z",
     "start_time": "2022-11-26T18:48:27.908433Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRECISION</th>\n",
       "      <th>RECALL</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ensemble GaussianNB x 12 + Final GaussianNB</th>\n",
       "      <td>0.508631</td>\n",
       "      <td>0.596489</td>\n",
       "      <td>0.549036</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             PRECISION    RECALL        F1\n",
       "Ensemble GaussianNB x 12 + Final GaussianNB   0.508631  0.596489  0.549036"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filas    = ['Ensemble GaussianNB x 12 + Final GaussianNB']\n",
    "columnas = [\"PRECISION\", \"RECALL\", \"F1\"]\n",
    "resultados = pd.DataFrame([gmean(e4_results)], columns=columnas, index=filas)\n",
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "632b5234",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T18:48:27.953354Z",
     "start_time": "2022-11-26T18:48:27.924355Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRECISION</th>\n",
       "      <th>RECALL</th>\n",
       "      <th>F1</th>\n",
       "      <th>TIEMPO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ensemble GaussianNB x 12 + Final GaussianNB</th>\n",
       "      <td>0.508631</td>\n",
       "      <td>0.596489</td>\n",
       "      <td>0.549036</td>\n",
       "      <td>534.493685</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             PRECISION    RECALL        F1  \\\n",
       "Ensemble GaussianNB x 12 + Final GaussianNB   0.508631  0.596489  0.549036   \n",
       "\n",
       "                                                 TIEMPO  \n",
       "Ensemble GaussianNB x 12 + Final GaussianNB  534.493685  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados['TIEMPO']= tiempo_ejecucion\n",
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e0686d8f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T18:48:27.969355Z",
     "start_time": "2022-11-26T18:48:27.955355Z"
    }
   },
   "outputs": [],
   "source": [
    "resultados.to_pickle(\"resultados_e4.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "874f142e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T18:48:27.985427Z",
     "start_time": "2022-11-26T18:48:27.972356Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[16831.63950851,  1157.6188637 ],\n",
       "        [  810.52995485,  1198.82268297]]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados_cm= gmean(e4_results_cm)\n",
    "resultados_cm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "39b13029",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T18:48:28.001354Z",
     "start_time": "2022-11-26T18:48:27.986365Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('resultados_e4_cm.pkl','wb') as f:\n",
    "    pickle.dump(resultados_cm, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7f2830",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd6378f",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009890b7",
   "metadata": {},
   "source": [
    "<font size='5' style=\"color:orange\">  <b> GaussianNB x 24 </b> </font>\n",
    "<a name=\"ensemble_5\"></a>\n",
    "\n",
    "[[ Back to Top ]](#content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "551a67f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T18:48:28.016355Z",
     "start_time": "2022-11-26T18:48:28.002355Z"
    }
   },
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb2 = GaussianNB()\n",
    "gnb3 = GaussianNB()\n",
    "gnb4 = GaussianNB()\n",
    "gnb5 = GaussianNB()\n",
    "gnb6 = GaussianNB()\n",
    "gnb7 = GaussianNB()\n",
    "gnb8 = GaussianNB()\n",
    "gnb9 = GaussianNB()\n",
    "gnb10 = GaussianNB()\n",
    "gnb11 = GaussianNB()\n",
    "gnb12 = GaussianNB()\n",
    "gnb13 = GaussianNB()\n",
    "gnb14 = GaussianNB()\n",
    "gnb15 = GaussianNB()\n",
    "gnb16 = GaussianNB()\n",
    "gnb17 = GaussianNB()\n",
    "gnb18 = GaussianNB()\n",
    "gnb19 = GaussianNB()\n",
    "gnb20 = GaussianNB()\n",
    "gnb21 = GaussianNB()\n",
    "gnb22 = GaussianNB()\n",
    "gnb23 = GaussianNB()\n",
    "gnb24 = GaussianNB()\n",
    "gnb_final = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "71291a5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T18:48:28.032354Z",
     "start_time": "2022-11-26T18:48:28.017393Z"
    }
   },
   "outputs": [],
   "source": [
    "ensemble_5 =  StackingClassifier (estimators = [ ('gnb',gnb), ('gnb2',gnb2), ('gnb3',gnb3), ('gnb4',gnb4), ('gnb5',gnb5), \n",
    "                                                ('gnb6',gnb6),('gnb7',gnb7), ('gnb8',gnb8), ('gnb9',gnb9), ('gnb10',gnb10), \n",
    "                                                ('gnb11',gnb11), ('gnb12',gnb12),('gnb13',gnb13),('gnb14',gnb14), \n",
    "                                                ('gnb15',gnb15), ('gnb16',gnb16),('gnb17',gnb17), ('gnb18',gnb18), \n",
    "                                                ('gnb19',gnb19), ('gnb20',gnb20), ('gnb21',gnb21), ('gnb22',gnb22),\n",
    "                                                ('gnb23',gnb23), ('gnb24',gnb24)], final_estimator = gnb_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5ae70707",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T19:05:21.563069Z",
     "start_time": "2022-11-26T18:48:28.033355Z"
    }
   },
   "outputs": [],
   "source": [
    "e5_results    = []\n",
    "e5_results_cm = []\n",
    "tiempo_ejecucion = []\n",
    "inicio = time.time()\n",
    "\n",
    "for train_index, test_index in skf.split(X,y):\n",
    "    \n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    ensemble_5.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = ensemble_5.predict(X_test)\n",
    "    \n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall    = recall_score(y_test, y_pred)\n",
    "    f1        = f1_score(y_test, y_pred)\n",
    "    cm        = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    list_results   = [precision, recall, f1]\n",
    "    list_cm = [cm]\n",
    "    e5_results.append(list_results)\n",
    "    e5_results_cm.append(list_cm)\n",
    "    \n",
    "fin = time.time()\n",
    "tiempo_ejecucion.append(fin - inicio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a1fa29c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T19:05:21.578762Z",
     "start_time": "2022-11-26T19:05:21.563759Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRECISION</th>\n",
       "      <th>RECALL</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ensemble GaussianNB x 24 + Final GaussianNB</th>\n",
       "      <td>0.502216</td>\n",
       "      <td>0.60296</td>\n",
       "      <td>0.547965</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             PRECISION   RECALL        F1\n",
       "Ensemble GaussianNB x 24 + Final GaussianNB   0.502216  0.60296  0.547965"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filas    = ['Ensemble GaussianNB x 24 + Final GaussianNB']\n",
    "columnas = [\"PRECISION\", \"RECALL\", \"F1\"]\n",
    "resultados = pd.DataFrame([gmean(e5_results)], columns=columnas, index=filas)\n",
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6318fd71",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T19:05:21.593763Z",
     "start_time": "2022-11-26T19:05:21.579763Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRECISION</th>\n",
       "      <th>RECALL</th>\n",
       "      <th>F1</th>\n",
       "      <th>TIEMPO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ensemble GaussianNB x 24 + Final GaussianNB</th>\n",
       "      <td>0.502216</td>\n",
       "      <td>0.60296</td>\n",
       "      <td>0.547965</td>\n",
       "      <td>1013.523686</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             PRECISION   RECALL        F1  \\\n",
       "Ensemble GaussianNB x 24 + Final GaussianNB   0.502216  0.60296  0.547965   \n",
       "\n",
       "                                                  TIEMPO  \n",
       "Ensemble GaussianNB x 24 + Final GaussianNB  1013.523686  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados['TIEMPO']= tiempo_ejecucion\n",
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "314710e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T19:05:21.609807Z",
     "start_time": "2022-11-26T19:05:21.595761Z"
    }
   },
   "outputs": [],
   "source": [
    "resultados.to_pickle(\"resultados_e5.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3ede7a3a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T19:05:21.625763Z",
     "start_time": "2022-11-26T19:05:21.611761Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[16788.63481105,  1200.59103611],\n",
       "        [  797.53005772,  1211.82804684]]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados_cm = gmean(e5_results_cm)\n",
    "resultados_cm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e15678a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T19:05:21.641838Z",
     "start_time": "2022-11-26T19:05:21.626762Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('resultados_e5_cm.pkl','wb') as f:\n",
    "    pickle.dump(resultados_cm, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfc4ccf",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6053e257",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a269b320",
   "metadata": {},
   "source": [
    "<font size='5' style=\"color:orange\">  <b> GaussianNB + Logistic Regression (Final GaussianNB)</b> </font>\n",
    "<a name=\"ensemble_6\"></a>\n",
    "\n",
    "[[ Back to Top ]](#content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8c52972d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T19:05:21.657762Z",
     "start_time": "2022-11-26T19:05:21.642761Z"
    }
   },
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "lgr = LogisticRegression(max_iter = 7000)\n",
    "gnb_final = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "670f68a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T19:05:21.673762Z",
     "start_time": "2022-11-26T19:05:21.658761Z"
    }
   },
   "outputs": [],
   "source": [
    "ensemble_6 =  StackingClassifier (estimators = [ ('gnb',gnb), ('lgr',lgr)], final_estimator = gnb_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "64339459",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T20:26:00.681498Z",
     "start_time": "2022-11-26T19:05:21.675761Z"
    }
   },
   "outputs": [],
   "source": [
    "e6_results    = []\n",
    "e6_results_cm = []\n",
    "tiempo_ejecucion = []\n",
    "inicio = time.time()\n",
    "\n",
    "for train_index, test_index in skf.split(X,y):\n",
    "    \n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    ensemble_6.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = ensemble_6.predict(X_test)\n",
    "    \n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall    = recall_score(y_test, y_pred)\n",
    "    f1        = f1_score(y_test, y_pred)\n",
    "    cm        = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    list_results   = [precision, recall, f1]\n",
    "    list_cm = [cm]\n",
    "    e6_results.append(list_results)\n",
    "    e6_results_cm.append(list_cm)\n",
    "    \n",
    "fin = time.time()\n",
    "tiempo_ejecucion.append(fin - inicio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "44f90798",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T20:26:00.697493Z",
     "start_time": "2022-11-26T20:26:00.682493Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRECISION</th>\n",
       "      <th>RECALL</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ensemble GaussianNB + Logistic Regression + Final GaussianNB</th>\n",
       "      <td>0.541653</td>\n",
       "      <td>0.530205</td>\n",
       "      <td>0.535842</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    PRECISION    RECALL  \\\n",
       "Ensemble GaussianNB + Logistic Regression + Fin...   0.541653  0.530205   \n",
       "\n",
       "                                                          F1  \n",
       "Ensemble GaussianNB + Logistic Regression + Fin...  0.535842  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filas    = ['Ensemble GaussianNB + Logistic Regression + Final GaussianNB']\n",
    "columnas = [\"PRECISION\", \"RECALL\", \"F1\"]\n",
    "resultados = pd.DataFrame([gmean(e6_results)], columns=columnas, index=filas)\n",
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3b26722e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T20:26:00.713493Z",
     "start_time": "2022-11-26T20:26:00.698493Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRECISION</th>\n",
       "      <th>RECALL</th>\n",
       "      <th>F1</th>\n",
       "      <th>TIEMPO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ensemble GaussianNB + Logistic Regression + Final GaussianNB</th>\n",
       "      <td>0.541653</td>\n",
       "      <td>0.530205</td>\n",
       "      <td>0.535842</td>\n",
       "      <td>4838.985724</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    PRECISION    RECALL  \\\n",
       "Ensemble GaussianNB + Logistic Regression + Fin...   0.541653  0.530205   \n",
       "\n",
       "                                                          F1       TIEMPO  \n",
       "Ensemble GaussianNB + Logistic Regression + Fin...  0.535842  4838.985724  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados['TIEMPO']= tiempo_ejecucion\n",
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9362ea00",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T20:26:00.729493Z",
     "start_time": "2022-11-26T20:26:00.716493Z"
    }
   },
   "outputs": [],
   "source": [
    "resultados.to_pickle(\"resultados_e6.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ff742469",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T20:26:00.745493Z",
     "start_time": "2022-11-26T20:26:00.731493Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[17088.26123245,   901.16013791],\n",
       "        [  943.77230563,  1065.60619108]]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados_cm = gmean(e6_results_cm)\n",
    "resultados_cm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d4c299b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T20:26:00.761498Z",
     "start_time": "2022-11-26T20:26:00.747493Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('resultados_e6_cm.pkl','wb') as f:\n",
    "    pickle.dump(resultados_cm, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ab4273",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94008ec7",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace44281",
   "metadata": {},
   "source": [
    "<font size='5' style=\"color:orange\">  <b> Logistic Regression + GaussianNB (Final Logistic Regression) </b> </font>\n",
    "<a name=\"ensemble_7\"></a>\n",
    "\n",
    "[[ Back to Top ]](#content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7b03671b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T20:26:00.777492Z",
     "start_time": "2022-11-26T20:26:00.762493Z"
    }
   },
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "lgr = LogisticRegression(max_iter = 7000)\n",
    "lgr_final = LogisticRegression(max_iter = 7000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d5278f13",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T20:26:00.792493Z",
     "start_time": "2022-11-26T20:26:00.779492Z"
    }
   },
   "outputs": [],
   "source": [
    "ensemble_7 =  StackingClassifier (estimators = [ ('gnb',gnb), ('lgr',lgr)], final_estimator = lgr_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b93bebd5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T21:46:05.255583Z",
     "start_time": "2022-11-26T20:26:00.793493Z"
    }
   },
   "outputs": [],
   "source": [
    "e7_results    = []\n",
    "e7_results_cm = []\n",
    "tiempo_ejecucion = []\n",
    "inicio = time.time()\n",
    "\n",
    "for train_index, test_index in skf.split(X,y):\n",
    "    \n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    ensemble_7.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = ensemble_7.predict(X_test)\n",
    "    \n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall    = recall_score(y_test, y_pred)\n",
    "    f1        = f1_score(y_test, y_pred)\n",
    "    cm        = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    list_results   = [precision, recall, f1]\n",
    "    list_cm = [cm]\n",
    "    e7_results.append(list_results)\n",
    "    e7_results_cm.append(list_cm)\n",
    "    \n",
    "fin = time.time()\n",
    "tiempo_ejecucion.append(fin - inicio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4641cfa0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T21:46:05.271582Z",
     "start_time": "2022-11-26T21:46:05.256583Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRECISION</th>\n",
       "      <th>RECALL</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ensemble GaussianNB + Logistic Regression + Final GaussianNB</th>\n",
       "      <td>0.704308</td>\n",
       "      <td>0.374719</td>\n",
       "      <td>0.489145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    PRECISION    RECALL  \\\n",
       "Ensemble GaussianNB + Logistic Regression + Fin...   0.704308  0.374719   \n",
       "\n",
       "                                                          F1  \n",
       "Ensemble GaussianNB + Logistic Regression + Fin...  0.489145  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filas    = ['Ensemble GaussianNB + Logistic Regression + Final GaussianNB']\n",
    "columnas = [\"PRECISION\", \"RECALL\", \"F1\"]\n",
    "resultados = pd.DataFrame([gmean(e7_results)], columns=columnas, index=filas)\n",
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "496db5d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T21:46:05.286584Z",
     "start_time": "2022-11-26T21:46:05.273583Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRECISION</th>\n",
       "      <th>RECALL</th>\n",
       "      <th>F1</th>\n",
       "      <th>TIEMPO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ensemble GaussianNB + Logistic Regression + Final GaussianNB</th>\n",
       "      <td>0.704308</td>\n",
       "      <td>0.374719</td>\n",
       "      <td>0.489145</td>\n",
       "      <td>4804.446089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    PRECISION    RECALL  \\\n",
       "Ensemble GaussianNB + Logistic Regression + Fin...   0.704308  0.374719   \n",
       "\n",
       "                                                          F1       TIEMPO  \n",
       "Ensemble GaussianNB + Logistic Regression + Fin...  0.489145  4804.446089  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados['TIEMPO']= tiempo_ejecucion\n",
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "135e345a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T21:46:05.302582Z",
     "start_time": "2022-11-26T21:46:05.288583Z"
    }
   },
   "outputs": [],
   "source": [
    "resultados.to_pickle(\"resultados_e7.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "02513757",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T22:23:22.141278Z",
     "start_time": "2022-11-26T22:23:22.123795Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRECISION</th>\n",
       "      <th>RECALL</th>\n",
       "      <th>F1</th>\n",
       "      <th>TIEMPO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ensemble GaussianNB + Logistic Regression + Final Logistic Regression</th>\n",
       "      <td>0.704308</td>\n",
       "      <td>0.374719</td>\n",
       "      <td>0.489145</td>\n",
       "      <td>4804.446089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    PRECISION    RECALL  \\\n",
       "Ensemble GaussianNB + Logistic Regression + Fin...   0.704308  0.374719   \n",
       "\n",
       "                                                          F1       TIEMPO  \n",
       "Ensemble GaussianNB + Logistic Regression + Fin...  0.489145  4804.446089  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Renombro el índice ya que por error le había asignado otro nombre\n",
    "resultados_cb_full = pd.read_pickle('resultados_e7.pkl')\n",
    "resultados_cb_full.index= ['Ensemble GaussianNB + Logistic Regression + Final Logistic Regression']\n",
    "resultados_cb_full.to_pickle(\"resultados_e7.pkl\")\n",
    "resultados_cb_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8e39e5a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T21:46:05.318583Z",
     "start_time": "2022-11-26T21:46:05.303583Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[17673.88954425,   315.69858819],\n",
       "        [ 1256.38503915,   753.11083107]]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados_cm= gmean(e7_results_cm)\n",
    "resultados_cm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1561840f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T21:46:05.334582Z",
     "start_time": "2022-11-26T21:46:05.320584Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('resultados_e7_cm.pkl','wb') as f:\n",
    "    pickle.dump(resultados_cm, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99dc3762",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf53b01a",
   "metadata": {},
   "source": [
    "Para ver cuál de los dos modelos convenía utilizarse como final estimator, se realizaron dos ensambles diferentes. Por un lado uno con los modelos Logistic Regression + GaussianNB con Logistic Regression como final estimator y por el otro un ensamble con los modelos Logistic Regression + GaussianNB con GaussianNB como final estimator. Se puede observar que este útilmo obtuvo un mejor resultado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b320fd",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc33094b",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa0822f",
   "metadata": {},
   "source": [
    "<font size='5' style=\"color:orange\">  <b> Logistic Regression + Catboost Classifier (Final Catboost Classifier) </b> </font>\n",
    "<a name=\"ensemble_8\"></a>\n",
    "\n",
    "[[ Back to Top ]](#content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "8d55faf8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-15T22:20:28.804543Z",
     "start_time": "2022-11-15T22:20:28.788491Z"
    }
   },
   "outputs": [],
   "source": [
    "lgr = LogisticRegression(max_iter = 7000)\n",
    "cb = CatBoostClassifier()\n",
    "cb_final = CatBoostClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "f5cbd7e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-15T22:20:29.489282Z",
     "start_time": "2022-11-15T22:20:29.448880Z"
    }
   },
   "outputs": [],
   "source": [
    "ensemble_8 =  StackingClassifier (estimators = [ ('lgr',lgr), ('cb',cb)], final_estimator = cb_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fc8313",
   "metadata": {},
   "outputs": [],
   "source": [
    "e8_results    = []\n",
    "e8_results_cm = []\n",
    "tiempo_ejecucion = []\n",
    "inicio = time.time()\n",
    "\n",
    "for train_index, test_index in skf.split(X,y):\n",
    "    \n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    ensemble_8.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = ensemble_8.predict(X_test)\n",
    "    \n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall    = recall_score(y_test, y_pred)\n",
    "    f1        = f1_score(y_test, y_pred)\n",
    "    cm        = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    list_results   = [precision, recall, f1]\n",
    "    list_cm = [cm]\n",
    "    e8_results.append(list_results)\n",
    "    e8_results_cm.append(list_cm)\n",
    "    \n",
    "fin = time.time()\n",
    "tiempo_ejecucion.append(fin - inicio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "317a8199",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-15T19:52:15.950082Z",
     "start_time": "2022-11-15T19:52:15.935431Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRECISION</th>\n",
       "      <th>RECALL</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ensemble Lgr + Catboost (Final Catboost)</th>\n",
       "      <td>0.714156</td>\n",
       "      <td>0.392728</td>\n",
       "      <td>0.506712</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          PRECISION    RECALL        F1\n",
       "Ensemble Lgr + Catboost (Final Catboost)   0.714156  0.392728  0.506712"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filas    = ['Ensemble Lgr + Catboost (Final Catboost)']\n",
    "columnas = [\"PRECISION\", \"RECALL\", \"F1\"]\n",
    "resultados = pd.DataFrame([gmean(e8_results)], columns=columnas, index=filas)\n",
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "e3dae951",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-15T19:52:15.966080Z",
     "start_time": "2022-11-15T19:52:15.952080Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRECISION</th>\n",
       "      <th>RECALL</th>\n",
       "      <th>F1</th>\n",
       "      <th>TIEMPO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ensemble Lgr + Catboost (Final Catboost)</th>\n",
       "      <td>0.714156</td>\n",
       "      <td>0.392728</td>\n",
       "      <td>0.506712</td>\n",
       "      <td>11731.662214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          PRECISION    RECALL        F1  \\\n",
       "Ensemble Lgr + Catboost (Final Catboost)   0.714156  0.392728  0.506712   \n",
       "\n",
       "                                                TIEMPO  \n",
       "Ensemble Lgr + Catboost (Final Catboost)  11731.662214  "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados['TIEMPO']= tiempo_ejecucion\n",
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "4f55571c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-15T19:52:15.982080Z",
     "start_time": "2022-11-15T19:52:15.968080Z"
    }
   },
   "outputs": [],
   "source": [
    "resultados.to_pickle(\"resultados_e8.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "abcf65e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-15T19:52:15.998081Z",
     "start_time": "2022-11-15T19:52:15.983080Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[17673.98790785,   315.53104694],\n",
       "        [ 1220.00911767,   789.30386391]]])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados_cm= gmean(e8_results_cm)\n",
    "resultados_cm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "cba328ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-15T19:52:16.014079Z",
     "start_time": "2022-11-15T19:52:15.999080Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('resultados_e8_cm.pkl','wb') as f:\n",
    "    pickle.dump(resultados_cm, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c06cd9",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ac2861",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76cae04",
   "metadata": {},
   "source": [
    "<font size='5' style=\"color:orange\">  <b> Logistic Regression + Catboost Classifier + GaussianNB (Final GaussianNb)</b> </font>\n",
    "<a name=\"ensemble_9\"></a>\n",
    "\n",
    "[[ Back to Top ]](#content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "3dfea0ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-15T22:22:08.466958Z",
     "start_time": "2022-11-15T22:22:08.450943Z"
    }
   },
   "outputs": [],
   "source": [
    "lgr = LogisticRegression(max_iter = 7000)\n",
    "cb = CatBoostClassifier() \n",
    "gnb = GaussianNB()\n",
    "gnb_final = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "d0449230",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-15T22:23:14.310222Z",
     "start_time": "2022-11-15T22:23:14.293222Z"
    }
   },
   "outputs": [],
   "source": [
    "ensemble_9 =  StackingClassifier (estimators = [ ('lgr',lgr), ('cb',cb), ('gnb',gnb)], final_estimator = gnb_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e90ff6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cabe aclarar que corrí esta celda pero Catboost Cassifier arroja mucha información sobre su learning rate mientras se \n",
    "# procesa que hacían que la notebook fuese más pesada. Es por ello que corte el contenido de la celda que había corrido, \n",
    "# pero sin mostrar los resultados parciales del learning rate que va arrojando Catboost Classifier.\n",
    "\n",
    "e9_results    = []\n",
    "e9_results_cm = []\n",
    "tiempo_ejecucion = []\n",
    "inicio = time.time()\n",
    "\n",
    "for train_index, test_index in skf.split(X,y):\n",
    "    \n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    ensemble_9.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = ensemble_9.predict(X_test)\n",
    "    \n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall    = recall_score(y_test, y_pred)\n",
    "    f1        = f1_score(y_test, y_pred)\n",
    "    cm        = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    list_results   = [precision, recall, f1]\n",
    "    list_cm = [cm]\n",
    "    e9_results.append(list_results)\n",
    "    e9_results_cm.append(list_cm)\n",
    "    \n",
    "fin = time.time()\n",
    "tiempo_ejecucion.append(fin - inicio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "e948faa6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-16T00:46:40.880067Z",
     "start_time": "2022-11-16T00:46:40.867352Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRECISION</th>\n",
       "      <th>RECALL</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ensemble Lgr + Catboost + GaussianNB (Final GaussianNB)</th>\n",
       "      <td>0.497075</td>\n",
       "      <td>0.61293</td>\n",
       "      <td>0.548931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    PRECISION   RECALL  \\\n",
       "Ensemble Lgr + Catboost + GaussianNB (Final Gau...   0.497075  0.61293   \n",
       "\n",
       "                                                          F1  \n",
       "Ensemble Lgr + Catboost + GaussianNB (Final Gau...  0.548931  "
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filas    = ['Ensemble Lgr + Catboost + GaussianNB (Final GaussianNB)']\n",
    "columnas = [\"PRECISION\", \"RECALL\", \"F1\"]\n",
    "resultados = pd.DataFrame([gmean(e9_results)], columns=columnas, index=filas)\n",
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "fadefd22",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-16T00:46:40.909851Z",
     "start_time": "2022-11-16T00:46:40.881068Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRECISION</th>\n",
       "      <th>RECALL</th>\n",
       "      <th>F1</th>\n",
       "      <th>TIEMPO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ensemble Lgr + Catboost + GaussianNB (Final GaussianNB)</th>\n",
       "      <td>0.497075</td>\n",
       "      <td>0.61293</td>\n",
       "      <td>0.548931</td>\n",
       "      <td>8581.06651</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    PRECISION   RECALL  \\\n",
       "Ensemble Lgr + Catboost + GaussianNB (Final Gau...   0.497075  0.61293   \n",
       "\n",
       "                                                          F1      TIEMPO  \n",
       "Ensemble Lgr + Catboost + GaussianNB (Final Gau...  0.548931  8581.06651  "
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados['TIEMPO']= tiempo_ejecucion\n",
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "9d18a927",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-20T16:36:59.187897Z",
     "start_time": "2022-11-20T16:36:59.165101Z"
    }
   },
   "outputs": [],
   "source": [
    "resultados.to_pickle(\"resultados_e9.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "6cdbdf33",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-16T00:46:40.940070Z",
     "start_time": "2022-11-16T00:46:40.925537Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[16743.55451381,  1245.98601968],\n",
       "        [  777.31861252,  1231.86699111]]])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados_cm= gmean(e9_results_cm)\n",
    "resultados_cm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "36b63bcd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-16T00:46:40.956080Z",
     "start_time": "2022-11-16T00:46:40.941070Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('resultados_e9_cm.pkl','wb') as f:\n",
    "    pickle.dump(resultados_cm, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26aa4086",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1dbe490",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec1c7f9",
   "metadata": {},
   "source": [
    "<font size='5' style=\"color:orange\">  <b> Logistic Regression + Catboost Classifier + GaussianNB + K Neighbors Classifier</b> </font>\n",
    "<a name=\"ensemble_10\"></a>\n",
    "\n",
    "[[ Back to Top ]](#content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "551c1c3a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-19T21:12:30.641496Z",
     "start_time": "2022-11-19T21:12:30.572106Z"
    }
   },
   "outputs": [],
   "source": [
    "lgr = LogisticRegression(max_iter = 7000)\n",
    "cb = CatBoostClassifier(iterations = 3600, depth = 4, learning_rate = 0.85) # hiperparámetros obtenidos de la notebook de Santiago\n",
    "gnb = GaussianNB()\n",
    "knc = KNeighborsClassifier(n_neighbors = 2, weights = 'distance', metric = 'minkowski')\n",
    "gnb_final = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "1ad1e1e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-19T21:12:39.110011Z",
     "start_time": "2022-11-19T21:12:39.080554Z"
    }
   },
   "outputs": [],
   "source": [
    "ensemble_10 =  StackingClassifier (estimators = [ ('lgr',lgr), ('cb',cb), ('gnb',gnb), ('knc', knc)], final_estimator = gnb_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd5a64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cabe aclarar que corrí esta celda pero Catboost Cassifier arroja mucha información sobre su learning rate mientras se \n",
    "# procesa que hacían que la notebook fuese más pesada. Es por ello que corte el contenido de la celda que había corrido, \n",
    "# pero sin mostrar los resultados parciales del learning rate que va arrojando Catboost Classifier.\n",
    "\n",
    "e10_results    = []\n",
    "e10_results_cm = []\n",
    "tiempo_ejecucion = []\n",
    "inicio = time.time()\n",
    "\n",
    "for train_index, test_index in skf.split(X,y):\n",
    "    \n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    ensemble_10.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = ensemble_10.predict(X_test)\n",
    "    \n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall    = recall_score(y_test, y_pred)\n",
    "    f1        = f1_score(y_test, y_pred)\n",
    "    cm        = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    list_results   = [precision, recall, f1]\n",
    "    list_cm = [cm]\n",
    "    e10_results.append(list_results)\n",
    "    e10_results_cm.append(list_cm)\n",
    "    \n",
    "fin = time.time()\n",
    "tiempo_ejecucion.append(fin - inicio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "991ad79f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-20T02:22:56.395386Z",
     "start_time": "2022-11-20T02:22:56.357311Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRECISION</th>\n",
       "      <th>RECALL</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ensemble Opt Lgr + Catboost + GaussianNB + KNC (Final GaussianNB)</th>\n",
       "      <td>0.477716</td>\n",
       "      <td>0.608762</td>\n",
       "      <td>0.535311</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    PRECISION    RECALL  \\\n",
       "Ensemble Opt Lgr + Catboost + GaussianNB + KNC ...   0.477716  0.608762   \n",
       "\n",
       "                                                          F1  \n",
       "Ensemble Opt Lgr + Catboost + GaussianNB + KNC ...  0.535311  "
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filas    = ['Ensemble Opt Lgr + Catboost + GaussianNB + KNC (Final GaussianNB)']\n",
    "columnas = [\"PRECISION\", \"RECALL\", \"F1\"]\n",
    "resultados = pd.DataFrame([gmean(e10_results)], columns=columnas, index=filas)\n",
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "5e9477c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-20T02:22:56.443308Z",
     "start_time": "2022-11-20T02:22:56.397308Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRECISION</th>\n",
       "      <th>RECALL</th>\n",
       "      <th>F1</th>\n",
       "      <th>TIEMPO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ensemble Opt Lgr + Catboost + GaussianNB + KNC (Final GaussianNB)</th>\n",
       "      <td>0.477716</td>\n",
       "      <td>0.608762</td>\n",
       "      <td>0.535311</td>\n",
       "      <td>18614.442411</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    PRECISION    RECALL  \\\n",
       "Ensemble Opt Lgr + Catboost + GaussianNB + KNC ...   0.477716  0.608762   \n",
       "\n",
       "                                                          F1        TIEMPO  \n",
       "Ensemble Opt Lgr + Catboost + GaussianNB + KNC ...  0.535311  18614.442411  "
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados['TIEMPO']= tiempo_ejecucion\n",
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "3e03e1aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-20T02:22:56.459308Z",
     "start_time": "2022-11-20T02:22:56.446310Z"
    }
   },
   "outputs": [],
   "source": [
    "resultados.to_pickle(\"resultados_e10.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "d6eb62f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-20T02:22:56.475309Z",
     "start_time": "2022-11-20T02:22:56.461308Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[16652.24647945,  1337.23284894],\n",
       "        [  785.75559881,  1223.49053091]]])"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados_cm= gmean(e10_results_cm)\n",
    "resultados_cm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "8450cc83",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-20T02:22:56.491309Z",
     "start_time": "2022-11-20T02:22:56.477329Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('resultados_e10_cm.pkl','wb') as f:\n",
    "    pickle.dump(resultados_cm, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5078466",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c9d231",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1a530d",
   "metadata": {},
   "source": [
    "<font size='5' style=\"color:orange\">  <b>GaussianNB + Logistic Regression + Calibrated Classifier CV (Final GaussianNB)</b> </font>\n",
    "<a name=\"ensemble_11\"></a>\n",
    "\n",
    "[[ Back to Top ]](#content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "c2d39b75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-21T01:32:38.205998Z",
     "start_time": "2022-11-21T01:32:38.174925Z"
    }
   },
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "lgr = LogisticRegression(max_iter = 7000)\n",
    "cccv = CalibratedClassifierCV(base_estimator = GaussianNB(), cv=3)\n",
    "gnb_final = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "51c45299",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-21T01:32:39.003279Z",
     "start_time": "2022-11-21T01:32:38.970766Z"
    }
   },
   "outputs": [],
   "source": [
    "ensemble_11 =  StackingClassifier (estimators = [ ('gnb',gnb), ('lgr',lgr), ('cccv',cccv)], final_estimator = gnb_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "id": "569bae33",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-21T02:53:31.297459Z",
     "start_time": "2022-11-21T01:32:39.724126Z"
    }
   },
   "outputs": [],
   "source": [
    "e11_results    = []\n",
    "e11_results_cm = []\n",
    "tiempo_ejecucion = []\n",
    "inicio = time.time()\n",
    "\n",
    "for train_index, test_index in skf.split(X,y):\n",
    "    \n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    ensemble_11.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = ensemble_11.predict(X_test)\n",
    "    \n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall    = recall_score(y_test, y_pred)\n",
    "    f1        = f1_score(y_test, y_pred)\n",
    "    cm        = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    list_results   = [precision, recall, f1]\n",
    "    list_cm = [cm]\n",
    "    e11_results.append(list_results)\n",
    "    e11_results_cm.append(list_cm)\n",
    "    \n",
    "fin = time.time()\n",
    "tiempo_ejecucion.append(fin - inicio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "a080755d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-21T02:53:31.313466Z",
     "start_time": "2022-11-21T02:53:31.298469Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRECISION</th>\n",
       "      <th>RECALL</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ensemble GaussianNB + Lgr + Calibrated Classifier (Final GaussianNB)</th>\n",
       "      <td>0.508529</td>\n",
       "      <td>0.580394</td>\n",
       "      <td>0.542056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    PRECISION    RECALL  \\\n",
       "Ensemble GaussianNB + Lgr + Calibrated Classifi...   0.508529  0.580394   \n",
       "\n",
       "                                                          F1  \n",
       "Ensemble GaussianNB + Lgr + Calibrated Classifi...  0.542056  "
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filas    = ['Ensemble GaussianNB + Lgr + Calibrated Classifier (Final GaussianNB)']\n",
    "columnas = [\"PRECISION\", \"RECALL\", \"F1\"]\n",
    "resultados = pd.DataFrame([gmean(e11_results)], columns=columnas, index=filas)\n",
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "id": "ce9e7f2a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-21T02:53:31.345536Z",
     "start_time": "2022-11-21T02:53:31.315468Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRECISION</th>\n",
       "      <th>RECALL</th>\n",
       "      <th>F1</th>\n",
       "      <th>TIEMPO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ensemble GaussianNB + Lgr + Calibrated Classifier (Final GaussianNB)</th>\n",
       "      <td>0.508529</td>\n",
       "      <td>0.580394</td>\n",
       "      <td>0.542056</td>\n",
       "      <td>4851.522139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    PRECISION    RECALL  \\\n",
       "Ensemble GaussianNB + Lgr + Calibrated Classifi...   0.508529  0.580394   \n",
       "\n",
       "                                                          F1       TIEMPO  \n",
       "Ensemble GaussianNB + Lgr + Calibrated Classifi...  0.542056  4851.522139  "
      ]
     },
     "execution_count": 476,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados['TIEMPO']= tiempo_ejecucion\n",
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "ddd6953b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-21T02:59:46.226009Z",
     "start_time": "2022-11-21T02:59:46.217979Z"
    }
   },
   "outputs": [],
   "source": [
    "resultados.to_pickle(\"resultados_e11.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "9e0d08c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-21T02:59:47.014769Z",
     "start_time": "2022-11-21T02:59:46.998770Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[16862.43371971,  1126.71400253],\n",
       "        [  842.77999381,  1166.47641845]]])"
      ]
     },
     "execution_count": 478,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados_cm= gmean(e11_results_cm)\n",
    "resultados_cm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "ee043557",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-21T02:59:47.784021Z",
     "start_time": "2022-11-21T02:59:47.767954Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('resultados_e11_cm.pkl','wb') as f:\n",
    "    pickle.dump(resultados_cm, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c1f990",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac1b4fe",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82aa06da",
   "metadata": {},
   "source": [
    "<font size='5' style=\"color:orange\">  <b> GaussianNB + Linear Discriminant Analysis (Final GaussianNB)</b> </font>\n",
    "<a name=\"ensemble_12\"></a>\n",
    "\n",
    "[[ Back to Top ]](#content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0de7b2c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T21:46:05.350590Z",
     "start_time": "2022-11-26T21:46:05.335583Z"
    }
   },
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "gnb_final = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e281f0cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T21:46:05.366583Z",
     "start_time": "2022-11-26T21:46:05.351583Z"
    }
   },
   "outputs": [],
   "source": [
    "ensemble_12 =  StackingClassifier (estimators = [ ('gnb',gnb), ('lda',lda)], final_estimator = gnb_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "00b77c3d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T21:50:22.856320Z",
     "start_time": "2022-11-26T21:46:05.367583Z"
    }
   },
   "outputs": [],
   "source": [
    "e12_results    = []\n",
    "e12_results_cm = []\n",
    "tiempo_ejecucion = []\n",
    "inicio = time.time()\n",
    "\n",
    "for train_index, test_index in skf.split(X,y):\n",
    "    \n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    ensemble_12.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = ensemble_12.predict(X_test)\n",
    "    \n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall    = recall_score(y_test, y_pred)\n",
    "    f1        = f1_score(y_test, y_pred)\n",
    "    cm        = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    list_results   = [precision, recall, f1]\n",
    "    list_cm = [cm]\n",
    "    e12_results.append(list_results)\n",
    "    e12_results_cm.append(list_cm)\n",
    "    \n",
    "fin = time.time()\n",
    "tiempo_ejecucion.append(fin - inicio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "af2dda03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T21:50:22.871777Z",
     "start_time": "2022-11-26T21:50:22.857321Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRECISION</th>\n",
       "      <th>RECALL</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ensemble GaussianNB + Linear Discriminant Analysis + Final GaussianNB</th>\n",
       "      <td>0.540601</td>\n",
       "      <td>0.531153</td>\n",
       "      <td>0.535813</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    PRECISION    RECALL  \\\n",
       "Ensemble GaussianNB + Linear Discriminant Analy...   0.540601  0.531153   \n",
       "\n",
       "                                                          F1  \n",
       "Ensemble GaussianNB + Linear Discriminant Analy...  0.535813  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filas    = ['Ensemble GaussianNB + Linear Discriminant Analysis + Final GaussianNB']\n",
    "columnas = [\"PRECISION\", \"RECALL\", \"F1\"]\n",
    "resultados = pd.DataFrame([gmean(e12_results)], columns=columnas, index=filas)\n",
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a674119f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T21:50:22.902749Z",
     "start_time": "2022-11-26T21:50:22.873748Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRECISION</th>\n",
       "      <th>RECALL</th>\n",
       "      <th>F1</th>\n",
       "      <th>TIEMPO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ensemble GaussianNB + Linear Discriminant Analysis + Final GaussianNB</th>\n",
       "      <td>0.540601</td>\n",
       "      <td>0.531153</td>\n",
       "      <td>0.535813</td>\n",
       "      <td>257.475737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    PRECISION    RECALL  \\\n",
       "Ensemble GaussianNB + Linear Discriminant Analy...   0.540601  0.531153   \n",
       "\n",
       "                                                          F1      TIEMPO  \n",
       "Ensemble GaussianNB + Linear Discriminant Analy...  0.535813  257.475737  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados['TIEMPO']= tiempo_ejecucion\n",
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "84bb125f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T21:50:22.918748Z",
     "start_time": "2022-11-26T21:50:22.903748Z"
    }
   },
   "outputs": [],
   "source": [
    "resultados.to_pickle(\"resultados_e12.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8fc93ca2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T21:50:22.934748Z",
     "start_time": "2022-11-26T21:50:22.919748Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[17082.8674622 ,   906.6817171 ],\n",
       "        [  941.879153  ,  1067.51205715]]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados_cm= gmean(e12_results_cm)\n",
    "resultados_cm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "bc767234",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T21:50:22.950748Z",
     "start_time": "2022-11-26T21:50:22.935748Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('resultados_e12_cm.pkl','wb') as f:\n",
    "    pickle.dump(resultados_cm, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e96893",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a6cec9",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae10718c",
   "metadata": {},
   "source": [
    "<font size='5' style=\"color:orange\">  <b> GaussianNB + Logistic Regression + Linear Discriminant Analysis (Final GNB)</b> </font>\n",
    "<a name=\"ensemble_13\"></a>\n",
    "\n",
    "[[ Back to Top ]](#content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "bceacc0c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T22:27:18.320042Z",
     "start_time": "2022-11-26T22:27:18.313972Z"
    }
   },
   "outputs": [],
   "source": [
    "lda = LinearDiscriminantAnalysis()\n",
    "lgr = LogisticRegression (max_iter = 7000)\n",
    "gnb = GaussianNB()\n",
    "gnb2 = GaussianNB()\n",
    "gnb3 = GaussianNB()\n",
    "gnb4 = GaussianNB()\n",
    "gnb5 = GaussianNB()\n",
    "gnb6 = GaussianNB()\n",
    "gnb7 = GaussianNB()\n",
    "gnb8 = GaussianNB()\n",
    "gnb9 = GaussianNB()\n",
    "gnb10 = GaussianNB()\n",
    "gnb11 = GaussianNB()\n",
    "gnb12 = GaussianNB()\n",
    "gnb_final = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6621b3a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T22:27:34.224151Z",
     "start_time": "2022-11-26T22:27:34.210022Z"
    }
   },
   "outputs": [],
   "source": [
    "ensemble_13 =  StackingClassifier (estimators = [ ('gnb',gnb), ('gnb2',gnb2), ('gnb3',gnb3),\n",
    "                                               ('gnb4',gnb4), ('gnb5',gnb5), ('gnb6',gnb6),\n",
    "                                               ('gnb7',gnb7), ('gnb8',gnb8), ('gnb9',gnb9), \n",
    "                                               ('gnb10',gnb10), ('gnb11',gnb11), ('gnb12',gnb12),\n",
    "                                               ('lda',lda), ('lgr',lgr)], final_estimator = gnb_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7b074512",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T23:59:26.623772Z",
     "start_time": "2022-11-26T22:27:41.295046Z"
    }
   },
   "outputs": [],
   "source": [
    "e13_results    = []\n",
    "e13_results_cm = []\n",
    "tiempo_ejecucion = []\n",
    "inicio = time.time()\n",
    "\n",
    "for train_index, test_index in skf.split(X,y):\n",
    "    \n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    ensemble_13.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = ensemble_13.predict(X_test)\n",
    "    \n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall    = recall_score(y_test, y_pred)\n",
    "    f1        = f1_score(y_test, y_pred)\n",
    "    cm        = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    list_results   = [precision, recall, f1]\n",
    "    list_cm = [cm]\n",
    "    e13_results.append(list_results)\n",
    "    e13_results_cm.append(list_cm)\n",
    "    \n",
    "fin = time.time()\n",
    "tiempo_ejecucion.append(fin - inicio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "40a4c337",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T23:59:26.655503Z",
     "start_time": "2022-11-26T23:59:26.628770Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRECISION</th>\n",
       "      <th>RECALL</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ensemble GaussianNB + Logistic Regression + Linear Discriminant Analysis + Final GaussianNB</th>\n",
       "      <td>0.501568</td>\n",
       "      <td>0.599313</td>\n",
       "      <td>0.546071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    PRECISION    RECALL  \\\n",
       "Ensemble GaussianNB + Logistic Regression + Lin...   0.501568  0.599313   \n",
       "\n",
       "                                                          F1  \n",
       "Ensemble GaussianNB + Logistic Regression + Lin...  0.546071  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filas    = ['Ensemble GaussianNB + Logistic Regression + Linear Discriminant Analysis + Final GaussianNB']\n",
    "columnas = [\"PRECISION\", \"RECALL\", \"F1\"]\n",
    "resultados = pd.DataFrame([gmean(e13_results)], columns=columnas, index=filas)\n",
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ec836003",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T23:59:26.687505Z",
     "start_time": "2022-11-26T23:59:26.657428Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRECISION</th>\n",
       "      <th>RECALL</th>\n",
       "      <th>F1</th>\n",
       "      <th>TIEMPO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ensemble GaussianNB + Logistic Regression + Linear Discriminant Analysis + Final GaussianNB</th>\n",
       "      <td>0.501568</td>\n",
       "      <td>0.599313</td>\n",
       "      <td>0.546071</td>\n",
       "      <td>5505.319759</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    PRECISION    RECALL  \\\n",
       "Ensemble GaussianNB + Logistic Regression + Lin...   0.501568  0.599313   \n",
       "\n",
       "                                                          F1       TIEMPO  \n",
       "Ensemble GaussianNB + Logistic Regression + Lin...  0.546071  5505.319759  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados['TIEMPO']= tiempo_ejecucion\n",
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "22c020d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T23:59:26.703430Z",
     "start_time": "2022-11-26T23:59:26.689429Z"
    }
   },
   "outputs": [],
   "source": [
    "resultados.to_pickle(\"resultados_e13.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5467bf61",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T23:59:26.719428Z",
     "start_time": "2022-11-26T23:59:26.705428Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[16792.84262993,  1196.49645094],\n",
       "        [  804.79155419,  1204.49950936]]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados_cm= gmean(e13_results_cm)\n",
    "resultados_cm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f99578b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T23:59:26.735429Z",
     "start_time": "2022-11-26T23:59:26.720428Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('resultados_e13_cm.pkl','wb') as f:\n",
    "    pickle.dump(resultados_cm, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da84e00e",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75671e48",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c2f40a",
   "metadata": {},
   "source": [
    "<font size='5' style=\"color:orange\">  <b> GaussianNB + XGBoost Classifier + Logistic Regression (Final GaussianNB)</b> </font>\n",
    "<a name=\"ensemble_14\"></a>\n",
    "\n",
    "[[ Back to Top ]](#content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "id": "b4e70c23",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-21T16:49:37.238441Z",
     "start_time": "2022-11-21T16:49:37.196813Z"
    }
   },
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "xgb = XGBClassifier()\n",
    "lgr = LogisticRegression(max_iter = 7000)\n",
    "gnb_final = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "id": "2808e3de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-21T16:49:39.136856Z",
     "start_time": "2022-11-21T16:49:39.113748Z"
    }
   },
   "outputs": [],
   "source": [
    "ensemble_14 =  StackingClassifier (estimators = [ ('gnb',gnb), ('xgb',xgb), ('lgr',lgr)], final_estimator = gnb_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "id": "7bec9e81",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-21T20:07:52.199521Z",
     "start_time": "2022-11-21T16:50:14.497050Z"
    }
   },
   "outputs": [],
   "source": [
    "e14_results    = []\n",
    "e14_results_cm = []\n",
    "tiempo_ejecucion = []\n",
    "inicio = time.time()\n",
    "\n",
    "for train_index, test_index in skf.split(X,y):\n",
    "    \n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    ensemble_14.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = ensemble_14.predict(X_test)\n",
    "    \n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall    = recall_score(y_test, y_pred)\n",
    "    f1        = f1_score(y_test, y_pred)\n",
    "    cm        = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    list_results   = [precision, recall, f1]\n",
    "    list_cm = [cm]\n",
    "    e14_results.append(list_results)\n",
    "    e14_results_cm.append(list_cm)\n",
    "    \n",
    "fin = time.time()\n",
    "tiempo_ejecucion.append(fin - inicio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "id": "638d2d10",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-21T20:07:52.214703Z",
     "start_time": "2022-11-21T20:07:52.202838Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRECISION</th>\n",
       "      <th>RECALL</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ensemble GaussianNB + Lgr + XGBoost Classifier (Final GaussianNB)</th>\n",
       "      <td>0.4857</td>\n",
       "      <td>0.6041</td>\n",
       "      <td>0.538443</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    PRECISION  RECALL  \\\n",
       "Ensemble GaussianNB + Lgr + XGBoost Classifier ...     0.4857  0.6041   \n",
       "\n",
       "                                                          F1  \n",
       "Ensemble GaussianNB + Lgr + XGBoost Classifier ...  0.538443  "
      ]
     },
     "execution_count": 500,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filas    = ['Ensemble GaussianNB + Lgr + XGBoost Classifier (Final GaussianNB)']\n",
    "columnas = [\"PRECISION\", \"RECALL\", \"F1\"]\n",
    "resultados = pd.DataFrame([gmean(e14_results)], columns=columnas, index=filas)\n",
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "id": "e9c53192",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-21T20:07:52.245697Z",
     "start_time": "2022-11-21T20:07:52.215696Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRECISION</th>\n",
       "      <th>RECALL</th>\n",
       "      <th>F1</th>\n",
       "      <th>TIEMPO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ensemble GaussianNB + Lgr + XGBoost Classifier (Final GaussianNB)</th>\n",
       "      <td>0.4857</td>\n",
       "      <td>0.6041</td>\n",
       "      <td>0.538443</td>\n",
       "      <td>11857.672548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    PRECISION  RECALL  \\\n",
       "Ensemble GaussianNB + Lgr + XGBoost Classifier ...     0.4857  0.6041   \n",
       "\n",
       "                                                          F1        TIEMPO  \n",
       "Ensemble GaussianNB + Lgr + XGBoost Classifier ...  0.538443  11857.672548  "
      ]
     },
     "execution_count": 501,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados['TIEMPO']= tiempo_ejecucion\n",
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "id": "c607a8e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-21T20:07:52.261696Z",
     "start_time": "2022-11-21T20:07:52.247696Z"
    }
   },
   "outputs": [],
   "source": [
    "resultados.to_pickle(\"resultados_e14.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "id": "56fe700f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-21T20:07:52.276696Z",
     "start_time": "2022-11-21T20:07:52.263696Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[16704.35192467,  1285.17677775],\n",
       "        [  794.96074445,  1214.11998067]]])"
      ]
     },
     "execution_count": 503,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados_cm= gmean(e14_results_cm)\n",
    "resultados_cm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "id": "309d6f90",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-21T20:07:52.292697Z",
     "start_time": "2022-11-21T20:07:52.278696Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('resultados_e14_cm.pkl','wb') as f:\n",
    "    pickle.dump(resultados_cm, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bf20cd",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4490df8",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e989baa",
   "metadata": {},
   "source": [
    "<font size='5' style=\"color:orange\">  <b> GaussianNB X 6 + Linear Discriminant Analysis (Final GaussianNB) </b> </font>\n",
    "<a name=\"ensemble_15\"></a>\n",
    "\n",
    "[[ Back to Top ]](#content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b74d27d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T21:50:22.966754Z",
     "start_time": "2022-11-26T21:50:22.951748Z"
    }
   },
   "outputs": [],
   "source": [
    "lda = LinearDiscriminantAnalysis()\n",
    "gnb = GaussianNB()\n",
    "gnb2 = GaussianNB()\n",
    "gnb3 = GaussianNB()\n",
    "gnb4 = GaussianNB()\n",
    "gnb5 = GaussianNB()\n",
    "gnb6 = GaussianNB()\n",
    "gnb_final = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0800593f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T21:50:22.982748Z",
     "start_time": "2022-11-26T21:50:22.967748Z"
    }
   },
   "outputs": [],
   "source": [
    "ensemble_15 =  StackingClassifier (estimators = [ ('lda',lda),('gnb',gnb), ('gnb2',gnb2), ('gnb3',gnb3), \n",
    "                                                 ('gnb4',gnb4), ('gnb5',gnb5), ('gnb6',gnb6)], final_estimator = gnb_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8ed2e607",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T21:58:00.778059Z",
     "start_time": "2022-11-26T21:50:22.984748Z"
    }
   },
   "outputs": [],
   "source": [
    "e15_results    = []\n",
    "e15_results_cm = []\n",
    "tiempo_ejecucion = []\n",
    "inicio = time.time()\n",
    "\n",
    "for train_index, test_index in skf.split(X,y):\n",
    "    \n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    ensemble_15.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = ensemble_15.predict(X_test)\n",
    "    \n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall    = recall_score(y_test, y_pred)\n",
    "    f1        = f1_score(y_test, y_pred)\n",
    "    cm        = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    list_results   = [precision, recall, f1]\n",
    "    list_cm = [cm]\n",
    "    e15_results.append(list_results)\n",
    "    e15_results_cm.append(list_cm)\n",
    "    \n",
    "fin = time.time()\n",
    "tiempo_ejecucion.append(fin - inicio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "36f7e3b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T21:58:00.793928Z",
     "start_time": "2022-11-26T21:58:00.779067Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRECISION</th>\n",
       "      <th>RECALL</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ensemble GaussianNB X 6 + Linear Discriminant Analysis + Final GaussianNB</th>\n",
       "      <td>0.511693</td>\n",
       "      <td>0.587918</td>\n",
       "      <td>0.547133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    PRECISION    RECALL  \\\n",
       "Ensemble GaussianNB X 6 + Linear Discriminant A...   0.511693  0.587918   \n",
       "\n",
       "                                                          F1  \n",
       "Ensemble GaussianNB X 6 + Linear Discriminant A...  0.547133  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filas    = ['Ensemble GaussianNB X 6 + Linear Discriminant Analysis + Final GaussianNB']\n",
    "columnas = [\"PRECISION\", \"RECALL\", \"F1\"]\n",
    "resultados = pd.DataFrame([gmean(e15_results)], columns=columnas, index=filas)\n",
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ab3ef7ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T21:58:00.826010Z",
     "start_time": "2022-11-26T21:58:00.794929Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRECISION</th>\n",
       "      <th>RECALL</th>\n",
       "      <th>F1</th>\n",
       "      <th>TIEMPO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ensemble GaussianNB X 6 + Linear Discriminant Analysis + Final GaussianNB</th>\n",
       "      <td>0.511693</td>\n",
       "      <td>0.587918</td>\n",
       "      <td>0.547133</td>\n",
       "      <td>457.78031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    PRECISION    RECALL  \\\n",
       "Ensemble GaussianNB X 6 + Linear Discriminant A...   0.511693  0.587918   \n",
       "\n",
       "                                                          F1     TIEMPO  \n",
       "Ensemble GaussianNB X 6 + Linear Discriminant A...  0.547133  457.78031  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados['TIEMPO']= tiempo_ejecucion\n",
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "070d5e9a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T21:58:00.841927Z",
     "start_time": "2022-11-26T21:58:00.827927Z"
    }
   },
   "outputs": [],
   "source": [
    "resultados.to_pickle(\"resultados_e15.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "eb71b345",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T21:58:00.857964Z",
     "start_time": "2022-11-26T21:58:00.843929Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[16862.24544918,  1127.08278639],\n",
       "        [  827.70149129,  1181.59656847]]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados_cm= gmean(e15_results_cm)\n",
    "resultados_cm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6ef1cd54",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T21:58:00.873998Z",
     "start_time": "2022-11-26T21:58:00.858928Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('resultados_e15_cm.pkl','wb') as f:\n",
    "    pickle.dump(resultados_cm, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088c01cf",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e6631c",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7840d5",
   "metadata": {},
   "source": [
    "<font size='5' style=\"color:orange\">  <b> Model Stacking - Summary </b> </font>\n",
    "<a name=\"summary_stacking\"></a>\n",
    "\n",
    "[[ Back to Top ]](#content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0300e2b3",
   "metadata": {},
   "source": [
    "Se realiza un gráfico que permita comparar el recall y el tiempo de ejecución de cada uno de los modelos con los que se realizó Stacking. A su vez, se incluirán aquellos modelos simples donde se ha obtenido los mejores recall, a un tiempo de ejecución acorde."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4b5e46f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-27T00:04:38.147054Z",
     "start_time": "2022-11-27T00:04:38.074170Z"
    }
   },
   "outputs": [],
   "source": [
    "# Stacking\n",
    "resultados_e2 = pd.read_pickle('resultados_e2.pkl')\n",
    "resultados_e3 = pd.read_pickle('resultados_e3.pkl')\n",
    "resultados_e4 = pd.read_pickle('resultados_e4.pkl')\n",
    "resultados_e5 = pd.read_pickle('resultados_e5.pkl')\n",
    "resultados_e6 = pd.read_pickle('resultados_e6.pkl')\n",
    "resultados_e7 = pd.read_pickle('resultados_e7.pkl')\n",
    "resultados_e8 = pd.read_pickle('resultados_e8.pkl')\n",
    "resultados_e9 = pd.read_pickle('resultados_e9.pkl')\n",
    "resultados_e10 = pd.read_pickle('resultados_e10.pkl')\n",
    "resultados_e11 = pd.read_pickle('resultados_e11.pkl')\n",
    "resultados_e12 = pd.read_pickle('resultados_e12.pkl')\n",
    "resultados_e13 = pd.read_pickle('resultados_e13.pkl')\n",
    "resultados_e14 = pd.read_pickle('resultados_e14.pkl')\n",
    "resultados_e15 = pd.read_pickle('resultados_e15.pkl')\n",
    "\n",
    "# Models with default parameters\n",
    "resultados_lgr_full = pd.read_pickle('resultados_lgr_full.pkl')\n",
    "resultados_gnb_full = pd.read_pickle(\"resultados_gnb_full.pkl\")\n",
    "resultados_cb_full = pd.read_pickle('resultados_cb_full2.pkl')\n",
    "resultados_mlpc_full = pd.read_pickle('resultados_mlpc_full.pkl')\n",
    "resultados_lda_full = pd.read_pickle('resultados_lda_full.pkl')\n",
    "resultados_cccv_full = pd.read_pickle('resultados_cccv_full.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c3d9b54d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-27T00:04:39.355416Z",
     "start_time": "2022-11-27T00:04:39.335897Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRECISION</th>\n",
       "      <th>RECALL</th>\n",
       "      <th>F1</th>\n",
       "      <th>TIEMPO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ensemble GaussianNB x 3 + Final GassianNB</th>\n",
       "      <td>0.541327</td>\n",
       "      <td>0.561671</td>\n",
       "      <td>0.551273</td>\n",
       "      <td>137.101123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ensemble GaussianNB x 6 + Final GaussianNB</th>\n",
       "      <td>0.519980</td>\n",
       "      <td>0.583310</td>\n",
       "      <td>0.549795</td>\n",
       "      <td>276.241724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ensemble GaussianNB x 12 + Final GaussianNB</th>\n",
       "      <td>0.508631</td>\n",
       "      <td>0.596489</td>\n",
       "      <td>0.549036</td>\n",
       "      <td>534.493685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ensemble GaussianNB x 24 + Final GaussianNB</th>\n",
       "      <td>0.502216</td>\n",
       "      <td>0.602960</td>\n",
       "      <td>0.547965</td>\n",
       "      <td>1013.523686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ensemble GaussianNB + Logistic Regression + Final GaussianNB</th>\n",
       "      <td>0.541653</td>\n",
       "      <td>0.530205</td>\n",
       "      <td>0.535842</td>\n",
       "      <td>4838.985724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ensemble GaussianNB + Logistic Regression + Final Logistic Regression</th>\n",
       "      <td>0.704308</td>\n",
       "      <td>0.374719</td>\n",
       "      <td>0.489145</td>\n",
       "      <td>4804.446089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ensemble Lgr + Catboost (Final Catboost)</th>\n",
       "      <td>0.714156</td>\n",
       "      <td>0.392728</td>\n",
       "      <td>0.506712</td>\n",
       "      <td>11731.662214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ensemble Lgr + Catboost + GaussianNB (Final GaussianNB)</th>\n",
       "      <td>0.497075</td>\n",
       "      <td>0.612930</td>\n",
       "      <td>0.548931</td>\n",
       "      <td>8581.066510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ensemble Opt Lgr + Catboost + GaussianNB + KNC (Final GaussianNB)</th>\n",
       "      <td>0.477716</td>\n",
       "      <td>0.608762</td>\n",
       "      <td>0.535311</td>\n",
       "      <td>18614.442411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ensemble GaussianNB + Lgr + Calibrated Classifier (Final GaussianNB)</th>\n",
       "      <td>0.508529</td>\n",
       "      <td>0.580394</td>\n",
       "      <td>0.542056</td>\n",
       "      <td>4851.522139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ensemble GaussianNB + Linear Discriminant Analysis + Final GaussianNB</th>\n",
       "      <td>0.540601</td>\n",
       "      <td>0.531153</td>\n",
       "      <td>0.535813</td>\n",
       "      <td>257.475737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ensemble GaussianNB + Logistic Regression + Linear Discriminant Analysis + Final GaussianNB</th>\n",
       "      <td>0.501568</td>\n",
       "      <td>0.599313</td>\n",
       "      <td>0.546071</td>\n",
       "      <td>5505.319759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ensemble GaussianNB + Lgr + XGBoost Classifier (Final GaussianNB)</th>\n",
       "      <td>0.485700</td>\n",
       "      <td>0.604100</td>\n",
       "      <td>0.538443</td>\n",
       "      <td>11857.672548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ensemble GaussianNB X 6 + Linear Discriminant Analysis + Final GaussianNB</th>\n",
       "      <td>0.511693</td>\n",
       "      <td>0.587918</td>\n",
       "      <td>0.547133</td>\n",
       "      <td>457.780310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression_full</th>\n",
       "      <td>0.685480</td>\n",
       "      <td>0.269483</td>\n",
       "      <td>0.386856</td>\n",
       "      <td>1081.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianNB_full</th>\n",
       "      <td>0.647487</td>\n",
       "      <td>0.403787</td>\n",
       "      <td>0.497367</td>\n",
       "      <td>6.070000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CatboostClassifier_full</th>\n",
       "      <td>0.767672</td>\n",
       "      <td>0.336274</td>\n",
       "      <td>0.467646</td>\n",
       "      <td>631.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLPClassifier</th>\n",
       "      <td>0.560490</td>\n",
       "      <td>0.296374</td>\n",
       "      <td>0.385380</td>\n",
       "      <td>2115.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearDiscriminantAnalysis_full</th>\n",
       "      <td>0.679732</td>\n",
       "      <td>0.278250</td>\n",
       "      <td>0.394843</td>\n",
       "      <td>46.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CalibratedClassifierCV_GNB_full</th>\n",
       "      <td>0.703706</td>\n",
       "      <td>0.374022</td>\n",
       "      <td>0.488408</td>\n",
       "      <td>23.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    PRECISION    RECALL  \\\n",
       "Ensemble GaussianNB x 3 + Final GassianNB            0.541327  0.561671   \n",
       "Ensemble GaussianNB x 6 + Final GaussianNB           0.519980  0.583310   \n",
       "Ensemble GaussianNB x 12 + Final GaussianNB          0.508631  0.596489   \n",
       "Ensemble GaussianNB x 24 + Final GaussianNB          0.502216  0.602960   \n",
       "Ensemble GaussianNB + Logistic Regression + Fin...   0.541653  0.530205   \n",
       "Ensemble GaussianNB + Logistic Regression + Fin...   0.704308  0.374719   \n",
       "Ensemble Lgr + Catboost (Final Catboost)             0.714156  0.392728   \n",
       "Ensemble Lgr + Catboost + GaussianNB (Final Gau...   0.497075  0.612930   \n",
       "Ensemble Opt Lgr + Catboost + GaussianNB + KNC ...   0.477716  0.608762   \n",
       "Ensemble GaussianNB + Lgr + Calibrated Classifi...   0.508529  0.580394   \n",
       "Ensemble GaussianNB + Linear Discriminant Analy...   0.540601  0.531153   \n",
       "Ensemble GaussianNB + Logistic Regression + Lin...   0.501568  0.599313   \n",
       "Ensemble GaussianNB + Lgr + XGBoost Classifier ...   0.485700  0.604100   \n",
       "Ensemble GaussianNB X 6 + Linear Discriminant A...   0.511693  0.587918   \n",
       "LogisticRegression_full                              0.685480  0.269483   \n",
       "GaussianNB_full                                      0.647487  0.403787   \n",
       "CatboostClassifier_full                              0.767672  0.336274   \n",
       "MLPClassifier                                        0.560490  0.296374   \n",
       "LinearDiscriminantAnalysis_full                      0.679732  0.278250   \n",
       "CalibratedClassifierCV_GNB_full                      0.703706  0.374022   \n",
       "\n",
       "                                                          F1        TIEMPO  \n",
       "Ensemble GaussianNB x 3 + Final GassianNB           0.551273    137.101123  \n",
       "Ensemble GaussianNB x 6 + Final GaussianNB          0.549795    276.241724  \n",
       "Ensemble GaussianNB x 12 + Final GaussianNB         0.549036    534.493685  \n",
       "Ensemble GaussianNB x 24 + Final GaussianNB         0.547965   1013.523686  \n",
       "Ensemble GaussianNB + Logistic Regression + Fin...  0.535842   4838.985724  \n",
       "Ensemble GaussianNB + Logistic Regression + Fin...  0.489145   4804.446089  \n",
       "Ensemble Lgr + Catboost (Final Catboost)            0.506712  11731.662214  \n",
       "Ensemble Lgr + Catboost + GaussianNB (Final Gau...  0.548931   8581.066510  \n",
       "Ensemble Opt Lgr + Catboost + GaussianNB + KNC ...  0.535311  18614.442411  \n",
       "Ensemble GaussianNB + Lgr + Calibrated Classifi...  0.542056   4851.522139  \n",
       "Ensemble GaussianNB + Linear Discriminant Analy...  0.535813    257.475737  \n",
       "Ensemble GaussianNB + Logistic Regression + Lin...  0.546071   5505.319759  \n",
       "Ensemble GaussianNB + Lgr + XGBoost Classifier ...  0.538443  11857.672548  \n",
       "Ensemble GaussianNB X 6 + Linear Discriminant A...  0.547133    457.780310  \n",
       "LogisticRegression_full                             0.386856   1081.000000  \n",
       "GaussianNB_full                                     0.497367      6.070000  \n",
       "CatboostClassifier_full                             0.467646    631.000000  \n",
       "MLPClassifier                                       0.385380   2115.000000  \n",
       "LinearDiscriminantAnalysis_full                     0.394843     46.000000  \n",
       "CalibratedClassifierCV_GNB_full                     0.488408     23.000000  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_resultados_finales = pd.concat([resultados_e2,resultados_e3,resultados_e4,resultados_e5,\n",
    "                        resultados_e6,resultados_e7,resultados_e8, resultados_e9, resultados_e10,\n",
    "                         resultados_e11,resultados_e12, resultados_e13, resultados_e14, resultados_e15,\n",
    "                        resultados_lgr_full,resultados_gnb_full, resultados_cb_full, resultados_mlpc_full, resultados_lda_full,resultados_cccv_full ])\n",
    "df_resultados_finales "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "id": "23430696",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-25T22:29:58.951083Z",
     "start_time": "2022-11-25T22:29:58.932093Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRECISION</th>\n",
       "      <th>RECALL</th>\n",
       "      <th>F1</th>\n",
       "      <th>TIEMPO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ensemble Gaussian x4</th>\n",
       "      <td>0.474078</td>\n",
       "      <td>0.599564</td>\n",
       "      <td>0.529461</td>\n",
       "      <td>115.862217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ensemble Gaussian x7</th>\n",
       "      <td>0.459896</td>\n",
       "      <td>0.614447</td>\n",
       "      <td>0.526031</td>\n",
       "      <td>203.384345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ensemble Gaussian x13</th>\n",
       "      <td>0.451242</td>\n",
       "      <td>0.623919</td>\n",
       "      <td>0.523695</td>\n",
       "      <td>372.654705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ensemble Gaussian x25</th>\n",
       "      <td>0.446858</td>\n",
       "      <td>0.629791</td>\n",
       "      <td>0.522764</td>\n",
       "      <td>702.263942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ensemble Gaussian + Lgr (final GNB)</th>\n",
       "      <td>0.488541</td>\n",
       "      <td>0.582881</td>\n",
       "      <td>0.531536</td>\n",
       "      <td>4961.193512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ensemble Lgr + Gaussian (Final Lgr)</th>\n",
       "      <td>0.653212</td>\n",
       "      <td>0.397763</td>\n",
       "      <td>0.494418</td>\n",
       "      <td>9378.001774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ensemble Lgr + Catboost (Final Catboost)</th>\n",
       "      <td>0.714156</td>\n",
       "      <td>0.392728</td>\n",
       "      <td>0.506712</td>\n",
       "      <td>11731.662214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ensemble Lgr + Catboost + GaussianNB (Final GaussianNB)</th>\n",
       "      <td>0.497075</td>\n",
       "      <td>0.612930</td>\n",
       "      <td>0.548931</td>\n",
       "      <td>8581.066510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ensemble Opt Lgr + Catboost + GaussianNB + KNC (Final GaussianNB)</th>\n",
       "      <td>0.477716</td>\n",
       "      <td>0.608762</td>\n",
       "      <td>0.535311</td>\n",
       "      <td>18614.442411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ensemble GaussianNB + Lgr + Calibrated Classifier (Final GaussianNB)</th>\n",
       "      <td>0.508529</td>\n",
       "      <td>0.580394</td>\n",
       "      <td>0.542056</td>\n",
       "      <td>4851.522139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ensemble GaussianNB + Linear Discriminant Analysis (Final GaussianNB)</th>\n",
       "      <td>0.488824</td>\n",
       "      <td>0.584673</td>\n",
       "      <td>0.532446</td>\n",
       "      <td>278.656879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ensemble GaussianNB + Lgr + Linear Discriminant Analysis (Final GaussianNB)</th>\n",
       "      <td>0.480258</td>\n",
       "      <td>0.590446</td>\n",
       "      <td>0.529667</td>\n",
       "      <td>4997.701715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ensemble GaussianNB + Lgr + XGBoost Classifier (Final GaussianNB)</th>\n",
       "      <td>0.485700</td>\n",
       "      <td>0.604100</td>\n",
       "      <td>0.538443</td>\n",
       "      <td>11857.672548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ensemble GaussianNB X 6 + Linear Discriminant Analysis (Final GaussianNB)</th>\n",
       "      <td>0.460803</td>\n",
       "      <td>0.618600</td>\n",
       "      <td>0.528150</td>\n",
       "      <td>469.583959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression_full</th>\n",
       "      <td>0.685480</td>\n",
       "      <td>0.269483</td>\n",
       "      <td>0.386856</td>\n",
       "      <td>1081.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianNB_full</th>\n",
       "      <td>0.647487</td>\n",
       "      <td>0.403787</td>\n",
       "      <td>0.497367</td>\n",
       "      <td>6.070000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CatboostClassifier_full</th>\n",
       "      <td>0.767672</td>\n",
       "      <td>0.336274</td>\n",
       "      <td>0.467646</td>\n",
       "      <td>631.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLPClassifier</th>\n",
       "      <td>0.560490</td>\n",
       "      <td>0.296374</td>\n",
       "      <td>0.385380</td>\n",
       "      <td>2115.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearDiscriminantAnalysis_full</th>\n",
       "      <td>0.679732</td>\n",
       "      <td>0.278250</td>\n",
       "      <td>0.394843</td>\n",
       "      <td>46.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CalibratedClassifierCV_GNB_full</th>\n",
       "      <td>0.703706</td>\n",
       "      <td>0.374022</td>\n",
       "      <td>0.488408</td>\n",
       "      <td>23.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    PRECISION    RECALL  \\\n",
       "Ensemble Gaussian x4                                 0.474078  0.599564   \n",
       "Ensemble Gaussian x7                                 0.459896  0.614447   \n",
       "Ensemble Gaussian x13                                0.451242  0.623919   \n",
       "Ensemble Gaussian x25                                0.446858  0.629791   \n",
       "Ensemble Gaussian + Lgr (final GNB)                  0.488541  0.582881   \n",
       "Ensemble Lgr + Gaussian (Final Lgr)                  0.653212  0.397763   \n",
       "Ensemble Lgr + Catboost (Final Catboost)             0.714156  0.392728   \n",
       "Ensemble Lgr + Catboost + GaussianNB (Final Gau...   0.497075  0.612930   \n",
       "Ensemble Opt Lgr + Catboost + GaussianNB + KNC ...   0.477716  0.608762   \n",
       "Ensemble GaussianNB + Lgr + Calibrated Classifi...   0.508529  0.580394   \n",
       "Ensemble GaussianNB + Linear Discriminant Analy...   0.488824  0.584673   \n",
       "Ensemble GaussianNB + Lgr + Linear Discriminant...   0.480258  0.590446   \n",
       "Ensemble GaussianNB + Lgr + XGBoost Classifier ...   0.485700  0.604100   \n",
       "Ensemble GaussianNB X 6 + Linear Discriminant A...   0.460803  0.618600   \n",
       "LogisticRegression_full                              0.685480  0.269483   \n",
       "GaussianNB_full                                      0.647487  0.403787   \n",
       "CatboostClassifier_full                              0.767672  0.336274   \n",
       "MLPClassifier                                        0.560490  0.296374   \n",
       "LinearDiscriminantAnalysis_full                      0.679732  0.278250   \n",
       "CalibratedClassifierCV_GNB_full                      0.703706  0.374022   \n",
       "\n",
       "                                                          F1        TIEMPO  \n",
       "Ensemble Gaussian x4                                0.529461    115.862217  \n",
       "Ensemble Gaussian x7                                0.526031    203.384345  \n",
       "Ensemble Gaussian x13                               0.523695    372.654705  \n",
       "Ensemble Gaussian x25                               0.522764    702.263942  \n",
       "Ensemble Gaussian + Lgr (final GNB)                 0.531536   4961.193512  \n",
       "Ensemble Lgr + Gaussian (Final Lgr)                 0.494418   9378.001774  \n",
       "Ensemble Lgr + Catboost (Final Catboost)            0.506712  11731.662214  \n",
       "Ensemble Lgr + Catboost + GaussianNB (Final Gau...  0.548931   8581.066510  \n",
       "Ensemble Opt Lgr + Catboost + GaussianNB + KNC ...  0.535311  18614.442411  \n",
       "Ensemble GaussianNB + Lgr + Calibrated Classifi...  0.542056   4851.522139  \n",
       "Ensemble GaussianNB + Linear Discriminant Analy...  0.532446    278.656879  \n",
       "Ensemble GaussianNB + Lgr + Linear Discriminant...  0.529667   4997.701715  \n",
       "Ensemble GaussianNB + Lgr + XGBoost Classifier ...  0.538443  11857.672548  \n",
       "Ensemble GaussianNB X 6 + Linear Discriminant A...  0.528150    469.583959  \n",
       "LogisticRegression_full                             0.386856   1081.000000  \n",
       "GaussianNB_full                                     0.497367      6.070000  \n",
       "CatboostClassifier_full                             0.467646    631.000000  \n",
       "MLPClassifier                                       0.385380   2115.000000  \n",
       "LinearDiscriminantAnalysis_full                     0.394843     46.000000  \n",
       "CalibratedClassifierCV_GNB_full                     0.488408     23.000000  "
      ]
     },
     "execution_count": 643,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_resultados_finales = pd.concat([resultados_e2,resultados_e3,resultados_e4,resultados_e5,\n",
    "                        resultados_e6,resultados_e7,resultados_e8, resultados_e9, resultados_e10,\n",
    "                         resultados_e11,resultados_e12, resultados_e13, resultados_e14, resultados_e15,\n",
    "                        resultados_lgr_full,resultados_gnb_full, resultados_cb_full, resultados_mlpc_full, resultados_lda_full,resultados_cccv_full ])\n",
    "df_resultados_finales "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "id": "fe174919",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-25T22:30:00.453727Z",
     "start_time": "2022-11-25T22:30:00.151474Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (15, 10))\n",
    "ax=sns.scatterplot(data = df_resultados_finales, x = df_resultados_finales['TIEMPO'],y = df_resultados_finales['RECALL'], \n",
    "                hue = df_resultados_finales.index, style = df_resultados_finales.index, palette = 'colorblind', s = 250) \n",
    "plt.xlabel('Time (seconds)', y = -0.8, fontsize = 20)\n",
    "plt.ylabel('Recall', x = -1, fontsize = 20)\n",
    "plt.yticks(fontsize = 12)\n",
    "plt.xticks(fontsize = 12)\n",
    "plt.title('Model Comparison', y = 1.015, fontsize = 30)\n",
    "sns.move_legend(ax, \"upper left\",bbox_to_anchor= (0.25,-0.1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9bbdee28",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-27T00:05:15.982849Z",
     "start_time": "2022-11-27T00:05:15.976723Z"
    }
   },
   "outputs": [],
   "source": [
    "df_resultados_finales.to_pickle(\"df_resultados_finales2.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee886da",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ba36a7",
   "metadata": {},
   "source": [
    "<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
